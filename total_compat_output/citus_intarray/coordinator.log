2023-11-25 00:43:28.194 UTC [3758160] LOG:  00000: number of prepared transactions has not been configured, overriding
2023-11-25 00:43:28.194 UTC [3758160] DETAIL:  max_prepared_transactions is now set to 200
2023-11-25 00:43:28.194 UTC [3758160] LOCATION:  AdjustMaxPreparedTransactions, transaction_management.c:761
2023-11-25 00:43:28.211 UTC [3758160] LOG:  00000: starting PostgreSQL 15.3 on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0, 64-bit
2023-11-25 00:43:28.211 UTC [3758160] LOCATION:  PostmasterMain, postmaster.c:1189
2023-11-25 00:43:28.211 UTC [3758160] LOG:  00000: listening on IPv4 address "127.0.0.1", port 57636
2023-11-25 00:43:28.211 UTC [3758160] LOCATION:  StreamServerPort, pqcomm.c:582
2023-11-25 00:43:28.211 UTC [3758160] LOG:  00000: listening on Unix socket "/tmp/.s.PGSQL.57636"
2023-11-25 00:43:28.211 UTC [3758160] LOCATION:  StreamServerPort, pqcomm.c:577
2023-11-25 00:43:28.212 UTC [3758163] LOG:  00000: database system was shut down at 2023-11-25 00:43:28 UTC
2023-11-25 00:43:28.212 UTC [3758163] LOCATION:  StartupXLOG, xlog.c:4928
2023-11-25 00:43:28.215 UTC [3758160] LOG:  00000: database system is ready to accept connections
2023-11-25 00:43:28.215 UTC [3758160] LOCATION:  reaper, postmaster.c:3117
2023-11-25 00:43:28.969 UTC [3758230] LOG:  00000: starting maintenance daemon on database 16384 user 10
2023-11-25 00:43:28.969 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:43:28.969 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:373
2023-11-25 00:43:28.988 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:43:28.988 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:43:28.988 UTC [3758160] LOG:  00000: parameter "citus.metadata_sync_interval" changed to "3000"
2023-11-25 00:43:28.988 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:43:28.988 UTC [3758160] LOG:  00000: parameter "citus.metadata_sync_retry_interval" changed to "500"
2023-11-25 00:43:28.988 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:43:29.189 UTC [3758264] ERROR:  55000: disabling the first worker node in the metadata is not allowed
2023-11-25 00:43:29.189 UTC [3758264] DETAIL:  Citus uses the first worker node in the metadata for certain internal operations when replicated tables are modified. Synchronous mode ensures that all nodes have the same view of the first worker node, which is used for certain locking operations.
2023-11-25 00:43:29.189 UTC [3758264] HINT:  You can force disabling node, SELECT citus_disable_node('localhost', 57637, synchronous:=true);
2023-11-25 00:43:29.189 UTC [3758264] LOCATION:  citus_disable_node, node_metadata.c:542
2023-11-25 00:43:29.189 UTC [3758264] STATEMENT:  SELECT citus_disable_node('localhost', 57637);
2023-11-25 00:43:29.245 UTC [3758264] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 00:43:29.245 UTC [3758264] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 00:43:29.245 UTC [3758264] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 00:43:29.245 UTC [3758264] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 00:43:29.245 UTC [3758264] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 00:43:29.252 UTC [3758264] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 00:43:29.252 UTC [3758264] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 00:43:29.252 UTC [3758264] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 00:43:29.252 UTC [3758264] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 00:43:29.252 UTC [3758264] STATEMENT:  SELECT citus_remove_node('localhost', 57638);
2023-11-25 00:43:29.252 UTC [3758264] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 00:43:29.252 UTC [3758264] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 00:43:29.252 UTC [3758264] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 00:43:29.252 UTC [3758264] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 00:43:29.252 UTC [3758264] STATEMENT:  SELECT citus_disable_node('localhost', 57638);
2023-11-25 00:43:29.252 UTC [3758264] ERROR:  XX000: node at "localhost.noexist:2345" does not exist
2023-11-25 00:43:29.252 UTC [3758264] LOCATION:  ModifiableWorkerNode, node_metadata.c:732
2023-11-25 00:43:29.252 UTC [3758264] STATEMENT:  SELECT citus_disable_node('localhost.noexist', 2345);
2023-11-25 00:43:29.356 UTC [3758264] ERROR:  42501: permission denied for function master_add_inactive_node
2023-11-25 00:43:29.356 UTC [3758264] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:29.356 UTC [3758264] STATEMENT:  SELECT 1 FROM master_add_inactive_node('localhost', 57638 + 1);
2023-11-25 00:43:29.356 UTC [3758264] ERROR:  42501: permission denied for function master_activate_node
2023-11-25 00:43:29.356 UTC [3758264] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:29.356 UTC [3758264] STATEMENT:  SELECT 1 FROM master_activate_node('localhost', 57638 + 1);
2023-11-25 00:43:29.356 UTC [3758264] ERROR:  42501: permission denied for function citus_disable_node
2023-11-25 00:43:29.356 UTC [3758264] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:29.356 UTC [3758264] STATEMENT:  SELECT 1 FROM citus_disable_node('localhost', 57638 + 1);
2023-11-25 00:43:29.357 UTC [3758264] ERROR:  42501: permission denied for function master_remove_node
2023-11-25 00:43:29.357 UTC [3758264] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:29.357 UTC [3758264] STATEMENT:  SELECT 1 FROM master_remove_node('localhost', 57638 + 1);
2023-11-25 00:43:29.357 UTC [3758264] ERROR:  42501: permission denied for function master_add_node
2023-11-25 00:43:29.357 UTC [3758264] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:29.357 UTC [3758264] STATEMENT:  SELECT 1 FROM master_add_node('localhost', 57638 + 1);
2023-11-25 00:43:29.357 UTC [3758264] ERROR:  42501: permission denied for function master_add_secondary_node
2023-11-25 00:43:29.357 UTC [3758264] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:29.357 UTC [3758264] STATEMENT:  SELECT 1 FROM master_add_secondary_node('localhost', 57638 + 2, 'localhost', 57638);
2023-11-25 00:43:29.357 UTC [3758264] ERROR:  42501: permission denied for function master_update_node
2023-11-25 00:43:29.357 UTC [3758264] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:29.357 UTC [3758264] STATEMENT:  SELECT master_update_node(nodeid, 'localhost', 57638 + 3) FROM pg_dist_node WHERE nodeport = 57638;
2023-11-25 00:43:29.357 UTC [3758264] ERROR:  XX000: operation is not allowed
2023-11-25 00:43:29.357 UTC [3758264] HINT:  Run the command with a superuser.
2023-11-25 00:43:29.357 UTC [3758264] LOCATION:  EnsureSuperUser, metadata_utility.c:2299
2023-11-25 00:43:29.357 UTC [3758264] STATEMENT:  SELECT 1 FROM master_add_node('localhost', 57638);
2023-11-25 00:43:29.409 UTC [3758292] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 00:43:29.409 UTC [3758292] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 00:43:29.409 UTC [3758292] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 00:43:29.409 UTC [3758292] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 00:43:29.409 UTC [3758292] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 00:43:29.426 UTC [3758292] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 00:43:29.426 UTC [3758292] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 00:43:29.426 UTC [3758292] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 00:43:29.426 UTC [3758292] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 00:43:29.426 UTC [3758292] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 00:43:29.442 UTC [3758292] ERROR:  XX000: node group 5 does not have a primary node
2023-11-25 00:43:29.442 UTC [3758292] LOCATION:  LookupNodeForGroup, metadata_cache.c:1189
2023-11-25 00:43:29.442 UTC [3758292] STATEMENT:  SELECT * FROM cluster_management_test;
2023-11-25 00:43:29.456 UTC [3758292] ERROR:  XX000: there is a shard placement in node group 5 but there are no nodes in that group
2023-11-25 00:43:29.456 UTC [3758292] LOCATION:  LookupNodeForGroup, metadata_cache.c:1181
2023-11-25 00:43:29.456 UTC [3758292] STATEMENT:  SELECT * FROM cluster_management_test;
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220001
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220003
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220005
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220007
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220009
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220011
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220013
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.462 UTC [3758292] WARNING:  01000: could not find any shard placements for shardId 1220015
2023-11-25 00:43:29.462 UTC [3758292] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 00:43:29.491 UTC [3758292] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 00:43:29.491 UTC [3758292] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 00:43:29.491 UTC [3758292] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 00:43:29.491 UTC [3758292] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 00:43:29.491 UTC [3758292] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 00:43:29.715 UTC [3758330] ERROR:  XX000: primaries must be added to the default cluster
2023-11-25 00:43:29.715 UTC [3758330] LOCATION:  AddNodeMetadata, node_metadata.c:2141
2023-11-25 00:43:29.715 UTC [3758330] STATEMENT:  SELECT master_add_node('localhost', 9999, nodecluster => 'olap');
2023-11-25 00:43:29.716 UTC [3758330] ERROR:  XX000: group 14 already has a primary node
2023-11-25 00:43:29.716 UTC [3758330] LOCATION:  AddNodeMetadata, node_metadata.c:2130
2023-11-25 00:43:29.716 UTC [3758330] STATEMENT:  SELECT master_add_node('localhost', 9999, groupid => 14, noderole => 'primary');
2023-11-25 00:43:29.719 UTC [3758330] ERROR:  P0001: there cannot be two primary nodes in a group
2023-11-25 00:43:29.719 UTC [3758330] CONTEXT:  PL/pgSQL function citus_internal.pg_dist_node_trigger_func() line 10 at RAISE
2023-11-25 00:43:29.719 UTC [3758330] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:29.719 UTC [3758330] STATEMENT:  INSERT INTO pg_dist_node (nodename, nodeport, groupid, noderole)
	  VALUES ('localhost', 5000, 14, 'primary');
2023-11-25 00:43:29.719 UTC [3758330] ERROR:  P0001: there cannot be two primary nodes in a group
2023-11-25 00:43:29.719 UTC [3758330] CONTEXT:  PL/pgSQL function citus_internal.pg_dist_node_trigger_func() line 18 at RAISE
2023-11-25 00:43:29.719 UTC [3758330] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:29.719 UTC [3758330] STATEMENT:  UPDATE pg_dist_node SET noderole = 'primary'
	  WHERE groupid = 14 AND nodeport = 9998;
2023-11-25 00:43:29.720 UTC [3758330] ERROR:  23514: new row for relation "pg_dist_node" violates check constraint "primaries_are_only_allowed_in_the_default_cluster"
2023-11-25 00:43:29.720 UTC [3758330] DETAIL:  Failing row contains (24, 1000, localhost, 5000, default, f, t, primary, olap, f, t).
2023-11-25 00:43:29.720 UTC [3758330] LOCATION:  ExecConstraints, execMain.c:2019
2023-11-25 00:43:29.720 UTC [3758330] STATEMENT:  INSERT INTO pg_dist_node (nodename, nodeport, groupid, noderole, nodecluster)
	  VALUES ('localhost', 5000, 1000, 'primary', 'olap');
2023-11-25 00:43:29.720 UTC [3758330] ERROR:  23514: new row for relation "pg_dist_node" violates check constraint "primaries_are_only_allowed_in_the_default_cluster"
2023-11-25 00:43:29.720 UTC [3758330] DETAIL:  Failing row contains (16, 14, localhost, 57637, default, f, t, primary, olap, f, t).
2023-11-25 00:43:29.720 UTC [3758330] LOCATION:  ExecConstraints, execMain.c:2019
2023-11-25 00:43:29.720 UTC [3758330] STATEMENT:  UPDATE pg_dist_node SET nodecluster = 'olap'
	  WHERE nodeport = 57637;
2023-11-25 00:43:29.721 UTC [3758330] ERROR:  XX000: node at "localhost:2000" does not exist
2023-11-25 00:43:29.721 UTC [3758330] LOCATION:  GroupForNode, node_metadata.c:801
2023-11-25 00:43:29.721 UTC [3758330] STATEMENT:  SELECT master_add_secondary_node('localhost', 9993, 'localhost', 2000);
2023-11-25 00:43:29.723 UTC [3758330] ERROR:  P0002: node 100 not found
2023-11-25 00:43:29.723 UTC [3758330] LOCATION:  citus_update_node, node_metadata.c:1216
2023-11-25 00:43:29.723 UTC [3758330] STATEMENT:  SELECT master_update_node(100, 'localhost', 8000);
2023-11-25 00:43:29.723 UTC [3758330] ERROR:  55000: there is already another node with the specified hostname and port
2023-11-25 00:43:29.723 UTC [3758330] LOCATION:  citus_update_node, node_metadata.c:1207
2023-11-25 00:43:29.723 UTC [3758330] STATEMENT:  SELECT master_update_node(16, 'localhost', 57638);
2023-11-25 00:43:29.792 UTC [3758330] ERROR:  XX000: only the 'shouldhaveshards' property can be set using this function
2023-11-25 00:43:29.792 UTC [3758330] LOCATION:  citus_set_node_property, node_metadata.c:695
2023-11-25 00:43:29.792 UTC [3758330] STATEMENT:  SELECT * from master_set_node_property('localhost', 57638, 'bogusproperty', false);
2023-11-25 00:43:29.835 UTC [3758330] ERROR:  XX000: do not sync metadata in transaction block when the sync mode is nontransactional
2023-11-25 00:43:29.835 UTC [3758330] HINT:  resync after SET citus.metadata_sync_mode TO 'transactional'
2023-11-25 00:43:29.835 UTC [3758330] LOCATION:  ActivateNodeList, node_metadata.c:1061
2023-11-25 00:43:29.835 UTC [3758330] STATEMENT:  SELECT start_metadata_sync_to_all_nodes();
2023-11-25 00:43:29.881 UTC [3758330] ERROR:  XX000: do not add node in transaction block when the sync mode is nontransactional
2023-11-25 00:43:29.881 UTC [3758330] HINT:  add the node after SET citus.metadata_sync_mode TO 'transactional'
2023-11-25 00:43:29.881 UTC [3758330] LOCATION:  citus_add_node, node_metadata.c:322
2023-11-25 00:43:29.881 UTC [3758330] STATEMENT:  SELECT citus_add_node('localhost', 57637);
2023-11-25 00:43:29.979 UTC [3758359] ERROR:  42601: syntax error at or near ""123"" at character 37
2023-11-25 00:43:29.979 UTC [3758359] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:43:29.979 UTC [3758359] STATEMENT:  CREATE ROLE create_role_sysid SYSID "123";
2023-11-25 00:43:30.345 UTC [3758416] ERROR:  42704: role "nonexisting_role_2" does not exist
2023-11-25 00:43:30.345 UTC [3758416] LOCATION:  get_role_oid, acl.c:5184
2023-11-25 00:43:30.345 UTC [3758416] STATEMENT:  GRANT existing_role_1, nonexisting_role_1 TO existing_role_2, nonexisting_role_2;
2023-11-25 00:43:30.354 UTC [3758420] ERROR:  42704: role "nonexisting_role_1" does not exist
2023-11-25 00:43:30.354 UTC [3758420] LOCATION:  DropRole, user.c:951
2023-11-25 00:43:30.354 UTC [3758420] STATEMENT:  DROP ROLE existing_role_1, existing_role_2, nonexisting_role_1, nonexisting_role_2;
2023-11-25 00:43:31.040 UTC [3758549] ERROR:  42P16: cannot distribute relation "data_load_test"
2023-11-25 00:43:31.040 UTC [3758549] DETAIL:  Relation "data_load_test" contains data.
2023-11-25 00:43:31.040 UTC [3758549] HINT:  Empty your table before distributing it.
2023-11-25 00:43:31.040 UTC [3758549] LOCATION:  EnsureLocalTableEmpty, create_distributed_table.c:2032
2023-11-25 00:43:31.040 UTC [3758549] STATEMENT:  SELECT create_distributed_table('data_load_test', 'col1', 'append');
2023-11-25 00:43:31.049 UTC [3758549] ERROR:  42P16: cannot distribute relation "data_load_test"
2023-11-25 00:43:31.049 UTC [3758549] DETAIL:  Relation "data_load_test" contains data.
2023-11-25 00:43:31.049 UTC [3758549] HINT:  Empty your table before distributing it.
2023-11-25 00:43:31.049 UTC [3758549] LOCATION:  EnsureLocalTableEmpty, create_distributed_table.c:2032
2023-11-25 00:43:31.049 UTC [3758549] STATEMENT:  SELECT create_distributed_table('data_load_test', 'col1', 'range');
2023-11-25 00:43:31.195 UTC [3758549] ERROR:  0A000: cannot create a citus table from a catalog table
2023-11-25 00:43:31.195 UTC [3758549] LOCATION:  ErrorIfTableIsACatalogTable, create_distributed_table.c:1968
2023-11-25 00:43:31.195 UTC [3758549] STATEMENT:  SELECT create_distributed_table('pg_class', 'relname');
2023-11-25 00:43:31.196 UTC [3758549] ERROR:  0A000: cannot create a citus table from a catalog table
2023-11-25 00:43:31.196 UTC [3758549] LOCATION:  ErrorIfTableIsACatalogTable, create_distributed_table.c:1968
2023-11-25 00:43:31.196 UTC [3758549] STATEMENT:  SELECT create_reference_table('pg_class');
2023-11-25 00:43:31.207 UTC [3758549] ERROR:  XX000: 0 is outside the valid range for parameter "shard_count" (1 .. 64000)
2023-11-25 00:43:31.207 UTC [3758549] LOCATION:  create_distributed_table, create_distributed_table.c:276
2023-11-25 00:43:31.207 UTC [3758549] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=0);
2023-11-25 00:43:31.207 UTC [3758549] ERROR:  XX000: -100 is outside the valid range for parameter "shard_count" (1 .. 64000)
2023-11-25 00:43:31.207 UTC [3758549] LOCATION:  create_distributed_table, create_distributed_table.c:276
2023-11-25 00:43:31.207 UTC [3758549] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=-100);
2023-11-25 00:43:31.207 UTC [3758549] ERROR:  XX000: 64001 is outside the valid range for parameter "shard_count" (1 .. 64000)
2023-11-25 00:43:31.207 UTC [3758549] LOCATION:  create_distributed_table, create_distributed_table.c:276
2023-11-25 00:43:31.207 UTC [3758549] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=64001);
2023-11-25 00:43:31.207 UTC [3758549] ERROR:  XX000: Cannot use colocate_with with a table and shard_count at the same time
2023-11-25 00:43:31.207 UTC [3758549] LOCATION:  create_distributed_table, create_distributed_table.c:237
2023-11-25 00:43:31.207 UTC [3758549] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=12, colocate_with:='shard_count');
2023-11-25 00:43:31.255 UTC [3758549] LOG:  00000: performing blocking isolate_tenant_to_new_shard 
2023-11-25 00:43:31.255 UTC [3758549] LOCATION:  SplitShard, shard_split.c:507
2023-11-25 00:43:31.255 UTC [3758549] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:43:31.255 UTC [3758549] LOG:  00000: creating child shards for isolate_tenant_to_new_shard
2023-11-25 00:43:31.255 UTC [3758549] LOCATION:  BlockingShardSplit, shard_split.c:571
2023-11-25 00:43:31.255 UTC [3758549] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:43:31.264 UTC [3758549] LOG:  00000: performing copy for isolate_tenant_to_new_shard
2023-11-25 00:43:31.264 UTC [3758549] LOCATION:  BlockingShardSplit, shard_split.c:577
2023-11-25 00:43:31.264 UTC [3758549] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:43:31.265 UTC [3758549] LOG:  00000: creating auxillary structures (indexes, stats, replicaindentities, triggers) for isolate_tenant_to_new_shard
2023-11-25 00:43:31.265 UTC [3758549] LOCATION:  BlockingShardSplit, shard_split.c:587
2023-11-25 00:43:31.265 UTC [3758549] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:43:31.265 UTC [3758549] LOG:  00000: marking deferred cleanup of source shard(s) for isolate_tenant_to_new_shard
2023-11-25 00:43:31.265 UTC [3758549] LOCATION:  BlockingShardSplit, shard_split.c:609
2023-11-25 00:43:31.265 UTC [3758549] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:43:31.266 UTC [3758549] LOG:  00000: creating foreign key constraints (if any) for isolate_tenant_to_new_shard
2023-11-25 00:43:31.266 UTC [3758549] LOCATION:  BlockingShardSplit, shard_split.c:625
2023-11-25 00:43:31.266 UTC [3758549] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:43:31.322 UTC [3758549] ERROR:  0A000: cannot distribute a temporary table
2023-11-25 00:43:31.322 UTC [3758549] LOCATION:  ErrorIfTemporaryTable, create_distributed_table.c:1950
2023-11-25 00:43:31.322 UTC [3758549] STATEMENT:  select create_distributed_table('temp_table', 'a');
2023-11-25 00:43:31.322 UTC [3758549] ERROR:  0A000: cannot distribute a temporary table
2023-11-25 00:43:31.322 UTC [3758549] LOCATION:  ErrorIfTemporaryTable, create_distributed_table.c:1950
2023-11-25 00:43:31.322 UTC [3758549] STATEMENT:  select create_reference_table('temp_table');
2023-11-25 00:43:32.364 UTC [3758781] WARNING:  0A000: table "uniq_cns_append_tables" has a UNIQUE or EXCLUDE constraint
2023-11-25 00:43:32.364 UTC [3758781] DETAIL:  UNIQUE constraints, EXCLUDE constraints, and PRIMARY KEYs on append-partitioned tables cannot be enforced.
2023-11-25 00:43:32.364 UTC [3758781] HINT:  Consider using hash partitioning.
2023-11-25 00:43:32.364 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:2975
2023-11-25 00:43:32.367 UTC [3758781] WARNING:  0A000: table "excl_cns_append_tables" has a UNIQUE or EXCLUDE constraint
2023-11-25 00:43:32.367 UTC [3758781] DETAIL:  UNIQUE constraints, EXCLUDE constraints, and PRIMARY KEYs on append-partitioned tables cannot be enforced.
2023-11-25 00:43:32.367 UTC [3758781] HINT:  Consider using hash partitioning.
2023-11-25 00:43:32.367 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:2975
2023-11-25 00:43:32.374 UTC [3758781] ERROR:  0A000: cannot create constraint on "pk_on_non_part_col"
2023-11-25 00:43:32.374 UTC [3758781] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 00:43:32.374 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 00:43:32.374 UTC [3758781] STATEMENT:  SELECT create_distributed_table('pk_on_non_part_col', 'partition_col', 'hash');
2023-11-25 00:43:32.426 UTC [3758781] ERROR:  23505: duplicate key value violates unique constraint "pk_on_non_part_col_pkey_365000"
2023-11-25 00:43:32.426 UTC [3758781] DETAIL:  Key (other_col)=(1) already exists.
2023-11-25 00:43:32.426 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.426 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.426 UTC [3758781] STATEMENT:  INSERT INTO pk_on_non_part_col VALUES (1,1);
2023-11-25 00:43:32.436 UTC [3758781] ERROR:  0A000: cannot create constraint on "uq_on_non_part_col"
2023-11-25 00:43:32.436 UTC [3758781] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 00:43:32.436 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 00:43:32.436 UTC [3758781] STATEMENT:  SELECT create_distributed_table('uq_on_non_part_col', 'partition_col', 'hash');
2023-11-25 00:43:32.439 UTC [3758781] ERROR:  0A000: cannot create constraint on "ex_on_non_part_col"
2023-11-25 00:43:32.439 UTC [3758781] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 00:43:32.439 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 00:43:32.439 UTC [3758781] STATEMENT:  SELECT create_distributed_table('ex_on_non_part_col', 'partition_col', 'hash');
2023-11-25 00:43:32.472 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_non_part_col_other_col_excl_365004"
2023-11-25 00:43:32.472 UTC [3758781] DETAIL:  Key (other_col)=(1) conflicts with existing key (other_col)=(1).
2023-11-25 00:43:32.472 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.472 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.472 UTC [3758781] STATEMENT:  INSERT INTO ex_on_non_part_col VALUES (1,1);
2023-11-25 00:43:32.532 UTC [3758781] ERROR:  23505: duplicate key value violates unique constraint "uq_two_columns_partition_col_other_col_key_365016"
2023-11-25 00:43:32.532 UTC [3758781] DETAIL:  Key (partition_col, other_col)=(1, 1) already exists.
2023-11-25 00:43:32.532 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.532 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.532 UTC [3758781] STATEMENT:  INSERT INTO uq_two_columns (partition_col, other_col) VALUES (1,1);
2023-11-25 00:43:32.535 UTC [3758781] ERROR:  0A000: cannot create constraint on "pk_on_two_non_part_cols"
2023-11-25 00:43:32.535 UTC [3758781] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 00:43:32.535 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 00:43:32.535 UTC [3758781] STATEMENT:  SELECT create_distributed_table('pk_on_two_non_part_cols', 'partition_col', 'hash');
2023-11-25 00:43:32.577 UTC [3758781] ERROR:  23505: duplicate key value violates unique constraint "pk_on_two_non_part_cols_pkey_365020"
2023-11-25 00:43:32.577 UTC [3758781] DETAIL:  Key (other_col, other_col_2)=(1, 1) already exists.
2023-11-25 00:43:32.577 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.577 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.577 UTC [3758781] STATEMENT:  INSERT INTO pk_on_two_non_part_cols VALUES (1,1,1);
2023-11-25 00:43:32.657 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_part_col_partition_col_excl_365024"
2023-11-25 00:43:32.657 UTC [3758781] DETAIL:  Key (partition_col)=(1) conflicts with existing key (partition_col)=(1).
2023-11-25 00:43:32.657 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.657 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.657 UTC [3758781] STATEMENT:  INSERT INTO ex_on_part_col (partition_col, other_col) VALUES (1,2);
2023-11-25 00:43:32.685 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_two_columns_partition_col_other_col_excl_365028"
2023-11-25 00:43:32.685 UTC [3758781] DETAIL:  Key (partition_col, other_col)=(1, 1) conflicts with existing key (partition_col, other_col)=(1, 1).
2023-11-25 00:43:32.685 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.685 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.685 UTC [3758781] STATEMENT:  INSERT INTO ex_on_two_columns (partition_col, other_col) VALUES (1,1);
2023-11-25 00:43:32.716 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_two_columns_prt_partition_col_other_col_excl_365032"
2023-11-25 00:43:32.716 UTC [3758781] DETAIL:  Key (partition_col, other_col)=(1, 101) conflicts with existing key (partition_col, other_col)=(1, 101).
2023-11-25 00:43:32.716 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.716 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.716 UTC [3758781] STATEMENT:  INSERT INTO ex_on_two_columns_prt (partition_col, other_col) VALUES (1,101);
2023-11-25 00:43:32.719 UTC [3758781] ERROR:  0A000: cannot create constraint on "ex_wrong_operator"
2023-11-25 00:43:32.719 UTC [3758781] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 00:43:32.719 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 00:43:32.719 UTC [3758781] STATEMENT:  SELECT create_distributed_table('ex_wrong_operator', 'partition_col', 'hash');
2023-11-25 00:43:32.740 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_overlaps_other_col_partition_col_excl_365039"
2023-11-25 00:43:32.740 UTC [3758781] DETAIL:  Key (other_col, partition_col)=(["2016-01-15 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]) conflicts with existing key (other_col, partition_col)=(["2016-01-01 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]).
2023-11-25 00:43:32.740 UTC [3758781] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:32.740 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.740 UTC [3758781] STATEMENT:  INSERT INTO ex_overlaps (partition_col, other_col) VALUES ('[2016-01-01 00:00:00, 2016-02-01 00:00:00]', '[2016-01-15 00:00:00, 2016-02-01 00:00:00]');
2023-11-25 00:43:32.785 UTC [3758781] ERROR:  23505: duplicate key value violates unique constraint "uq_two_columns_named_uniq_365048"
2023-11-25 00:43:32.785 UTC [3758781] DETAIL:  Key (partition_col, other_col)=(1, 1) already exists.
2023-11-25 00:43:32.785 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.785 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.785 UTC [3758781] STATEMENT:  INSERT INTO uq_two_columns_named (partition_col, other_col) VALUES (1,1);
2023-11-25 00:43:32.804 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_part_col_named_exclude_365052"
2023-11-25 00:43:32.804 UTC [3758781] DETAIL:  Key (partition_col)=(1) conflicts with existing key (partition_col)=(1).
2023-11-25 00:43:32.804 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.804 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.804 UTC [3758781] STATEMENT:  INSERT INTO ex_on_part_col_named (partition_col, other_col) VALUES (1,2);
2023-11-25 00:43:32.816 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_two_columns_named_exclude_365056"
2023-11-25 00:43:32.816 UTC [3758781] DETAIL:  Key (partition_col, other_col)=(1, 1) conflicts with existing key (partition_col, other_col)=(1, 1).
2023-11-25 00:43:32.816 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.816 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.816 UTC [3758781] STATEMENT:  INSERT INTO ex_on_two_columns_named (partition_col, other_col) VALUES (1,1);
2023-11-25 00:43:32.833 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_multiple_excludes_excl1_365060"
2023-11-25 00:43:32.833 UTC [3758781] DETAIL:  Key (partition_col, other_col)=(1, 1) conflicts with existing key (partition_col, other_col)=(1, 1).
2023-11-25 00:43:32.833 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.833 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.833 UTC [3758781] STATEMENT:  INSERT INTO ex_multiple_excludes (partition_col, other_col, other_other_col) VALUES (1,1,2);
2023-11-25 00:43:32.834 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_multiple_excludes_excl2_365060"
2023-11-25 00:43:32.834 UTC [3758781] DETAIL:  Key (partition_col, other_other_col)=(1, 1) conflicts with existing key (partition_col, other_other_col)=(1, 1).
2023-11-25 00:43:32.834 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.834 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.834 UTC [3758781] STATEMENT:  INSERT INTO ex_multiple_excludes (partition_col, other_col, other_other_col) VALUES (1,2,1);
2023-11-25 00:43:32.835 UTC [3758781] ERROR:  0A000: cannot create constraint on "ex_wrong_operator_named"
2023-11-25 00:43:32.835 UTC [3758781] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 00:43:32.835 UTC [3758781] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 00:43:32.835 UTC [3758781] STATEMENT:  SELECT create_distributed_table('ex_wrong_operator_named', 'partition_col', 'hash');
2023-11-25 00:43:32.851 UTC [3758781] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_overlaps_operator_named_exclude_365067"
2023-11-25 00:43:32.851 UTC [3758781] DETAIL:  Key (other_col, partition_col)=(["2016-01-15 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]) conflicts with existing key (other_col, partition_col)=(["2016-01-01 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]).
2023-11-25 00:43:32.851 UTC [3758781] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:32.851 UTC [3758781] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:32.851 UTC [3758781] STATEMENT:  INSERT INTO ex_overlaps_named (partition_col, other_col) VALUES ('[2016-01-01 00:00:00, 2016-02-01 00:00:00]', '[2016-01-15 00:00:00, 2016-02-01 00:00:00]');
2023-11-25 00:43:33.022 UTC [3758881] ERROR:  2BP01: cannot drop table raw_table_1 because other objects depend on it
2023-11-25 00:43:33.022 UTC [3758881] DETAIL:  constraint raw_table_2_user_id_fkey on table raw_table_2 depends on table raw_table_1
2023-11-25 00:43:33.022 UTC [3758881] HINT:  Use DROP ... CASCADE to drop the dependent objects too.
2023-11-25 00:43:33.022 UTC [3758881] LOCATION:  reportDependentObjects, dependency.c:1189
2023-11-25 00:43:33.022 UTC [3758881] STATEMENT:  DROP TABLE raw_table_1;
2023-11-25 00:43:33.260 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:43:33.260 UTC [3758969] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:43:33.260 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg)
	SELECT user_id, array_length(events_table, 1)
	FROM (
	  SELECT user_id, array_agg(event ORDER BY time) AS events_table
	  FROM (
	    SELECT u.user_id, e.event_type::text AS event, e.time
	    FROM users_table AS u,
	         events_table AS e
	    WHERE u.user_id != e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (100, 101, 102)
	  ) t
	  GROUP BY user_id
	) q;
2023-11-25 00:43:33.262 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:43:33.262 UTC [3758969] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:43:33.262 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg, value_2_agg )
	SELECT user_id, sum(array_length(events_table, 1)), length(hasdone_event)
	FROM (
	  SELECT
	    t1.user_id,
	    array_agg(event ORDER BY time) AS events_table,
	    COALESCE(hasdone_event, 'Has not done event') AS hasdone_event
	  FROM (
	    (
	      SELECT u.user_id, 'step=>1'::text AS event, e.time
	      FROM users_table AS u,
	          events_table AS e
	      WHERE  u.user_id != e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (100, 101, 102)
	    )
	    UNION
	    (
	      SELECT u.user_id, 'step=>2'::text AS event, e.time
	      FROM users_table AS u,
	         events_table AS e
	      WHERE  u.user_id = e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (103, 104, 105)
	    )
	  ) t1 LEFT JOIN (
	      SELECT DISTINCT user_id,
	        'Has done event'::TEXT AS hasdone_event
	      FROM  events_table AS e
	      WHERE  e.user_id >= 10
	      AND e.user_id <= 25
	      AND e.event_type IN (106, 107, 108)
	  ) t2 ON (t1.user_id = t2.user_id)
	  GROUP BY  t1.user_id, hasdone_event
	) t GROUP BY user_id, hasdone_event;
2023-11-25 00:43:33.265 UTC [3758969] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:43:33.265 UTC [3758969] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:43:33.265 UTC [3758969] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:43:33.265 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg, value_2_agg )
	SELECT user_id, sum(array_length(events_table, 1)), length(hasdone_event)
	FROM (
	  SELECT
	    t1.user_id,
	    array_agg(event ORDER BY time) AS events_table,
	    COALESCE(hasdone_event, 'Has not done event') AS hasdone_event
	  FROM (
	    (
	      SELECT u.user_id, 'step=>1'::text AS event, e.time
	      FROM users_table AS u,
	          events_table AS e
	      WHERE  u.user_id = e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (100, 101, 102)
	    )
	    UNION
	    (
	      SELECT u.user_id, 'step=>2'::text AS event, e.time
	      FROM users_table AS u,
	         events_table AS e
	      WHERE  u.user_id = e.event_type
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (103, 104, 105)
	    )
	  ) t1 LEFT JOIN (
	      SELECT DISTINCT user_id,
	        'Has done event'::TEXT AS hasdone_event
	      FROM  events_table AS e
	      WHERE  e.user_id >= 10
	      AND e.user_id <= 25
	      AND e.event_type IN (106, 107, 108)
	  ) t2 ON (t1.user_id = t2.user_id)
	  GROUP BY  t1.user_id, hasdone_event
	) t GROUP BY user_id, hasdone_event;
2023-11-25 00:43:33.295 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:43:33.295 UTC [3758969] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:43:33.295 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg, value_2_agg)
	SELECT
	  user_id,
	  avg(array_length(events_table, 1)) AS event_average,
	  count_pay
	  FROM (
	  SELECT
	  subquery_1.user_id,
	  array_agg(event ORDER BY time) AS events_table,
	  COALESCE(count_pay, 0) AS count_pay
	  FROM
	  (
	    (SELECT
	      users_table.user_id,
	      'action=>1'AS event,
	      events_table.time
	    FROM
	      users_table,
	      events_table
	    WHERE
	      users_table.user_id = events_table.user_id AND
	      users_table.user_id >= 10 AND
	      users_table.user_id <= 70 AND
	      events_table.event_type > 10 AND events_table.event_type < 12
	      )
	    UNION
	    (SELECT
	      users_table.user_id,
	      'action=>2'AS event,
	      events_table.time
	    FROM
	      users_table,
	      events_table
	    WHERE
	      users_table.user_id != events_table.user_id AND
	      users_table.user_id >= 10 AND
	      users_table.user_id <= 70 AND
	      events_table.event_type > 12 AND events_table.event_type < 14
	    )
	  ) AS subquery_1
	  LEFT JOIN
	    (SELECT
	       user_id,
	      COUNT(*) AS count_pay
	    FROM
	      users_table
	    WHERE
	      user_id >= 10 AND
	      user_id <= 70 AND
	      users_table.value_1 > 15 AND users_table.value_1 < 17
	    GROUP BY
	      user_id
	    HAVING
	      COUNT(*) > 1) AS subquery_2
	  ON
	    subquery_1.user_id = subquery_2.user_id
	  GROUP BY
	    subquery_1.user_id,
	    count_pay) AS subquery_top
	WHERE
	  array_ndims(events_table) > 0
	GROUP BY
	  count_pay, user_id
	ORDER BY
	  count_pay;
2023-11-25 00:43:33.311 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.311 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.311 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third (user_id, agg_time, value_2_agg)
	SELECT
	    user_id,
	    user_lastseen,
	    array_length(event_array, 1)
	FROM (
	    SELECT
	        user_id,
	        max(u.time) as user_lastseen,
	        array_agg(event_type ORDER BY u.time) AS event_array
	    FROM (
	        SELECT user_id, time
	        FROM users_table
	        WHERE
	        user_id >= 10 AND
	        user_id <= 70 AND
	        users_table.value_1 > 10 AND users_table.value_1 < 12
	        ) u LEFT JOIN LATERAL (
	          SELECT event_type, time
	          FROM events_table
	          WHERE user_id != u.user_id AND
	          events_table.event_type > 10 AND events_table.event_type < 12
	        ) t ON true
	        GROUP BY user_id
	) AS shard_union
	ORDER BY user_lastseen DESC;
2023-11-25 00:43:33.312 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.312 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.312 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third (user_id, agg_time, value_2_agg)
	SELECT
	    user_id,
	    user_lastseen,
	    array_length(event_array, 1)
	FROM (
	    SELECT
	        user_id,
	        max(u.time) as user_lastseen,
	        array_agg(event_type ORDER BY u.time) AS event_array
	    FROM (
	        SELECT user_id, time
	        FROM users_table
	        WHERE
	        user_id >= 10 AND
	        user_id <= 70 AND
	        users_table.value_1 > 10 AND users_table.value_1 < 12
	        ) u LEFT JOIN LATERAL (
	          SELECT event_type, time
	          FROM events_table
	          WHERE event_type = u.user_id AND
	          events_table.event_type > 10 AND events_table.event_type < 12
	        ) t ON true
	        GROUP BY user_id
	) AS shard_union
	ORDER BY user_lastseen DESC;
2023-11-25 00:43:33.314 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.314 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.314 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third (user_id, agg_time, value_2_agg)
	SELECT
	    user_id,
	    user_lastseen,
	    array_length(event_array, 1)
	FROM (
	    SELECT
	        user_id,
	        max(u.time) as user_lastseen,
	        array_agg(event_type ORDER BY u.time) AS event_array
	    FROM (
	        SELECT user_id, time, value_3 as val_3
	        FROM users_table
	        WHERE
	        user_id >= 10 AND
	        user_id <= 70 AND
	        users_table.value_1 > 10 AND users_table.value_1 < 12
	        ) u LEFT JOIN LATERAL (
	          SELECT event_type, time
	          FROM events_table
	          WHERE event_type = u.val_3 AND
	          events_table.event_type > 10 AND events_table.event_type < 12
	        ) t ON true
	        GROUP BY user_id
	) AS shard_union
	ORDER BY user_lastseen DESC;
2023-11-25 00:43:33.336 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.336 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.336 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 101 AND value_1 < 110
	  AND value_2 >= 5
	  AND EXISTS (SELECT user_id FROM events_table WHERE event_type>101  AND event_type < 110 AND value_3 > 100 AND user_id!=users_table.user_id);
2023-11-25 00:43:33.337 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.337 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.337 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 101 AND value_1 < 110
	  AND value_2 >= 5
	  AND EXISTS (SELECT user_id FROM events_table WHERE event_type>101  AND event_type < 110 AND value_3 > 100 AND event_type = users_table.user_id);
2023-11-25 00:43:33.338 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.338 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.338 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 = 101
	  AND value_2 >= 5
	  AND NOT EXISTS (SELECT user_id FROM events_table WHERE event_type=101 AND value_3 > 100 AND user_id!=users_table.user_id);
2023-11-25 00:43:33.339 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.339 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.339 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 = 101
	  AND value_2 >= 5
	  AND NOT EXISTS (SELECT user_id FROM events_table WHERE event_type=101 AND value_3 > 100 AND event_type=users_table.user_id);
2023-11-25 00:43:33.340 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.340 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.340 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 100
	  AND value_2 >= 5
	  AND  EXISTS (SELECT user_id FROM events_table WHERE event_type!=100 AND value_3 > 100 AND user_id=users_table.user_id)
	  AND  EXISTS (SELECT user_id FROM events_table WHERE event_type=101 AND value_3 > 100 AND user_id!=users_table.user_id);
2023-11-25 00:43:33.341 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.341 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.341 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_2 >= 5
	  AND  EXISTS (SELECT user_id FROM events_table WHERE event_type > 100 AND event_type <= 300 AND value_3 > 100 AND user_id!=users_table.user_id)
	  AND  NOT EXISTS (SELECT user_id FROM events_table WHERE event_type > 300 AND event_type <= 350  AND value_3 > 100 AND user_id=users_table.user_id);
2023-11-25 00:43:33.342 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.342 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.342 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	  SELECT user_id,
	         value_2
	  FROM   users_table
	  WHERE  value_1 > 100
	         AND value_1 < 124
	         AND value_2 >= 5
	         AND EXISTS (SELECT user_id
	                     FROM   events_table
	                     WHERE  event_type > 100
	                            AND event_type < 124
	                            AND value_3 > 100
	                            AND user_id != users_table.user_id
	                     GROUP  BY user_id
	                     HAVING Count(*) > 2);
2023-11-25 00:43:33.343 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.343 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.343 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	  SELECT user_id,
	         value_2
	  FROM   users_table
	  WHERE  value_1 > 100
	         AND value_1 < 124
	         AND value_2 >= 5
	         AND EXISTS (SELECT user_id
	                     FROM   events_table
	                     WHERE  event_type > 100
	                            AND event_type < 124
	                            AND value_3 > 100
	                            AND event_type = users_table.user_id
	                     GROUP  BY user_id
	                     HAVING Count(*) > 2);
2023-11-25 00:43:33.343 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.343 UTC [3758969] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.343 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	  SELECT user_id,
	         value_2
	  FROM   users_table
	  WHERE  value_1 > 100
	         AND value_1 < 124
	         AND value_2 >= 5
	         AND EXISTS (SELECT user_id
	                     FROM   events_table
	                     WHERE  event_type > 100
	                            AND event_type < 124
	                            AND value_3 > 100
	                            AND user_id = users_table.value_1
	                     GROUP  BY user_id
	                     HAVING Count(*) > 2);
2023-11-25 00:43:33.376 UTC [3758969] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:43:33.376 UTC [3758969] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:43:33.376 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_1_agg, value_3_agg)
	SELECT
	    users_table.user_id, users_table.value_1, prob
	FROM
	   users_table
	        JOIN
	   (SELECT
	      ma.user_id, (GREATEST(coalesce(ma.value_4 / 250, 0.0) + GREATEST(1.0))) / 2 AS prob
	    FROM
	      users_table AS ma, events_table as short_list
	    WHERE
	      short_list.user_id != ma.user_id and ma.value_1 < 50 and short_list.event_type < 50
	    ) temp
	  ON users_table.user_id = temp.user_id
	  WHERE users_table.value_1 < 50;
2023-11-25 00:43:33.378 UTC [3758969] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:43:33.378 UTC [3758969] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:43:33.378 UTC [3758969] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:43:33.378 UTC [3758969] STATEMENT:  INSERT INTO agg_results_third(user_id, value_1_agg, value_3_agg)
	SELECT
	    users_table.user_id, users_table.value_1, prob
	FROM
	   users_table
	        JOIN
	   (SELECT
	      ma.user_id, (GREATEST(coalesce(ma.value_4 / 250, 0.0) + GREATEST(1.0))) / 2 AS prob
	    FROM
	      users_table AS ma, events_table as short_list
	    WHERE
	      short_list.user_id = ma.value_2 and ma.value_1 < 50 and short_list.event_type < 50
	    ) temp
	  ON users_table.user_id = temp.user_id
	  WHERE users_table.value_1 < 50;
2023-11-25 00:43:33.403 UTC [3758968] ERROR:  23505: duplicate key value violates unique constraint "raw_events_second_user_id_value_1_key_13300004"
2023-11-25 00:43:33.403 UTC [3758968] DETAIL:  Key (user_id, value_1)=(1, 10) already exists.
2023-11-25 00:43:33.403 UTC [3758968] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:33.403 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:33.403 UTC [3758968] STATEMENT:  INSERT INTO raw_events_second  SELECT * FROM raw_events_first;
2023-11-25 00:43:33.452 UTC [3758968] ERROR:  42883: function multi_insert_select.evaluate_on_master(integer) does not exist
2023-11-25 00:43:33.452 UTC [3758968] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:43:33.452 UTC [3758968] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:33.452 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:33.452 UTC [3758968] STATEMENT:  INSERT INTO raw_events_second (user_id, value_1)
	SELECT
	  user_id, evaluate_on_master(value_1)
	FROM
	  raw_events_first
	WHERE
	  user_id = 0;
2023-11-25 00:43:33.477 UTC [3758968] ERROR:  23505: duplicate key value violates unique constraint "raw_events_second_user_id_value_1_key_13300007"
2023-11-25 00:43:33.477 UTC [3758968] DETAIL:  Key (user_id, value_1)=(9, 90) already exists.
2023-11-25 00:43:33.477 UTC [3758968] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:33.477 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:33.477 UTC [3758968] STATEMENT:  INSERT INTO raw_events_second (user_id, value_1, value_3)
	SELECT
	   user_id, value_1, value_3
	FROM
	   raw_events_first
	WHERE
	   user_id = 9 OR user_id = 16
	RETURNING *;
2023-11-25 00:43:33.493 UTC [3758968] ERROR:  23505: duplicate key value violates unique constraint "agg_events_user_id_value_1_agg_key_13300008"
2023-11-25 00:43:33.493 UTC [3758968] DETAIL:  Key (user_id, value_1_agg)=(1, 10) already exists.
2023-11-25 00:43:33.493 UTC [3758968] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:33.493 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:33.493 UTC [3758968] STATEMENT:  INSERT INTO agg_events (value_3_agg, value_4_agg, value_1_agg, user_id)
	SELECT
	   sum(value_3), count(value_4), sum(value_1), user_id
	FROM
	   raw_events_first
	GROUP BY
	   value_2, user_id
	RETURNING *;
2023-11-25 00:43:33.501 UTC [3758968] ERROR:  23505: duplicate key value violates unique constraint "agg_events_user_id_value_1_agg_key_13300008"
2023-11-25 00:43:33.501 UTC [3758968] DETAIL:  Key (user_id, value_1_agg)=(1, 10) already exists.
2023-11-25 00:43:33.501 UTC [3758968] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:33.501 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:33.501 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	            (value_1_agg,
	             user_id)
	SELECT SUM(value_1),
	       id
	FROM   (SELECT raw_events_second.user_id AS id,
	               raw_events_second.value_1
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id = raw_events_second.user_id) AS foo
	GROUP  BY id
	ORDER  BY id;
2023-11-25 00:43:33.505 UTC [3758968] ERROR:  23505: duplicate key value violates unique constraint "agg_events_user_id_value_1_agg_key_13300008"
2023-11-25 00:43:33.505 UTC [3758968] DETAIL:  Key (user_id, value_1_agg)=(1, 10) already exists.
2023-11-25 00:43:33.505 UTC [3758968] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:33.505 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:33.505 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	            (value_4_agg,
	             value_1_agg,
	             user_id)
	SELECT v4,
	       v1,
	       id
	FROM   (SELECT SUM(raw_events_second.value_4) AS v4,
	               SUM(raw_events_first.value_1) AS v1,
	               raw_events_second.user_id      AS id
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id = raw_events_second.user_id
	        GROUP  BY raw_events_second.user_id) AS foo
	ORDER  BY id;
2023-11-25 00:43:33.932 UTC [3758968] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:33.932 UTC [3758968] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:33.932 UTC [3758968] STATEMENT:  INSERT INTO agg_events (user_id)
	 SELECT
	   raw_events_first.user_id
	 FROM
	   raw_events_first LEFT JOIN raw_events_second ON raw_events_first.user_id = raw_events_second.value_1;
2023-11-25 00:43:34.019 UTC [3758968] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:43:34.019 UTC [3758968] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:43:34.019 UTC [3758968] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 00:43:34.019 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	             (user_id)
	 SELECT raw_events_second.user_id
	 FROM   raw_events_first,
	        raw_events_second
	 WHERE  raw_events_first.user_id = raw_events_first.value_1;
2023-11-25 00:43:34.019 UTC [3758968] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:34.019 UTC [3758968] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:34.019 UTC [3758968] STATEMENT:  INSERT INTO agg_events (user_id)
	 SELECT
	   raw_events_first.user_id
	 FROM
	   raw_events_first LEFT JOIN raw_events_second ON raw_events_first.value_1 = raw_events_second.value_1;
2023-11-25 00:43:34.125 UTC [3758968] ERROR:  XX000: EXPLAIN ANALYZE is currently not supported for INSERT ... SELECT commands via coordinator
2023-11-25 00:43:34.125 UTC [3758968] LOCATION:  NonPushableInsertSelectExplainScan, multi_explain.c:252
2023-11-25 00:43:34.125 UTC [3758968] STATEMENT:  EXPLAIN (costs off, analyze on)
	 INSERT INTO agg_events (user_id)
	 SELECT
	   raw_events_first.user_id
	 FROM
	   raw_events_first INNER JOIN raw_events_second ON raw_events_first.value_1 = raw_events_second.value_1;
2023-11-25 00:43:34.126 UTC [3758968] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:34.126 UTC [3758968] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:34.126 UTC [3758968] STATEMENT:  INSERT INTO agg_events (user_id)
	SELECT
	  raw_events_first.user_id
	FROM
	  raw_events_first LEFT JOIN raw_events_second ON raw_events_first.user_id = raw_events_second.value_1
	WHERE
	  raw_events_first.user_id = 10;
2023-11-25 00:43:34.141 UTC [3758968] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:43:34.141 UTC [3758968] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:43:34.141 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	            (value_4_agg,
	             value_1_agg,
	             user_id)
	SELECT v4,
	       v1,
	       id
	FROM   (SELECT SUM(raw_events_second.value_4) AS v4,
	               SUM(raw_events_first.value_1) AS v1,
	               raw_events_second.user_id      AS id
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id != raw_events_second.user_id
	        GROUP  BY raw_events_second.user_id) AS foo;
2023-11-25 00:43:34.145 UTC [3758968] ERROR:  22004: the partition column of table multi_insert_select.agg_events cannot be NULL
2023-11-25 00:43:34.145 UTC [3758968] LOCATION:  ShardIdForTuple, multi_copy.c:2592
2023-11-25 00:43:34.145 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	            (value_4_agg,
	             value_1_agg,
	             user_id)
	SELECT v4,
	       v1,
	       id
	FROM   (SELECT SUM(raw_events_second.value_4) AS v4,
	               SUM(raw_events_first.value_1) AS v1,
	               raw_events_second.value_3      AS id
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id = raw_events_second.user_id
	        GROUP  BY raw_events_second.value_3) AS foo;
2023-11-25 00:43:34.146 UTC [3758968] ERROR:  22004: the partition column of table multi_insert_select.raw_events_second should have a value
2023-11-25 00:43:34.146 UTC [3758968] LOCATION:  NonPushableInsertSelectExecScan, insert_select_executor.c:153
2023-11-25 00:43:34.146 UTC [3758968] STATEMENT:  INSERT INTO raw_events_second
	            (value_1)
	SELECT value_1
	FROM   raw_events_first;
2023-11-25 00:43:34.146 UTC [3758968] ERROR:  22004: the partition column of table multi_insert_select.raw_events_second should have a value
2023-11-25 00:43:34.146 UTC [3758968] LOCATION:  NonPushableInsertSelectExecScan, insert_select_executor.c:153
2023-11-25 00:43:34.146 UTC [3758968] STATEMENT:  INSERT INTO raw_events_second
	            (value_1)
	SELECT user_id
	FROM   raw_events_first;
2023-11-25 00:43:34.148 UTC [3758968] ERROR:  22004: the partition column value cannot be NULL
2023-11-25 00:43:34.148 UTC [3758968] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:34.148 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:34.148 UTC [3758968] STATEMENT:  INSERT INTO raw_events_second
	            (user_id)
	SELECT value_1
	FROM   raw_events_first;
2023-11-25 00:43:34.176 UTC [3758968] ERROR:  22004: the partition column value cannot be NULL
2023-11-25 00:43:34.176 UTC [3758968] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:34.176 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:34.176 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	            (value_3_agg,
	             value_4_agg,
	             value_1_agg,
	             value_2_agg,
	             user_id)
	SELECT SUM(value_3),
	       Count(value_4),
	       user_id,
	       SUM(value_1),
	       Avg(value_2)
	FROM   raw_events_first
	GROUP  BY user_id;
2023-11-25 00:43:34.184 UTC [3758968] ERROR:  22004: the partition column value cannot be NULL
2023-11-25 00:43:34.184 UTC [3758968] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:34.184 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:34.184 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	            (value_3_agg,
	             value_4_agg,
	             value_1_agg,
	             value_2_agg,
	             user_id)
	SELECT SUM(value_3),
	       Count(value_4),
	       user_id,
	       SUM(value_1),
	       value_2
	FROM   raw_events_first
	GROUP  BY user_id,
	          value_2;
2023-11-25 00:43:34.279 UTC [3758968] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 00:43:34.279 UTC [3758968] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:43:34.279 UTC [3758968] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:43:34.279 UTC [3758968] STATEMENT:  INSERT INTO agg_events
	            (user_id,
	             value_1_agg,
	             value_2_agg)
	SELECT user_id,
	       Sum(value_1) AS sum_val1,
	       Sum(value_2) AS sum_val2
	FROM   raw_events_second
	GROUP  BY grouping sets ( ( user_id ), ( value_1 ), ( user_id, value_1 ), ( ) );
2023-11-25 00:43:35.158 UTC [3758968] ERROR:  0A000: INSERT ... SELECT into an append-distributed table is not supported
2023-11-25 00:43:35.158 UTC [3758968] LOCATION:  NonPushableInsertSelectSupported, insert_select_planner.c:1572
2023-11-25 00:43:35.158 UTC [3758968] STATEMENT:  INSERT INTO insert_append_table (user_id, value_4)
	SELECT user_id, 1 FROM raw_events_second LIMIT 5;
2023-11-25 00:43:35.283 UTC [3758968] ERROR:  XX000: value too long for type character(1)
2023-11-25 00:43:35.283 UTC [3758968] LOCATION:  ReportCopyError, multi_copy.c:1193
2023-11-25 00:43:35.283 UTC [3758968] STATEMENT:  INSERT INTO coerce_agg(user_id, value_1_agg)
	SELECT *
	FROM (
	  SELECT user_id, value_1
	  FROM coerce_events
	) AS ftop
	LIMIT 5;
2023-11-25 00:43:35.304 UTC [3758968] ERROR:  XX000: value too long for type character(1)
2023-11-25 00:43:35.304 UTC [3758968] LOCATION:  ReportCopyError, multi_copy.c:1193
2023-11-25 00:43:35.304 UTC [3758968] STATEMENT:  INSERT INTO coerce_agg(user_id, value_1_agg)
	SELECT *
	FROM (
	  SELECT user_id, value_1
	  FROM coerce_events
	) AS ftop
	LIMIT 5;
2023-11-25 00:43:35.349 UTC [3758968] ERROR:  23514: new row for relation "coerce_agg_13300067" violates check constraint "small_number_13300067"
2023-11-25 00:43:35.349 UTC [3758968] DETAIL:  Failing row contains (10, 10).
2023-11-25 00:43:35.349 UTC [3758968] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:35.349 UTC [3758968] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:35.349 UTC [3758968] STATEMENT:  INSERT INTO coerce_agg(user_id, value_1_agg)
	SELECT *
	FROM (
	  SELECT user_id, value_1
	  FROM coerce_events
	) AS ftop;
2023-11-25 00:43:35.428 UTC [3758968] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:43:35.428 UTC [3758968] LOCATION:  ErrorIfOnConflictNotSupported, multi_router_planner.c:1255
2023-11-25 00:43:35.428 UTC [3758968] STATEMENT:  INSERT INTO agg_events AS ae
	            (
	                        user_id,
	                        value_1_agg,
	                        agg_time
	            )
	SELECT user_id,
	       value_1,
	       time
	FROM   raw_events_first
	ON conflict (user_id, value_1_agg)
	DO UPDATE
	   SET    user_id = 42
	RETURNING user_id, value_1_agg;
2023-11-25 00:43:35.984 UTC [3760155] ERROR:  42P01: relation "users_copy_table" does not exist at character 26
2023-11-25 00:43:35.984 UTC [3760155] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:43:35.984 UTC [3760155] STATEMENT:  SELECT SUM(value_3) FROM users_copy_table;
2023-11-25 00:43:36.344 UTC [3760155] ERROR:  21000: more than one row returned by a subquery used as an expression
2023-11-25 00:43:36.344 UTC [3760155] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:36.344 UTC [3760155] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:36.344 UTC [3760155] STATEMENT:  UPDATE users_test_table as utt
	SET    value_1 = 3
	WHERE value_2 > (SELECT value_3 FROM events_test_table as ett WHERE utt.user_id = ett.user_id);
2023-11-25 00:43:36.346 UTC [3760155] ERROR:  0A000: only reference tables may be queried when targeting a reference table with multi shard UPDATE/DELETE queries with multiple tables 
2023-11-25 00:43:36.346 UTC [3760155] LOCATION:  MultiShardUpdateDeleteSupported, multi_router_planner.c:1294
2023-11-25 00:43:36.346 UTC [3760155] STATEMENT:  UPDATE users_reference_copy_table
	SET    value_2 = 5
	FROM   events_test_table
	WHERE  users_reference_copy_table.user_id = events_test_table.user_id;
2023-11-25 00:43:36.346 UTC [3760155] ERROR:  0A000: a join with USING causes an internal naming conflict, use ON instead
2023-11-25 00:43:36.346 UTC [3760155] LOCATION:  MultiShardUpdateDeleteSupported, multi_router_planner.c:1279
2023-11-25 00:43:36.346 UTC [3760155] STATEMENT:  UPDATE events_test_table
	SET value_2 = users_test_table.user_id
	FROM users_test_table
	FULL OUTER JOIN events_test_table e2 USING (user_id)
	WHERE e2.user_id = events_test_table.user_id RETURNING events_test_table.value_2;
2023-11-25 00:43:36.369 UTC [3760155] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:36.369 UTC [3760155] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:36.369 UTC [3760155] STATEMENT:  UPDATE users_test_table
	SET    value_2 = (SELECT value_3
	                  FROM   users_test_table);
2023-11-25 00:43:36.369 UTC [3760155] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:36.369 UTC [3760155] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:36.369 UTC [3760155] STATEMENT:  UPDATE users_test_table
	SET value_2 = 2
	WHERE
	  value_2 >
	          (SELECT
	              max(value_2)
	           FROM
	              events_test_table
	           WHERE
	              users_test_table.user_id > events_test_table.user_id AND
	              users_test_table.value_1 = events_test_table.value_1
	           GROUP BY
	              user_id
	          );
2023-11-25 00:43:36.379 UTC [3760155] ERROR:  0A000: functions used in the WHERE/ON/WHEN clause of modification queries on distributed tables must not be VOLATILE
2023-11-25 00:43:36.379 UTC [3760155] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:616
2023-11-25 00:43:36.379 UTC [3760155] STATEMENT:  UPDATE users_test_table
	SET    value_2 = 5
	FROM   events_test_table
	WHERE  users_test_table.user_id = events_test_table.user_id * random();
2023-11-25 00:43:36.380 UTC [3760155] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 00:43:36.380 UTC [3760155] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:575
2023-11-25 00:43:36.380 UTC [3760155] STATEMENT:  UPDATE users_test_table
	SET    value_2 = 5 * random()
	FROM   events_test_table
	WHERE  users_test_table.user_id = events_test_table.user_id;
2023-11-25 00:43:36.380 UTC [3760155] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 00:43:36.380 UTC [3760155] LOCATION:  SingleShardUpdateDeleteSupported, multi_router_planner.c:1330
2023-11-25 00:43:36.380 UTC [3760155] STATEMENT:  UPDATE users_test_table
	SET    value_1 = 3
	WHERE  user_id = 1 AND value_1 IN (SELECT value_1
	                                   FROM users_test_table
	                                   WHERE user_id = 1 AND value_2 > random());
2023-11-25 00:43:36.380 UTC [3760155] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 00:43:36.380 UTC [3760155] LOCATION:  SingleShardUpdateDeleteSupported, multi_router_planner.c:1330
2023-11-25 00:43:36.380 UTC [3760155] STATEMENT:  UPDATE users_test_table
	SET    value_2 = subquery.random FROM (SELECT user_id, random()
	                                       FROM events_test_table) subquery
	WHERE  users_test_table.user_id = subquery.user_id;
2023-11-25 00:43:36.407 UTC [3760155] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:43:36.407 UTC [3760155] DETAIL:  Shards of relations in subquery need to have 1-to-1 shard partitioning
2023-11-25 00:43:36.407 UTC [3760155] LOCATION:  ErrorIfUnsupportedShardDistribution, multi_physical_planner.c:2432
2023-11-25 00:43:36.407 UTC [3760155] STATEMENT:  UPDATE users_test_table
	SET    value_2 = 5
	FROM   events_test_table_2
	WHERE  users_test_table.user_id = events_test_table_2.user_id;
2023-11-25 00:43:36.410 UTC [3760155] ERROR:  21000: more than one row returned by a subquery used as an expression
2023-11-25 00:43:36.410 UTC [3760155] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:36.410 UTC [3760155] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:36.410 UTC [3760155] STATEMENT:  DELETE FROM users_test_table
	WHERE  users_test_table.user_id = (SELECT user_id
	                                   FROM   events_test_table);
2023-11-25 00:43:36.416 UTC [3760155] ERROR:  0A000: cannot run DML queries with cursors
2023-11-25 00:43:36.416 UTC [3760155] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:655
2023-11-25 00:43:36.416 UTC [3760155] STATEMENT:  UPDATE users_test_table SET value_2 = 5 WHERE CURRENT OF test_cursor;
2023-11-25 00:43:36.457 UTC [3760155] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 00:43:36.457 UTC [3760155] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:575
2023-11-25 00:43:36.457 UTC [3760155] STATEMENT:  UPDATE test_table_2 SET double_col = random();
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400256 us JOIN public.events_table_1400260 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400257 us JOIN public.events_table_1400261 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400258 us JOIN public.events_table_1400262 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400259 us JOIN public.events_table_1400263 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 integer) ORDER BY user_id, sum LIMIT '5'::bigint
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 13 in 4444 microseconds
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.705 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.705 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.706 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 15 in 10074 microseconds
2023-11-25 00:43:36.706 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.706 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 821 microseconds on worker node localhost:57637
2023-11-25 00:43:36.706 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.706 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 933 microseconds on worker node localhost:57638
2023-11-25 00:43:36.706 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.707 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 416 microseconds on worker node localhost:57637
2023-11-25 00:43:36.707 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.707 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 781 microseconds on worker node localhost:57638
2023-11-25 00:43:36.707 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.709 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 16 in 3579 microseconds
2023-11-25 00:43:36.709 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.711 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 14 in 5580 microseconds
2023-11-25 00:43:36.711 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.711 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 13: 2 to node localhost:57637
2023-11-25 00:43:36.711 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.711 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 14: 0 to node localhost:57637
2023-11-25 00:43:36.711 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.711 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 15: 2 to node localhost:57638
2023-11-25 00:43:36.711 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.711 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 16: 0 to node localhost:57638
2023-11-25 00:43:36.711 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400256 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400260 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400257 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400261 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400258 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400262 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400259 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400263 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, value_1, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, sum bigint) ORDER BY sum DESC, value_1 DESC, user_id DESC LIMIT '5'::bigint
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 17 in 4444 microseconds
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.712 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 19 in 10074 microseconds
2023-11-25 00:43:36.712 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.713 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 818 microseconds on worker node localhost:57637
2023-11-25 00:43:36.713 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.713 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 883 microseconds on worker node localhost:57638
2023-11-25 00:43:36.713 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.714 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 506 microseconds on worker node localhost:57637
2023-11-25 00:43:36.714 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.714 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 799 microseconds on worker node localhost:57638
2023-11-25 00:43:36.714 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.716 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 18 in 4172 microseconds
2023-11-25 00:43:36.716 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.717 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 20 in 4342 microseconds
2023-11-25 00:43:36.717 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.717 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 17: 2 to node localhost:57637
2023-11-25 00:43:36.717 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.717 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 18: 0 to node localhost:57637
2023-11-25 00:43:36.717 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.717 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 19: 2 to node localhost:57638
2023-11-25 00:43:36.717 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.717 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 20: 0 to node localhost:57638
2023-11-25 00:43:36.717 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: push down of limit count: 10
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400256 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400257 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.724 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400258 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 00:43:36.724 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400259 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rank bigint) ORDER BY rank DESC, user_id LIMIT '10'::bigint
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 21 in 4444 microseconds
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.725 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.725 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.726 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 23 in 10074 microseconds
2023-11-25 00:43:36.726 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.727 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1831 microseconds on worker node localhost:57637
2023-11-25 00:43:36.727 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.727 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 731 microseconds on worker node localhost:57638
2023-11-25 00:43:36.727 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.727 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 536 microseconds on worker node localhost:57637
2023-11-25 00:43:36.727 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.727 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 500 microseconds on worker node localhost:57638
2023-11-25 00:43:36.727 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.730 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 24 in 3808 microseconds
2023-11-25 00:43:36.730 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.731 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 22 in 5804 microseconds
2023-11-25 00:43:36.731 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.731 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 21: 2 to node localhost:57637
2023-11-25 00:43:36.731 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.731 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 22: 0 to node localhost:57637
2023-11-25 00:43:36.731 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.731 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 23: 2 to node localhost:57638
2023-11-25 00:43:36.731 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.731 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 24: 0 to node localhost:57638
2023-11-25 00:43:36.731 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.736 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.736 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.736 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.736 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.736 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.736 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.736 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.736 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.736 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.736 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.736 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400256 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 00:43:36.736 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400257 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400258 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400259 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT user_id, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rank bigint, worker_column_3 integer) ORDER BY rank DESC, user_id
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 25 in 4444 microseconds
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.737 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 27 in 10074 microseconds
2023-11-25 00:43:36.737 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.738 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 726 microseconds on worker node localhost:57637
2023-11-25 00:43:36.738 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.738 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 390 microseconds on worker node localhost:57637
2023-11-25 00:43:36.738 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.739 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1356 microseconds on worker node localhost:57638
2023-11-25 00:43:36.739 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.740 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 1161 microseconds on worker node localhost:57638
2023-11-25 00:43:36.740 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.741 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 26 in 4049 microseconds
2023-11-25 00:43:36.741 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.742 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 28 in 5019 microseconds
2023-11-25 00:43:36.742 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.742 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 25: 2 to node localhost:57637
2023-11-25 00:43:36.742 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.742 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 26: 0 to node localhost:57637
2023-11-25 00:43:36.742 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.742 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 27: 2 to node localhost:57638
2023-11-25 00:43:36.742 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.742 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 28: 0 to node localhost:57638
2023-11-25 00:43:36.742 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.743 UTC [3760517] DEBUG:  00000: switching to sequential query execution mode
2023-11-25 00:43:36.743 UTC [3760517] DETAIL:  A command for a distributed view is run. To make sure subsequent commands see the view correctly we need to make sure to use only one connection for all future commands
2023-11-25 00:43:36.743 UTC [3760517] LOCATION:  EnsureSequentialMode, multi_executor.c:745
2023-11-25 00:43:36.743 UTC [3760517] DEBUG:  00000: drop auto-cascades to type window_view
2023-11-25 00:43:36.743 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:36.743 UTC [3760517] DEBUG:  00000: drop auto-cascades to type window_view[]
2023-11-25 00:43:36.743 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:36.743 UTC [3760517] DEBUG:  00000: drop auto-cascades to rule _RETURN on view window_view
2023-11-25 00:43:36.743 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:36.743 UTC [3760517] DEBUG:  00000: drop auto-cascades to type users_view
2023-11-25 00:43:36.743 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:36.743 UTC [3760517] DEBUG:  00000: drop auto-cascades to type users_view[]
2023-11-25 00:43:36.743 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:36.743 UTC [3760517] DEBUG:  00000: drop auto-cascades to rule _RETURN on view users_view
2023-11-25 00:43:36.743 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:36.744 UTC [3760517] DEBUG:  00000: EventTriggerInvoke 16675
2023-11-25 00:43:36.744 UTC [3760517] LOCATION:  EventTriggerInvoke, event_trigger.c:900
2023-11-25 00:43:36.747 UTC [3760517] DEBUG:  00000: opening 1 new connections to localhost:57637
2023-11-25 00:43:36.747 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.747 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 29 in 4444 microseconds
2023-11-25 00:43:36.747 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.747 UTC [3760517] DEBUG:  00000: opening 1 new connections to localhost:57638
2023-11-25 00:43:36.747 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.747 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 30 in 10074 microseconds
2023-11-25 00:43:36.747 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.752 UTC [3760517] DEBUG:  00000: task execution (0) for placement (0) on anchor shard (0) finished in 4257 microseconds on worker node localhost:57637
2023-11-25 00:43:36.752 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.752 UTC [3760517] DEBUG:  00000: task execution (0) for placement (0) on anchor shard (0) finished in 4487 microseconds on worker node localhost:57638
2023-11-25 00:43:36.752 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.752 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 29: 1 to node localhost:57637
2023-11-25 00:43:36.752 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.752 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 30: 1 to node localhost:57638
2023-11-25 00:43:36.752 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.753 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.753 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.753 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.753 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.753 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.753 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.753 UTC [3760517] DEBUG:  00000: Distributed planning for a fast-path router query
2023-11-25 00:43:36.753 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2322
2023-11-25 00:43:36.753 UTC [3760517] DEBUG:  00000: Creating router plan
2023-11-25 00:43:36.753 UTC [3760517] LOCATION:  CreateSingleTaskRouterSelectPlan, multi_router_planner.c:284
2023-11-25 00:43:36.753 UTC [3760517] DEBUG:  00000: generating subplan 8_1 for subquery SELECT min(k_no) AS min FROM public.users_ref_test_table
2023-11-25 00:43:36.753 UTC [3760517] LOCATION:  RecursivelyPlanSubquery, recursive_planning.c:1551
2023-11-25 00:43:36.753 UTC [3760517] DEBUG:  00000: Plan 8 query after replacing subqueries and CTEs: SELECT user_id, count(user_id) OVER (PARTITION BY user_id) AS count FROM public.users_table GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY user_id DESC, (count(user_id) OVER (PARTITION BY user_id)) DESC LIMIT 1
2023-11-25 00:43:36.753 UTC [3760517] LOCATION:  GenerateSubplansForSubqueriesAndCTEs, recursive_planning.c:248
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: push down of limit count: 1
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, count FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, count bigint) ORDER BY user_id DESC, count DESC LIMIT '1'::bigint
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: Subplan 8_1 is used in 8
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  RecordSubplanExecutionsOnNodes, intermediate_result_pruning.c:193
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: Subplan 8_1 will be sent to localhost:57637
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: Subplan 8_1 will be sent to localhost:57638
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: opening 1 new connections to localhost:57637
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 31 in 4444 microseconds
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: task execution (0) for placement (888) on anchor shard (1400284) finished in 243 microseconds on worker node localhost:57637
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.754 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 31: 1 to node localhost:57637
2023-11-25 00:43:36.754 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.755 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.755 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.755 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 32 in 4444 microseconds
2023-11-25 00:43:36.755 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.755 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.755 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.755 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 34 in 10074 microseconds
2023-11-25 00:43:36.755 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.756 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1134 microseconds on worker node localhost:57637
2023-11-25 00:43:36.756 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.757 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 515 microseconds on worker node localhost:57637
2023-11-25 00:43:36.757 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.757 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1944 microseconds on worker node localhost:57638
2023-11-25 00:43:36.757 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.758 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 547 microseconds on worker node localhost:57638
2023-11-25 00:43:36.758 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.758 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 33 in 3373 microseconds
2023-11-25 00:43:36.758 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.759 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 35 in 3843 microseconds
2023-11-25 00:43:36.759 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.759 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 32: 2 to node localhost:57637
2023-11-25 00:43:36.759 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.759 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 33: 0 to node localhost:57637
2023-11-25 00:43:36.759 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.759 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 34: 2 to node localhost:57638
2023-11-25 00:43:36.759 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.759 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 35: 0 to node localhost:57638
2023-11-25 00:43:36.759 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: push down of limit count: 10
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400260 events_table, public.users_table_1400256 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400261 events_table, public.users_table_1400257 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400262 events_table, public.users_table_1400258 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400263 events_table, public.users_table_1400259 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT ON (rnk, user_id) user_id, rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rnk bigint, worker_column_3 timestamp without time zone, worker_column_4 integer) ORDER BY rnk DESC, user_id DESC LIMIT '10'::bigint
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.761 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.761 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.762 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 36 in 4444 microseconds
2023-11-25 00:43:36.762 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.762 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.762 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.762 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 38 in 10074 microseconds
2023-11-25 00:43:36.762 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.763 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1565 microseconds on worker node localhost:57637
2023-11-25 00:43:36.763 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.764 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 746 microseconds on worker node localhost:57637
2023-11-25 00:43:36.764 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.765 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 37 in 3463 microseconds
2023-11-25 00:43:36.765 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.765 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 39 in 3404 microseconds
2023-11-25 00:43:36.765 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.765 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 3640 microseconds on worker node localhost:57638
2023-11-25 00:43:36.765 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.770 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 4754 microseconds on worker node localhost:57638
2023-11-25 00:43:36.770 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.770 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 36: 2 to node localhost:57637
2023-11-25 00:43:36.770 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.770 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 37: 0 to node localhost:57637
2023-11-25 00:43:36.770 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.770 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 38: 1 to node localhost:57638
2023-11-25 00:43:36.770 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.770 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 39: 1 to node localhost:57638
2023-11-25 00:43:36.770 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: push down of limit count: 10
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400260 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400261 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400262 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400263 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.771 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT ON (rnk, user_id) user_id, rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rnk bigint, worker_column_3 timestamp without time zone, worker_column_4 integer) ORDER BY rnk DESC, user_id DESC LIMIT '10'::bigint
2023-11-25 00:43:36.771 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.772 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.772 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.772 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 40 in 4444 microseconds
2023-11-25 00:43:36.772 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.772 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.772 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.772 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 42 in 10074 microseconds
2023-11-25 00:43:36.772 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.772 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 600 microseconds on worker node localhost:57637
2023-11-25 00:43:36.772 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.773 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 665 microseconds on worker node localhost:57638
2023-11-25 00:43:36.773 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.773 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 476 microseconds on worker node localhost:57637
2023-11-25 00:43:36.773 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.773 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 576 microseconds on worker node localhost:57638
2023-11-25 00:43:36.773 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.775 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 43 in 3515 microseconds
2023-11-25 00:43:36.775 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.777 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 41 in 5302 microseconds
2023-11-25 00:43:36.777 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.777 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 40: 2 to node localhost:57637
2023-11-25 00:43:36.777 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.777 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 41: 0 to node localhost:57637
2023-11-25 00:43:36.777 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.777 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 42: 2 to node localhost:57638
2023-11-25 00:43:36.777 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.777 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 43: 0 to node localhost:57638
2023-11-25 00:43:36.777 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.778 UTC [3760517] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400260 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.778 UTC [3760517] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400261 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.778 UTC [3760517] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400262 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.778 UTC [3760517] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400263 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT ON ((rank() OVER my_win), user_id) user_id, rank() OVER my_win AS rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1 2)'::cstring(0)) remote_scan(user_id integer, worker_column_2 timestamp without time zone, worker_column_3 integer, worker_column_4 integer) WINDOW my_win AS (PARTITION BY worker_column_3, worker_column_4 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, user_id DESC LIMIT '10'::bigint
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.778 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 44 in 4444 microseconds
2023-11-25 00:43:36.778 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.779 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.779 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.779 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 46 in 10074 microseconds
2023-11-25 00:43:36.779 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.780 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 1141 microseconds on worker node localhost:57638
2023-11-25 00:43:36.780 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.780 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 1436 microseconds on worker node localhost:57637
2023-11-25 00:43:36.780 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.780 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 361 microseconds on worker node localhost:57638
2023-11-25 00:43:36.780 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.780 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 355 microseconds on worker node localhost:57637
2023-11-25 00:43:36.780 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.782 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 47 in 3238 microseconds
2023-11-25 00:43:36.782 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.783 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 45 in 4427 microseconds
2023-11-25 00:43:36.783 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.783 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 44: 2 to node localhost:57637
2023-11-25 00:43:36.783 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.783 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 45: 0 to node localhost:57637
2023-11-25 00:43:36.783 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.783 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 46: 2 to node localhost:57638
2023-11-25 00:43:36.783 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.783 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 47: 0 to node localhost:57638
2023-11-25 00:43:36.783 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400260 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400261 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.784 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400262 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 00:43:36.784 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.785 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400263 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 00:43:36.785 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.785 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.785 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.785 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.785 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.785 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.785 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.785 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.785 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.785 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, rnk, avg_val_2 FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rnk bigint, avg_val_2 numeric, worker_column_4 timestamp without time zone, worker_column_5 numeric) ORDER BY avg_val_2 DESC, rnk DESC, user_id DESC
2023-11-25 00:43:36.785 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.787 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.787 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.788 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 48 in 4444 microseconds
2023-11-25 00:43:36.788 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.788 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.788 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.789 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 50 in 10074 microseconds
2023-11-25 00:43:36.789 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.789 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 1108 microseconds on worker node localhost:57637
2023-11-25 00:43:36.789 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.789 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 515 microseconds on worker node localhost:57637
2023-11-25 00:43:36.789 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.790 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 918 microseconds on worker node localhost:57638
2023-11-25 00:43:36.790 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.790 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 423 microseconds on worker node localhost:57638
2023-11-25 00:43:36.790 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.792 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 49 in 4292 microseconds
2023-11-25 00:43:36.792 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.792 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 51 in 3280 microseconds
2023-11-25 00:43:36.792 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.792 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 48: 2 to node localhost:57637
2023-11-25 00:43:36.792 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.792 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 49: 0 to node localhost:57637
2023-11-25 00:43:36.792 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.792 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 50: 2 to node localhost:57638
2023-11-25 00:43:36.792 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.792 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 51: 0 to node localhost:57638
2023-11-25 00:43:36.792 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.793 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.793 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.793 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.793 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.793 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.793 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400256 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400257 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400258 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400259 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: combine query: SELECT count, cnt1, cnt2, datee, rnnk, filtered_count, cnt_with_filter_2 FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(count bigint, cnt1 bigint, cnt2 bigint, datee timestamp without time zone, rnnk bigint, filtered_count numeric, cnt_with_filter_2 double precision, worker_column_8 integer, worker_column_9 timestamp without time zone, worker_column_10 integer, worker_column_11 integer, worker_column_12 timestamp without time zone, worker_column_13 integer, worker_column_14 double precision, worker_column_15 integer, worker_column_16 integer) ORDER BY cnt_with_filter_2 DESC NULLS LAST, filtered_count DESC NULLS LAST, datee DESC NULLS LAST, rnnk DESC, cnt2 DESC, cnt1 DESC, worker_column_8 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 52 in 4444 microseconds
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.794 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.794 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.795 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 54 in 10074 microseconds
2023-11-25 00:43:36.795 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.797 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 2140 microseconds on worker node localhost:57637
2023-11-25 00:43:36.797 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.797 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 2501 microseconds on worker node localhost:57638
2023-11-25 00:43:36.797 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.798 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 940 microseconds on worker node localhost:57637
2023-11-25 00:43:36.798 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.798 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 53 in 3283 microseconds
2023-11-25 00:43:36.798 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.798 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 55 in 3200 microseconds
2023-11-25 00:43:36.798 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.799 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 1349 microseconds on worker node localhost:57638
2023-11-25 00:43:36.799 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.799 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 52: 2 to node localhost:57637
2023-11-25 00:43:36.799 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.799 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 53: 0 to node localhost:57637
2023-11-25 00:43:36.799 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.799 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 54: 2 to node localhost:57638
2023-11-25 00:43:36.799 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.799 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 55: 0 to node localhost:57638
2023-11-25 00:43:36.799 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.799 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.799 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.799 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.799 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400260 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400261 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400262 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400263 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, my_rank, avg, mx_time FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, my_rank bigint, avg numeric, mx_time timestamp without time zone, worker_column_5 integer, worker_column_6 bigint, worker_column_7 integer, worker_column_8 numeric) ORDER BY avg DESC, mx_time DESC, my_rank DESC, user_id DESC
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.800 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 56 in 4444 microseconds
2023-11-25 00:43:36.800 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.801 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.801 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.801 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 58 in 10074 microseconds
2023-11-25 00:43:36.801 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.803 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 2547 microseconds on worker node localhost:57637
2023-11-25 00:43:36.803 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.803 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 2443 microseconds on worker node localhost:57638
2023-11-25 00:43:36.803 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.804 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 602 microseconds on worker node localhost:57637
2023-11-25 00:43:36.804 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.804 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 587 microseconds on worker node localhost:57638
2023-11-25 00:43:36.804 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.805 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 57 in 4251 microseconds
2023-11-25 00:43:36.805 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.808 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 59 in 7052 microseconds
2023-11-25 00:43:36.808 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.808 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 56: 2 to node localhost:57637
2023-11-25 00:43:36.808 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.808 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 57: 0 to node localhost:57637
2023-11-25 00:43:36.808 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.808 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 58: 2 to node localhost:57638
2023-11-25 00:43:36.808 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.808 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 59: 0 to node localhost:57638
2023-11-25 00:43:36.808 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, rank, dense_rank, cume_dist, percent_rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rank bigint, dense_rank bigint, cume_dist double precision, percent_rank double precision, worker_column_6 numeric) ORDER BY cume_dist DESC, dense_rank DESC, rank DESC, user_id DESC
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.809 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.809 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.810 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 60 in 4444 microseconds
2023-11-25 00:43:36.810 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.810 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.810 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.810 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 62 in 10074 microseconds
2023-11-25 00:43:36.810 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.810 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 584 microseconds on worker node localhost:57637
2023-11-25 00:43:36.810 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.811 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 388 microseconds on worker node localhost:57637
2023-11-25 00:43:36.811 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.811 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1095 microseconds on worker node localhost:57638
2023-11-25 00:43:36.811 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.811 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 423 microseconds on worker node localhost:57638
2023-11-25 00:43:36.811 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.815 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 61 in 4864 microseconds
2023-11-25 00:43:36.815 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.816 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 63 in 6451 microseconds
2023-11-25 00:43:36.816 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.816 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 60: 2 to node localhost:57637
2023-11-25 00:43:36.816 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.816 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 61: 0 to node localhost:57637
2023-11-25 00:43:36.816 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.816 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 62: 2 to node localhost:57638
2023-11-25 00:43:36.816 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.816 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 63: 0 to node localhost:57638
2023-11-25 00:43:36.816 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.817 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.817 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.817 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.817 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.817 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.817 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.817 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.817 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.817 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.817 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, value_1, array_agg, array_agg_1 AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, array_agg integer[], array_agg_1 integer[]) ORDER BY user_id, value_1, array_agg, array_agg_1
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 64 in 4444 microseconds
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.818 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 66 in 10074 microseconds
2023-11-25 00:43:36.818 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.819 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1099 microseconds on worker node localhost:57637
2023-11-25 00:43:36.819 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.819 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1091 microseconds on worker node localhost:57638
2023-11-25 00:43:36.819 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.820 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 362 microseconds on worker node localhost:57637
2023-11-25 00:43:36.820 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.820 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 468 microseconds on worker node localhost:57638
2023-11-25 00:43:36.820 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.822 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 67 in 3425 microseconds
2023-11-25 00:43:36.822 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.822 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 65 in 3978 microseconds
2023-11-25 00:43:36.822 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.822 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 64: 2 to node localhost:57637
2023-11-25 00:43:36.822 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.822 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 65: 0 to node localhost:57637
2023-11-25 00:43:36.822 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.822 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 66: 2 to node localhost:57638
2023-11-25 00:43:36.822 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.822 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 67: 0 to node localhost:57638
2023-11-25 00:43:36.822 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.824 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, value_1, array_agg, array_agg_1 AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, array_agg integer[], array_agg_1 integer[]) ORDER BY user_id, value_1, array_agg, array_agg_1
2023-11-25 00:43:36.824 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.825 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.825 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.825 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 68 in 4444 microseconds
2023-11-25 00:43:36.825 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.825 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.825 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.825 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 70 in 10074 microseconds
2023-11-25 00:43:36.825 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.826 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 936 microseconds on worker node localhost:57637
2023-11-25 00:43:36.826 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.826 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 388 microseconds on worker node localhost:57637
2023-11-25 00:43:36.826 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 2967 microseconds on worker node localhost:57638
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 69 in 3378 microseconds
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 328 microseconds on worker node localhost:57638
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 71 in 3498 microseconds
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 68: 2 to node localhost:57637
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 69: 0 to node localhost:57637
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 70: 2 to node localhost:57638
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.828 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 71: 0 to node localhost:57638
2023-11-25 00:43:36.828 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.830 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.830 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, value_1, array_agg, array_agg_1 AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, array_agg integer[], array_agg_1 integer[]) ORDER BY user_id, value_1, array_agg, array_agg_1
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 72 in 4444 microseconds
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.831 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 74 in 10074 microseconds
2023-11-25 00:43:36.831 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.832 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 843 microseconds on worker node localhost:57637
2023-11-25 00:43:36.832 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.832 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 401 microseconds on worker node localhost:57637
2023-11-25 00:43:36.832 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.832 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1300 microseconds on worker node localhost:57638
2023-11-25 00:43:36.832 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.834 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 1119 microseconds on worker node localhost:57638
2023-11-25 00:43:36.834 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.835 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 73 in 4124 microseconds
2023-11-25 00:43:36.835 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.835 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 75 in 4000 microseconds
2023-11-25 00:43:36.835 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.835 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 72: 2 to node localhost:57637
2023-11-25 00:43:36.835 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.835 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 73: 0 to node localhost:57637
2023-11-25 00:43:36.835 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.835 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 74: 2 to node localhost:57638
2023-11-25 00:43:36.835 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.835 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 75: 0 to node localhost:57638
2023-11-25 00:43:36.835 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.836 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.836 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.836 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.836 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.836 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.836 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.837 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.837 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.837 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.837 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.837 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.837 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.837 UTC [3760517] DEBUG:  00000: combine query: SELECT value_2, rank() OVER (PARTITION BY value_2 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY value_2 ORDER BY (pg_catalog.sum(worker_column_2) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_3)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, worker_column_2 bigint, worker_column_3 bigint) GROUP BY value_2 ORDER BY (cume_dist() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)) DESC, (dense_rank() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)) DESC, (rank() OVER (PARTITION BY value_2 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)) DESC, value_2 DESC
2023-11-25 00:43:36.837 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.837 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.837 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.837 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 76 in 4444 microseconds
2023-11-25 00:43:36.837 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.837 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.837 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.839 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 78 in 10074 microseconds
2023-11-25 00:43:36.839 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.840 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 2513 microseconds on worker node localhost:57637
2023-11-25 00:43:36.840 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.840 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 325 microseconds on worker node localhost:57637
2023-11-25 00:43:36.840 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.840 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 486 microseconds on worker node localhost:57638
2023-11-25 00:43:36.840 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.840 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 315 microseconds on worker node localhost:57638
2023-11-25 00:43:36.840 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.843 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 79 in 3832 microseconds
2023-11-25 00:43:36.843 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.846 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 77 in 9328 microseconds
2023-11-25 00:43:36.846 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.846 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 76: 2 to node localhost:57637
2023-11-25 00:43:36.846 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.846 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 77: 0 to node localhost:57637
2023-11-25 00:43:36.846 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.846 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 78: 2 to node localhost:57638
2023-11-25 00:43:36.846 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.846 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 79: 0 to node localhost:57638
2023-11-25 00:43:36.846 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.847 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400256 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.847 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400257 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.847 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400258 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.847 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400259 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.847 UTC [3760517] DEBUG:  00000: combine query: SELECT value_2, value_1, array_agg(array_agg) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(array_agg_1) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, value_1 integer, array_agg integer, array_agg_1 integer) ORDER BY value_2, value_1, (array_agg(array_agg) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)), (array_agg(array_agg_1) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW))
2023-11-25 00:43:36.847 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.848 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.848 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.848 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 80 in 4444 microseconds
2023-11-25 00:43:36.848 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.848 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.848 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.848 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 82 in 10074 microseconds
2023-11-25 00:43:36.848 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.848 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 718 microseconds on worker node localhost:57637
2023-11-25 00:43:36.848 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.849 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 625 microseconds on worker node localhost:57638
2023-11-25 00:43:36.849 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.849 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 283 microseconds on worker node localhost:57637
2023-11-25 00:43:36.849 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.849 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 791 microseconds on worker node localhost:57638
2023-11-25 00:43:36.849 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.851 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 83 in 3579 microseconds
2023-11-25 00:43:36.851 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.856 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 81 in 7972 microseconds
2023-11-25 00:43:36.856 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.856 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 80: 2 to node localhost:57637
2023-11-25 00:43:36.856 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.856 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 81: 0 to node localhost:57637
2023-11-25 00:43:36.856 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.856 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 82: 2 to node localhost:57638
2023-11-25 00:43:36.856 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.856 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 83: 0 to node localhost:57638
2023-11-25 00:43:36.856 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.857 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400256 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.857 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400257 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.857 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400258 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.857 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.857 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400259 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.857 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: combine query: SELECT value_2, value_1, array_agg(array_agg) OVER range_window AS array_agg, array_agg(array_agg_1) OVER range_window_exclude AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, value_1 integer, array_agg integer, array_agg_1 integer) WINDOW range_window AS (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW) ORDER BY value_2, value_1, (array_agg(array_agg) OVER range_window), (array_agg(array_agg_1) OVER range_window_exclude)
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 84 in 4444 microseconds
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.858 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 86 in 10074 microseconds
2023-11-25 00:43:36.858 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.859 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 824 microseconds on worker node localhost:57637
2023-11-25 00:43:36.859 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.859 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 742 microseconds on worker node localhost:57638
2023-11-25 00:43:36.859 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.861 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 2108 microseconds on worker node localhost:57637
2023-11-25 00:43:36.861 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.861 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 2056 microseconds on worker node localhost:57638
2023-11-25 00:43:36.861 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.861 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 85 in 3541 microseconds
2023-11-25 00:43:36.861 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.862 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 87 in 3743 microseconds
2023-11-25 00:43:36.862 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.862 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 84: 2 to node localhost:57637
2023-11-25 00:43:36.862 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.862 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 85: 0 to node localhost:57637
2023-11-25 00:43:36.862 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.862 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 86: 2 to node localhost:57638
2023-11-25 00:43:36.862 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.862 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 87: 0 to node localhost:57638
2023-11-25 00:43:36.862 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.863 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400256 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.863 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400257 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.863 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400258 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.863 UTC [3760517] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400259 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.863 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.863 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.864 UTC [3760517] DEBUG:  00000: combine query: SELECT value_2, value_1, array_agg(array_agg) OVER row_window AS array_agg, array_agg(array_agg_1) OVER row_window_exclude AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, value_1 integer, array_agg integer, array_agg_1 integer) WINDOW row_window AS (PARTITION BY value_2 ORDER BY value_1 ROWS BETWEEN '1'::bigint PRECEDING AND '1'::bigint FOLLOWING), row_window_exclude AS (PARTITION BY value_2 ORDER BY value_1 ROWS BETWEEN '1'::bigint PRECEDING AND '1'::bigint FOLLOWING EXCLUDE CURRENT ROW) ORDER BY value_2, value_1, (array_agg(array_agg) OVER row_window), (array_agg(array_agg_1) OVER row_window_exclude)
2023-11-25 00:43:36.864 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.864 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.864 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.864 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 88 in 4444 microseconds
2023-11-25 00:43:36.864 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.864 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.864 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.864 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 90 in 10074 microseconds
2023-11-25 00:43:36.864 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.864 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 370 microseconds on worker node localhost:57637
2023-11-25 00:43:36.864 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.865 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 418 microseconds on worker node localhost:57637
2023-11-25 00:43:36.865 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.865 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 974 microseconds on worker node localhost:57638
2023-11-25 00:43:36.865 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.865 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 481 microseconds on worker node localhost:57638
2023-11-25 00:43:36.865 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.867 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 89 in 3243 microseconds
2023-11-25 00:43:36.867 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.867 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 91 in 3232 microseconds
2023-11-25 00:43:36.867 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.867 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 88: 2 to node localhost:57637
2023-11-25 00:43:36.867 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.867 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 89: 0 to node localhost:57637
2023-11-25 00:43:36.867 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.867 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 90: 2 to node localhost:57638
2023-11-25 00:43:36.867 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.867 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 91: 0 to node localhost:57638
2023-11-25 00:43:36.867 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.868 UTC [3760515] ERROR:  22004: the partition column of table insert_select_repartition.target_table should have a value
2023-11-25 00:43:36.868 UTC [3760515] LOCATION:  NonPushableInsertSelectExecScan, insert_select_executor.c:153
2023-11-25 00:43:36.868 UTC [3760515] STATEMENT:  INSERT INTO target_table(value) SELECT value FROM source_table;
2023-11-25 00:43:36.868 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.868 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.868 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.868 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.868 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.868 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.868 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.868 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.868 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:36.868 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.868 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:36.868 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.868 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400260 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.868 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400261 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400262 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400263 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, sum, event_type FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, event_type integer, worker_column_4 bigint, worker_column_5 integer) ORDER BY sum DESC, event_type DESC, user_id DESC LIMIT '5'::bigint
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 92 in 4444 microseconds
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.869 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 94 in 10074 microseconds
2023-11-25 00:43:36.869 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.871 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 1894 microseconds on worker node localhost:57637
2023-11-25 00:43:36.871 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.872 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 2189 microseconds on worker node localhost:57638
2023-11-25 00:43:36.872 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.872 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 887 microseconds on worker node localhost:57637
2023-11-25 00:43:36.872 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.872 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 861 microseconds on worker node localhost:57638
2023-11-25 00:43:36.872 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.873 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 93 in 3690 microseconds
2023-11-25 00:43:36.873 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.876 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 95 in 6658 microseconds
2023-11-25 00:43:36.876 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.876 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 92: 2 to node localhost:57637
2023-11-25 00:43:36.876 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.876 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 93: 0 to node localhost:57637
2023-11-25 00:43:36.876 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.876 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 94: 2 to node localhost:57638
2023-11-25 00:43:36.876 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.876 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 95: 0 to node localhost:57638
2023-11-25 00:43:36.876 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.877 UTC [3760517] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_1"
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.877 UTC [3760517] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_1"
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.877 UTC [3760517] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_1"
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.877 UTC [3760517] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_1"
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: combine query: SELECT value_1, (sum(avg) OPERATOR(pg_catalog./) (pg_catalog.sum(avg_1))::double precision) AS avg, dense_rank() OVER (PARTITION BY (sum(avg) OPERATOR(pg_catalog./) (pg_catalog.sum(avg_1))::double precision) ORDER BY (pg_catalog.sum(worker_column_4) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_5))) AS dense_rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_1 integer, avg double precision, avg_1 bigint, worker_column_4 bigint, worker_column_5 bigint) GROUP BY value_1 ORDER BY value_1
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.877 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.877 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.878 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 96 in 4444 microseconds
2023-11-25 00:43:36.878 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.878 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.878 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.878 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 98 in 10074 microseconds
2023-11-25 00:43:36.878 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.879 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1309 microseconds on worker node localhost:57637
2023-11-25 00:43:36.879 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.879 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1203 microseconds on worker node localhost:57638
2023-11-25 00:43:36.879 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.879 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 362 microseconds on worker node localhost:57637
2023-11-25 00:43:36.879 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.880 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 621 microseconds on worker node localhost:57638
2023-11-25 00:43:36.880 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.881 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 97 in 3752 microseconds
2023-11-25 00:43:36.881 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.882 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 99 in 4390 microseconds
2023-11-25 00:43:36.882 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.882 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 96: 2 to node localhost:57637
2023-11-25 00:43:36.882 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.882 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 97: 0 to node localhost:57637
2023-11-25 00:43:36.882 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.882 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 98: 2 to node localhost:57638
2023-11-25 00:43:36.882 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.882 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 99: 0 to node localhost:57638
2023-11-25 00:43:36.882 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 integer, worker_column_4 integer) ORDER BY sum DESC, user_id LIMIT '10'::bigint
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.883 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 100 in 4444 microseconds
2023-11-25 00:43:36.883 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.884 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.884 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.884 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 102 in 10074 microseconds
2023-11-25 00:43:36.884 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.884 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 807 microseconds on worker node localhost:57637
2023-11-25 00:43:36.884 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.885 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 831 microseconds on worker node localhost:57638
2023-11-25 00:43:36.885 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.885 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 516 microseconds on worker node localhost:57637
2023-11-25 00:43:36.885 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.885 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 453 microseconds on worker node localhost:57638
2023-11-25 00:43:36.885 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.887 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 101 in 3848 microseconds
2023-11-25 00:43:36.887 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.887 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 103 in 3689 microseconds
2023-11-25 00:43:36.887 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.887 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 100: 2 to node localhost:57637
2023-11-25 00:43:36.887 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.887 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 101: 0 to node localhost:57637
2023-11-25 00:43:36.887 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.887 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 102: 2 to node localhost:57638
2023-11-25 00:43:36.887 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.887 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 103: 0 to node localhost:57638
2023-11-25 00:43:36.887 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.888 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.888 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.888 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.888 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.888 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.888 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT ON (user_id) user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 integer, worker_column_4 integer) ORDER BY user_id, sum DESC LIMIT '10'::bigint
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.889 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.889 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.890 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 104 in 4444 microseconds
2023-11-25 00:43:36.890 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.890 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.890 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.890 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 106 in 10074 microseconds
2023-11-25 00:43:36.890 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.890 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 532 microseconds on worker node localhost:57637
2023-11-25 00:43:36.890 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.890 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 574 microseconds on worker node localhost:57638
2023-11-25 00:43:36.890 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.891 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 432 microseconds on worker node localhost:57638
2023-11-25 00:43:36.891 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.891 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 742 microseconds on worker node localhost:57637
2023-11-25 00:43:36.891 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.893 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 105 in 3568 microseconds
2023-11-25 00:43:36.893 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.893 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 107 in 3436 microseconds
2023-11-25 00:43:36.893 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.893 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 104: 2 to node localhost:57637
2023-11-25 00:43:36.893 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.893 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 105: 0 to node localhost:57637
2023-11-25 00:43:36.893 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.893 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 106: 2 to node localhost:57638
2023-11-25 00:43:36.893 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.893 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 107: 0 to node localhost:57638
2023-11-25 00:43:36.893 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT ON (worker_column_3) user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 bigint, worker_column_4 integer, worker_column_5 integer) ORDER BY worker_column_3, sum DESC, user_id LIMIT '10'::bigint
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 108 in 4444 microseconds
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.894 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.894 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.895 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 110 in 10074 microseconds
2023-11-25 00:43:36.895 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.895 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 944 microseconds on worker node localhost:57637
2023-11-25 00:43:36.895 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.896 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 445 microseconds on worker node localhost:57637
2023-11-25 00:43:36.896 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.896 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1282 microseconds on worker node localhost:57638
2023-11-25 00:43:36.896 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.896 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 374 microseconds on worker node localhost:57638
2023-11-25 00:43:36.896 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.900 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 111 in 5472 microseconds
2023-11-25 00:43:36.900 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 109 in 9138 microseconds
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 108: 2 to node localhost:57637
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 109: 0 to node localhost:57637
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 110: 2 to node localhost:57638
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 111: 0 to node localhost:57638
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.904 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.904 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, avg_1 AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, avg_1 numeric, worker_column_4 integer, worker_column_5 integer, worker_column_6 integer, worker_column_7 numeric) ORDER BY avg_1 DESC, avg DESC, user_id DESC
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 112 in 4444 microseconds
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.905 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 114 in 10074 microseconds
2023-11-25 00:43:36.905 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.906 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 730 microseconds on worker node localhost:57638
2023-11-25 00:43:36.906 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.907 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 475 microseconds on worker node localhost:57638
2023-11-25 00:43:36.907 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.907 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1901 microseconds on worker node localhost:57637
2023-11-25 00:43:36.907 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.908 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 830 microseconds on worker node localhost:57637
2023-11-25 00:43:36.908 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.909 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 115 in 3615 microseconds
2023-11-25 00:43:36.909 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.912 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 113 in 6858 microseconds
2023-11-25 00:43:36.912 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.912 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 112: 2 to node localhost:57637
2023-11-25 00:43:36.912 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.912 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 113: 0 to node localhost:57637
2023-11-25 00:43:36.912 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.912 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 114: 2 to node localhost:57638
2023-11-25 00:43:36.912 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.912 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 115: 0 to node localhost:57638
2023-11-25 00:43:36.912 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.913 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, avg_1 AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, avg_1 numeric, worker_column_4 integer, worker_column_5 integer, worker_column_6 integer, worker_column_7 numeric) ORDER BY avg_1 DESC, avg DESC, user_id DESC
2023-11-25 00:43:36.913 UTC [3760517] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:43:36.913 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.915 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.915 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.915 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.915 UTC [3760517] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_2"
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.915 UTC [3760517] DEBUG:  00000: combine query: SELECT value_2, avg((pg_catalog.sum(avg) OPERATOR(pg_catalog./) pg_catalog.sum(avg_1))) OVER (PARTITION BY value_2, (max(worker_column_6)), (min(worker_column_7))) AS avg, avg((pg_catalog.sum(avg_2) OPERATOR(pg_catalog./) pg_catalog.sum(avg_3))) OVER (PARTITION BY value_2, (min(worker_column_7)), (pg_catalog.sum(worker_column_8) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_9))) AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, avg bigint, avg_1 bigint, avg_2 bigint, avg_3 bigint, worker_column_6 integer, worker_column_7 integer, worker_column_8 bigint, worker_column_9 bigint) GROUP BY value_2 ORDER BY (avg((pg_catalog.sum(avg_2) OPERATOR(pg_catalog./) pg_catalog.sum(avg_3))) OVER (PARTITION BY value_2, (min(worker_column_7)), (pg_catalog.sum(worker_column_8) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_9)))) DESC, (avg((pg_catalog.sum(avg) OPERATOR(pg_catalog./) pg_catalog.sum(avg_1))) OVER (PARTITION BY value_2, (max(worker_column_6)), (min(worker_column_7)))) DESC, value_2 DESC
2023-11-25 00:43:36.915 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.916 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.916 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.916 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 116 in 4444 microseconds
2023-11-25 00:43:36.916 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.916 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.916 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.916 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 118 in 10074 microseconds
2023-11-25 00:43:36.916 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.916 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 520 microseconds on worker node localhost:57637
2023-11-25 00:43:36.916 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.916 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 410 microseconds on worker node localhost:57638
2023-11-25 00:43:36.916 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.919 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 2504 microseconds on worker node localhost:57637
2023-11-25 00:43:36.919 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.919 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 2485 microseconds on worker node localhost:57638
2023-11-25 00:43:36.919 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.921 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 117 in 5052 microseconds
2023-11-25 00:43:36.921 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.921 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 119 in 5081 microseconds
2023-11-25 00:43:36.921 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.921 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 116: 2 to node localhost:57637
2023-11-25 00:43:36.921 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.921 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 117: 0 to node localhost:57637
2023-11-25 00:43:36.921 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.921 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 118: 2 to node localhost:57638
2023-11-25 00:43:36.921 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.921 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 119: 0 to node localhost:57638
2023-11-25 00:43:36.921 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.922 UTC [3760517] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.922 UTC [3760517] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.922 UTC [3760517] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.922 UTC [3760517] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.922 UTC [3760517] DEBUG:  00000: combine query: SELECT value_2, user_id, avg(avg) OVER (PARTITION BY value_2, worker_column_5, worker_column_6) AS avg, avg(avg_1) OVER (PARTITION BY user_id, worker_column_6, worker_column_7) AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, user_id integer, avg numeric, avg_1 numeric, worker_column_5 integer, worker_column_6 integer, worker_column_7 numeric) ORDER BY (avg(avg) OVER (PARTITION BY value_2, worker_column_5, worker_column_6)) DESC, user_id DESC, value_2 DESC
2023-11-25 00:43:36.922 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.923 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.923 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.923 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 120 in 4444 microseconds
2023-11-25 00:43:36.923 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.923 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.923 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.924 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 122 in 10074 microseconds
2023-11-25 00:43:36.924 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.926 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 2194 microseconds on worker node localhost:57637
2023-11-25 00:43:36.926 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.926 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 2092 microseconds on worker node localhost:57638
2023-11-25 00:43:36.926 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.926 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 416 microseconds on worker node localhost:57637
2023-11-25 00:43:36.926 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.926 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 395 microseconds on worker node localhost:57638
2023-11-25 00:43:36.926 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.927 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 121 in 3627 microseconds
2023-11-25 00:43:36.927 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.929 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 123 in 5164 microseconds
2023-11-25 00:43:36.929 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.929 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 120: 2 to node localhost:57637
2023-11-25 00:43:36.929 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.929 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 121: 0 to node localhost:57637
2023-11-25 00:43:36.929 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.929 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 122: 2 to node localhost:57638
2023-11-25 00:43:36.929 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.929 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 123: 0 to node localhost:57638
2023-11-25 00:43:36.929 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.930 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.930 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.930 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.930 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.930 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.930 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:36.931 UTC [3760517] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400256 users_table WHERE true GROUP BY user_id"
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:36.931 UTC [3760517] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400257 users_table WHERE true GROUP BY user_id"
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:36.931 UTC [3760517] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400258 users_table WHERE true GROUP BY user_id"
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:36.931 UTC [3760517] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400259 users_table WHERE true GROUP BY user_id"
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, sum(sum) OVER () AS sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(user_id integer, sum numeric) ORDER BY user_id LIMIT '10'::bigint
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 124 in 4444 microseconds
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 126 in 10074 microseconds
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.931 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 432 microseconds on worker node localhost:57637
2023-11-25 00:43:36.931 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.932 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 426 microseconds on worker node localhost:57638
2023-11-25 00:43:36.932 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.932 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 520 microseconds on worker node localhost:57637
2023-11-25 00:43:36.932 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.932 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 827 microseconds on worker node localhost:57638
2023-11-25 00:43:36.932 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.935 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 125 in 3688 microseconds
2023-11-25 00:43:36.935 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.937 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 127 in 6004 microseconds
2023-11-25 00:43:36.937 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.937 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 124: 2 to node localhost:57637
2023-11-25 00:43:36.937 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.937 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 125: 0 to node localhost:57637
2023-11-25 00:43:36.937 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.937 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 126: 2 to node localhost:57638
2023-11-25 00:43:36.937 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.937 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 127: 0 to node localhost:57638
2023-11-25 00:43:36.937 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, "?column?", "?column?_1" AS "?column?" FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, "?column?" bigint, "?column?_1" numeric, worker_column_4 integer) ORDER BY user_id, worker_column_4
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 128 in 4444 microseconds
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.938 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 130 in 10074 microseconds
2023-11-25 00:43:36.938 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.939 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 851 microseconds on worker node localhost:57637
2023-11-25 00:43:36.939 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.939 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 730 microseconds on worker node localhost:57638
2023-11-25 00:43:36.939 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.940 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 479 microseconds on worker node localhost:57637
2023-11-25 00:43:36.940 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.940 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 450 microseconds on worker node localhost:57638
2023-11-25 00:43:36.940 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.943 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 129 in 5041 microseconds
2023-11-25 00:43:36.943 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.943 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 131 in 4991 microseconds
2023-11-25 00:43:36.943 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.943 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 128: 2 to node localhost:57637
2023-11-25 00:43:36.943 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.943 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 129: 0 to node localhost:57637
2023-11-25 00:43:36.943 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.943 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 130: 2 to node localhost:57638
2023-11-25 00:43:36.943 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.943 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 131: 0 to node localhost:57638
2023-11-25 00:43:36.943 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.944 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, "?column?", "?column?_1" AS "?column?" FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, "?column?" bigint, "?column?_1" numeric, worker_column_4 integer) ORDER BY "?column?" DESC, user_id LIMIT '5'::bigint
2023-11-25 00:43:36.944 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.945 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.945 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.945 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 132 in 4444 microseconds
2023-11-25 00:43:36.945 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.945 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.945 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.945 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 134 in 10074 microseconds
2023-11-25 00:43:36.945 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.945 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 636 microseconds on worker node localhost:57637
2023-11-25 00:43:36.945 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.945 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 554 microseconds on worker node localhost:57638
2023-11-25 00:43:36.945 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.946 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 437 microseconds on worker node localhost:57638
2023-11-25 00:43:36.946 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.946 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 1020 microseconds on worker node localhost:57637
2023-11-25 00:43:36.946 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.948 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 133 in 3748 microseconds
2023-11-25 00:43:36.948 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.952 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 135 in 7067 microseconds
2023-11-25 00:43:36.952 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.952 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 132: 2 to node localhost:57637
2023-11-25 00:43:36.952 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.952 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 133: 0 to node localhost:57637
2023-11-25 00:43:36.952 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.952 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 134: 2 to node localhost:57638
2023-11-25 00:43:36.952 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.952 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 135: 0 to node localhost:57638
2023-11-25 00:43:36.952 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer) ORDER BY user_id, worker_column_4 DESC
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.953 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.953 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.954 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 136 in 4444 microseconds
2023-11-25 00:43:36.954 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.954 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.954 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.954 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 138 in 10074 microseconds
2023-11-25 00:43:36.954 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.956 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1914 microseconds on worker node localhost:57638
2023-11-25 00:43:36.956 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.956 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 2191 microseconds on worker node localhost:57637
2023-11-25 00:43:36.956 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 3082 microseconds on worker node localhost:57637
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 3192 microseconds on worker node localhost:57638
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 139 in 5216 microseconds
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 137 in 5415 microseconds
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 136: 2 to node localhost:57637
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 137: 0 to node localhost:57637
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 138: 2 to node localhost:57638
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.959 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 139: 0 to node localhost:57638
2023-11-25 00:43:36.959 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.960 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.960 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.961 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 140 in 4444 microseconds
2023-11-25 00:43:36.961 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.961 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.961 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.961 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 142 in 10074 microseconds
2023-11-25 00:43:36.961 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.961 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 823 microseconds on worker node localhost:57637
2023-11-25 00:43:36.961 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.961 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 735 microseconds on worker node localhost:57638
2023-11-25 00:43:36.961 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.962 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 509 microseconds on worker node localhost:57637
2023-11-25 00:43:36.962 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.962 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 467 microseconds on worker node localhost:57638
2023-11-25 00:43:36.962 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.966 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 141 in 5917 microseconds
2023-11-25 00:43:36.966 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 143 in 5933 microseconds
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 140: 2 to node localhost:57637
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 141: 0 to node localhost:57637
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 142: 2 to node localhost:57638
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 143: 0 to node localhost:57638
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.967 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.967 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.968 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC
2023-11-25 00:43:36.968 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.970 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.970 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 144 in 4444 microseconds
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:36.971 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 146 in 10074 microseconds
2023-11-25 00:43:36.971 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.972 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 684 microseconds on worker node localhost:57637
2023-11-25 00:43:36.972 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.974 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 2794 microseconds on worker node localhost:57638
2023-11-25 00:43:36.974 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.974 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 2328 microseconds on worker node localhost:57637
2023-11-25 00:43:36.974 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.975 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 1139 microseconds on worker node localhost:57638
2023-11-25 00:43:36.975 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:36.979 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 145 in 8574 microseconds
2023-11-25 00:43:36.979 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.983 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 147 in 12426 microseconds
2023-11-25 00:43:36.983 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:36.983 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 144: 2 to node localhost:57637
2023-11-25 00:43:36.983 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.983 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 145: 0 to node localhost:57637
2023-11-25 00:43:36.983 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.983 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 146: 2 to node localhost:57638
2023-11-25 00:43:36.983 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.983 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 147: 0 to node localhost:57638
2023-11-25 00:43:36.983 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:36.984 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.984 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.984 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.984 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.984 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.984 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.985 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 00:43:36.985 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.990 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 00:43:36.990 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.992 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 bigint) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 00:43:36.992 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: push down of limit count: 5
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.994 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.994 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.995 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 00:43:36.995 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:36.995 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:36.995 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.995 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:36.995 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.995 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:36.995 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.995 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:36.995 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:36.995 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 bigint) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 00:43:36.995 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:37.002 UTC [3760517] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400256 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:37.002 UTC [3760517] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400257 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:37.002 UTC [3760517] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400258 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:37.002 UTC [3760517] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400259 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.002 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, count, stddev, count(count_1) OVER (PARTITION BY worker_column_5) AS count FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(user_id integer, count bigint, stddev numeric, count_1 integer, worker_column_5 double precision) LIMIT '1'::bigint
2023-11-25 00:43:37.002 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: CTE cte is going to be inlined via distributed planning
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  InlineCTEsInQueryTree, cte_inline.c:117
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:37.007 UTC [3760517] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400260 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:37.007 UTC [3760517] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400261 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:37.007 UTC [3760517] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400262 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:37.007 UTC [3760517] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400263 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, value_2, COALESCE((pg_catalog.sum(c))::bigint, '0'::bigint) AS c FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1 2)'::cstring(0)) remote_scan(user_id integer, value_2 integer, c bigint) GROUP BY user_id, value_2
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: generating subplan 46_1 for subquery SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table JOIN public.users_ref_test_table uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) GROUP BY uref.id, events_table.value_2
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  RecursivelyPlanSubquery, recursive_planning.c:1551
2023-11-25 00:43:37.007 UTC [3760517] DEBUG:  00000: Plan 46 query after replacing subqueries and CTEs: SELECT DISTINCT cte.value_2, cte.c, sum(cte.value_2) OVER (PARTITION BY cte.c) AS sum FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c)))) ORDER BY cte.value_2
2023-11-25 00:43:37.007 UTC [3760517] LOCATION:  GenerateSubplansForSubqueriesAndCTEs, recursive_planning.c:248
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400260 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400261 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400262 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400263 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: combine query: SELECT DISTINCT value_2, c, sum(sum) OVER (PARTITION BY c) AS sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(value_2 integer, c bigint, sum integer) ORDER BY value_2
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: Subplan 46_1 is used in 46
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  RecordSubplanExecutionsOnNodes, intermediate_result_pruning.c:193
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: Subplan 46_1 will be sent to localhost:57637
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: Subplan 46_1 will be sent to localhost:57638
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 00:43:37.008 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:37.008 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.009 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 148 in 4444 microseconds
2023-11-25 00:43:37.009 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.009 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:37.009 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.009 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 150 in 10074 microseconds
2023-11-25 00:43:37.009 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.010 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 534 microseconds on worker node localhost:57637
2023-11-25 00:43:37.010 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.011 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 957 microseconds on worker node localhost:57638
2023-11-25 00:43:37.011 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.011 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 685 microseconds on worker node localhost:57637
2023-11-25 00:43:37.011 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.012 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 946 microseconds on worker node localhost:57638
2023-11-25 00:43:37.012 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.014 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 151 in 5008 microseconds
2023-11-25 00:43:37.014 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.015 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 149 in 6085 microseconds
2023-11-25 00:43:37.015 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.015 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 148: 2 to node localhost:57637
2023-11-25 00:43:37.015 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.015 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 149: 0 to node localhost:57637
2023-11-25 00:43:37.015 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.015 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 150: 2 to node localhost:57638
2023-11-25 00:43:37.015 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.015 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 151: 0 to node localhost:57638
2023-11-25 00:43:37.015 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.016 UTC [3760517] DEBUG:  00000: Session 152 (localhost:57637) has an assigned task
2023-11-25 00:43:37.016 UTC [3760517] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 00:43:37.016 UTC [3760517] DEBUG:  00000: Session 153 (localhost:57638) has an assigned task
2023-11-25 00:43:37.016 UTC [3760517] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 00:43:37.016 UTC [3760517] DEBUG:  00000: Session 152 (localhost:57637) has an assigned task
2023-11-25 00:43:37.016 UTC [3760517] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 00:43:37.017 UTC [3760517] DEBUG:  00000: Session 153 (localhost:57638) has an assigned task
2023-11-25 00:43:37.017 UTC [3760517] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 00:43:37.018 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 822 microseconds on worker node localhost:57637
2023-11-25 00:43:37.018 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.019 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 2395 microseconds on worker node localhost:57638
2023-11-25 00:43:37.019 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.019 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 1689 microseconds on worker node localhost:57637
2023-11-25 00:43:37.019 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.021 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 1680 microseconds on worker node localhost:57638
2023-11-25 00:43:37.021 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.021 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 152: 2 to node localhost:57637
2023-11-25 00:43:37.021 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.021 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 153: 2 to node localhost:57638
2023-11-25 00:43:37.021 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.050 UTC [3760517] DEBUG:  00000: FromList item is not empty
2023-11-25 00:43:37.050 UTC [3760517] CONTEXT:  SQL statement "SELECT TRUE FROM public.daily_uniques LIMIT 1"
2023-11-25 00:43:37.050 UTC [3760517] LOCATION:  TryToDelegateFunctionCall, function_call_delegation.c:196
2023-11-25 00:43:37.052 UTC [3760517] DEBUG:  00000: opening 1 new connections to localhost:57637
2023-11-25 00:43:37.052 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.052 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 154 in 4444 microseconds
2023-11-25 00:43:37.052 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.052 UTC [3760517] DEBUG:  00000: opening 1 new connections to localhost:57638
2023-11-25 00:43:37.052 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.052 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 155 in 10074 microseconds
2023-11-25 00:43:37.052 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.053 UTC [3760517] DEBUG:  00000: task execution (2) for placement (1070) on anchor shard (360164) finished in 1213 microseconds on worker node localhost:57638
2023-11-25 00:43:37.053 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.053 UTC [3760517] DEBUG:  00000: task execution (1) for placement (1069) on anchor shard (360164) finished in 1298 microseconds on worker node localhost:57637
2023-11-25 00:43:37.053 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.056 UTC [3760517] DEBUG:  00000: task execution (4) for placement (1072) on anchor shard (360165) finished in 2613 microseconds on worker node localhost:57638
2023-11-25 00:43:37.056 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.060 UTC [3760517] DEBUG:  00000: task execution (3) for placement (1071) on anchor shard (360165) finished in 6407 microseconds on worker node localhost:57637
2023-11-25 00:43:37.060 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.062 UTC [3760517] DEBUG:  00000: task execution (6) for placement (1074) on anchor shard (360166) finished in 5534 microseconds on worker node localhost:57638
2023-11-25 00:43:37.062 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.062 UTC [3760517] DEBUG:  00000: task execution (5) for placement (1073) on anchor shard (360166) finished in 1889 microseconds on worker node localhost:57637
2023-11-25 00:43:37.062 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.064 UTC [3760517] DEBUG:  00000: task execution (8) for placement (1076) on anchor shard (360167) finished in 2243 microseconds on worker node localhost:57638
2023-11-25 00:43:37.064 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.064 UTC [3760517] DEBUG:  00000: task execution (7) for placement (1075) on anchor shard (360167) finished in 2235 microseconds on worker node localhost:57637
2023-11-25 00:43:37.064 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.064 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 154: 4 to node localhost:57637
2023-11-25 00:43:37.064 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.064 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 155: 4 to node localhost:57638
2023-11-25 00:43:37.064 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: no shard pruning constraints on daily_uniques found
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: shard count after pruning for daily_uniques: 4
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: push down of limit count: 10
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: no shard pruning constraints on daily_uniques found
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: shard count after pruning for daily_uniques: 4
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360164 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360165 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360166 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360167 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.085 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, commits, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id bigint, commits double precision, rank bigint) ORDER BY commits DESC LIMIT '10'::bigint
2023-11-25 00:43:37.085 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.092 UTC [3760517] DEBUG:  00000: drop auto-cascades to type daily_uniques
2023-11-25 00:43:37.092 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:37.092 UTC [3760517] DEBUG:  00000: drop auto-cascades to type daily_uniques[]
2023-11-25 00:43:37.092 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:37.092 UTC [3760517] DEBUG:  00000: drop auto-cascades to trigger truncate_trigger_18553 on table daily_uniques
2023-11-25 00:43:37.092 UTC [3760517] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 00:43:37.092 UTC [3760517] DEBUG:  00000: EventTriggerInvoke 16675
2023-11-25 00:43:37.092 UTC [3760517] LOCATION:  EventTriggerInvoke, event_trigger.c:900
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:37.126 UTC [3760517] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400260 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.126 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:37.126 UTC [3760517] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400261 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:37.126 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:37.127 UTC [3760517] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400262 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:37.127 UTC [3760517] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400263 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: combine query: SELECT value_2, sum(rnk) OVER (PARTITION BY worker_column_3) AS rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1 2)'::cstring(0)) remote_scan(value_2 integer, rnk integer, worker_column_3 integer)
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: generating subplan 49_1 for subquery SELECT events_table.value_2, sum(uref.k_no) OVER (PARTITION BY uref.id) AS rnk FROM (public.events_table JOIN public.users_ref_test_table uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id)))
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  RecursivelyPlanSubquery, recursive_planning.c:1551
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: Plan 49 query after replacing subqueries and CTEs: SELECT DISTINCT value_2, array_agg(rnk ORDER BY rnk) AS array_agg FROM (SELECT intermediate_result.value_2, intermediate_result.rnk FROM read_intermediate_result('49_1'::text, 'binary'::citus_copy_format) intermediate_result(value_2 integer, rnk bigint)) sq GROUP BY value_2 ORDER BY value_2
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  GenerateSubplansForSubqueriesAndCTEs, recursive_planning.c:248
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: Creating router plan
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  CreateSingleTaskRouterSelectPlan, multi_router_planner.c:284
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: Subplan 49_1 is used in 49
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  RecordSubplanExecutionsOnNodes, intermediate_result_pruning.c:193
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: Subplan 49_1 will be written to local file
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:416
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 156 in 4444 microseconds
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.127 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 158 in 10074 microseconds
2023-11-25 00:43:37.127 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.129 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 1405 microseconds on worker node localhost:57637
2023-11-25 00:43:37.129 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.129 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 389 microseconds on worker node localhost:57637
2023-11-25 00:43:37.129 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.129 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 440 microseconds on worker node localhost:57638
2023-11-25 00:43:37.129 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.130 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 356 microseconds on worker node localhost:57638
2023-11-25 00:43:37.130 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.135 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 159 in 7520 microseconds
2023-11-25 00:43:37.135 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.137 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 157 in 10239 microseconds
2023-11-25 00:43:37.137 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.137 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 156: 2 to node localhost:57637
2023-11-25 00:43:37.137 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.138 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 157: 0 to node localhost:57637
2023-11-25 00:43:37.138 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.138 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 158: 2 to node localhost:57638
2023-11-25 00:43:37.138 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.138 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 159: 0 to node localhost:57638
2023-11-25 00:43:37.138 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.141 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:37.141 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.141 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:37.141 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: push down of limit count: 1
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: generated sql query for task 1
2023-11-25 00:43:37.148 UTC [3760517] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400256 ut WHERE true LIMIT '1'::bigint"
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: generated sql query for task 2
2023-11-25 00:43:37.148 UTC [3760517] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400257 ut WHERE true LIMIT '1'::bigint"
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: generated sql query for task 3
2023-11-25 00:43:37.148 UTC [3760517] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400258 ut WHERE true LIMIT '1'::bigint"
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: generated sql query for task 4
2023-11-25 00:43:37.148 UTC [3760517] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400259 ut WHERE true LIMIT '1'::bigint"
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: combine query: SELECT "?column?" FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan("?column?" boolean) LIMIT '1'::bigint
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.148 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:37.148 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.152 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 160 in 4444 microseconds
2023-11-25 00:43:37.152 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.152 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:37.152 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.153 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 162 in 10074 microseconds
2023-11-25 00:43:37.153 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.153 UTC [3760517] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 269 microseconds on worker node localhost:57637
2023-11-25 00:43:37.153 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.153 UTC [3760517] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 241 microseconds on worker node localhost:57638
2023-11-25 00:43:37.153 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.153 UTC [3760517] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 211 microseconds on worker node localhost:57637
2023-11-25 00:43:37.153 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.153 UTC [3760517] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 251 microseconds on worker node localhost:57638
2023-11-25 00:43:37.153 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.157 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 161 in 4400 microseconds
2023-11-25 00:43:37.157 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.160 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 163 in 7541 microseconds
2023-11-25 00:43:37.160 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.160 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 160: 2 to node localhost:57637
2023-11-25 00:43:37.160 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.160 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 161: 0 to node localhost:57637
2023-11-25 00:43:37.160 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.160 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 162: 2 to node localhost:57638
2023-11-25 00:43:37.160 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.160 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 163: 0 to node localhost:57638
2023-11-25 00:43:37.160 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400256 us, public.events_table_1400260 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.161 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400257 us, public.events_table_1400261 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 00:43:37.161 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400258 us, public.events_table_1400262 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400259 us, public.events_table_1400263 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: combine query: SELECT user_id, max FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, max integer, worker_column_3 integer, worker_column_4 integer) ORDER BY max DESC, user_id
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 164 in 4444 microseconds
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 00:43:37.162 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 166 in 10074 microseconds
2023-11-25 00:43:37.162 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.164 UTC [3760517] DEBUG:  00000: task execution (1) for placement (848) on anchor shard (1400260) finished in 2187 microseconds on worker node localhost:57637
2023-11-25 00:43:37.164 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.164 UTC [3760517] DEBUG:  00000: task execution (2) for placement (849) on anchor shard (1400261) finished in 2069 microseconds on worker node localhost:57638
2023-11-25 00:43:37.164 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.165 UTC [3760517] DEBUG:  00000: task execution (3) for placement (850) on anchor shard (1400262) finished in 1028 microseconds on worker node localhost:57637
2023-11-25 00:43:37.165 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.165 UTC [3760517] DEBUG:  00000: task execution (4) for placement (851) on anchor shard (1400263) finished in 1079 microseconds on worker node localhost:57638
2023-11-25 00:43:37.165 UTC [3760517] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 00:43:37.173 UTC [3760517] DEBUG:  00000: established connection to localhost:57638 for session 167 in 10378 microseconds
2023-11-25 00:43:37.173 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: established connection to localhost:57637 for session 165 in 12543 microseconds
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 164: 2 to node localhost:57637
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 165: 0 to node localhost:57637
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 166: 2 to node localhost:57638
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: Total number of commands sent over the session 167: 0 to node localhost:57638
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: shmem_exit(0): 6 before_shmem_exit callbacks to make
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  shmem_exit, ipc.c:236
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: shmem_exit(0): 6 on_shmem_exit callbacks to make
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  shmem_exit, ipc.c:269
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: proc_exit(0): 2 callbacks to make
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  proc_exit_prepare, ipc.c:196
2023-11-25 00:43:37.175 UTC [3760517] DEBUG:  00000: exit(0)
2023-11-25 00:43:37.175 UTC [3760517] LOCATION:  proc_exit, ipc.c:150
2023-11-25 00:43:37.176 UTC [3760517] DEBUG:  00000: shmem_exit(-1): 0 before_shmem_exit callbacks to make
2023-11-25 00:43:37.176 UTC [3760517] LOCATION:  shmem_exit, ipc.c:236
2023-11-25 00:43:37.176 UTC [3760517] DEBUG:  00000: shmem_exit(-1): 0 on_shmem_exit callbacks to make
2023-11-25 00:43:37.176 UTC [3760517] LOCATION:  shmem_exit, ipc.c:269
2023-11-25 00:43:37.176 UTC [3760517] DEBUG:  00000: proc_exit(-1): 0 callbacks to make
2023-11-25 00:43:37.176 UTC [3760517] LOCATION:  proc_exit_prepare, ipc.c:196
2023-11-25 00:43:37.215 UTC [3760518] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:37.215 UTC [3760518] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:37.215 UTC [3760518] STATEMENT:  UPDATE
		second_distributed_table
	SET
		dept = foo.tenant_id::int / 4
	FROM
	(
		SELECT DISTINCT foo_inner_1.tenant_id FROM
		(
			SELECT
				second_distributed_table.dept, second_distributed_table.tenant_id
			FROM
				second_distributed_table, distributed_table
			WHERE
				distributed_table.tenant_id = second_distributed_table.tenant_id
			AND
				second_distributed_table.dept IN (select dept from second_distributed_table))
		foo_inner_1 JOIN LATERAL
		(
			SELECT
				second_distributed_table.tenant_id
			FROM
				second_distributed_table, distributed_table
			WHERE
				distributed_table.tenant_id = second_distributed_table.tenant_id
				AND foo_inner_1.dept = second_distributed_table.dept
			AND
				second_distributed_table.dept IN (4,5)
		) foo_inner_2
		ON (foo_inner_2.tenant_id != foo_inner_1.tenant_id)
		) as foo
	RETURNING *;
2023-11-25 00:43:37.216 UTC [3760518] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:37.216 UTC [3760518] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:37.216 UTC [3760518] STATEMENT:  UPDATE
		second_distributed_table
	SET
		dept = foo.tenant_id::int / 4
	FROM
	(
		SELECT baz.tenant_id FROM
		(
			SELECT
				second_distributed_table.dept, second_distributed_table.tenant_id
			FROM
				second_distributed_table, distributed_table as d1
			WHERE
				d1.tenant_id = second_distributed_table.tenant_id
			AND
				second_distributed_table.dept IN (3,4)
				AND
				second_distributed_table.tenant_id IN
				(
						SELECT s2.tenant_id
						FROM second_distributed_table as s2
						GROUP BY d1.tenant_id, s2.tenant_id
				)
		) as baz
		) as foo WHERE second_distributed_table.tenant_id = foo.tenant_id
	RETURNING *;
2023-11-25 00:43:37.217 UTC [3760518] ERROR:  0A000: subqueries are not supported within INSERT queries
2023-11-25 00:43:37.217 UTC [3760518] HINT:  Try rewriting your queries with 'INSERT INTO ... SELECT' syntax.
2023-11-25 00:43:37.217 UTC [3760518] LOCATION:  ModifyPartialQuerySupported, multi_router_planner.c:696
2023-11-25 00:43:37.217 UTC [3760518] STATEMENT:  INSERT INTO
		second_distributed_table (tenant_id, dept)
	VALUES ('3', (WITH  vals AS (SELECT 3) select * from vals));
2023-11-25 00:43:37.217 UTC [3760518] ERROR:  0A000: subqueries are not supported within INSERT queries
2023-11-25 00:43:37.217 UTC [3760518] HINT:  Try rewriting your queries with 'INSERT INTO ... SELECT' syntax.
2023-11-25 00:43:37.217 UTC [3760518] LOCATION:  ModifyPartialQuerySupported, multi_router_planner.c:696
2023-11-25 00:43:37.217 UTC [3760518] STATEMENT:  INSERT INTO
		second_distributed_table (tenant_id, dept)
	VALUES ('3', (SELECT 3));
2023-11-25 00:43:37.421 UTC [3760515] ERROR:  XX000: EXPLAIN ANALYZE is currently not supported for INSERT ... SELECT commands with repartitioning
2023-11-25 00:43:37.421 UTC [3760515] LOCATION:  NonPushableInsertSelectExplainScan, multi_explain.c:252
2023-11-25 00:43:37.421 UTC [3760515] STATEMENT:  EXPLAIN ANALYZE INSERT INTO target_table SELECT a, max(b) FROM source_table GROUP BY a;
2023-11-25 00:43:37.697 UTC [3760515] ERROR:  23502: null value in column "b" of relation "target_table_4213617" violates not-null constraint
2023-11-25 00:43:37.697 UTC [3760515] DETAIL:  Failing row contains (2, null).
2023-11-25 00:43:37.697 UTC [3760515] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:37.697 UTC [3760515] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:37.697 UTC [3760515] STATEMENT:  INSERT INTO target_table SELECT * FROM source_table;
2023-11-25 00:43:37.766 UTC [3760515] ERROR:  55000: could not find shard for partition column value
2023-11-25 00:43:37.766 UTC [3760515] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:37.766 UTC [3760515] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:37.766 UTC [3760515] STATEMENT:  INSERT INTO target_table SELECT a * 10, b FROM source_table WHERE b IS NOT NULL;
2023-11-25 00:43:38.437 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.437 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.437 UTC [3761320] STATEMENT:  CREATE TRIGGER update_value_dist
	AFTER INSERT ON distributed_table
	FOR EACH ROW EXECUTE FUNCTION update_value();
2023-11-25 00:43:38.437 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.437 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.437 UTC [3761320] STATEMENT:  CREATE TRIGGER update_value_ref
	AFTER INSERT ON reference_table
	FOR EACH ROW EXECUTE FUNCTION update_value();
2023-11-25 00:43:38.459 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.459 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.459 UTC [3761320] STATEMENT:  ALTER TRIGGER update_value_dist ON distributed_table RENAME TO update_value_dist1;
2023-11-25 00:43:38.459 UTC [3761320] ERROR:  XX000: trigger "update_value_dist" depends on an extension and this is not supported for distributed tables and local tables added to metadata
2023-11-25 00:43:38.459 UTC [3761320] DETAIL:  Triggers from extensions are expected to be created on the workers by the extension they depend on.
2023-11-25 00:43:38.459 UTC [3761320] LOCATION:  PreprocessAlterTriggerDependsStmt, trigger.c:552
2023-11-25 00:43:38.459 UTC [3761320] STATEMENT:  ALTER TRIGGER update_value_dist ON distributed_table DEPENDS ON EXTENSION seg;
2023-11-25 00:43:38.459 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.459 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.459 UTC [3761320] STATEMENT:  DROP TRIGGER update_value_dist ON distributed_table;
2023-11-25 00:43:38.459 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.459 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.459 UTC [3761320] STATEMENT:  ALTER TABLE distributed_table DISABLE TRIGGER ALL;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE distributed_table DISABLE TRIGGER USER;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE distributed_table DISABLE TRIGGER update_value_dist;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE distributed_table ENABLE TRIGGER ALL;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE distributed_table ENABLE TRIGGER USER;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE distributed_table ENABLE TRIGGER update_value_dist;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TRIGGER update_value_ref ON reference_table RENAME TO update_value_ref1;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: trigger "update_value_ref" depends on an extension and this is not supported for distributed tables and local tables added to metadata
2023-11-25 00:43:38.460 UTC [3761320] DETAIL:  Triggers from extensions are expected to be created on the workers by the extension they depend on.
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  PreprocessAlterTriggerDependsStmt, trigger.c:552
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TRIGGER update_value_ref ON reference_table DEPENDS ON EXTENSION seg;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  DROP TRIGGER update_value_ref ON reference_table;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE reference_table DISABLE TRIGGER ALL;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE reference_table DISABLE TRIGGER USER;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE reference_table DISABLE TRIGGER update_value_ref;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE reference_table ENABLE TRIGGER ALL;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE reference_table ENABLE TRIGGER USER;
2023-11-25 00:43:38.460 UTC [3761320] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 00:43:38.460 UTC [3761320] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 00:43:38.460 UTC [3761320] STATEMENT:  ALTER TABLE reference_table ENABLE TRIGGER update_value_ref;
2023-11-25 00:43:38.462 UTC [3761320] ERROR:  XX000: cannot distribute relation "distributed_table_1" because it has triggers
2023-11-25 00:43:38.462 UTC [3761320] HINT:  Consider dropping all the triggers on "distributed_table_1" and retry.
2023-11-25 00:43:38.462 UTC [3761320] LOCATION:  EnsureRelationHasNoTriggers, create_distributed_table.c:2095
2023-11-25 00:43:38.462 UTC [3761320] STATEMENT:  SELECT create_distributed_table('distributed_table_1', 'value');
2023-11-25 00:43:38.462 UTC [3761320] ERROR:  XX000: cannot distribute relation "reference_table_1" because it has triggers
2023-11-25 00:43:38.462 UTC [3761320] HINT:  Consider dropping all the triggers on "reference_table_1" and retry.
2023-11-25 00:43:38.462 UTC [3761320] LOCATION:  EnsureRelationHasNoTriggers, create_distributed_table.c:2095
2023-11-25 00:43:38.462 UTC [3761320] STATEMENT:  SELECT create_reference_table('reference_table_1');
2023-11-25 00:43:38.552 UTC [3761321] ERROR:  23503: insert or update on table "target_table_1900000" violates foreign key constraint "fkey_1900000"
2023-11-25 00:43:38.552 UTC [3761321] DETAIL:  Key (col_1)=(1) is not present in table "test_ref_table_1900012".
2023-11-25 00:43:38.552 UTC [3761321] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:38.552 UTC [3761321] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:38.552 UTC [3761321] STATEMENT:  INSERT INTO
			target_table
		SELECT
			col_2,
			col_1
		FROM source_table_1 ON CONFLICT (col_1) DO UPDATE SET col_2 = 55 RETURNING *;
2023-11-25 00:43:39.266 UTC [3761440] ERROR:  XX000: cannot undistribute table because the table is not distributed
2023-11-25 00:43:39.266 UTC [3761440] LOCATION:  UndistributeTable, alter_table.c:379
2023-11-25 00:43:39.266 UTC [3761440] STATEMENT:  SELECT undistribute_table('local_source_table_1');
2023-11-25 00:43:39.424 UTC [3761595] ERROR:  42883: function hll_hash_bigint(bigint) does not exist at character 49
2023-11-25 00:43:39.424 UTC [3761595] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:43:39.424 UTC [3761595] QUERY:  
	 EXPLAIN SELECT symbol_id,
	        HLL_ADD_AGG(HLL_HASH_BIGINT(event_id)) AS event_hll_hash,
	        HLL_CARDINALITY(HLL_ADD_AGG(HLL_HASH_BIGINT(event_id))) AS event_n_users
	 FROM (
	    SELECT event_time, composite_id, event_id, 4640476 symbol_id FROM "events"
	 UNION ALL
	    SELECT event_time, composite_id, event_id, 4640477 symbol_id FROM "events"
	 ) pushdown_events
	 GROUP BY symbol_id;
	 
2023-11-25 00:43:39.424 UTC [3761595] CONTEXT:  PL/pgSQL function explain_has_distributed_subplan(text) line 5 at FOR over EXECUTE statement
2023-11-25 00:43:39.424 UTC [3761595] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:43:39.424 UTC [3761595] STATEMENT:  SELECT public.explain_has_distributed_subplan($$
	 EXPLAIN SELECT symbol_id,
	        HLL_ADD_AGG(HLL_HASH_BIGINT(event_id)) AS event_hll_hash,
	        HLL_CARDINALITY(HLL_ADD_AGG(HLL_HASH_BIGINT(event_id))) AS event_n_users
	 FROM (
	    SELECT event_time, composite_id, event_id, 4640476 symbol_id FROM "events"
	 UNION ALL
	    SELECT event_time, composite_id, event_id, 4640477 symbol_id FROM "events"
	 ) pushdown_events
	 GROUP BY symbol_id;
	 $$);
2023-11-25 00:43:39.430 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.430 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.430 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.430 UTC [3761595] STATEMENT:  SELECT count(distinct l_orderkey) FROM lineitem;
2023-11-25 00:43:39.431 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.431 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.431 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.431 UTC [3761595] STATEMENT:  SELECT count(distinct l_orderkey) FROM lineitem;
2023-11-25 00:43:39.431 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.431 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.431 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.431 UTC [3761595] STATEMENT:  SELECT count(distinct l_partkey) FROM lineitem;
2023-11-25 00:43:39.431 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.431 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.431 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.431 UTC [3761595] STATEMENT:  SELECT count(distinct l_extendedprice) FROM lineitem;
2023-11-25 00:43:39.431 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.431 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.431 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.431 UTC [3761595] STATEMENT:  SELECT count(distinct l_shipdate) FROM lineitem;
2023-11-25 00:43:39.432 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.432 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.432 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.432 UTC [3761595] STATEMENT:  SELECT count(distinct l_comment) FROM lineitem;
2023-11-25 00:43:39.432 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.432 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.432 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.432 UTC [3761595] STATEMENT:  SELECT count(distinct (l_orderkey * 2 + 1)) FROM lineitem;
2023-11-25 00:43:39.432 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.432 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.432 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.432 UTC [3761595] STATEMENT:  SELECT count(distinct extract(month from l_shipdate)) AS my_month FROM lineitem;
2023-11-25 00:43:39.432 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.432 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.432 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.432 UTC [3761595] STATEMENT:  SELECT count(distinct l_partkey) / count(distinct l_orderkey) FROM lineitem;
2023-11-25 00:43:39.432 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.432 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.432 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.432 UTC [3761595] STATEMENT:  SELECT count(distinct l_orderkey) FROM lineitem
		WHERE octet_length(l_comment) + octet_length('randomtext'::text) > 40;
2023-11-25 00:43:39.433 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.433 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.433 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.433 UTC [3761595] STATEMENT:  SELECT count(DISTINCT l_orderkey) FROM lineitem, orders
		WHERE l_orderkey = o_orderkey AND l_quantity < 5;
2023-11-25 00:43:39.433 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.433 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.433 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.433 UTC [3761595] STATEMENT:  SELECT count(DISTINCT l_orderkey) as distinct_order_count, l_quantity FROM lineitem
		WHERE l_quantity < 32.0
		GROUP BY l_quantity
		ORDER BY distinct_order_count ASC, l_quantity ASC
		LIMIT 10;
2023-11-25 00:43:39.459 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.459 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.459 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.459 UTC [3761595] STATEMENT:  SELECT COUNT (DISTINCT n_regionkey) FROM test_count_distinct_schema.nation_hash;
2023-11-25 00:43:39.459 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.459 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.459 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.459 UTC [3761595] STATEMENT:  SELECT COUNT (DISTINCT n_regionkey) FROM nation_hash;
2023-11-25 00:43:39.459 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.459 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.459 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.459 UTC [3761595] STATEMENT:  SELECT l_returnflag, count(DISTINCT l_shipdate) as count_distinct, count(*) as total
		FROM lineitem
		GROUP BY l_returnflag
		ORDER BY count_distinct
		LIMIT 10;
2023-11-25 00:43:39.460 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.460 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.460 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.460 UTC [3761595] STATEMENT:  SELECT l_returnflag, count(DISTINCT l_shipdate) as count_distinct, count(*) as total
		FROM lineitem
		GROUP BY l_returnflag
		ORDER BY total
		LIMIT 10;
2023-11-25 00:43:39.460 UTC [3761595] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 00:43:39.460 UTC [3761595] HINT:  You need to have the hll extension loaded.
2023-11-25 00:43:39.460 UTC [3761595] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 00:43:39.460 UTC [3761595] STATEMENT:  SELECT
		l_partkey,
		count(l_partkey) FILTER (WHERE l_shipmode = 'AIR'),
		count(DISTINCT l_partkey) FILTER (WHERE l_shipmode = 'AIR'),
		count(DISTINCT CASE WHEN l_shipmode = 'AIR' THEN l_partkey ELSE NULL END)
		FROM lineitem
		GROUP BY l_partkey
		ORDER BY 2 DESC, 1 DESC
		LIMIT 10;
2023-11-25 00:43:40.184 UTC [3761644] ERROR:  23502: null value in column "b" of relation "target_table_4213646" violates not-null constraint
2023-11-25 00:43:40.184 UTC [3761644] DETAIL:  Failing row contains (84, null).
2023-11-25 00:43:40.184 UTC [3761644] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:40.184 UTC [3761644] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:40.184 UTC [3761644] STATEMENT:  INSERT INTO target_table SELECT a, CASE WHEN a < 50 THEN b ELSE null END  FROM source_table;
2023-11-25 00:43:40.590 UTC [3761770] ERROR:  XX000: "parent_table" is not a partition
2023-11-25 00:43:40.590 UTC [3761770] LOCATION:  GenerateAlterTableAttachPartitionCommand, multi_partitioning_utils.c:1221
2023-11-25 00:43:40.590 UTC [3761770] STATEMENT:  SELECT public.generate_alter_table_attach_partition_command('parent_table');
2023-11-25 00:43:40.590 UTC [3761770] ERROR:  XX000: "child_1" is not a parent table
2023-11-25 00:43:40.590 UTC [3761770] LOCATION:  GeneratePartitioningInformation, multi_partitioning_utils.c:1155
2023-11-25 00:43:40.590 UTC [3761770] STATEMENT:  SELECT public.generate_partition_information('partition_child_1_schema.child_1');
2023-11-25 00:43:40.590 UTC [3761770] ERROR:  XX000: "child_1" is not a parent table
2023-11-25 00:43:40.590 UTC [3761770] LOCATION:  PartitionList, multi_partitioning_utils.c:1075
2023-11-25 00:43:40.590 UTC [3761770] STATEMENT:  SELECT public.print_partitions('partition_child_1_schema.child_1');
2023-11-25 00:43:40.613 UTC [3761770] ERROR:  42809: capitals is not a regular, foreign or partitioned table
2023-11-25 00:43:40.613 UTC [3761770] LOCATION:  EnsureRelationKindSupported, citus_ruleutils.c:635
2023-11-25 00:43:40.613 UTC [3761770] STATEMENT:  SELECT master_get_table_ddl_events('capitals');
2023-11-25 00:43:40.613 UTC [3761770] ERROR:  42809: cities is not a regular, foreign or partitioned table
2023-11-25 00:43:40.613 UTC [3761770] LOCATION:  EnsureRelationKindSupported, citus_ruleutils.c:635
2023-11-25 00:43:40.613 UTC [3761770] STATEMENT:  SELECT master_get_table_ddl_events('cities');
2023-11-25 00:43:40.684 UTC [3761769] ERROR:  23514: no partition of relation "partitioning_hash_test_1660012" found for row
2023-11-25 00:43:40.684 UTC [3761769] DETAIL:  Partition key of the failing row contains (subid) = (5).
2023-11-25 00:43:40.684 UTC [3761769] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:40.684 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:40.684 UTC [3761769] STATEMENT:  INSERT INTO partitioning_hash_test VALUES (8, 5);
2023-11-25 00:43:40.687 UTC [3761769] ERROR:  23514: no partition of relation "partitioning_hash_test_1660015" found for row
2023-11-25 00:43:40.687 UTC [3761769] DETAIL:  Partition key of the failing row contains (subid) = (12).
2023-11-25 00:43:40.687 UTC [3761769] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:40.687 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:40.687 UTC [3761769] STATEMENT:  INSERT INTO partitioning_hash_test VALUES (9, 12);
2023-11-25 00:43:40.690 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.690 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.690 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.690 UTC [3761768] STATEMENT:  INSERT INTO collections_4 (key, ts, collection_id, value) VALUES (4, '2009-01-01', 2, 2);
2023-11-25 00:43:40.690 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.690 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.690 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.690 UTC [3761768] STATEMENT:  UPDATE collections_1 SET ts = now() WHERE key = 1;
2023-11-25 00:43:40.691 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.691 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.691 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.691 UTC [3761768] STATEMENT:  DELETE FROM collections_1 WHERE ts = now() AND key = 1;
2023-11-25 00:43:40.691 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.691 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.691 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.691 UTC [3761768] STATEMENT:  UPDATE collections_1 SET ts = now();
2023-11-25 00:43:40.691 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.691 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.691 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.691 UTC [3761768] STATEMENT:  DELETE FROM collections_1 WHERE ts = now();
2023-11-25 00:43:40.691 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.691 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.691 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.691 UTC [3761768] STATEMENT:  INSERT INTO collections_1 SELECT * FROM collections_1;
2023-11-25 00:43:40.691 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.691 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.691 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.691 UTC [3761768] STATEMENT:  INSERT INTO collections_1 SELECT * FROM collections_1 OFFSET 0;
2023-11-25 00:43:40.691 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.691 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.691 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.691 UTC [3761768] STATEMENT:  COPY collections_1 FROM STDIN;
2023-11-25 00:43:40.692 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.692 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.692 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.692 UTC [3761768] STATEMENT:  CREATE INDEX index_on_partition ON collections_1(key);
2023-11-25 00:43:40.692 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.692 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.692 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.692 UTC [3761768] STATEMENT:  UPDATE collections_1 SET ts = now() WHERE key = 1;
2023-11-25 00:43:40.693 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.693 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.693 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.693 UTC [3761768] STATEMENT:  TRUNCATE collections_1;
2023-11-25 00:43:40.693 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.693 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.693 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.693 UTC [3761768] STATEMENT:  TRUNCATE collections, collections_1;
2023-11-25 00:43:40.693 UTC [3761768] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:40.693 UTC [3761768] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 00:43:40.693 UTC [3761768] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:40.693 UTC [3761768] STATEMENT:  WITH collections_5_cte AS
	(
		DELETE FROM collections_5 RETURNING *
	)
	SELECT * FROM collections_5_cte;
2023-11-25 00:43:40.704 UTC [3761768] ERROR:  0A000: cannot create foreign key constraint
2023-11-25 00:43:40.704 UTC [3761768] DETAIL:  Citus currently supports foreign key constraints only for "citus.shard_replication_factor = 1".
2023-11-25 00:43:40.704 UTC [3761768] HINT:  Please change "citus.shard_replication_factor to 1". To learn more about using foreign keys with other replication factors, please contact us at https://citusdata.com/about/contact_us.
2023-11-25 00:43:40.704 UTC [3761768] LOCATION:  EnsureReferencingTableNotReplicated, foreign_constraint.c:599
2023-11-25 00:43:40.704 UTC [3761768] STATEMENT:  ALTER TABLE
		collections_5
	ADD CONSTRAINT
		fkey_delete FOREIGN KEY(key)
	REFERENCES
		fkey_test(key) ON DELETE CASCADE;
2023-11-25 00:43:40.737 UTC [3761769] ERROR:  XX000: cannot distribute relation "partitioning_test_failure_2009" which is partition of "partitioning_test_failure"
2023-11-25 00:43:40.737 UTC [3761769] DETAIL:  Citus does not support distributing partitions if their parent is not distributed table.
2023-11-25 00:43:40.737 UTC [3761769] HINT:  Distribute the partitioned table "partitioning_test_failure" instead.
2023-11-25 00:43:40.737 UTC [3761769] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1895
2023-11-25 00:43:40.737 UTC [3761769] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure_2009', 'id');
2023-11-25 00:43:40.738 UTC [3761769] ERROR:  0A000: distributing partitioned tables in only supported for hash-distributed tables
2023-11-25 00:43:40.738 UTC [3761769] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1914
2023-11-25 00:43:40.738 UTC [3761769] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure', 'id', 'append');
2023-11-25 00:43:40.738 UTC [3761769] ERROR:  0A000: distributing partitioned tables in only supported for hash-distributed tables
2023-11-25 00:43:40.738 UTC [3761769] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1914
2023-11-25 00:43:40.738 UTC [3761769] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure', 'id', 'range');
2023-11-25 00:43:40.738 UTC [3761769] ERROR:  0A000: distributing partitioned tables in only supported for hash-distributed tables
2023-11-25 00:43:40.738 UTC [3761769] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1914
2023-11-25 00:43:40.738 UTC [3761769] STATEMENT:  SELECT create_reference_table('partitioning_test_failure');
2023-11-25 00:43:40.748 UTC [3761769] ERROR:  XX000: non-citus partitioned tables cannot have citus table partitions
2023-11-25 00:43:40.748 UTC [3761769] HINT:  Distribute the partitioned table "partitioning_test_failure" instead, or add it to metadata
2023-11-25 00:43:40.748 UTC [3761769] LOCATION:  ErrorIfAttachCitusTableToPgLocalTable, table.c:651
2023-11-25 00:43:40.748 UTC [3761769] STATEMENT:  ALTER TABLE partitioning_test_failure ATTACH PARTITION partitioning_test_failure_2009 FOR VALUES FROM ('2009-01-01') TO ('2010-01-01');
2023-11-25 00:43:40.765 UTC [3761769] ERROR:  0A000: distributing multi-level partitioned tables is not supported
2023-11-25 00:43:40.765 UTC [3761769] DETAIL:  Relation "partitioning_test_failure_2009" is partitioned table itself and it is also partition of relation "partitioning_test_failure".
2023-11-25 00:43:40.765 UTC [3761769] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1924
2023-11-25 00:43:40.765 UTC [3761769] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure', 'id');
2023-11-25 00:43:40.772 UTC [3761769] ERROR:  0A000: distributing multi-level partitioned tables is not supported
2023-11-25 00:43:40.772 UTC [3761769] DETAIL:  Relation "partitioning_test_failure_2009" is partitioned table itself and it is also partition of relation "partitioning_test_failure".
2023-11-25 00:43:40.772 UTC [3761769] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1924
2023-11-25 00:43:40.772 UTC [3761769] STATEMENT:  CREATE TABLE partitioning_test_failure_2009 PARTITION OF partitioning_test_failure FOR VALUES FROM ('2009-01-01') TO ('2010-01-01') PARTITION BY RANGE (time);
2023-11-25 00:43:40.799 UTC [3761769] ERROR:  23514: no partition of relation "partitioning_test_1660001" found for row
2023-11-25 00:43:40.799 UTC [3761769] DETAIL:  Partition key of the failing row contains ("time") = (2020-07-07).
2023-11-25 00:43:40.799 UTC [3761769] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:40.799 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:40.799 UTC [3761769] STATEMENT:  UPDATE partitioning_test SET time = '2020-07-07' WHERE id = 7;
2023-11-25 00:43:40.811 UTC [3761768] ERROR:  25001: cannot open new connections after the first modification command within a transaction
2023-11-25 00:43:40.811 UTC [3761768] LOCATION:  EnsureNoModificationsHaveBeenDone, worker_transaction.c:320
2023-11-25 00:43:40.811 UTC [3761768] STATEMENT:  SELECT citus_copy_shard_placement(1760036, 'localhost', 57637, 'localhost', 57638, transfer_mode := 'block_writes');
2023-11-25 00:43:40.823 UTC [3761899] LOG:  00000: deferred drop of orphaned resource public.shard_split_table_360047 on localhost:57638 completed
2023-11-25 00:43:40.823 UTC [3761899] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 00:43:40.823 UTC [3761899] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:40.838 UTC [3761769] ERROR:  23514: updated partition constraint for default partition "partitioning_test_default_1660054" would be violated by some row
2023-11-25 00:43:40.838 UTC [3761769] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:40.838 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:40.838 UTC [3761769] STATEMENT:  CREATE TABLE partitioning_test_2014 PARTITION OF partitioning_test FOR VALUES FROM ('2014-01-01') TO ('2015-01-01');
2023-11-25 00:43:40.886 UTC [3761769] ERROR:  23514: new row for relation "partitioning_test_2009_1660005" violates partition constraint
2023-11-25 00:43:40.886 UTC [3761769] DETAIL:  Failing row contains (3, 2010-03-11).
2023-11-25 00:43:40.886 UTC [3761769] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:40.886 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:40.886 UTC [3761769] STATEMENT:  UPDATE partitioning_test_2009 SET time = time + INTERVAL '6 month';
2023-11-25 00:43:40.928 UTC [3761945] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1760036 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:40.928 UTC [3761945] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:40.928 UTC [3761945] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:40.929 UTC [3761945] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1_1760037 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:40.929 UTC [3761945] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:40.929 UTC [3761945] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:40.929 UTC [3761945] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_2_1760038 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:40.929 UTC [3761945] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:40.929 UTC [3761945] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:41.022 UTC [3761769] ERROR:  2BP01: cannot drop index partitioning_test_2009_id_idx because index partitioning_index requires it
2023-11-25 00:43:41.022 UTC [3761769] HINT:  You can drop index partitioning_index instead.
2023-11-25 00:43:41.022 UTC [3761769] LOCATION:  reportDependentObjects, dependency.c:1055
2023-11-25 00:43:41.022 UTC [3761769] STATEMENT:  DROP INDEX partitioning_test_2009_id_idx;
2023-11-25 00:43:41.048 UTC [3761769] ERROR:  42809: cannot add column to a partition
2023-11-25 00:43:41.048 UTC [3761769] LOCATION:  ATExecAddColumn, tablecmds.c:6753
2023-11-25 00:43:41.048 UTC [3761769] STATEMENT:  ALTER TABLE partitioning_test_2010 ADD new_column_2 int;
2023-11-25 00:43:41.056 UTC [3761769] ERROR:  0A000: unique constraint on partitioned table must include all partitioning columns
2023-11-25 00:43:41.056 UTC [3761769] DETAIL:  PRIMARY KEY constraint on table "partitioning_test" lacks column "time" which is part of the partition key.
2023-11-25 00:43:41.056 UTC [3761769] LOCATION:  DefineIndex, indexcmds.c:1035
2023-11-25 00:43:41.056 UTC [3761769] STATEMENT:  ALTER TABLE partitioning_test ADD CONSTRAINT partitioning_primary PRIMARY KEY (id);
2023-11-25 00:43:41.078 UTC [3761769] ERROR:  55006: cannot ALTER TABLE "partitioning_test_2009" because it is being used by active queries in this session
2023-11-25 00:43:41.078 UTC [3761769] LOCATION:  CheckTableNotInUse, tablecmds.c:4005
2023-11-25 00:43:41.078 UTC [3761769] STATEMENT:  ALTER TABLE partitioning_test ADD CONSTRAINT partitioning_foreign FOREIGN KEY (id) REFERENCES partitioning_test_2009 (id);
2023-11-25 00:43:41.426 UTC [3761769] ERROR:  23514: no partition of relation "multi_column_partitioning_1660133" found for row
2023-11-25 00:43:41.426 UTC [3761769] DETAIL:  Partition key of the failing row contains (c1, c2) = (10, 1).
2023-11-25 00:43:41.426 UTC [3761769] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:41.426 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:41.426 UTC [3761769] STATEMENT:  INSERT INTO multi_column_partitioning VALUES(10, 1);
2023-11-25 00:43:41.439 UTC [3761769] ERROR:  23514: no partition of relation "multi_column_partitioning_1660133" found for row
2023-11-25 00:43:41.439 UTC [3761769] DETAIL:  Partition key of the failing row contains (c1, c2) = (20, -20).
2023-11-25 00:43:41.439 UTC [3761769] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:41.439 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:41.439 UTC [3761769] STATEMENT:  INSERT INTO multi_column_partitioning VALUES(20, -20);
2023-11-25 00:43:41.694 UTC [3761769] ERROR:  23503: insert or update on table "partitioning_test_2010_1660314" violates foreign key constraint "partitioning_reference_fkey_1660302"
2023-11-25 00:43:41.694 UTC [3761769] DETAIL:  Key (id)=(1) is not present in table "reference_table_1660300".
2023-11-25 00:43:41.694 UTC [3761769] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:41.694 UTC [3761769] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:41.694 UTC [3761769] STATEMENT:  ALTER TABLE partitioning_test ATTACH PARTITION partitioning_test_2010
	      FOR VALUES FROM ('2010-01-01') TO ('2011-01-01');
2023-11-25 00:43:41.713 UTC [3761769] ERROR:  42P07: relation "partitioning_test_2011" already exists
2023-11-25 00:43:41.713 UTC [3761769] LOCATION:  heap_create_with_catalog, heap.c:1146
2023-11-25 00:43:41.713 UTC [3761769] STATEMENT:  CREATE TABLE partitioning_test_2011 PARTITION OF partitioning_test FOR VALUES FROM ('2011-01-01') TO ('2012-01-01');
2023-11-25 00:43:41.720 UTC [3761769] ERROR:  42P07: relation "not_partition" already exists
2023-11-25 00:43:41.720 UTC [3761769] LOCATION:  heap_create_with_catalog, heap.c:1146
2023-11-25 00:43:41.720 UTC [3761769] STATEMENT:  CREATE TABLE not_partition PARTITION OF partitioning_test FOR VALUES FROM ('2011-01-01') TO ('2012-01-01');
2023-11-25 00:43:41.722 UTC [3761769] ERROR:  42P07: relation "partition_of_other_table" already exists
2023-11-25 00:43:41.722 UTC [3761769] LOCATION:  heap_create_with_catalog, heap.c:1146
2023-11-25 00:43:41.722 UTC [3761769] STATEMENT:  CREATE TABLE partition_of_other_table PARTITION OF partitioning_test FOR VALUES FROM ('2014-01-01') TO ('2015-01-01');
2023-11-25 00:43:41.724 UTC [3761769] ERROR:  XX000: fix_pre_citus10_partitioned_table_constraint_names can only be called for distributed partitioned tables
2023-11-25 00:43:41.724 UTC [3761769] LOCATION:  fix_pre_citus10_partitioned_table_constraint_names, multi_partitioning_utils.c:105
2023-11-25 00:43:41.724 UTC [3761769] STATEMENT:  SELECT fix_pre_citus10_partitioned_table_constraint_names('public.non_distributed_partitioned_table');
2023-11-25 00:43:41.724 UTC [3761769] ERROR:  XX000: could not fix partition constraints: relation does not exist or is not partitioned
2023-11-25 00:43:41.724 UTC [3761769] LOCATION:  fix_pre_citus10_partitioned_table_constraint_names, multi_partitioning_utils.c:100
2023-11-25 00:43:41.724 UTC [3761769] STATEMENT:  SELECT fix_pre_citus10_partitioned_table_constraint_names('reference_table');
2023-11-25 00:43:41.771 UTC [3761769] ERROR:  XX000: relation "multi_column_partitioned_p1" is a partition with multiple partition columns
2023-11-25 00:43:41.771 UTC [3761769] DETAIL:  time_partition_range can only be used for partitions of range-partitioned tables with a single partition column
2023-11-25 00:43:41.771 UTC [3761769] LOCATION:  time_partition_range, partitioning.c:102
2023-11-25 00:43:41.771 UTC [3761769] STATEMENT:  SELECT * FROM time_partition_range('multi_column_partitioned_p1');
2023-11-25 00:43:41.773 UTC [3761769] ERROR:  XX000: relation "list_partitioned_p1" is not a range partition
2023-11-25 00:43:41.773 UTC [3761769] DETAIL:  time_partition_range can only be used for partitions of range-partitioned tables with a single partition column
2023-11-25 00:43:41.773 UTC [3761769] LOCATION:  time_partition_range, partitioning.c:78
2023-11-25 00:43:41.773 UTC [3761769] STATEMENT:  SELECT * FROM time_partition_range('list_partitioned_p1');
2023-11-25 00:43:41.778 UTC [3761769] ERROR:  XX000: non-distributed tables cannot inherit distributed tables
2023-11-25 00:43:41.778 UTC [3761769] LOCATION:  PostprocessCreateTableStmt, table.c:253
2023-11-25 00:43:41.778 UTC [3761769] STATEMENT:  CREATE TABLE local_inheritance (k int) INHERITS (test_inheritance);
2023-11-25 00:43:41.887 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:41.887 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
2023-11-25 00:43:41.887 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:41.887 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 00:43:41.888 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:41.888 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
2023-11-25 00:43:41.888 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:41.888 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 00:43:41.927 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_2021_01_01 with the range from 01-01-2021 to 01-02-2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:41.927 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:41.927 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:41.927 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:41.927 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 00:43:41.947 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_2021_01_01 with the range from 01-01-2021 to 01-02-2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:41.947 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:41.947 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:41.947 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:41.947 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 00:43:41.985 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_2021_01_01 with the range from 01-01-2021 to 01-02-2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:41.985 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:41.985 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:41.985 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:41.985 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 00:43:42.004 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_2021_01_02 with the range from 01-04-2021 to 01-06-2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.004 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.004 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.004 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.004 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-15', '2020-12-30');
2023-11-25 00:43:42.035 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.035 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.035 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.035 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.035 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.054 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.054 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.054 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.054 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.054 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.092 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.092 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.092 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.092 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.092 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.111 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_2021_01_02 with the range from Mon Jan 04 00:00:00 2021 PST to Wed Jan 06 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.111 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.111 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.111 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.111 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.150 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.150 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.150 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.150 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.150 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.169 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.169 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.169 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.169 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.169 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.207 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.207 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.207 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.207 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.207 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.225 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_02 with the range from Mon Jan 04 00:00:00 2021 to Wed Jan 06 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.225 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.225 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.225 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.225 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.245 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:42.245 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.245 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.245 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 00:43:42.245 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:42.245 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.245 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.245 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 00:43:42.327 UTC [3762099] ERROR:  P0001: start_from (Mon Feb 01 00:00:00 2021 PST) must be older than end_at (Fri Jan 01 00:00:00 2021 PST)
2023-11-25 00:43:42.327 UTC [3762099] CONTEXT:  PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 12 at RAISE
2023-11-25 00:43:42.327 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.327 UTC [3762099] STATEMENT:  SELECT * FROM create_time_partitions('date_partitioned_table', INTERVAL '1 day', '2021-01-01', '2021-02-01');
2023-11-25 00:43:42.334 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_p2020_12_30 with the range from 12-30-2020 to 12-31-2020 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.334 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.334 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.334 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.334 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '2 days', '2021-01-15', '2020-12-25');
2023-11-25 00:43:42.341 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_p2020_12_30 with the range from 12-30-2020 to 12-31-2020 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.341 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.341 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.341 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.341 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 00:43:42.352 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_2020_01_02 with the range from 01-02-2021 to 01-04-2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.352 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.352 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.352 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.352 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '1 day', '2021-01-05', '2020-12-30');
2023-11-25 00:43:42.354 UTC [3762099] ERROR:  P0001: partition date_partitioned_table_2021_01_02 with the range from 01-04-2021 to 01-06-2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.354 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.354 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.354 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.354 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '2 days', '2021-01-15', '2020-12-30');
2023-11-25 00:43:42.407 UTC [3762099] ERROR:  P0001: start_from (Tue Jan 05 00:00:00 2021 PST) must be older than end_at (Fri Jan 01 00:00:00 2021 PST)
2023-11-25 00:43:42.407 UTC [3762099] CONTEXT:  PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 12 at RAISE
2023-11-25 00:43:42.407 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.407 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '1 day', '2021-01-01 00:00:00', '2021-01-05 00:00:00');
2023-11-25 00:43:42.413 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 PST to Thu Dec 31 00:00:00 2020 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.413 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.413 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 00:43:42.413 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.413 UTC [3762099] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.420 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 PST to Thu Dec 31 00:00:00 2020 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.420 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.420 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.420 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.420 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.431 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.431 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.431 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.431 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.431 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.433 UTC [3762099] ERROR:  P0001: partition tstz_partitioned_table_2021_01_02 with the range from Mon Jan 04 00:00:00 2021 PST to Wed Jan 06 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 00:43:42.433 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.433 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.433 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.433 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.898 UTC [3762099] ERROR:  P0001: start_from (Tue Jan 05 00:00:00 2021 PST) must be older than end_at (Fri Jan 01 00:00:00 2021 PST)
2023-11-25 00:43:42.898 UTC [3762099] CONTEXT:  PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 12 at RAISE
2023-11-25 00:43:42.898 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.898 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '1 day', '2021-01-01 00:00:00', '2021-01-05 00:00:00');
2023-11-25 00:43:42.944 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 to Thu Dec 31 00:00:00 2020 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.944 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.944 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.944 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.944 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:42.990 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 to Thu Dec 31 00:00:00 2020 does not align with the initial partition given the partition interval
2023-11-25 00:43:42.990 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:42.990 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:42.990 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:42.990 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:43.072 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_2020_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:43.072 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:43.072 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:43.072 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:43.072 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:43.091 UTC [3762099] ERROR:  P0001: partition tswtz_partitioned_table_2020_01_02 with the range from Mon Jan 04 00:00:00 2021 to Wed Jan 06 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 00:43:43.091 UTC [3762099] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 00:43:43.091 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:43.091 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:43.091 UTC [3762099] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 00:43:43.314 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:43.314 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:43.314 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:43.314 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_distributed_partitioned_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 00:43:43.315 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:43.315 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:43.315 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:43.315 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_distributed_partitioned_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 00:43:43.968 UTC [3762169] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1760036 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:43.968 UTC [3762169] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:43.968 UTC [3762169] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:43.968 UTC [3762169] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1_1760037 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:43.968 UTC [3762169] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:43.968 UTC [3762169] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:43.969 UTC [3762169] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_2_1760038 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:43.969 UTC [3762169] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:43.969 UTC [3762169] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:44.101 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:44.101 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:44.101 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:44.101 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_citus_local_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 00:43:44.102 UTC [3762099] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 00:43:44.102 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:44.102 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:44.102 UTC [3762099] STATEMENT:  SELECT create_time_partitions('date_partitioned_citus_local_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 00:43:46.139 UTC [3762099] ERROR:  P0001: partitioned tables with multiple partition columns are not supported
2023-11-25 00:43:46.139 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 33 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:46.139 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:46.139 UTC [3762099] STATEMENT:  SELECT create_time_partitions('multiple_partition_column_table', INTERVAL '1 month', now() + INTERVAL '1 year');
2023-11-25 00:43:46.139 UTC [3762099] ERROR:  P0001: partitioned tables with multiple partition columns are not supported
2023-11-25 00:43:46.139 UTC [3762099] CONTEXT:  PL/pgSQL function drop_old_time_partitions(regclass,timestamp with time zone) line 17 at RAISE
2023-11-25 00:43:46.139 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:46.139 UTC [3762099] STATEMENT:  CALL drop_old_time_partitions('multiple_partition_column_table', now());
2023-11-25 00:43:46.141 UTC [3762099] ERROR:  P0001: type of the partition column of the table invalid_partition_column_table must be date, timestamp or timestamptz
2023-11-25 00:43:46.141 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 47 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:46.141 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:46.141 UTC [3762099] STATEMENT:  SELECT create_time_partitions('invalid_partition_column_table', INTERVAL '1 month', now() + INTERVAL '1 year');
2023-11-25 00:43:46.142 UTC [3762099] ERROR:  P0001: type of the partition column of the table invalid_partition_column_table must be date, timestamp or timestamptz
2023-11-25 00:43:46.142 UTC [3762099] CONTEXT:  PL/pgSQL function drop_old_time_partitions(regclass,timestamp with time zone) line 29 at RAISE
2023-11-25 00:43:46.142 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:46.142 UTC [3762099] STATEMENT:  CALL drop_old_time_partitions('invalid_partition_column_table', now());
2023-11-25 00:43:46.143 UTC [3762099] ERROR:  P0001: non_partitioned_table is not partitioned
2023-11-25 00:43:46.143 UTC [3762099] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 31 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 00:43:46.143 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:46.143 UTC [3762099] STATEMENT:  SELECT create_time_partitions('non_partitioned_table', INTERVAL '1 month', now() + INTERVAL '1 year');
2023-11-25 00:43:46.144 UTC [3762099] ERROR:  P0001: non_partitioned_table is not partitioned
2023-11-25 00:43:46.144 UTC [3762099] CONTEXT:  PL/pgSQL function drop_old_time_partitions(regclass,timestamp with time zone) line 15 at RAISE
2023-11-25 00:43:46.144 UTC [3762099] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:46.144 UTC [3762099] STATEMENT:  CALL drop_old_time_partitions('non_partitioned_table', now());
2023-11-25 00:43:46.871 UTC [3762266] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:43:46.871 UTC [3762266] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:43:46.871 UTC [3762266] STATEMENT:  SELECT (SELECT id FROM dist WHERE dist.id > d1.id GROUP BY id) FROM ref FULL JOIN dist d1 USING (id);
2023-11-25 00:43:47.892 UTC [3762533] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 00:43:47.892 UTC [3762533] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 00:43:47.892 UTC [3762533] STATEMENT:  SELECT
	   bar.user_id
	FROM
	    (
		     WITH RECURSIVE cte AS MATERIALIZED (
		    SELECT
		    	DISTINCT users_table.user_id
		     FROM
		     	users_table, events_table
		     WHERE
		     	users_table.user_id = events_table.user_id AND
		     event_type IN (1,2,3,4)
		     ) SELECT * FROM cte ORDER BY 1 DESC
	     ) as foo,
	    (
		    SELECT
		    	DISTINCT users_table.user_id
		     FROM
		     	users_table, events_table
		     WHERE
		     	users_table.user_id = events_table.user_id AND
		     event_type IN (1,2,3,4)
	     ) as bar
	WHERE foo.user_id = bar.user_id
	ORDER BY 1 DESC;
2023-11-25 00:43:47.982 UTC [3762533] ERROR:  P0001: (3/3) failed to execute one of the tasks
2023-11-25 00:43:47.982 UTC [3762533] CONTEXT:  PL/pgSQL function inline_code_block line 31 at RAISE
2023-11-25 00:43:47.982 UTC [3762533] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:43:47.982 UTC [3762533] STATEMENT:  DO $$
	DECLARE
		errors_received INTEGER;
	BEGIN
	errors_received := 0;
	FOR i IN 1..3 LOOP
		BEGIN
			WITH cte as (
				SELECT
					user_id, value_2
				from
					events_table
			)
			SELECT * FROM users_table where value_2 < (
				SELECT
					min(cte.value_2)
				FROM
					cte
				WHERE
					users_table.user_id=cte.user_id
				GROUP BY
					user_id, cte.value_2);
		EXCEPTION WHEN OTHERS THEN
			IF SQLERRM LIKE 'more than one row returned by a subquery%%' THEN
				errors_received := errors_received + 1;
			ELSIF SQLERRM LIKE 'failed to execute task%' THEN
				errors_received := errors_received + 1;
			END IF;
		END;
	END LOOP;
	RAISE '(%/3) failed to execute one of the tasks', errors_received;
	END;
	$$;
2023-11-25 00:43:48.364 UTC [3762662] ERROR:  0A000: cannot pushdown the subquery since not all subqueries in the UNION have the partition column in the same position
2023-11-25 00:43:48.364 UTC [3762662] DETAIL:  Each leaf query of the UNION should return the partition column in the same position and all joins must be on the partition column
2023-11-25 00:43:48.364 UTC [3762662] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:582
2023-11-25 00:43:48.364 UTC [3762662] STATEMENT:  SELECT * FROM ((SELECT * FROM test) UNION (SELECT * FROM test)) foo WHERE x IN (SELECT y FROM test);
2023-11-25 00:43:48.414 UTC [3762662] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:43:48.414 UTC [3762662] DETAIL:  Complex subqueries and CTEs are not supported within a UNION
2023-11-25 00:43:48.414 UTC [3762662] LOCATION:  DeferErrorIfUnsupportedUnionQuery, query_pushdown_planning.c:1362
2023-11-25 00:43:48.414 UTC [3762662] STATEMENT:  SELECT * FROM test a WHERE x IN (SELECT x FROM test b UNION SELECT y FROM test c WHERE a.x = c.x) ORDER BY 1,2;
2023-11-25 00:43:48.432 UTC [3762662] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 00:43:48.432 UTC [3762662] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 00:43:48.432 UTC [3762662] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 00:43:48.432 UTC [3762662] STATEMENT:  select count(DISTINCT t.x) FROM ((SELECT avg(DISTINCT y) FROM test GROUP BY y) UNION (SELECT avg(DISTINCT y) FROM test GROUP BY y)) as t(x) ORDER BY 1;
2023-11-25 00:43:49.006 UTC [3762867] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:49.006 UTC [3762867] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:49.006 UTC [3762867] STATEMENT:  EXPLAIN
	   SELECT
	    (SELECT user_id FROM users_table_part WHERE user_id = e.value_1
	        UNION ALL
	     SELECT user_id FROM users_table_part WHERE user_id = e.value_1)
	  FROM
	    (SELECT * FROM users_table_part) as e;
2023-11-25 00:43:49.033 UTC [3762867] WARNING:  0A000: "view v2" has dependency to "table range_dist_table_2" that is not in Citus' metadata
2023-11-25 00:43:49.033 UTC [3762867] DETAIL:  "view v2" will be created only locally
2023-11-25 00:43:49.033 UTC [3762867] HINT:  Distribute "table range_dist_table_2" first to distribute "view v2"
2023-11-25 00:43:49.033 UTC [3762867] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:43:49.119 UTC [3762867] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:49.119 UTC [3762867] CONTEXT:  PL/pgSQL function public.explain_has_distributed_subplan(text) line 5 at FOR over EXECUTE statement
2023-11-25 00:43:49.119 UTC [3762867] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:49.119 UTC [3762867] STATEMENT:  SELECT public.explain_has_distributed_subplan($$
	EXPLAIN SELECT * FROM users_table_part u1 WHERE (value_1, user_id) IN
	(
	SELECT u1.user_id, user_id FROM users_table_part
	UNION
	SELECT u1.user_id, user_id FROM users_table_part
	);
	$$);
2023-11-25 00:43:49.313 UTC [3762930] ERROR:  22012: division by zero
2023-11-25 00:43:49.313 UTC [3762930] LOCATION:  int4div, int.c:840
2023-11-25 00:43:49.313 UTC [3762930] STATEMENT:  (SELECT x FROM test) INTERSECT (SELECT i/0 FROM generate_series(0, 100) i) ORDER BY 1 DESC;
2023-11-25 00:43:49.542 UTC [3763060] ERROR:  42P01: relation "events_table_local" does not exist at character 130
2023-11-25 00:43:49.542 UTC [3763060] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:43:49.542 UTC [3763060] STATEMENT:  SELECT COUNT(user_id) FROM users_table WHERE user_id IN
		(SELECT
			user_id
		 FROM
		 	users_table_local JOIN (SELECT user_id FROM events_table_local) as foo
		 USING (user_id)
		 );
2023-11-25 00:43:49.544 UTC [3763060] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 00:43:49.544 UTC [3763060] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 00:43:49.544 UTC [3763060] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 00:43:49.544 UTC [3763060] STATEMENT:  SELECT
		*
	FROM
	(
		SELECT avg(DISTINCT value_1), random() FROM users_table GROUP BY user_id OFFSET 3
	) as baz,
	(
		SELECT count(DISTINCT value_1), random() FROM users_table GROUP BY value_2 OFFSET 3
	) as bar,
	(
		SELECT avg(DISTINCT value_1), random() FROM users_table GROUP BY value_2 OFFSET 3
	) as foo;
2023-11-25 00:43:49.545 UTC [3763060] ERROR:  0A000: array_agg with order by is unsupported
2023-11-25 00:43:49.545 UTC [3763060] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4008
2023-11-25 00:43:49.545 UTC [3763060] STATEMENT:  SELECT
		*
	FROM
		(
			SELECT
				array_agg(users_table.value_2 ORDER BY users_table.time)
			FROM
				users_table, (SELECT user_id FROM events_table) as evs
			WHERE users_table.user_id = evs.user_id
			GROUP BY users_table.value_2
			LIMIT 5
		) as foo;
2023-11-25 00:43:49.547 UTC [3763060] ERROR:  0A000: cannot handle complex subqueries when the router executor is disabled
2023-11-25 00:43:49.547 UTC [3763060] LOCATION:  QueryPushdownSqlTaskList, multi_physical_planner.c:2182
2023-11-25 00:43:49.547 UTC [3763060] STATEMENT:  SELECT
	   user_id
	FROM
	    (SELECT
	    	DISTINCT users_table.user_id
	     FROM
	     	users_table, events_table
	     WHERE
	     	users_table.user_id = events_table.user_id AND
	     event_type IN (1,2,3,4)
	     ORDER BY 1 DESC LIMIT 5
	     ) as foo
	    ORDER BY 1 DESC;
2023-11-25 00:43:49.562 UTC [3763060] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 00:43:49.562 UTC [3763060] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:43:49.562 UTC [3763060] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:43:49.562 UTC [3763060] STATEMENT:  SELECT * FROM (SELECT user_id, value_1 FROM users_table GROUP BY GROUPING SETS ((user_id), (value_1))) s;
2023-11-25 00:43:49.562 UTC [3763060] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 00:43:49.562 UTC [3763060] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:43:49.562 UTC [3763060] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:43:49.562 UTC [3763060] STATEMENT:  SELECT * FROM (SELECT user_id, value_1 FROM users_table GROUP BY ROLLUP (user_id, value_1)) s;
2023-11-25 00:43:49.562 UTC [3763060] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 00:43:49.562 UTC [3763060] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:43:49.562 UTC [3763060] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:43:49.562 UTC [3763060] STATEMENT:  SELECT * FROM (SELECT user_id, value_1 FROM users_table GROUP BY CUBE (user_id, value_1)) s;
2023-11-25 00:43:49.677 UTC [3763058] WARNING:  0A000: "view subquery_from_from_where_local_table" has dependency to "table events_table_local" that is not in Citus' metadata
2023-11-25 00:43:49.677 UTC [3763058] DETAIL:  "view subquery_from_from_where_local_table" will be created only locally
2023-11-25 00:43:49.677 UTC [3763058] HINT:  Distribute "table events_table_local" first to distribute "view subquery_from_from_where_local_table"
2023-11-25 00:43:49.677 UTC [3763058] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:43:49.689 UTC [3763061] WARNING:  0A000: "view subquery_and_ctes" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 00:43:49.689 UTC [3763061] DETAIL:  "view subquery_and_ctes" will be created only locally
2023-11-25 00:43:49.689 UTC [3763061] HINT:  Distribute "table users_table_local" first to distribute "view subquery_and_ctes"
2023-11-25 00:43:49.689 UTC [3763061] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:43:49.797 UTC [3763058] WARNING:  0A000: "view all_executors_view" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 00:43:49.797 UTC [3763058] DETAIL:  "view all_executors_view" will be created only locally
2023-11-25 00:43:49.797 UTC [3763058] HINT:  Distribute "table users_table_local" first to distribute "view all_executors_view"
2023-11-25 00:43:49.797 UTC [3763058] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:43:49.886 UTC [3763058] WARNING:  0A000: "view subquery_and_ctes" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 00:43:49.886 UTC [3763058] DETAIL:  "view subquery_and_ctes" will be created only locally
2023-11-25 00:43:49.886 UTC [3763058] HINT:  Distribute "table users_table_local" first to distribute "view subquery_and_ctes"
2023-11-25 00:43:49.886 UTC [3763058] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:43:49.904 UTC [3763058] WARNING:  0A000: "view subquery_and_ctes_second" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 00:43:49.904 UTC [3763058] DETAIL:  "view subquery_and_ctes_second" will be created only locally
2023-11-25 00:43:49.904 UTC [3763058] HINT:  Distribute "table users_table_local" first to distribute "view subquery_and_ctes_second"
2023-11-25 00:43:49.904 UTC [3763058] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:43:50.223 UTC [3763371] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 00:43:50.223 UTC [3763371] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 00:43:50.223 UTC [3763371] STATEMENT:  WITH event_id
	     AS(SELECT user_id AS events_user_id,
	                time    AS events_time,
	                event_type
	         FROM   events_table)
	SELECT Count(*)
	FROM   event_id
	WHERE  events_user_id IN (SELECT user_id
	                          FROM   users_table
	                          WHERE  users_table.time = events_time);
2023-11-25 00:43:50.309 UTC [3763370] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:43:50.309 UTC [3763370] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:43:50.309 UTC [3763370] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:43:50.309 UTC [3763370] STATEMENT:  SELECT key, count(*) FROM (SELECT *, random() FROM append_table a JOIN append_table b USING (key)) u GROUP BY key ORDER BY 1,2 LIMIT 3;
2023-11-25 00:43:50.315 UTC [3763372] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.315 UTC [3763372] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.315 UTC [3763372] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.user_id GROUP BY user_id)
	FROM users_table u JOIN events_table e USING (value_2)
	ORDER BY 1,2 LIMIT 1;
2023-11-25 00:43:50.316 UTC [3763372] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.316 UTC [3763372] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.316 UTC [3763372] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.value_2)
	FROM events_table e
	ORDER BY 1,2 LIMIT 1;
2023-11-25 00:43:50.316 UTC [3763372] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.316 UTC [3763372] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.316 UTC [3763372] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.value_2 GROUP BY user_id)
	FROM events_table e
	ORDER BY 1,2 LIMIT 1;
2023-11-25 00:43:50.318 UTC [3763370] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.318 UTC [3763370] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.318 UTC [3763370] STATEMENT:  SELECT key, value FROM append_table a WHERE key IN (SELECT key FROM append_table WHERE value > 100) ORDER BY 1,2;
2023-11-25 00:43:50.342 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:43:50.342 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:43:50.342 UTC [3763372] STATEMENT:  SELECT (SELECT max(u1.time) FROM users_table u1 JOIN users_reference_table u2 USING (user_id) WHERE u2.user_id = e.user_id GROUP BY user_id), 5
	FROM events_reference_table e
	GROUP BY 1
	ORDER BY 1,2 LIMIT 1;
2023-11-25 00:43:50.342 UTC [3763372] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.342 UTC [3763372] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.342 UTC [3763372] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.user_id GROUP BY user_id)
	FROM users_table u JOIN events_table e USING (value_2)
	ORDER BY 1,2 LIMIT 1;
2023-11-25 00:43:50.347 UTC [3763370] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.347 UTC [3763370] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.347 UTC [3763370] STATEMENT:  DELETE FROM append_table a USING append_table b WHERE a.key = b.key;
2023-11-25 00:43:50.365 UTC [3763370] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.365 UTC [3763370] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.365 UTC [3763370] STATEMENT:  UPDATE append_table a sET extra = 1 FROM append_table b WHERE a.key = b.key;
2023-11-25 00:43:50.377 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 00:43:50.377 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 00:43:50.377 UTC [3763372] STATEMENT:  WITH cte_1 AS (SELECT min(user_id) u, max(time) m FROM users_table)
	SELECT count(*), (SELECT max(time) FROM users_table WHERE user_id = cte_1.u GROUP BY user_id)
	FROM cte_1
	GROUP BY 2
	ORDER BY 1,2 LIMIT 1;
2023-11-25 00:43:50.388 UTC [3763372] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 00:43:50.388 UTC [3763372] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 00:43:50.388 UTC [3763372] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 00:43:50.388 UTC [3763372] STATEMENT:  SELECT sum(e.user_id) + (SELECT max(value_3) FROM users_reference_table WHERE value_2 = e.value_2 GROUP BY user_id)
	FROM events_table e
	GROUP BY e.value_2
	ORDER BY 1 LIMIT 3;
2023-11-25 00:43:50.389 UTC [3763372] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 00:43:50.389 UTC [3763372] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 00:43:50.389 UTC [3763372] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 00:43:50.389 UTC [3763372] STATEMENT:  SELECT sum(e.user_id) + (SELECT user_id FROM users_reference_table WHERE user_id = 1 AND value_1 = 1)
	FROM events_table e;
2023-11-25 00:43:50.400 UTC [3763372] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 00:43:50.400 UTC [3763372] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 00:43:50.400 UTC [3763372] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 00:43:50.400 UTC [3763372] STATEMENT:  SELECT e.value_2, sum((SELECT any_value(value_3) FROM users_reference_table WHERE user_id = e.user_id GROUP BY user_id)) OVER (PARTITION BY e.value_2)
	FROM events_table e
	ORDER BY 1, 2 LIMIT 3;
2023-11-25 00:43:50.424 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:43:50.424 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:43:50.424 UTC [3763372] STATEMENT:  SELECT (SELECT (SELECT e.user_id + user_id) FROM users_reference_table WHERE user_id = e.user_id GROUP BY user_id)
	FROM events_table e
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 00:43:50.425 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 00:43:50.425 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 00:43:50.425 UTC [3763372] STATEMENT:  WITH cte_1 AS (SELECT user_id FROM users_table ORDER BY 1 LIMIT 1)
	SELECT (SELECT (SELECT e.user_id + user_id) FROM cte_1 WHERE user_id = e.user_id GROUP BY user_id)
	FROM events_table e
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 00:43:50.425 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a subquery without FROM
2023-11-25 00:43:50.425 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:690
2023-11-25 00:43:50.425 UTC [3763372] STATEMENT:  SELECT (SELECT (SELECT e.user_id + user_id) FROM (SELECT 1 AS user_id) s WHERE user_id = e.user_id GROUP BY user_id)
	FROM events_table e
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 00:43:50.427 UTC [3763372] WARNING:  0A000: "view view_1" has dependency on unsupported object "schema pg_temp_9"
2023-11-25 00:43:50.427 UTC [3763372] DETAIL:  "view view_1" will be created only locally
2023-11-25 00:43:50.427 UTC [3763372] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 00:43:50.449 UTC [3763372] WARNING:  0A000: "view view_2" has dependency on unsupported object "schema pg_temp_9"
2023-11-25 00:43:50.449 UTC [3763372] DETAIL:  "view view_2" will be created only locally
2023-11-25 00:43:50.449 UTC [3763372] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 00:43:50.462 UTC [3763372] ERROR:  42704: type "view_1" does not exist
2023-11-25 00:43:50.462 UTC [3763372] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:50.462 UTC [3763372] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:50.462 UTC [3763372] STATEMENT:  SELECT (SELECT view_1)
	FROM view_1
	ORDER BY 1 LIMIT 1;
2023-11-25 00:43:50.464 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a subquery without FROM
2023-11-25 00:43:50.464 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:690
2023-11-25 00:43:50.464 UTC [3763372] STATEMENT:  SELECT (SELECT (SELECT user_id))
	FROM events_table e
	ORDER BY 1 LIMIT 1;
2023-11-25 00:43:50.479 UTC [3763372] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:43:50.479 UTC [3763372] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:43:50.479 UTC [3763372] STATEMENT:  SELECT (SELECT (user_id,value_1) FROM users_table u WHERE u.user_id = e.user_id AND time = 'Thu Nov 23 09:26:42.145043 2017')
	FROM events_table e
	WHERE user_id < 3
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 00:43:50.494 UTC [3763371] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 00:43:50.494 UTC [3763371] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 00:43:50.494 UTC [3763371] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (SELECT min(value_3) v FROM users_table WHERE user_id = e.user_id GROUP BY e.value_2 HAVING min(value_3) > (SELECT e.value_3));
2023-11-25 00:43:50.510 UTC [3763371] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.510 UTC [3763371] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.510 UTC [3763371] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (
	    SELECT min(r.value_3) v FROM users_reference_table r JOIN (SELECT * FROM users_table WHERE value_2 = e.user_id) u USING (user_id)
	    WHERE u.value_2 > 3
	    GROUP BY e.value_2 HAVING min(r.value_3) > e.value_3);
2023-11-25 00:43:50.511 UTC [3763371] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.511 UTC [3763371] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.511 UTC [3763371] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (
	    SELECT min(r.value_3) v FROM users_reference_table r JOIN users_table u USING (user_id)
	    WHERE u.value_2 > 3
	    GROUP BY e.value_2 HAVING min(r.value_3) > e.value_3);
2023-11-25 00:43:50.511 UTC [3763371] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.511 UTC [3763371] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.511 UTC [3763371] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (
	    SELECT min(r.value_3) v FROM users_reference_table r JOIN users_table u USING (user_id)
	    WHERE u.value_2 > 3
	    GROUP BY u.value_2 HAVING min(r.value_3) > e.value_3);
2023-11-25 00:43:50.516 UTC [3763369] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:43:50.516 UTC [3763369] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:43:50.516 UTC [3763369] STATEMENT:  SELECT b FROM (SELECT a FROM items a GROUP BY key) b ORDER BY b;
2023-11-25 00:43:50.546 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a subquery without FROM
2023-11-25 00:43:50.546 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:690
2023-11-25 00:43:50.546 UTC [3763372] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table) AND value_2 = a)
	FROM (SELECT 1 AS a) r;
2023-11-25 00:43:50.546 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:43:50.546 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:43:50.546 UTC [3763372] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table) AND value_2 = r.user_id)
	FROM users_reference_table r;
2023-11-25 00:43:50.549 UTC [3763372] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.549 UTC [3763372] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.549 UTC [3763372] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table WHERE user_id = a))
	FROM (SELECT 1 AS a) r;
2023-11-25 00:43:50.554 UTC [3763371] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.554 UTC [3763371] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.554 UTC [3763371] STATEMENT:  SELECT
		u1.user_id, u2.user_id
	FROM
		users_table u1, users_table u2
	WHERE
		u1.value_1 < u2.value_1 AND
		(SELECT
			count(*)
		FROM
			events_table e1
		WHERE
			e1.user_id = u2.user_id AND
			u1.user_id = u2.user_id) > 10
	ORDER BY 1,2;
2023-11-25 00:43:50.556 UTC [3763371] WARNING:  0A000: "view correlated_subquery_view" has dependency on unsupported object "schema pg_temp_8"
2023-11-25 00:43:50.556 UTC [3763371] DETAIL:  "view correlated_subquery_view" will be created only locally
2023-11-25 00:43:50.556 UTC [3763371] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 00:43:50.562 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:43:50.562 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:43:50.562 UTC [3763372] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table ))
	FROM (SELECT * FROM users_reference_table WHERE value_2 IN (SELECT value_2 FROM events_table WHERE events_table.user_id = users_reference_table.user_id)) r
	ORDER BY 1 LIMIT 3;
2023-11-25 00:43:50.571 UTC [3763371] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.571 UTC [3763371] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.571 UTC [3763371] STATEMENT:  SELECT sum(value_1)
	FROM users_table u1
	WHERE (SELECT COUNT(DISTINCT e1.value_2)
	     FROM events_table e1
	     WHERE e1.user_id = u1.user_id AND false
	          ) > 115;
2023-11-25 00:43:50.582 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:43:50.582 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:43:50.582 UTC [3763372] STATEMENT:  SELECT (SELECT (SELECT user_id FROM users_table WHERE user_id = users_reference_table.user_id GROUP BY user_id)
	        FROM users_reference_table WHERE user_id < 2 GROUP BY user_id)
	FROM users_reference_table r
	ORDER BY 1 LIMIT 3;
2023-11-25 00:43:50.586 UTC [3763372] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:50.586 UTC [3763372] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:50.586 UTC [3763372] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table WHERE user_id = r.user_id))
	FROM (SELECT user_id FROM users_table ORDER BY 1 LIMIT 3) r;
2023-11-25 00:43:50.587 UTC [3763372] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 00:43:50.587 UTC [3763372] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 00:43:50.587 UTC [3763372] STATEMENT:  SELECT (SELECT (SELECT max(user_id) FROM users_table) FROM users_table WHERE user_id = r.user_id)
	FROM (SELECT user_id FROM users_table ORDER BY 1 LIMIT 3) r;
2023-11-25 00:43:50.588 UTC [3763372] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:43:50.588 UTC [3763372] DETAIL:  For Update/Share commands are currently unsupported
2023-11-25 00:43:50.588 UTC [3763372] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 00:43:50.588 UTC [3763372] STATEMENT:  SELECT count(*) FROM (SELECT
	  (SELECT user_id FROM users_table WHERE user_id = u1.user_id FOR UPDATE)
	FROM users_table u1
	GROUP BY user_id) as foo;
2023-11-25 00:43:51.599 UTC [3763741] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:51.599 UTC [3763741] CONTEXT:  SQL statement "EXPLAIN (FORMAT JSON) 
	
	    SELECT
	        count(*)
	    FROM
	        (users_table u1 JOIN users_table u2 using(value_1)) a JOIN (SELECT value_1, random() FROM users_table) as u3 USING (value_1);
	"
	PL/pgSQL function explain_json_2(text) line 5 at EXECUTE
2023-11-25 00:43:51.599 UTC [3763741] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:51.599 UTC [3763741] STATEMENT:  SELECT true AS valid FROM explain_json_2($$
	
	    SELECT
	        count(*)
	    FROM
	        (users_table u1 JOIN users_table u2 using(value_1)) a JOIN (SELECT value_1, random() FROM users_table) as u3 USING (value_1);
	$$);
2023-11-25 00:43:51.626 UTC [3763741] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:51.626 UTC [3763741] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:51.626 UTC [3763741] STATEMENT:  SELECT *
	FROM
	  (SELECT *
	   FROM users_table
	   OFFSET 0) AS users_table
	JOIN LATERAL
	  (SELECT *
	   FROM
	     (SELECT *
	      FROM events_table
	      WHERE user_id = users_table.user_id) AS bar
	   LEFT JOIN users_table u2 ON u2.user_id = bar.value_2) AS foo ON TRUE;
2023-11-25 00:43:51.626 UTC [3763741] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:51.626 UTC [3763741] CONTEXT:  SQL statement "EXPLAIN (FORMAT JSON) 
	SELECT *
	FROM
	  (SELECT 1 AS user_id) AS users_table
	JOIN LATERAL
	  (SELECT *
	   FROM
	     (SELECT *
	      FROM events_table
	      WHERE user_id = users_table.user_id) AS bar
	   LEFT JOIN users_table u2 ON u2.user_id = bar.value_2) AS foo ON TRUE
	"
	PL/pgSQL function explain_json_2(text) line 5 at EXECUTE
2023-11-25 00:43:51.626 UTC [3763741] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:51.626 UTC [3763741] STATEMENT:  SELECT true AS valid FROM explain_json_2($$
	SELECT *
	FROM
	  (SELECT 1 AS user_id) AS users_table
	JOIN LATERAL
	  (SELECT *
	   FROM
	     (SELECT *
	      FROM events_table
	      WHERE user_id = users_table.user_id) AS bar
	   LEFT JOIN users_table u2 ON u2.user_id = bar.value_2) AS foo ON TRUE
	$$);
2023-11-25 00:43:51.839 UTC [3763794] WARNING:  0A000: "view recursive_defined_non_recursive_view" has dependency to "table local_table" that is not in Citus' metadata
2023-11-25 00:43:51.839 UTC [3763794] DETAIL:  "view recursive_defined_non_recursive_view" will be created only locally
2023-11-25 00:43:51.839 UTC [3763794] HINT:  Distribute "table local_table" first to distribute "view recursive_defined_non_recursive_view"
2023-11-25 00:43:51.839 UTC [3763794] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:43:51.873 UTC [3763794] ERROR:  0A000: direct joins between distributed and local tables are not supported
2023-11-25 00:43:51.873 UTC [3763794] HINT:  Use CTE's or subqueries to select from local tables and use them in joins
2023-11-25 00:43:51.873 UTC [3763794] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:43:51.873 UTC [3763794] STATEMENT:  SELECT ref_table.* FROM ref_table WHERE EXISTS (SELECT * FROM local_table l WHERE l.a = ref_table.a);
2023-11-25 00:43:51.899 UTC [3763796] ERROR:  0A000: recursive complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:51.899 UTC [3763796] LOCATION:  CreateDistributedPlan, distributed_planner.c:1092
2023-11-25 00:43:51.899 UTC [3763796] STATEMENT:  SELECT t1.id
	FROM (
	    SELECT t2.id
	    FROM (
	        SELECT t0.id
	        FROM tbl_dist1 t0
	        LIMIT 5
	    ) AS t2
	    INNER JOIN tbl_dist1 AS t3 USING (id)
	) AS t1
	FULL JOIN tbl_dist1 t4 USING (id);
2023-11-25 00:43:51.927 UTC [3763793] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 00:43:51.927 UTC [3763793] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:43:51.927 UTC [3763793] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:43:51.927 UTC [3763793] STATEMENT:  WITH cte_1 AS (SELECT * FROM test_table)
	SELECT
		count(*)
	FROM
		cte_1
	WHERE
		key IN (
				SELECT
					key
				FROM
					test_table
	  			 	FOR UPDATE
				);
2023-11-25 00:43:52.045 UTC [3763793] ERROR:  0A000: CTEs that refer to other subqueries are not supported in multi-shard queries
2023-11-25 00:43:52.045 UTC [3763793] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1110
2023-11-25 00:43:52.045 UTC [3763793] STATEMENT:  SELECT count(*)
		FROM
		  (SELECT *
		   FROM test_table) AS test_table_cte
		JOIN LATERAL
		  (WITH bar AS  (SELECT *
		      FROM test_table
		      WHERE key = test_table_cte.key)
		  	SELECT *
		   FROM
		      bar
		   LEFT JOIN test_table u2 ON u2.key = bar.value::int) AS foo ON TRUE;
2023-11-25 00:43:52.075 UTC [3763797] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains VALUES
2023-11-25 00:43:52.075 UTC [3763797] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:697
2023-11-25 00:43:52.075 UTC [3763797] STATEMENT:  SELECT
		*
	FROM
		test_values as t1
			JOIN LATERAL (
				SELECT
					t1.key
				FROM
					(VALUES (1, 'one'), (2, 'two'), (3, 'three')) as t(num, v)
					  WHERE num > (SELECT max(key) FROM test_values)) as foo
		ON (true);
2023-11-25 00:43:52.091 UTC [3763797] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains VALUES
2023-11-25 00:43:52.091 UTC [3763797] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:697
2023-11-25 00:43:52.091 UTC [3763797] STATEMENT:  SELECT
	  count(*)
	FROM
	 (SELECT a, b FROM (VALUES (1, 'one'), (2, 'two'), (3, 'three')) as t(a,b)) as values_data(a,b)
	WHERE
	  NOT EXISTS
	      (SELECT
	          value
	       FROM
	          test_values
	       WHERE
	          test_values.key = values_data.a
	      );
2023-11-25 00:43:52.093 UTC [3763793] ERROR:  21000: more than one row returned by a subquery used as an expression
2023-11-25 00:43:52.093 UTC [3763793] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:52.093 UTC [3763793] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:52.093 UTC [3763793] STATEMENT:  WITH cte_1 AS (SELECT * FROM test_table),
		 cte_2 AS (SELECT * FROM test_table)
	(SELECT *, (SELECT key FROM cte_1) FROM test_table)
	UNION
	(SELECT *, 1 FROM cte_2);
2023-11-25 00:43:52.234 UTC [3763796] ERROR:  0A000: recursive complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:52.234 UTC [3763796] LOCATION:  CreateDistributedPlan, distributed_planner.c:1092
2023-11-25 00:43:52.234 UTC [3763796] STATEMENT:  SELECT avg(avgsub.id) FROM (
	    SELECT table_0.id FROM (
	        SELECT table_1.id FROM (
	            SELECT table_2.id FROM (
	                SELECT table_3.id FROM (
	                    SELECT table_4.id FROM dist0 AS table_4
	                    LEFT JOIN dist1 AS table_5 USING (id)
	                ) AS table_3 INNER JOIN dist0 AS table_6 USING (id)
	            ) AS table_2 WHERE table_2.id < 10 ORDER BY id LIMIT 47
	        ) AS table_1 RIGHT JOIN dist0 AS table_7 USING (id)
	    ) AS table_0 RIGHT JOIN dist1 AS table_8 USING (id)
	) AS avgsub;
2023-11-25 00:43:52.250 UTC [3763796] ERROR:  0A000: recursive complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:52.250 UTC [3763796] LOCATION:  CreateDistributedPlan, distributed_planner.c:1092
2023-11-25 00:43:52.250 UTC [3763796] STATEMENT:  WITH cte_0 AS (
	    SELECT table_0.id FROM dist1 AS table_0 FULL JOIN dist1 AS table_1 USING (id)
	)
	SELECT avg(table_5.id) FROM (
	    SELECT table_6.id FROM (
	        SELECT table_7.id FROM dist0 AS table_7 ORDER BY id LIMIT 87
	    ) AS table_6 INNER JOIN dist0 AS table_8 USING (id) WHERE table_8.id < 0 ORDER BY id
	) AS table_5 INNER JOIN dist0 AS table_9 USING (id);
2023-11-25 00:43:53.030 UTC [3764207] ERROR:  42601: parallel workers for vacuum must be between 0 and 1024 at character 9
2023-11-25 00:43:53.030 UTC [3764207] LOCATION:  ExecVacuum, vacuum.c:188
2023-11-25 00:43:53.030 UTC [3764207] STATEMENT:  VACUUM (PARALLEL -5) dist_table;
2023-11-25 00:43:53.030 UTC [3764207] ERROR:  42601: parallel option requires a value between 0 and 1024 at character 9
2023-11-25 00:43:53.030 UTC [3764207] LOCATION:  ExecVacuum, vacuum.c:176
2023-11-25 00:43:53.030 UTC [3764207] STATEMENT:  VACUUM (PARALLEL) dist_table;
2023-11-25 00:43:53.036 UTC [3764207] ERROR:  0A000: alter table command is currently unsupported
2023-11-25 00:43:53.036 UTC [3764207] DETAIL:  Only ADD|DROP COLUMN, SET|DROP NOT NULL, SET|DROP DEFAULT, ADD|DROP|VALIDATE CONSTRAINT, SET (), RESET (), ENABLE|DISABLE|NO FORCE|FORCE ROW LEVEL SECURITY, ATTACH|DETACH PARTITION and TYPE subcommands are supported.
2023-11-25 00:43:53.036 UTC [3764207] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3506
2023-11-25 00:43:53.036 UTC [3764207] STATEMENT:  ALTER TABLE generated_col_table ALTER COLUMN b DROP EXPRESSION;
2023-11-25 00:43:53.042 UTC [3764208] ERROR:  0A000: cannot distribute relation: gen2
2023-11-25 00:43:53.042 UTC [3764208] DETAIL:  Distribution column must not use GENERATED ALWAYS AS (...) STORED.
2023-11-25 00:43:53.042 UTC [3764208] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1825
2023-11-25 00:43:53.042 UTC [3764208] STATEMENT:  select create_distributed_table('gen2', 'val2');
2023-11-25 00:43:53.060 UTC [3764207] WARNING:  0A000: "function myvarcharin(cstring,oid,integer)" has dependency on unsupported object "type myvarchar"
2023-11-25 00:43:53.060 UTC [3764207] DETAIL:  "function myvarcharin(cstring,oid,integer)" will be created only locally
2023-11-25 00:43:53.060 UTC [3764207] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 00:43:53.060 UTC [3764207] WARNING:  0A000: "function myvarcharout(myvarchar)" has dependency on unsupported object "type myvarchar"
2023-11-25 00:43:53.060 UTC [3764207] DETAIL:  "function myvarcharout(myvarchar)" will be created only locally
2023-11-25 00:43:53.060 UTC [3764207] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 00:43:53.062 UTC [3764207] ERROR:  0A000: "table my_table" has dependency on unsupported object "type myvarchar"
2023-11-25 00:43:53.062 UTC [3764207] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 00:43:53.062 UTC [3764207] STATEMENT:  SELECT create_distributed_table('my_table', 'a');
2023-11-25 00:43:53.073 UTC [3764207] ERROR:  22023: EXPLAIN option WAL requires ANALYZE
2023-11-25 00:43:53.073 UTC [3764207] LOCATION:  ExplainQuery, explain.c:231
2023-11-25 00:43:53.073 UTC [3764207] STATEMENT:  EXPLAIN (WAL) INSERT INTO test_wal VALUES(1,11);
2023-11-25 00:43:53.080 UTC [3764208] ERROR:  XX000: Citus does not support COPY FROM with WHERE
2023-11-25 00:43:53.080 UTC [3764208] LOCATION:  ProcessCopyStmt, multi_copy.c:2934
2023-11-25 00:43:53.080 UTC [3764208] STATEMENT:  copy cptest from STDIN with csv where val < 4;
2023-11-25 00:43:53.080 UTC [3764208] ERROR:  42601: syntax error at or near "1" at character 1
2023-11-25 00:43:53.080 UTC [3764208] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:43:53.080 UTC [3764208] STATEMENT:  1,6
	2,3
	3,2
	4,9
	5,4
	select sum(id), sum(val) from cptest;
2023-11-25 00:43:53.127 UTC [3764208] ERROR:  23503: insert or update on table "collection_users" violates foreign key constraint "collection_users_fkey"
2023-11-25 00:43:53.127 UTC [3764208] DETAIL:  Key (key, collection_id)=(1, 1000) is not present in table "collections_list".
2023-11-25 00:43:53.127 UTC [3764208] LOCATION:  ri_ReportViolation, ri_triggers.c:2596
2023-11-25 00:43:53.127 UTC [3764208] STATEMENT:  INSERT INTO collection_users VALUES (1, 1000, 1);
2023-11-25 00:43:53.167 UTC [3764208] ERROR:  23503: insert or update on table "collection_users_60028" violates foreign key constraint "collection_users_fkey_60028"
2023-11-25 00:43:53.167 UTC [3764208] DETAIL:  Key (key, collection_id)=(1, 1000) is not present in table "collections_list_60016".
2023-11-25 00:43:53.167 UTC [3764208] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:53.167 UTC [3764208] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:53.167 UTC [3764208] STATEMENT:  INSERT INTO collection_users VALUES (1, 1000, 1);
2023-11-25 00:43:53.197 UTC [3764208] ERROR:  25006: cannot execute UPDATE in a read-only transaction
2023-11-25 00:43:53.197 UTC [3764208] LOCATION:  PreventCommandIfReadOnly, utility.c:414
2023-11-25 00:43:53.197 UTC [3764208] STATEMENT:  UPDATE test SET y = 35;
2023-11-25 00:43:53.200 UTC [3764208] ERROR:  25006: cannot execute UPDATE in a read-only transaction
2023-11-25 00:43:53.200 UTC [3764208] LOCATION:  PreventCommandIfReadOnly, utility.c:414
2023-11-25 00:43:53.200 UTC [3764208] STATEMENT:  UPDATE test SET y = 40;
2023-11-25 00:43:53.206 UTC [3764208] ERROR:  0A000: Hash distributed partition columns may not use a non deterministic collation
2023-11-25 00:43:53.206 UTC [3764208] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1864
2023-11-25 00:43:53.206 UTC [3764208] STATEMENT:  select create_distributed_table('col_test', 'val');
2023-11-25 00:43:53.499 UTC [3764208] ERROR:  42501: permission denied for schema test_pg12
2023-11-25 00:43:53.499 UTC [3764208] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:53.499 UTC [3764208] STATEMENT:  ALTER TABLE test_pg12.superuser_columnar_table SET(columnar.chunk_group_row_limit = 100);
2023-11-25 00:43:53.499 UTC [3764208] ERROR:  42501: permission denied for schema test_pg12
2023-11-25 00:43:53.499 UTC [3764208] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:53.499 UTC [3764208] STATEMENT:  ALTER TABLE test_pg12.superuser_columnar_table RESET (columnar.chunk_group_row_limit);
2023-11-25 00:43:53.678 UTC [3764336] ERROR:  0A000: PROCESS_TOAST required with VACUUM FULL
2023-11-25 00:43:53.678 UTC [3764336] LOCATION:  vacuum, vacuum.c:351
2023-11-25 00:43:53.678 UTC [3764336] STATEMENT:  VACUUM (FULL, PROCESS_TOAST false) t1;
2023-11-25 00:43:53.682 UTC [3764336] ERROR:  42601: index_cleanup requires a Boolean value
2023-11-25 00:43:53.682 UTC [3764336] LOCATION:  defGetBoolean, define.c:152
2023-11-25 00:43:53.682 UTC [3764336] STATEMENT:  VACUUM (INDEX_CLEANUP "AUTOX") t1;
2023-11-25 00:43:53.703 UTC [3764336] ERROR:  42704: tablespace "test_tablespace1" does not exist
2023-11-25 00:43:53.703 UTC [3764336] LOCATION:  get_tablespace_oid, tablespace.c:1484
2023-11-25 00:43:53.703 UTC [3764336] STATEMENT:  reindex(TABLESPACE test_tablespace1) index idx;
2023-11-25 00:43:53.708 UTC [3764336] ERROR:  0A000: only simple column references are allowed in CREATE STATISTICS
2023-11-25 00:43:53.708 UTC [3764336] LOCATION:  AppendColumnNames, deparse_statistics_stmts.c:242
2023-11-25 00:43:53.708 UTC [3764336] STATEMENT:  CREATE STATISTICS s3 (ndistinct) ON date_trunc('month', a), date_trunc('day', a) FROM tbl1;
2023-11-25 00:43:53.718 UTC [3764336] ERROR:  XX000: ALTER TABLE .. DETACH PARTITION .. CONCURRENTLY commands are currently unsupported.
2023-11-25 00:43:53.718 UTC [3764336] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3420
2023-11-25 00:43:53.718 UTC [3764336] STATEMENT:  ALTER TABLE par DETACH PARTITION par_2 CONCURRENTLY;
2023-11-25 00:43:53.718 UTC [3764336] ERROR:  XX000: ALTER TABLE .. DETACH PARTITION .. FINALIZE commands are currently unsupported.
2023-11-25 00:43:53.718 UTC [3764336] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3398
2023-11-25 00:43:53.718 UTC [3764336] STATEMENT:  ALTER TABLE par DETACH PARTITION par_2 FINALIZE;
2023-11-25 00:43:53.794 UTC [3764349] LOG:  00000: deferred drop of orphaned resource pg14.col_compression_980010 on localhost:57637 completed
2023-11-25 00:43:53.794 UTC [3764349] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 00:43:53.794 UTC [3764349] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:53.834 UTC [3764336] LOG:  00000: deferred drop of orphaned resource pg14.col_compression_980010 on localhost:57638 completed
2023-11-25 00:43:53.834 UTC [3764336] CONTEXT:  SQL statement "CALL pg_catalog.citus_cleanup_orphaned_resources()"
	PL/pgSQL function public.wait_for_resource_cleanup() line 7 at CALL
2023-11-25 00:43:53.834 UTC [3764336] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 00:43:53.834 UTC [3764336] STATEMENT:  SELECT public.wait_for_resource_cleanup();
2023-11-25 00:43:54.066 UTC [3764336] ERROR:  22004: jsonb subscript in assignment must not be null
2023-11-25 00:43:54.066 UTC [3764336] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:54.066 UTC [3764336] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:54.066 UTC [3764336] STATEMENT:  update test_jsonb_subscript set test_json[NULL] = '1';
2023-11-25 00:43:54.087 UTC [3764336] ERROR:  42P01: invalid reference to FROM-clause entry for table "j1_tbl" at character 57
2023-11-25 00:43:54.087 UTC [3764336] HINT:  There is an entry for table "j1_tbl", but it cannot be referenced from this part of the query.
2023-11-25 00:43:54.087 UTC [3764336] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 00:43:54.087 UTC [3764336] STATEMENT:  SELECT * FROM (J1_TBL JOIN J2_TBL USING (i)) AS x WHERE J1_TBL.t = 'one' ORDER BY 1,2,3,4;
2023-11-25 00:43:54.088 UTC [3764336] ERROR:  42703: column x.t does not exist at character 55
2023-11-25 00:43:54.088 UTC [3764336] LOCATION:  errorMissingColumn, parse_relation.c:3656
2023-11-25 00:43:54.088 UTC [3764336] STATEMENT:  SELECT * FROM J1_TBL JOIN J2_TBL USING (i) AS x WHERE x.t = 'one' ORDER BY 1,2,3,4;
2023-11-25 00:43:54.088 UTC [3764336] ERROR:  42P01: missing FROM-clause entry for table "x" at character 63
2023-11-25 00:43:54.088 UTC [3764336] LOCATION:  errorMissingRTE, parse_relation.c:3608
2023-11-25 00:43:54.088 UTC [3764336] STATEMENT:  SELECT * FROM (J1_TBL JOIN J2_TBL USING (i) AS x) AS xx WHERE x.i = 1 ORDER BY 1,2,3,4;
2023-11-25 00:43:54.088 UTC [3764336] ERROR:  42712: table name "a1" specified more than once
2023-11-25 00:43:54.088 UTC [3764336] LOCATION:  checkNameSpaceConflicts, parse_relation.c:443
2023-11-25 00:43:54.088 UTC [3764336] STATEMENT:  SELECT * FROM J1_TBL a1 JOIN J2_TBL a2 USING (i) AS a1 ORDER BY 1,2,3,4;
2023-11-25 00:43:54.104 UTC [3764336] ERROR:  0A000: REINDEX TABLE queries on distributed partitioned tables are not supported
2023-11-25 00:43:54.104 UTC [3764336] LOCATION:  PreprocessReindexStmt, index.c:635
2023-11-25 00:43:54.104 UTC [3764336] STATEMENT:  REINDEX TABLE dist_part_table;
2023-11-25 00:43:54.112 UTC [3764336] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 00:43:54.112 UTC [3764336] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 00:43:54.112 UTC [3764336] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph0 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph0 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	SELECT * FROM search_graph ORDER BY seq;
2023-11-25 00:43:54.112 UTC [3764336] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 00:43:54.112 UTC [3764336] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 00:43:54.112 UTC [3764336] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph0 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph0 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	DELETE FROM graph0 WHERE t IN (SELECT t FROM search_graph ORDER BY seq);
2023-11-25 00:43:54.117 UTC [3764336] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 00:43:54.117 UTC [3764336] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 00:43:54.117 UTC [3764336] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph1 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph1 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	SELECT * FROM search_graph ORDER BY seq;
2023-11-25 00:43:54.117 UTC [3764336] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 00:43:54.117 UTC [3764336] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 00:43:54.117 UTC [3764336] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph1 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph1 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	DELETE FROM graph1 WHERE t IN (SELECT t FROM search_graph ORDER BY seq);
2023-11-25 00:43:54.117 UTC [3764336] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 00:43:54.117 UTC [3764336] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 00:43:54.117 UTC [3764336] STATEMENT:  SELECT * FROM (
	    WITH RECURSIVE search_graph(f, t, label) AS (
	        SELECT *
	        FROM graph0 g
	        WHERE f = 1
	        UNION ALL SELECT g.*
	        FROM graph0 g, search_graph sg
	        WHERE g.f = sg.t AND g.f = 1
	    ) SEARCH DEPTH FIRST BY f, t SET seq
	    SELECT * FROM search_graph ORDER BY seq
	) as foo;
2023-11-25 00:43:54.125 UTC [3764336] ERROR:  42883: function "proc_with_out_param(date,int)" does not exist at character 36
2023-11-25 00:43:54.125 UTC [3764336] LOCATION:  regprocedurein, regproc.c:275
2023-11-25 00:43:54.125 UTC [3764336] STATEMENT:  SELECT create_distributed_function('proc_with_out_param(date,int)');
2023-11-25 00:43:55.587 UTC [3764441] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:43:55.587 UTC [3764441] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:43:55.587 UTC [3764441] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 00:43:55.588 UTC [3764441] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:43:55.588 UTC [3764441] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:43:55.588 UTC [3764441] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 00:43:55.589 UTC [3764441] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:43:55.589 UTC [3764441] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:43:55.589 UTC [3764441] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 00:43:55.623 UTC [3764456] LOG:  00000: cleaned up orphaned resource pg14.dist_table_1_980042 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:55.623 UTC [3764456] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:55.623 UTC [3764456] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:55.624 UTC [3764456] LOG:  00000: cleaned up orphaned resource pg14.dist_table_2_980044 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:55.624 UTC [3764456] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:55.624 UTC [3764456] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:56.667 UTC [3764441] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:43:56.667 UTC [3764441] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:43:56.667 UTC [3764441] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 00:43:56.667 UTC [3764441] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:43:56.667 UTC [3764441] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:43:56.667 UTC [3764441] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 00:43:56.668 UTC [3764441] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:43:56.668 UTC [3764441] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:43:56.668 UTC [3764441] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 00:43:56.837 UTC [3764482] ERROR:  42P17: parameter "locale" must be specified
2023-11-25 00:43:56.837 UTC [3764482] LOCATION:  DefineCollation, collationcmds.c:242
2023-11-25 00:43:56.837 UTC [3764482] STATEMENT:  CREATE COLLATION german_phonebook_test (provider = icu, lc_collate = 'de-u-co-phonebk');
2023-11-25 00:43:56.837 UTC [3764482] ERROR:  42P17: parameter "locale" must be specified
2023-11-25 00:43:56.837 UTC [3764482] LOCATION:  DefineCollation, collationcmds.c:242
2023-11-25 00:43:56.837 UTC [3764482] STATEMENT:  CREATE COLLATION german_phonebook_test (provider = icu, lc_collate = 'de-u-co-phonebk', lc_ctype = 'de-u-co-phonebk');
2023-11-25 00:43:57.014 UTC [3764482] ERROR:  XX000: cannot rename trigger "new_record_sale_trigger" on table "sale_newyork"
2023-11-25 00:43:57.014 UTC [3764482] HINT:  Rename the trigger on the partitioned table "sale" instead.
2023-11-25 00:43:57.014 UTC [3764482] LOCATION:  renametrig, trigger.c:1567
2023-11-25 00:43:57.014 UTC [3764482] STATEMENT:  ALTER TRIGGER "new_record_sale_trigger" ON "pg15"."sale_newyork" RENAME TO "another_trigger_name";
2023-11-25 00:43:57.022 UTC [3764482] ERROR:  2BP01: cannot drop column col_1 of table generated_stored_ref because other objects depend on it
2023-11-25 00:43:57.022 UTC [3764482] DETAIL:  column col_3 of table generated_stored_ref depends on column col_1 of table generated_stored_ref
	column col_5 of table generated_stored_ref depends on column col_1 of table generated_stored_ref
2023-11-25 00:43:57.022 UTC [3764482] HINT:  Use DROP ... CASCADE to drop the dependent objects too.
2023-11-25 00:43:57.022 UTC [3764482] LOCATION:  reportDependentObjects, dependency.c:1189
2023-11-25 00:43:57.022 UTC [3764482] STATEMENT:  ALTER TABLE generated_stored_ref DROP COLUMN col_1;
2023-11-25 00:43:57.052 UTC [3764518] LOG:  00000: cleaned up orphaned resource pg14.dist_table_1_980042 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:57.052 UTC [3764518] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:57.052 UTC [3764518] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:57.052 UTC [3764518] LOG:  00000: cleaned up orphaned resource pg14.dist_table_2_980044 on localhost:57638 which was left behind after a failed operation
2023-11-25 00:43:57.052 UTC [3764518] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 00:43:57.052 UTC [3764518] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:43:57.217 UTC [3764482] ERROR:  0A000: MERGE command is not supported on reference tables yet
2023-11-25 00:43:57.217 UTC [3764482] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:330
2023-11-25 00:43:57.217 UTC [3764482] STATEMENT:  MERGE INTO tbl1 USING tbl2 ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 00:43:57.225 UTC [3764482] ERROR:  0A000: MERGE command is not supported on reference tables yet
2023-11-25 00:43:57.225 UTC [3764482] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:330
2023-11-25 00:43:57.225 UTC [3764482] STATEMENT:  MERGE INTO tbl1 USING tbl2 ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 00:43:57.285 UTC [3764560] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:57.285 UTC [3764560] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:57.285 UTC [3764560] STATEMENT:  MERGE INTO tbl1 USING tbl2 ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 00:43:57.286 UTC [3764560] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:57.286 UTC [3764560] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:57.286 UTC [3764560] STATEMENT:  WITH targq AS (
	    SELECT * FROM tbl2
	)
	MERGE INTO tbl1 USING targq ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 00:43:57.286 UTC [3764560] ERROR:  0A000: MERGE not supported in WITH query at character 6
2023-11-25 00:43:57.286 UTC [3764560] LOCATION:  transformWithClause, parse_cte.c:131
2023-11-25 00:43:57.286 UTC [3764560] STATEMENT:  WITH foo AS (
	  MERGE INTO tbl1 USING tbl2 ON (true)
	  WHEN MATCHED THEN DELETE
	) SELECT * FROM foo;
2023-11-25 00:43:57.286 UTC [3764560] ERROR:  0A000: MERGE not supported in COPY
2023-11-25 00:43:57.286 UTC [3764560] LOCATION:  DoCopy, copy.c:281
2023-11-25 00:43:57.286 UTC [3764560] STATEMENT:  COPY (
	  MERGE INTO tbl1 USING tbl2 ON (true)
	  WHEN MATCHED THEN DELETE
	) TO stdout;
2023-11-25 00:43:57.286 UTC [3764560] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:43:57.286 UTC [3764560] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:43:57.286 UTC [3764560] STATEMENT:  MERGE INTO tbl1 t
	USING tbl2
	ON (true)
	WHEN MATCHED THEN
	    DO NOTHING;
2023-11-25 00:43:57.286 UTC [3764560] ERROR:  0A000: updating the distribution column is not allowed in MERGE actions
2023-11-25 00:43:57.286 UTC [3764560] LOCATION:  MergeQualAndTargetListFunctionsSupported, merge_planner.c:651
2023-11-25 00:43:57.286 UTC [3764560] STATEMENT:  MERGE INTO tbl1 t
	USING tbl2
	ON (true)
	WHEN MATCHED THEN
	    UPDATE SET x = (SELECT count(*) FROM tbl2);
2023-11-25 00:43:57.287 UTC [3764560] ERROR:  0A000: cannot distribute relation: numeric_negative_scale
2023-11-25 00:43:57.287 UTC [3764560] DETAIL:  Distribution column must not use numeric type with negative scale
2023-11-25 00:43:57.287 UTC [3764560] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1838
2023-11-25 00:43:57.287 UTC [3764560] STATEMENT:  SELECT create_distributed_table('numeric_negative_scale','numeric_column');
2023-11-25 00:43:57.305 UTC [3764560] ERROR:  0A000: cannot distribute relation: numeric_negative_scale_3037880381
2023-11-25 00:43:57.305 UTC [3764560] DETAIL:  Distribution column must not use numeric type with negative scale
2023-11-25 00:43:57.305 UTC [3764560] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1838
2023-11-25 00:43:57.305 UTC [3764560] STATEMENT:  SELECT alter_distributed_table('numeric_negative_scale',
	                                distribution_column := 'numeric_column');
2023-11-25 00:43:57.376 UTC [3764560] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:43:57.376 UTC [3764560] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:43:57.376 UTC [3764560] STATEMENT:  SELECT count(*)
	FROM numeric_repartition_first f,
	     numeric_repartition_second s
	WHERE f.id = s.numeric_column;
2023-11-25 00:43:57.595 UTC [3764560] ERROR:  22P04: column name mismatch in header line field 2: got "data", expected "data_"
2023-11-25 00:43:57.595 UTC [3764560] CONTEXT:  COPY copy_test2, line 1: "id	data"
2023-11-25 00:43:57.595 UTC [3764560] LOCATION:  NextCopyFromRawFields, copyfromparse.c:806
2023-11-25 00:43:57.595 UTC [3764560] STATEMENT:  COPY copy_test2 FROM '/tmp/''copy_test.txt' WITH ( HEADER match, FORMAT text);
2023-11-25 00:43:57.663 UTC [3764756] ERROR:  42P01: relation "seq_non_exists" does not exist
2023-11-25 00:43:57.663 UTC [3764756] LOCATION:  RangeVarGetRelidExtended, namespace.c:433
2023-11-25 00:43:57.663 UTC [3764756] STATEMENT:  ALTER SEQUENCE seq_non_exists SET LOGGED;
2023-11-25 00:43:57.737 UTC [3764770] ERROR:  0A000: cannot create foreign key constraint
2023-11-25 00:43:57.737 UTC [3764770] DETAIL:  SET NULL or SET DEFAULT is not supported in ON DELETE operation when distribution key is included in the foreign key constraint
2023-11-25 00:43:57.737 UTC [3764770] LOCATION:  EnsureSupportedFKeyOnDistKey, foreign_constraint.c:548
2023-11-25 00:43:57.737 UTC [3764770] STATEMENT:  SELECT create_distributed_table('FKTABLE', 'tid');
2023-11-25 00:43:57.791 UTC [3764775] ERROR:  23505: duplicate key value violates unique constraint "idx2_null_distinct_test_960150"
2023-11-25 00:43:57.791 UTC [3764775] DETAIL:  Key (id, c2)=(1, null) already exists.
2023-11-25 00:43:57.791 UTC [3764775] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:57.791 UTC [3764775] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:57.791 UTC [3764775] STATEMENT:  INSERT INTO null_distinct_test VALUES (1, NULL, NULL, 'data4') ;
2023-11-25 00:43:57.804 UTC [3764775] ERROR:  23505: could not create unique index "uniq_c1_960150"
2023-11-25 00:43:57.804 UTC [3764775] DETAIL:  Key (id, c1)=(1, null) is duplicated.
2023-11-25 00:43:57.804 UTC [3764775] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:57.804 UTC [3764775] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:57.804 UTC [3764775] STATEMENT:  ALTER TABLE null_distinct_test ADD CONSTRAINT uniq_c1 UNIQUE NULLS NOT DISTINCT (id,c1);
2023-11-25 00:43:57.821 UTC [3764775] ERROR:  23505: duplicate key value violates unique constraint "reference_uniq_test_x_y_key_960154"
2023-11-25 00:43:57.821 UTC [3764775] DETAIL:  Key (x, y)=(1, null) already exists.
2023-11-25 00:43:57.821 UTC [3764775] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:57.821 UTC [3764775] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:57.821 UTC [3764775] STATEMENT:  INSERT INTO reference_uniq_test VALUES (1, NULL);
2023-11-25 00:43:57.822 UTC [3764775] WARNING:  01000: not propagating CLUSTER command for partitioned table to worker nodes
2023-11-25 00:43:57.822 UTC [3764775] HINT:  Provide a child partition table names in order to CLUSTER distributed partitioned tables.
2023-11-25 00:43:57.822 UTC [3764775] LOCATION:  PreprocessClusterStmt, cluster.c:85
2023-11-25 00:43:57.825 UTC [3764775] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 00:43:57.825 UTC [3764775] HINT:  Run the query on the parent table "sale" instead.
2023-11-25 00:43:57.825 UTC [3764775] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 00:43:57.825 UTC [3764775] STATEMENT:  CLUSTER sale_newyork USING sale_newyork_pkey;
2023-11-25 00:43:57.848 UTC [3764775] WARNING:  01000: not propagating CLUSTER command for partitioned table to worker nodes
2023-11-25 00:43:57.848 UTC [3764775] HINT:  Provide a child partition table names in order to CLUSTER distributed partitioned tables.
2023-11-25 00:43:57.848 UTC [3764775] LOCATION:  PreprocessClusterStmt, cluster.c:85
2023-11-25 00:43:57.935 UTC [3764827] ERROR:  42501: permission denied for table events
2023-11-25 00:43:57.935 UTC [3764827] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:57.935 UTC [3764827] STATEMENT:  SELECT * FROM sec_invoker_view ORDER BY event_id;
2023-11-25 00:43:57.977 UTC [3764845] ERROR:  42501: permission denied for table events
2023-11-25 00:43:57.977 UTC [3764845] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:43:57.977 UTC [3764845] STATEMENT:  SELECT * FROM sec_definer_view ORDER BY event_id;
2023-11-25 00:43:57.991 UTC [3764845] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 00:43:57.991 UTC [3764845] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 00:43:57.991 UTC [3764845] STATEMENT:  UPDATE sec_invoker_view SET event_id = 5;
2023-11-25 00:43:58.010 UTC [3764845] ERROR:  XX000: cannot create foreign key constraint since Citus does not support ON DELETE / UPDATE SET DEFAULT actions on the columns that default to sequences
2023-11-25 00:43:58.010 UTC [3764845] LOCATION:  ErrorIfUnsupportedForeignConstraintExists, foreign_constraint.c:274
2023-11-25 00:43:58.010 UTC [3764845] STATEMENT:  SELECT create_reference_table('set_on_default_test_referencing');
2023-11-25 00:43:58.272 UTC [3764845] ERROR:  XX000: cannot create foreign key constraint since Citus does not support ON DELETE / UPDATE SET DEFAULT actions on the columns that default to sequences
2023-11-25 00:43:58.272 UTC [3764845] LOCATION:  ErrorIfUnsupportedForeignConstraintExists, foreign_constraint.c:274
2023-11-25 00:43:58.272 UTC [3764845] STATEMENT:  CREATE TABLE set_on_default_test_referencing(
	    col_1 int, col_2 int, col_3 serial, col_4 int,
	    FOREIGN KEY(col_1, col_3)
	    REFERENCES set_on_default_test_referenced(col_1, col_3)
	    ON DELETE SET DEFAULT (col_3)
	);
2023-11-25 00:43:58.298 UTC [3764919] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown at character 77
2023-11-25 00:43:58.298 UTC [3764919] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:43:58.298 UTC [3764919] LOCATION:  op_error, parse_oper.c:647
2023-11-25 00:43:58.298 UTC [3764919] STATEMENT:  DECLARE c1 CURSOR FOR
	SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 00:43:58.298 UTC [3764845] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown
2023-11-25 00:43:58.298 UTC [3764845] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:43:58.298 UTC [3764845] CONTEXT:  remote SQL command: SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 00:43:58.298 UTC [3764845] LOCATION:  pgfdw_report_error, connection.c:895
2023-11-25 00:43:58.298 UTC [3764845] STATEMENT:  SELECT * FROM foreign_table WHERE c1 LIKE 'foo' LIMIT 1;
2023-11-25 00:43:58.299 UTC [3764919] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown at character 77
2023-11-25 00:43:58.299 UTC [3764919] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:43:58.299 UTC [3764919] LOCATION:  op_error, parse_oper.c:647
2023-11-25 00:43:58.299 UTC [3764919] STATEMENT:  DECLARE c1 CURSOR FOR
	SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 00:43:58.299 UTC [3764845] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown
2023-11-25 00:43:58.299 UTC [3764845] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:43:58.299 UTC [3764845] CONTEXT:  remote SQL command: SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 00:43:58.299 UTC [3764845] LOCATION:  pgfdw_report_error, connection.c:895
2023-11-25 00:43:58.299 UTC [3764845] STATEMENT:  SELECT * FROM foreign_table WHERE c1::text LIKE 'foo' LIMIT 1;
2023-11-25 00:43:58.334 UTC [3758161] LOG:  00000: checkpoint starting: immediate force wait
2023-11-25 00:43:58.334 UTC [3758161] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 00:43:58.375 UTC [3758161] LOG:  00000: checkpoint complete: wrote 2905 buffers (17.7%); 0 WAL file(s) added, 0 removed, 3 recycled; write=0.012 s, sync=0.001 s, total=0.041 s; sync files=0, longest=0.000 s, average=0.000 s; distance=55099 kB, estimate=55099 kB
2023-11-25 00:43:58.375 UTC [3758161] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 00:43:58.729 UTC [3764948] ERROR:  22P02: invalid input syntax for type jsonpath: ""
2023-11-25 00:43:58.729 UTC [3764948] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:58.729 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.729 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '';
2023-11-25 00:43:58.736 UTC [3764948] ERROR:  22P02: invalid input syntax for type jsonpath: ""
2023-11-25 00:43:58.736 UTC [3764948] LOCATION:  jsonPathFromCstring, jsonpath.c:180
2023-11-25 00:43:58.736 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.737 UTC [3764948] ERROR:  42601: LAST is allowed only in array subscripts
2023-11-25 00:43:58.737 UTC [3764948] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:58.737 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.737 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = 'last';
2023-11-25 00:43:58.746 UTC [3764948] ERROR:  42601: LAST is allowed only in array subscripts
2023-11-25 00:43:58.746 UTC [3764948] LOCATION:  flattenJsonPathParseItem, jsonpath.c:366
2023-11-25 00:43:58.746 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = 'last' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.747 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "1.t" of jsonpath input
2023-11-25 00:43:58.747 UTC [3764948] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:58.747 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.747 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '1.type()';
2023-11-25 00:43:58.754 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "1.t" of jsonpath input
2023-11-25 00:43:58.754 UTC [3764948] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 00:43:58.754 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '1.type()' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.755 UTC [3764948] ERROR:  2201B: invalid regular expression: parentheses () not balanced
2023-11-25 00:43:58.755 UTC [3764948] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:58.755 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.755 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "(invalid pattern")';
2023-11-25 00:43:58.763 UTC [3764948] ERROR:  2201B: invalid regular expression: parentheses () not balanced
2023-11-25 00:43:58.763 UTC [3764948] LOCATION:  RE_compile_and_cache, regexp.c:207
2023-11-25 00:43:58.763 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "(invalid pattern")' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.764 UTC [3764948] ERROR:  0A000: XQuery "x" flag (expanded regular expressions) is not implemented
2023-11-25 00:43:58.764 UTC [3764948] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:58.764 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.764 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "pattern" flag "xsms")';
2023-11-25 00:43:58.773 UTC [3764948] ERROR:  0A000: XQuery "x" flag (expanded regular expressions) is not implemented
2023-11-25 00:43:58.773 UTC [3764948] LOCATION:  jspConvertRegexFlags, jsonpath_gram.y:582
2023-11-25 00:43:58.773 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "pattern" flag "xsms")' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.774 UTC [3764948] ERROR:  42601: @ is not allowed in root expressions
2023-11-25 00:43:58.774 UTC [3764948] CONTEXT:  while executing command on localhost:57638
2023-11-25 00:43:58.774 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.774 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '@ + 1';
2023-11-25 00:43:58.781 UTC [3764948] ERROR:  42601: @ is not allowed in root expressions
2023-11-25 00:43:58.781 UTC [3764948] LOCATION:  flattenJsonPathParseItem, jsonpath.c:360
2023-11-25 00:43:58.781 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '@ + 1' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.782 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "00" of jsonpath input
2023-11-25 00:43:58.782 UTC [3764948] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:58.782 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.782 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '00';
2023-11-25 00:43:58.791 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "00" of jsonpath input
2023-11-25 00:43:58.791 UTC [3764948] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 00:43:58.791 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '00' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.793 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "1.e" of jsonpath input
2023-11-25 00:43:58.793 UTC [3764948] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:58.793 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.793 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '1.e';
2023-11-25 00:43:58.802 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "1.e" of jsonpath input
2023-11-25 00:43:58.802 UTC [3764948] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 00:43:58.802 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '1.e' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:58.803 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "1.2e3a" of jsonpath input
2023-11-25 00:43:58.803 UTC [3764948] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:43:58.803 UTC [3764948] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:43:58.803 UTC [3764948] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '1.2e3a';
2023-11-25 00:43:58.810 UTC [3764948] ERROR:  42601: trailing junk after numeric literal at or near "1.2e3a" of jsonpath input
2023-11-25 00:43:58.810 UTC [3764948] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 00:43:58.810 UTC [3764948] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '1.2e3a' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 00:43:59.632 UTC [3764947] ERROR:  08006: connection to the remote node localhost:57637 failed with the following error: connection not open
2023-11-25 00:43:59.632 UTC [3764947] LOCATION:  ReportConnectionError, remote_commands.c:266
2023-11-25 00:43:59.632 UTC [3764947] STATEMENT:  SELECT count(*) FROM socket_test_table;
2023-11-25 00:44:00.837 UTC [3765304] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.837 UTC [3765304] LOCATION:  fake_tuple_insert, fake_am.c:204
2023-11-25 00:44:00.847 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.847 UTC [3765304] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_hash_dist LIMIT 1"
2023-11-25 00:44:00.847 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.855 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.855 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.856 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.856 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.857 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.857 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.857 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.857 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.857 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.857 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.858 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.858 UTC [3765304] DETAIL:  from localhost:57638
2023-11-25 00:44:00.858 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.858 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.858 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.858 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.858 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.858 UTC [3765304] DETAIL:  from localhost:57638
2023-11-25 00:44:00.858 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.860 UTC [3765304] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.860 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.860 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.861 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.861 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.861 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.861 UTC [3765304] ERROR:  XX000: fake_tuple_delete not implemented
2023-11-25 00:44:00.861 UTC [3765304] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:00.861 UTC [3765304] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:00.861 UTC [3765304] STATEMENT:  delete from test_hash_dist where id=1;
2023-11-25 00:44:00.863 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.863 UTC [3765304] DETAIL:  from localhost:57638
2023-11-25 00:44:00.863 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.864 UTC [3765304] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.864 UTC [3765304] LOCATION:  fake_tuple_insert, fake_am.c:204
2023-11-25 00:44:00.864 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.864 UTC [3765304] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_ref LIMIT 1"
2023-11-25 00:44:00.864 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.871 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.871 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.872 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.872 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.873 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.873 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.873 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.873 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.873 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.873 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.873 UTC [3765304] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.873 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.873 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.874 UTC [3765304] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.874 UTC [3765304] DETAIL:  from localhost:57638
2023-11-25 00:44:00.874 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.875 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.875 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.875 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.875 UTC [3765304] ERROR:  XX000: fake_tuple_delete not implemented
2023-11-25 00:44:00.875 UTC [3765304] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:00.875 UTC [3765304] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:00.875 UTC [3765304] STATEMENT:  delete from test_ref;
2023-11-25 00:44:00.877 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.877 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.877 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.877 UTC [3765304] ERROR:  XX000: fake_fetch_row_version not implemented
2023-11-25 00:44:00.877 UTC [3765304] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:00.877 UTC [3765304] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:00.877 UTC [3765304] STATEMENT:  update test_ref set a=2;
2023-11-25 00:44:00.878 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.878 UTC [3765304] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_range_dist LIMIT 1"
2023-11-25 00:44:00.878 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.878 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.878 UTC [3765304] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_range_dist LIMIT 1"
2023-11-25 00:44:00.878 UTC [3765304] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.884 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.884 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.884 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.884 UTC [3765304] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.884 UTC [3765304] DETAIL:  from localhost:57638
2023-11-25 00:44:00.884 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.885 UTC [3765304] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.885 UTC [3765304] DETAIL:  from localhost:57637
2023-11-25 00:44:00.885 UTC [3765304] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.931 UTC [3765331] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.931 UTC [3765331] LOCATION:  fake_tuple_insert, fake_am.c:204
2023-11-25 00:44:00.953 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.953 UTC [3765331] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_partitioned_p2 LIMIT 1"
2023-11-25 00:44:00.953 UTC [3765331] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.957 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.957 UTC [3765331] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.958 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.958 UTC [3765331] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 00:44:00.960 UTC [3765331] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.960 UTC [3765331] DETAIL:  from localhost:57637
2023-11-25 00:44:00.960 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.961 UTC [3765331] WARNING:  01000: fake_tuple_insert
2023-11-25 00:44:00.961 UTC [3765331] DETAIL:  from localhost:57638
2023-11-25 00:44:00.961 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.962 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.962 UTC [3765331] DETAIL:  from localhost:57637
2023-11-25 00:44:00.962 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.963 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.963 UTC [3765331] DETAIL:  from localhost:57638
2023-11-25 00:44:00.963 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.963 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.963 UTC [3765331] DETAIL:  from localhost:57638
2023-11-25 00:44:00.963 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.963 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.963 UTC [3765331] DETAIL:  from localhost:57637
2023-11-25 00:44:00.963 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.963 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.963 UTC [3765331] DETAIL:  from localhost:57638
2023-11-25 00:44:00.963 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.963 UTC [3765331] WARNING:  01000: fake_scan_getnextslot
2023-11-25 00:44:00.963 UTC [3765331] DETAIL:  from localhost:57638
2023-11-25 00:44:00.963 UTC [3765331] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 00:44:00.979 UTC [3765331] ERROR:  0A000: specifying a table access method is not supported on a partitioned table
2023-11-25 00:44:00.979 UTC [3765331] LOCATION:  DefineRelation, tablecmds.c:947
2023-11-25 00:44:00.979 UTC [3765331] STATEMENT:  CREATE TABLE test_partitioned(id int, p int, val int)
	PARTITION BY RANGE (p) USING fake_am;
2023-11-25 00:44:01.045 UTC [3765367] ERROR:  XX000: the backend has already been assigned a transaction id
2023-11-25 00:44:01.045 UTC [3765367] LOCATION:  assign_distributed_transaction_id, backend_data.c:168
2023-11-25 00:44:01.045 UTC [3765367] STATEMENT:  SELECT assign_distributed_transaction_id(51, 51, '2017-01-01 00:00:00+0');
2023-11-25 00:44:01.046 UTC [3765367] ERROR:  22012: division by zero
2023-11-25 00:44:01.046 UTC [3765367] LOCATION:  int4div, int.c:840
2023-11-25 00:44:01.046 UTC [3765367] STATEMENT:  SELECT 5 / 0;
2023-11-25 00:44:01.054 UTC [3765366] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 2 kB)
2023-11-25 00:44:01.054 UTC [3765366] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 00:44:01.054 UTC [3765366] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 00:44:01.054 UTC [3765366] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 00:44:01.054 UTC [3765366] STATEMENT:  WITH cte AS MATERIALIZED
	(
		SELECT * FROM users_table
	),
	cte2 AS MATERIALIZED (
		SELECT * FROM events_table
	)
	SELECT cte.user_id, cte.value_2 FROM cte,cte2 ORDER BY 1,2 LIMIT 10;
2023-11-25 00:44:01.059 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.059 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.153 UTC [3765368] ERROR:  CIINF: Query could not find the intermediate result file "squares", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.153 UTC [3765368] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:148
2023-11-25 00:44:01.153 UTC [3765368] STATEMENT:  SELECT x, x2
	FROM interesting_squares JOIN (SELECT * FROM read_intermediate_result('squares', 'binary') AS res (x text, x2 int)) squares ON (x = interested_in)
	WHERE user_id = 'jon' OR true
	ORDER BY x;
2023-11-25 00:44:01.155 UTC [3765368] ERROR:  CIINF: Query could not find the intermediate result file "squares", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.155 UTC [3765368] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:148
2023-11-25 00:44:01.155 UTC [3765368] STATEMENT:  SELECT x, x2
	FROM interesting_squares JOIN (SELECT * FROM read_intermediate_result('squares', 'binary') AS res (x text, x2 int)) squares ON (x = interested_in)
	WHERE user_id = 'jon'
	ORDER BY x;
2023-11-25 00:44:01.156 UTC [3765368] ERROR:  22021: invalid byte sequence for encoding "UTF8": 0x00
2023-11-25 00:44:01.156 UTC [3765368] LOCATION:  report_invalid_encoding, mbutils.c:1665
2023-11-25 00:44:01.156 UTC [3765368] STATEMENT:  SELECT * FROM read_intermediate_result('squares', 'binary') AS res (x text, x2 int);
2023-11-25 00:44:01.157 UTC [3765368] ERROR:  22P02: invalid input syntax for type integer: "PGCOPY"
2023-11-25 00:44:01.157 UTC [3765368] LOCATION:  pg_strtoint32, numutils.c:232
2023-11-25 00:44:01.157 UTC [3765368] STATEMENT:  SELECT * FROM read_intermediate_result('squares', 'csv') AS res (x int, x2 int);
2023-11-25 00:44:01.164 UTC [3765368] ERROR:  22P04: COPY file signature not recognized
2023-11-25 00:44:01.164 UTC [3765368] LOCATION:  ReceiveCopyBinaryHeader, copyfromparse.c:198
2023-11-25 00:44:01.164 UTC [3765368] STATEMENT:  SELECT * FROM read_intermediate_result('stored_squares', 'binary') AS res (s intermediate_results.square_type);
BEGIN
COPY 0
SELECT 5
COMMIT
2023-11-25 00:44:01.189 UTC [3765368] ERROR:  XX000: cannot execute utility commands
2023-11-25 00:44:01.189 UTC [3765368] LOCATION:  ExecuteQueryIntoDestReceiver, multi_executor.c:664
2023-11-25 00:44:01.189 UTC [3765368] STATEMENT:  select broadcast_intermediate_result('a', 'create table foo(int serial)');
2023-11-25 00:44:01.189 UTC [3765368] ERROR:  XX000: cannot execute utility commands
2023-11-25 00:44:01.189 UTC [3765368] LOCATION:  ExecuteQueryIntoDestReceiver, multi_executor.c:664
2023-11-25 00:44:01.189 UTC [3765368] STATEMENT:  select broadcast_intermediate_result('a', 'prepare foo as select 1');
2023-11-25 00:44:01.189 UTC [3765368] ERROR:  XX000: cannot execute utility commands
2023-11-25 00:44:01.189 UTC [3765368] LOCATION:  ExecuteQueryIntoDestReceiver, multi_executor.c:664
2023-11-25 00:44:01.189 UTC [3765368] STATEMENT:  select create_intermediate_result('a', 'create table foo(int serial)');
2023-11-25 00:44:01.191 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.191 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.191 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "notexistingfile", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.191 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.191 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "notexistingfile", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.191 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.192 UTC [3765368] ERROR:  22004: null array element not allowed in this context
2023-11-25 00:44:01.192 UTC [3765368] LOCATION:  deconstruct_array, arrayfuncs.c:3525
2023-11-25 00:44:01.192 UTC [3765368] STATEMENT:  SELECT * FROM read_intermediate_results(ARRAY['squares_1', NULL], 'binary') AS res (x int, x2 int);
2023-11-25 00:44:01.192 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.192 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.211 UTC [3765366] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 2 kB)
2023-11-25 00:44:01.211 UTC [3765366] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 00:44:01.211 UTC [3765366] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 00:44:01.211 UTC [3765366] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 00:44:01.211 UTC [3765366] STATEMENT:  WITH cte AS MATERIALIZED (SELECT * FROM users_table WHERE user_id IN (1,2,3,4,5))
	SELECT * FROM cte ORDER BY 1,2,3,4,5 LIMIT 10;
2023-11-25 00:44:01.211 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.211 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.211 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_2", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.211 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.212 UTC [3765366] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 0 kB)
2023-11-25 00:44:01.212 UTC [3765366] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 00:44:01.212 UTC [3765366] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 00:44:01.212 UTC [3765366] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 00:44:01.212 UTC [3765366] STATEMENT:  WITH cte AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=1),
	cte2 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=2),
	cte3 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=3),
	cte4 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=4),
	cte5 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=5)
	SELECT * FROM (
	(SELECT * FROM cte)
	UNION
	(SELECT * FROM cte2)
	UNION
	(SELECT * FROM cte3)
	UNION
	(SELECT * FROM cte4)
	UNION
	(SELECT * FROM cte5)
	)a ORDER BY 1,2,3,4,5 LIMIT 10;
2023-11-25 00:44:01.213 UTC [3765368] ERROR:  XX000: cannot connect to localhost:57635 to fetch intermediate results
2023-11-25 00:44:01.213 UTC [3765368] LOCATION:  fetch_intermediate_results, intermediate_results.c:929
2023-11-25 00:44:01.213 UTC [3765368] STATEMENT:  SELECT * FROM fetch_intermediate_results(ARRAY['squares_1', 'squares_2']::text[], 'localhost', 57635);
2023-11-25 00:44:01.215 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.215 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.215 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_2", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.215 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.227 UTC [3765366] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 3 kB)
2023-11-25 00:44:01.227 UTC [3765366] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 00:44:01.227 UTC [3765366] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 00:44:01.227 UTC [3765366] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 00:44:01.227 UTC [3765366] STATEMENT:  WITH cte AS MATERIALIZED (
		WITH cte2 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id IN (3,4,5,6)
		),
		cte3 AS MATERIALIZED(
			SELECT * FROM events_table WHERE event_type = 1
		)
		SELECT * FROM cte2, cte3 WHERE cte2.value_1 IN (SELECT value_2 FROM cte3)
	)
	SELECT count(*) FROM cte;
2023-11-25 00:44:01.229 UTC [3765368] ERROR:  22004: worker array object cannot contain null values
2023-11-25 00:44:01.229 UTC [3765368] LOCATION:  DeconstructArrayObject, array_type.c:43
2023-11-25 00:44:01.229 UTC [3765368] STATEMENT:  SELECT * FROM fetch_intermediate_results(ARRAY[NULL, 'squares_1', 'squares_2']::text[], 'localhost', 57637);
2023-11-25 00:44:01.231 UTC [3765366] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 2 kB)
2023-11-25 00:44:01.231 UTC [3765366] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 00:44:01.231 UTC [3765366] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 00:44:01.231 UTC [3765366] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 00:44:01.231 UTC [3765366] STATEMENT:  WITH cte AS MATERIALIZED (
		WITH cte2 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id IN (1, 2)
		),
		cte3 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id = 3
		)
		SELECT * FROM cte2 UNION (SELECT * FROM cte3)
	),
	cte4 AS MATERIALIZED (
		SELECT * FROM events_table
	)
	SELECT * FROM cte UNION ALL
	SELECT * FROM cte4 ORDER BY 1,2,3,4,5 LIMIT 5;
2023-11-25 00:44:01.231 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.231 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.231 UTC [3765368] WARNING:  CIINF: Query could not find the intermediate result file "squares_2", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 00:44:01.231 UTC [3765368] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 00:44:01.235 UTC [3765366] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 1 kB)
2023-11-25 00:44:01.235 UTC [3765366] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 00:44:01.235 UTC [3765366] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 00:44:01.235 UTC [3765366] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 00:44:01.235 UTC [3765366] STATEMENT:  WITH cte AS MATERIALIZED (
		WITH cte2 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id IN (1, 2)
		),
		cte3 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id = 3
		)
		SELECT * FROM cte2 UNION (SELECT * FROM cte3)
	),
	cte4 AS MATERIALIZED (
		SELECT * FROM events_table
	)
	SELECT * FROM cte UNION ALL
	SELECT * FROM cte4 ORDER BY 1,2,3,4,5 LIMIT 5;
2023-11-25 00:44:01.922 UTC [3765663] ERROR:  XX000: query must be distributed and shouldn't require any merging on the coordinator.
2023-11-25 00:44:01.922 UTC [3765663] LOCATION:  partition_task_list_results, distributed_intermediate_results.c:60
2023-11-25 00:44:01.922 UTC [3765663] STATEMENT:  SELECT partition_task_list_results('test', $$ SELECT avg(a) FROM source_table $$, 'target_table');
2023-11-25 00:44:01.922 UTC [3765663] ERROR:  XX000: query must be distributed and shouldn't require any merging on the coordinator.
2023-11-25 00:44:01.922 UTC [3765663] LOCATION:  partition_task_list_results, distributed_intermediate_results.c:60
2023-11-25 00:44:01.922 UTC [3765663] STATEMENT:  SELECT partition_task_list_results('test', $$ SELECT * FROM generate_series(1, 2) $$, 'target_table');
2023-11-25 00:44:02.025 UTC [3765666] ERROR:  25001: cannot perform query with placements that were modified over multiple connections
2023-11-25 00:44:02.025 UTC [3765666] LOCATION:  FindPlacementListConnection, placement_connection.c:613
2023-11-25 00:44:02.025 UTC [3765666] STATEMENT:  SELECT COUNT(*) FROM test_table JOIN ref_test_table USING (id);
2023-11-25 00:44:02.449 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:44:02.449 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:44:02.450 UTC [3758160] LOG:  00000: parameter "deadlock_timeout" changed to "250ms"
2023-11-25 00:44:02.450 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:44:02.456 UTC [3765816] ERROR:  0A000: repartitioning results of a tasklist is only supported when target relation is hash or range partitioned.
2023-11-25 00:44:02.456 UTC [3765816] LOCATION:  PartitionTasklistResults, distributed_intermediate_results.c:152
2023-11-25 00:44:02.456 UTC [3765816] STATEMENT:  CREATE TABLE distributed_result_info AS
	  SELECT * FROM redistribute_task_list_results('test', $$ SELECT * FROM source_table $$, 'target_table_reference');
2023-11-25 00:44:02.458 UTC [3765816] ERROR:  0A000: repartitioning results of a tasklist is only supported when target relation is hash or range partitioned.
2023-11-25 00:44:02.458 UTC [3765816] LOCATION:  PartitionTasklistResults, distributed_intermediate_results.c:152
2023-11-25 00:44:02.458 UTC [3765816] STATEMENT:  CREATE TABLE distributed_result_info AS
	  SELECT * FROM redistribute_task_list_results('test', $$ SELECT * FROM source_table $$, 'target_table_append');
2023-11-25 00:44:02.646 UTC [3765662] ERROR:  XX000: cannot EXPLAIN ANALYZE multiple queries
2023-11-25 00:44:02.646 UTC [3765662] LOCATION:  worker_save_query_explain_analyze, multi_explain.c:1048
2023-11-25 00:44:02.646 UTC [3765662] STATEMENT:  SELECT * FROM worker_save_query_explain_analyze('SELECT 1; SELECT 2', '{"costs": false, "timing": false, "summary": false}'::jsonb) as (a int);
2023-11-25 00:44:02.646 UTC [3765662] ERROR:  42703: column "x" does not exist at character 8
2023-11-25 00:44:02.646 UTC [3765662] LOCATION:  errorMissingColumn, parse_relation.c:3656
2023-11-25 00:44:02.646 UTC [3765662] STATEMENT:  SELECT * FROM worker_save_query_explain_analyze('SELECT x', '{"costs": false, "timing": false, "summary": false}'::jsonb) as (a int);
2023-11-25 00:44:02.646 UTC [3765662] ERROR:  XX000: Invalid explain analyze format: "invlaid_format"
2023-11-25 00:44:02.646 UTC [3765662] LOCATION:  ExtractFieldExplainFormat, multi_explain.c:1163
2023-11-25 00:44:02.646 UTC [3765662] STATEMENT:  SELECT * FROM worker_save_query_explain_analyze('SELECT 1', '{"format": "invlaid_format"}') as (a int);
2023-11-25 00:44:02.942 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:02.942 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:02.942 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:02.967 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:02.967 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:02.967 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:02.993 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:02.993 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:02.993 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.018 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:03.018 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:03.018 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.043 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:03.043 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:03.043 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.069 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:03.069 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:03.069 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.094 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:03.094 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:03.094 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.120 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:03.120 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:03.120 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.145 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:03.145 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:03.145 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.170 UTC [3765666] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:03.170 UTC [3765666] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:03.170 UTC [3765666] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 00:44:03.343 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:44:03.343 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:44:03.343 UTC [3758160] LOG:  00000: parameter "deadlock_timeout" removed from configuration file, reset to default
2023-11-25 00:44:03.343 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 00:44:03.705 UTC [3765665] ERROR:  XX000: worker_partition_query_result can only be used in a transaction block
2023-11-25 00:44:03.705 UTC [3765665] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:151
2023-11-25 00:44:03.705 UTC [3765665] STATEMENT:  SELECT * FROM worker_partition_query_result('squares_range',
	                                            'SELECT i, i * i FROM generate_series(1, 10) i',
	                                            1, 'range', '{0}'::text[], '{20}'::text[], true);
2023-11-25 00:44:03.705 UTC [3765665] ERROR:  42601: syntax error at or near "SELECxT" at character 1
2023-11-25 00:44:03.705 UTC [3765665] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:44:03.705 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECxT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.705 UTC [3765665] ERROR:  42602: result key "squares_range/a/" contains invalid character
2023-11-25 00:44:03.705 UTC [3765665] HINT:  Result keys may only contain letters, numbers, underscores and hyphens.
2023-11-25 00:44:03.705 UTC [3765665] LOCATION:  QueryResultFileName, intermediate_results.c:652
2023-11-25 00:44:03.705 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range/a/',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.706 UTC [3765665] ERROR:  22023: number of partitions cannot be 0
2023-11-25 00:44:03.706 UTC [3765665] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:176
2023-11-25 00:44:03.706 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range', ARRAY[]::text[], ARRAY[]::text[], true);
2023-11-25 00:44:03.706 UTC [3765665] ERROR:  22023: only hash and range partitiong schemes are supported
2023-11-25 00:44:03.706 UTC [3765665] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:135
2023-11-25 00:44:03.706 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'append',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.707 UTC [3765665] ERROR:  22023: query must generate a set of rows
2023-11-25 00:44:03.707 UTC [3765665] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:187
2023-11-25 00:44:03.707 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'INSERT INTO t VALUES (1), (2)',
	                                     1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.707 UTC [3765665] ERROR:  22023: partition column index must be between 0 and 1
2023-11-25 00:44:03.707 UTC [3765665] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:193
2023-11-25 00:44:03.707 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     -1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.707 UTC [3765665] ERROR:  22023: partition column index must be between 0 and 1
2023-11-25 00:44:03.707 UTC [3765665] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:193
2023-11-25 00:44:03.707 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     2, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.707 UTC [3765665] ERROR:  22023: min values and max values must have the same number of elements
2023-11-25 00:44:03.707 UTC [3765665] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:167
2023-11-25 00:44:03.707 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range',
	                                     '{0,21,41,61,101}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.708 UTC [3765665] ERROR:  XX000: hash partitioned table has uninitialized shards
2023-11-25 00:44:03.708 UTC [3765665] LOCATION:  ErrorIfInconsistentShardIntervals, metadata_cache.c:1976
2023-11-25 00:44:03.708 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_hash',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'hash',
	                                     '{NULL,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:03.708 UTC [3765665] ERROR:  XX000: cannot execute multiple utility events
2023-11-25 00:44:03.708 UTC [3765665] LOCATION:  ParseTreeRawStmt, worker_data_fetch_protocol.c:319
2023-11-25 00:44:03.708 UTC [3765665] STATEMENT:  SELECT worker_partition_query_result('squares_hash',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i; SELECT 4, 16;',
	                                     1, 'hash',
	                                     '{NULL,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 00:44:04.257 UTC [3765665] ERROR:  55000: could not find shard for partition column value
2023-11-25 00:44:04.257 UTC [3765665] CONTEXT:  SQL statement "INSERT INTO t SELECT x, x * x * x FROM generate_series(1, 105) x"
	PL/pgSQL function test_partition_query_results(regclass,text,boolean) line 35 at EXECUTE
2023-11-25 00:44:04.257 UTC [3765665] LOCATION:  ShardIdForTuple, multi_copy.c:2614
2023-11-25 00:44:04.257 UTC [3765665] STATEMENT:  CALL test_partition_query_results('t', 'SELECT x, x * x * x FROM generate_series(1, 105) x');
2023-11-25 00:44:04.843 UTC [3766330] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:04.843 UTC [3766330] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:04.843 UTC [3766330] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 00:44:04.843 UTC [3766330] STATEMENT:  SELECT count(*) FROM events_reference_table e1 CROSS JOIN events_table e2 CROSS JOIN users_table u;
2023-11-25 00:44:04.843 UTC [3766330] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:04.843 UTC [3766330] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:04.843 UTC [3766330] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 00:44:04.843 UTC [3766330] STATEMENT:  SELECT count(*) FROM events_reference_table e1, events_table e2, users_table u;
2023-11-25 00:44:04.880 UTC [3766327] ERROR:  42883: operator does not exist: integer[] public.@> integer[]
2023-11-25 00:44:04.880 UTC [3766327] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:04.880 UTC [3766327] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:04.880 UTC [3766327] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:04.880 UTC [3766327] STATEMENT:  SELECT count(*) FROM lineitem
		WHERE ARRAY[19353, 19354, 19355] @> ARRAY[l_partkey];
2023-11-25 00:44:04.888 UTC [3766326] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:04.888 UTC [3766326] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:04.888 UTC [3766326] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 00:44:04.888 UTC [3766326] STATEMENT:  SELECT
		avg(unit_price)
	FROM
		(SELECT
			l_orderkey,
			avg(o_totalprice / l_quantity) AS unit_price
		FROM
			lineitem_subquery,
			orders_subquery
		GROUP BY
			l_orderkey) AS unit_prices;
2023-11-25 00:44:05.017 UTC [3766327] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:05.017 UTC [3766327] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:05.017 UTC [3766327] STATEMENT:  SELECT count(*) FROM lineitem, orders WHERE l_orderkey + 1 = o_orderkey;
2023-11-25 00:44:05.079 UTC [3766331] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:05.079 UTC [3766331] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:05.079 UTC [3766331] STATEMENT:  SELECT ("final_query"."event_types") as types, count(*) AS sumOfEventType
	FROM
	  ( SELECT *, random()
	   FROM
	     ( SELECT "t"."user_id", "t"."time", unnest("t"."collected_events") AS "event_types"
	      FROM
	        ( SELECT "t1"."user_id", min("t1"."time") AS "time", array_agg(("t1"."event") ORDER BY TIME ASC, event DESC) AS collected_events
	         FROM (
	                 (SELECT
	                    *
	                  FROM
	                   (SELECT
	                      "events"."user_id", "events"."time", 0 AS event
	                    FROM
	                      events_table as  "events"
	                    WHERE
	                      event_type IN (1, 2) ) events_subquery_1)
	                 UNION
	                 (SELECT
	                    *
	                  FROM
	                    (SELECT
	                        "events"."user_id", "events"."time", 1 AS event
	                     FROM
	                        events_table as "events"
	                     WHERE
	                      event_type IN (3, 4) ) events_subquery_2)
	               UNION
	                 (SELECT
	                    *
	                  FROM
	                    (SELECT
	                        "events"."user_id", "events"."time", 2 AS event
	                     FROM
	                        events_table as  "events",  users_table as "users"
	                     WHERE
	                      event_type IN (5, 6)  AND users.user_id != events.user_id ) events_subquery_3)
	                UNION
	                  (SELECT
	                      *
	                   FROM
	                    (SELECT
	                        "events"."user_id", "events"."time", 3 AS event
	                     FROM
	                      events_table as "events"
	                     WHERE
	                      event_type IN (4, 5)) events_subquery_4)) t1
	         GROUP BY "t1"."user_id") AS t) "q"
	INNER JOIN
	     (SELECT
	        "users"."user_id"
	      FROM
	        users_table as "users"
	      WHERE
	        value_1 > 0 and value_1 < 4) AS t
	    ON (t.user_id = q.user_id)) as final_query
	GROUP BY
	  types
	ORDER BY
	  types;
2023-11-25 00:44:05.098 UTC [3766330] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.098 UTC [3766330] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.098 UTC [3766330] STATEMENT:  SELECT count(*) FROM users_table u1 CROSS JOIN users_ref_test_table ref2 LEFT JOIN users_table u2 ON (ref2.id = u2.user_id);
2023-11-25 00:44:05.098 UTC [3766330] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.098 UTC [3766330] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.098 UTC [3766330] STATEMENT:  SELECT count(*) FROM users_table u1 CROSS JOIN users_ref_test_table ref2 FULL JOIN users_table u2 ON (ref2.id = u2.user_id);
2023-11-25 00:44:05.099 UTC [3766330] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.099 UTC [3766330] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.099 UTC [3766330] STATEMENT:  SELECT count(*) FROM users_table u1 CROSS JOIN users_ref_test_table ref2 RIGHT JOIN users_table u2 ON (ref2.id = u2.user_id);
2023-11-25 00:44:05.217 UTC [3766326] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.217 UTC [3766326] DETAIL:  Limit in subquery without limit in the outermost query is unsupported
2023-11-25 00:44:05.217 UTC [3766326] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 00:44:05.217 UTC [3766326] STATEMENT:  SELECT
		avg(o_totalprice/l_quantity)
	FROM
			(SELECT
				l_orderkey,
				l_quantity
			FROM
				lineitem_subquery
			ORDER BY
				l_orderkey, l_quantity
			LIMIT 10
			) lineitem_quantities
		JOIN LATERAL
			(SELECT
				o_totalprice
			FROM
				orders_subquery
			WHERE
				lineitem_quantities.l_orderkey = o_orderkey) orders_price ON true;
2023-11-25 00:44:05.254 UTC [3766326] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:05.254 UTC [3766326] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:05.254 UTC [3766326] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey::int8 = o_orderkey::int4)
	WHERE
		(o_orderkey < l_quantity + 3)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 00:44:05.257 UTC [3766326] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:05.257 UTC [3766326] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:05.257 UTC [3766326] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey::int4 = o_orderkey::int8)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 00:44:05.268 UTC [3766331] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.268 UTC [3766331] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 00:44:05.268 UTC [3766331] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:05.268 UTC [3766331] STATEMENT:  SELECT "some_users_data".user_id, lastseen
	FROM
	     (SELECT user_id, max(time) AS lastseen
	      FROM
	        (SELECT user_id, time
	         FROM
	           (SELECT
	              user_id, time
	            FROM
	              events_table as "events"
	            WHERE
	              user_id > 1 and user_id < 4) "events_1"
	         ORDER BY
	           time DESC
	         LIMIT 1000) "recent_events_1"
	      GROUP BY
	        user_id
	      ORDER BY
	        max(TIME) DESC) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table as "users"
	      WHERE
	        "users"."value_1" = "some_recent_users"."user_id" AND
	        users.value_2 > 1 and users.value_2 < 3
	      ORDER BY 1 LIMIT 1) "some_users_data"
	     ON TRUE
	ORDER BY
	  user_id
	limit 50;
2023-11-25 00:44:05.269 UTC [3766331] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.269 UTC [3766331] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 00:44:05.269 UTC [3766331] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:05.269 UTC [3766331] STATEMENT:  SELECT "some_users_data".user_id, lastseen
	FROM
	     (SELECT 2 * user_id as user_id, max(time) AS lastseen
	      FROM
	        (SELECT user_id, time
	         FROM
	           (SELECT
	              user_id, time
	            FROM
	              events_table as "events"
	            WHERE
	              user_id > 1 and user_id < 4) "events_1"
	         ORDER BY
	           time DESC
	         LIMIT 1000) "recent_events_1"
	      GROUP BY
	        user_id
	      ORDER BY
	        max(TIME) DESC) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        users.value_2 > 1 and users.value_2 < 3
	      ORDER BY 1 LIMIT 1) "some_users_data"
	     ON TRUE
	ORDER BY
	  user_id
	limit 50;
2023-11-25 00:44:05.273 UTC [3766326] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:05.273 UTC [3766326] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:05.273 UTC [3766326] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey = o_orderkey + 1)
	WHERE
		(o_orderkey < l_quantity)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 00:44:05.274 UTC [3766326] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:05.274 UTC [3766326] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:05.274 UTC [3766326] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey = o_orderkey + 1)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 00:44:05.274 UTC [3766326] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:05.274 UTC [3766326] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:05.274 UTC [3766326] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey < o_orderkey)
	WHERE
		(o_orderkey < l_quantity)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 00:44:05.286 UTC [3766328] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.286 UTC [3766328] DETAIL:  Distinct on columns without partition column is currently unsupported
2023-11-25 00:44:05.286 UTC [3766328] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:05.286 UTC [3766328] STATEMENT:  SELECT a.user_id, avg(b.value_2) as subquery_avg
	FROM
		(SELECT
	      user_id
	   FROM
	      users_table
		 WHERE
	      (value_1 > 2)
		 GROUP BY
	      user_id
		 HAVING
	      count(distinct value_1) > 2
		) as a
		LEFT JOIN
		(SELECT
	      DISTINCT ON (value_2) value_2 , user_id, value_3
		 FROM
	      users_table
		 WHERE
	      (value_1 > 3)
		 ORDER BY
	      1,2,3
		) AS b
		USING (user_id)
	GROUP BY user_id;
2023-11-25 00:44:05.288 UTC [3766331] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.288 UTC [3766331] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 00:44:05.288 UTC [3766331] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:05.288 UTC [3766331] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4  and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id != "user_where_1_join_1".user_id)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 4 and user_id = filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 00:44:05.293 UTC [3766331] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.293 UTC [3766331] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 00:44:05.293 UTC [3766331] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:05.293 UTC [3766331] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id", "users"."value_1"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4 and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id = "user_where_1_join_1".value_1)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 4 and user_id = filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 00:44:05.295 UTC [3766331] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.295 UTC [3766331] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.295 UTC [3766331] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id", "users"."value_1"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id = "user_where_1_join_1".user_id)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 3 and user_id != filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 00:44:05.295 UTC [3766326] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.295 UTC [3766326] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.295 UTC [3766326] STATEMENT:  SELECT DISTINCT ON (t1.user_id) t1.user_id, t2.value_1, t2.value_2, t2.value_3
	FROM events_table t1
	LEFT JOIN users_table t2 ON t1.user_id > t2.user_id
	ORDER BY 1 DESC, 2 DESC, 3 DESC, 4 DESC
	LIMIT 5;
2023-11-25 00:44:05.298 UTC [3766331] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.298 UTC [3766331] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 00:44:05.298 UTC [3766331] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:05.298 UTC [3766331] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id", "users"."value_1"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id = "user_where_1_join_1".user_id)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 3 and user_id = filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."value_1" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 00:44:05.324 UTC [3766326] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.324 UTC [3766326] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.324 UTC [3766326] STATEMENT:  SELECT DISTINCT ON (t1.user_id) t1.user_id, t2.value_1, t2.value_2, t2.value_3
	 FROM
	 users_table t0 LEFT JOIN
	 events_table t1  ON t0.user_id = trunc(t1.user_id)
	 LEFT JOIN users_reference_table t2 ON t1.user_id = trunc(t2.user_id)
	 ORDER BY 1 DESC, 2 DESC, 3 DESC, 4 DESC
	 LIMIT 5;
2023-11-25 00:44:05.380 UTC [3766326] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 00:44:05.380 UTC [3766326] DETAIL:  Only count(distinct) aggregate is supported in subqueries
2023-11-25 00:44:05.380 UTC [3766326] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4111
2023-11-25 00:44:05.380 UTC [3766326] STATEMENT:  SELECT
		sum(DISTINCT a)
	FROM (
		SELECT
			count(*) a
		FROM
			lineitem_subquery
		GROUP BY
		   l_orderkey
	) z;
2023-11-25 00:44:05.381 UTC [3766326] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 00:44:05.381 UTC [3766326] DETAIL:  Only count(distinct) aggregate is supported in subqueries
2023-11-25 00:44:05.381 UTC [3766326] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4111
2023-11-25 00:44:05.381 UTC [3766326] STATEMENT:  SELECT
		avg(DISTINCT a)
	FROM (
		SELECT
			count(*) a
		FROM
			lineitem_subquery
		GROUP BY
		   l_orderkey
	) z;
2023-11-25 00:44:05.417 UTC [3766328] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.417 UTC [3766328] DETAIL:  Subqueries without a FROM clause can only contain immutable functions
2023-11-25 00:44:05.417 UTC [3766328] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 00:44:05.417 UTC [3766328] STATEMENT:  SELECT count(*) as subquery_count
	FROM (
	  SELECT
	      user_id
	    FROM
	    users_table
	  WHERE
	    (value_1 = '1' OR value_1 = '3')
	  GROUP BY user_id
	  HAVING count(distinct value_1) = 2
	  ) as a
	  INNER JOIN (
	  SELECT
	    random()::int as user_id
	  ) AS b
	  ON a.user_id = b.user_id
	WHERE b.user_id IS NULL
	GROUP BY a.user_id;
2023-11-25 00:44:05.433 UTC [3766326] ERROR:  0A000: shard counts of co-located tables do not match
2023-11-25 00:44:05.433 UTC [3766326] LOCATION:  QueryPushdownSqlTaskList, multi_physical_planner.c:2210
2023-11-25 00:44:05.433 UTC [3766326] STATEMENT:  SELECT
		avg(unit_price)
	FROM
		(SELECT
			l_orderkey,
			avg(o_totalprice / l_quantity) AS unit_price
		FROM
			lineitem_subquery,
			orders_subquery
		WHERE
			l_orderkey = o_orderkey
		GROUP BY
			l_orderkey) AS unit_prices;
2023-11-25 00:44:05.442 UTC [3766331] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:05.442 UTC [3766331] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 00:44:05.442 UTC [3766331] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:05.442 UTC [3766331] STATEMENT:  SELECT *
	FROM
	  (SELECT
	      "some_users_data".user_id, value_2
	   FROM
	     (SELECT user_id, max(value_2) AS value_2
	      FROM
	        (SELECT user_id, value_2
	         FROM
	           (SELECT
	              user_id, value_2
	            FROM
	              events_table as "events"
	            WHERE
	              user_id > 1 and user_id < 3) "events_1"
	         ORDER BY
	          value_2 DESC
	         LIMIT 10000) "recent_events_1"
	      GROUP BY
	        user_id
	      ORDER BY
	        max(value_2) DESC) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table as "users"
	      WHERE
	        "users"."value_2" = "some_recent_users"."user_id" AND
	        value_2 > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    value_2 DESC
	   LIMIT 10) "some_users"
	ORDER BY
	    value_2 DESC, user_id DESC
	LIMIT 10;
2023-11-25 00:44:05.465 UTC [3766326] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 00:44:05.465 UTC [3766326] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 00:44:05.465 UTC [3766326] STATEMENT:  WITH cte_1 AS (SELECT b max FROM subquery_pruning_varchar_test_table)
	SELECT a
	FROM subquery_pruning_varchar_test_table
	JOIN cte_1 ON a = max::text
	GROUP BY a HAVING a = (SELECT a)
	ORDER BY 1;
2023-11-25 00:44:05.470 UTC [3766328] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.470 UTC [3766328] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.470 UTC [3766328] STATEMENT:  SELECT user_id, array_length(events_table, 1)
	FROM (
	  SELECT user_id, array_agg(event ORDER BY time) AS events_table
	  FROM (
	    SELECT u.user_id, e.event_type::text AS event, e.time
	    FROM users_table AS u,
	         events_table AS e
	    WHERE test_join_function_2(u.user_id, e.user_id)
	  ) t
	  GROUP BY user_id
	) q
	ORDER BY 2 DESC, 1;
2023-11-25 00:44:05.491 UTC [3766328] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.491 UTC [3766328] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.491 UTC [3766328] STATEMENT:  SELECT
	  count(*)
	FROM
	  (SELECT
	    event_type, random()
	  FROM
	    events_table, users_table
	  WHERE
	    events_table.user_id > users_table.user_id AND
	    events_table.time = users_table.time AND
	    events_table.value_2 IN (0, 4)
	  ) as foo;
2023-11-25 00:44:05.502 UTC [3766328] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:05.502 UTC [3766328] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:05.502 UTC [3766328] STATEMENT:  SELECT
	  count(*)
	FROM
	  (SELECT
	    event_type, random()
	  FROM
	    events_table, users_table
	  WHERE
	    events_table.user_id = users_table.user_id AND
	    events_table.value_2 IN (0, 4)
	  ) as foo,
	(SELECT
	    event_type, random()
	  FROM
	    events_table, users_table
	  WHERE
	    events_table.user_id = users_table.user_id AND
	    events_table.value_2 IN (1, 5)
	  ) as bar
	WHERE foo.event_type = bar.event_type;
2023-11-25 00:44:05.538 UTC [3766330] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:05.538 UTC [3766330] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:05.538 UTC [3766330] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 00:44:05.538 UTC [3766330] STATEMENT:  SELECT dist2.c0 FROM dist1, dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 00:44:05.538 UTC [3766330] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:05.538 UTC [3766330] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:05.538 UTC [3766330] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 00:44:05.538 UTC [3766330] STATEMENT:  SELECT 1 FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 00:44:05.539 UTC [3766330] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:05.539 UTC [3766330] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:05.539 UTC [3766330] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 00:44:05.539 UTC [3766330] STATEMENT:  SELECT  FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 00:44:05.539 UTC [3766330] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:05.539 UTC [3766330] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:05.539 UTC [3766330] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 00:44:05.539 UTC [3766330] STATEMENT:  SELECT dist2.c0 FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 00:44:05.539 UTC [3766330] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:05.539 UTC [3766330] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:05.539 UTC [3766330] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 00:44:05.539 UTC [3766330] STATEMENT:  SELECT dist2.* FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 00:44:11.585 UTC [3766875] ERROR:  0A000: cannot perform distributed planning on this query because parameterized queries for SQL functions referencing distributed tables are not supported
2023-11-25 00:44:11.585 UTC [3766875] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 00:44:11.585 UTC [3766875] LOCATION:  distributed_planner, distributed_planner.c:301
2023-11-25 00:44:11.585 UTC [3766875] STATEMENT:  SELECT * FROM test_parameterized_sql_function(1);
2023-11-25 00:44:11.585 UTC [3766875] ERROR:  0A000: cannot perform distributed planning on this query because parameterized queries for SQL functions referencing distributed tables are not supported
2023-11-25 00:44:11.585 UTC [3766875] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 00:44:11.585 UTC [3766875] LOCATION:  GetRTEIdentity, distributed_planner.c:533
2023-11-25 00:44:11.585 UTC [3766875] STATEMENT:  SELECT (SELECT 1 FROM test_parameterized_sql limit 1) FROM test_parameterized_sql_function(1);
2023-11-25 00:44:11.585 UTC [3766875] ERROR:  0A000: could not create distributed plan
2023-11-25 00:44:11.585 UTC [3766875] DETAIL:  Possibly this is caused by the use of parameters in SQL functions, which is not supported in Citus.
2023-11-25 00:44:11.585 UTC [3766875] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 00:44:11.585 UTC [3766875] CONTEXT:  SQL function "test_parameterized_sql_function_in_subquery_where" statement 1
2023-11-25 00:44:11.585 UTC [3766875] LOCATION:  CreateDistributedPlannedStmt, distributed_planner.c:751
2023-11-25 00:44:11.585 UTC [3766875] STATEMENT:  SELECT test_parameterized_sql_function_in_subquery_where(1);
2023-11-25 00:44:11.615 UTC [3766875] ERROR:  23505: duplicate key value violates unique constraint "table_with_unique_constraint_a_key_1230009"
2023-11-25 00:44:11.615 UTC [3766875] DETAIL:  Key (a)=(4) already exists.
2023-11-25 00:44:11.615 UTC [3766875] CONTEXT:  while executing command on localhost:57638
	SQL function "insert_twice" statement 2
2023-11-25 00:44:11.615 UTC [3766875] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:11.615 UTC [3766875] STATEMENT:  SELECT insert_twice();
2023-11-25 00:44:12.463 UTC [3766876] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:12.463 UTC [3766876] DETAIL:  Limit in subquery without limit in the outermost query is unsupported
2023-11-25 00:44:12.463 UTC [3766876] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 00:44:12.463 UTC [3766876] STATEMENT:  SELECT * FROM recent_10_users;
2023-11-25 00:44:12.464 UTC [3766876] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:12.464 UTC [3766876] DETAIL:  Limit in subquery without limit in the outermost query is unsupported
2023-11-25 00:44:12.464 UTC [3766876] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 00:44:12.464 UTC [3766876] STATEMENT:  SELECT et.* FROM recent_10_users JOIN events_table et USING(user_id);
2023-11-25 00:44:12.959 UTC [3766878] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:12.959 UTC [3766878] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:12.959 UTC [3766878] STATEMENT:  SELECT
	  u1.user_id, count(*)
	FROM
	  events_table as e1, users_table as u1
	WHERE
	  event_type IN
	            (SELECT
	                event_type
	             FROM
	              events_reference_table as e2
	             WHERE
	              value_2 = 1 AND
	              value_3 > 3 AND
	              e1.value_2 > e2.value_2
	            )
	            AND u1.user_id > e1.user_id
	GROUP BY 1
	ORDER BY 2 DESC, 1 DESC
	LIMIT 5;
2023-11-25 00:44:13.035 UTC [3766876] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 00:44:13.035 UTC [3766876] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 00:44:13.035 UTC [3766876] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 00:44:13.035 UTC [3766876] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 00:44:13.035 UTC [3766876] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 00:44:13.035 UTC [3766876] STATEMENT:  DELETE FROM small_view;
2023-11-25 00:44:13.036 UTC [3766876] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 00:44:13.036 UTC [3766876] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 00:44:13.036 UTC [3766876] STATEMENT:  INSERT INTO small_view VALUES(8, 5) ON CONFLICT(tenant_id) DO UPDATE SET tenant_id=99;
2023-11-25 00:44:13.138 UTC [3766876] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 00:44:13.138 UTC [3766876] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 00:44:13.138 UTC [3766876] STATEMENT:  INSERT INTO small_view VALUES(3, 3);
2023-11-25 00:44:13.182 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.182 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.182 UTC [3766878] STATEMENT:  SELECT count(*) FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id FULL JOIN user_buy_test_table ON (ref1.id > 5);
2023-11-25 00:44:13.182 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.182 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.182 UTC [3766878] STATEMENT:  SELECT count(*) FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id FULL JOIN user_buy_test_table ON (user_buy_test_table.user_id > 5);
2023-11-25 00:44:13.220 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.220 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.220 UTC [3766878] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id ON (ref1.id > 5);
2023-11-25 00:44:13.220 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.220 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.220 UTC [3766878] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id ON (user_buy_test_table.user_id > 5);
2023-11-25 00:44:13.251 UTC [3766876] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 00:44:13.251 UTC [3766876] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 00:44:13.251 UTC [3766876] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 00:44:13.252 UTC [3766876] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 00:44:13.252 UTC [3766876] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 00:44:13.252 UTC [3766876] STATEMENT:  DELETE FROM small_view;
2023-11-25 00:44:13.257 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.257 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.257 UTC [3766878] STATEMENT:  SELECT count(*) FROM (SELECT ref1.*, random() FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo FULL JOIN user_buy_test_table ON (foo.id > 5);
2023-11-25 00:44:13.258 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.258 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.258 UTC [3766878] STATEMENT:  SELECT count(*) FROM (SELECT ref1.*, random() FROM users_ref_test_table ref1 LEFT JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo FULL JOIN user_buy_test_table ON (user_buy_test_table.user_id > 19);
2023-11-25 00:44:13.283 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.283 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.283 UTC [3766878] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN (SELECT ref1.*, random() FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo ON (foo.id > 5);
2023-11-25 00:44:13.283 UTC [3766878] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 00:44:13.283 UTC [3766878] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 00:44:13.283 UTC [3766878] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN (SELECT ref1.*, random() FROM users_ref_test_table ref1 LEFT JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo ON (user_buy_test_table.user_id > 19);
2023-11-25 00:44:13.472 UTC [3766876] ERROR:  55000: cannot insert into view "small_view"
2023-11-25 00:44:13.472 UTC [3766876] DETAIL:  Views that do not select from a single table or view are not automatically updatable.
2023-11-25 00:44:13.472 UTC [3766876] HINT:  To enable inserting into the view, provide an INSTEAD OF INSERT trigger or an unconditional ON INSERT DO INSTEAD rule.
2023-11-25 00:44:13.472 UTC [3766876] LOCATION:  rewriteTargetView, rewriteHandler.c:3096
2023-11-25 00:44:13.472 UTC [3766876] STATEMENT:  INSERT INTO small_view VALUES(3, 3);
2023-11-25 00:44:13.988 UTC [3767685] ERROR:  0A000: COMMIT is not allowed in an SQL function
2023-11-25 00:44:13.988 UTC [3767685] CONTEXT:  SQL function "test_procedure_commit" during startup
2023-11-25 00:44:13.988 UTC [3767685] LOCATION:  init_execution_state, functions.c:517
2023-11-25 00:44:13.988 UTC [3767685] STATEMENT:  CALL test_procedure_commit(2,5);
2023-11-25 00:44:13.997 UTC [3767685] ERROR:  0A000: ROLLBACK is not allowed in an SQL function
2023-11-25 00:44:13.997 UTC [3767685] CONTEXT:  SQL function "test_procedure_rollback" during startup
2023-11-25 00:44:13.997 UTC [3767685] LOCATION:  init_execution_state, functions.c:517
2023-11-25 00:44:13.997 UTC [3767685] STATEMENT:  CALL test_procedure_rollback(2,15);
2023-11-25 00:44:14.044 UTC [3767685] ERROR:  23505: duplicate key value violates unique constraint "idx_table_100503"
2023-11-25 00:44:14.044 UTC [3767685] DETAIL:  Key (id, org_id)=(2, 12) already exists.
2023-11-25 00:44:14.044 UTC [3767685] CONTEXT:  while executing command on localhost:57637
	SQL statement "INSERT INTO test_table VALUES (tt_id, tt_org_id)"
	PL/pgSQL function test_procedure_modify_insert(integer,integer) line 5 at SQL statement
2023-11-25 00:44:14.044 UTC [3767685] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:14.044 UTC [3767685] STATEMENT:  CALL test_procedure_modify_insert(2,12);
2023-11-25 00:44:14.059 UTC [3767685] ERROR:  23505: duplicate key value violates unique constraint "idx_table_100503"
2023-11-25 00:44:14.059 UTC [3767685] DETAIL:  Key (id, org_id)=(2, 30) already exists.
2023-11-25 00:44:14.059 UTC [3767685] CONTEXT:  while executing command on localhost:57637
	SQL statement "INSERT INTO test_table VALUES (tt_id, tt_org_id)"
	PL/pgSQL function test_procedure_modify_insert_commit(integer,integer) line 5 at SQL statement
2023-11-25 00:44:14.059 UTC [3767685] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:14.059 UTC [3767685] STATEMENT:  CALL test_procedure_modify_insert_commit(2,30);
2023-11-25 00:44:14.060 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.060 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.060 UTC [3767684] STATEMENT:  SELECT ARRAY[(x,(y,x),y),(y,(x,y))] FROM test ORDER BY x, y;
2023-11-25 00:44:14.073 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.073 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.073 UTC [3767684] STATEMENT:  SELECT ARRAY[[(x,(y,x))],[((x,x),y)]] FROM test ORDER BY x, y;
2023-11-25 00:44:14.092 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.092 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.092 UTC [3767684] STATEMENT:  SELECT CASE x WHEN 2 THEN (x, y, x) ELSE (y, x) END FROM test ORDER BY x, y;
2023-11-25 00:44:14.102 UTC [3767686] ERROR:  P0001: Task failed to execute
2023-11-25 00:44:14.102 UTC [3767686] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 00:44:14.102 UTC [3767686] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:44:14.102 UTC [3767686] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  WITH one_row AS (
	      SELECT * FROM table1 WHERE id=52
	      )
	  SELECT table1.id, table1.data
	  FROM one_row, table1, next_k_integers(one_row.id, 5) next_five_ids
	  WHERE table1.id = next_five_ids;
	$$);
2023-11-25 00:44:14.107 UTC [3767686] ERROR:  P0001: Task failed to execute
2023-11-25 00:44:14.107 UTC [3767686] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 00:44:14.107 UTC [3767686] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:44:14.107 UTC [3767686] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  SELECT * FROM table1 JOIN the_answer_to_life() the_answer ON (id = the_answer);
	$$);
2023-11-25 00:44:14.111 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.111 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.111 UTC [3767684] STATEMENT:  SELECT identity_returner((x, y)) FROM test ORDER BY x, y;
2023-11-25 00:44:14.113 UTC [3767686] ERROR:  P0001: Task failed to execute
2023-11-25 00:44:14.113 UTC [3767686] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 00:44:14.113 UTC [3767686] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:44:14.113 UTC [3767686] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  SELECT *
	  FROM table1
	         JOIN next_k_integers(10,5) WITH ORDINALITY next_integers
	           ON (id = next_integers.result);
	$$);
2023-11-25 00:44:14.120 UTC [3767686] ERROR:  P0001: Task failed to execute
2023-11-25 00:44:14.120 UTC [3767686] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 00:44:14.120 UTC [3767686] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:44:14.120 UTC [3767686] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  SELECT *
	  FROM table1
	         JOIN next_k_integers(10,5) WITH ORDINALITY next_integers
	           ON (id = next_integers.result)
	  ORDER BY id ASC;
	$$);
2023-11-25 00:44:14.128 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.128 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.128 UTC [3767684] STATEMENT:  SELECT array_agg((x, y)) FROM test;
2023-11-25 00:44:14.163 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.163 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.163 UTC [3767684] STATEMENT:  SELECT ARRAY[(x,(y,x),y),(y,(x,y))] FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 00:44:14.171 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.171 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.171 UTC [3767684] STATEMENT:  SELECT ARRAY[[(x,(y,x))],[((x,x),y)]] FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 00:44:14.178 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.178 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.178 UTC [3767684] STATEMENT:  SELECT CASE x WHEN 2 THEN (x, y, x) ELSE (y, x) END FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 00:44:14.186 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.186 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.186 UTC [3767684] STATEMENT:  SELECT identity_returner((x, y)) FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 00:44:14.192 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.192 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.192 UTC [3767684] STATEMENT:  SELECT array_agg((x, y)) FROM test WHERE x = 1;
2023-11-25 00:44:14.202 UTC [3767684] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 00:44:14.202 UTC [3767684] LOCATION:  record_in, rowtypes.c:103
2023-11-25 00:44:14.202 UTC [3767684] STATEMENT:  SELECT (x,table_returner(x)) FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 00:44:14.719 UTC [3767687] ERROR:  55000: materialized view "materialized_view" has not been populated
2023-11-25 00:44:14.719 UTC [3767687] HINT:  Use the REFRESH MATERIALIZED VIEW command.
2023-11-25 00:44:14.719 UTC [3767687] LOCATION:  ExecOpenScanRelation, execUtils.c:740
2023-11-25 00:44:14.719 UTC [3767687] STATEMENT:  SELECT count(*) FROM materialized_view;
2023-11-25 00:44:14.823 UTC [3767687] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 00:44:14.823 UTC [3767687] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 00:44:14.823 UTC [3767687] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 00:44:14.845 UTC [3767687] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 00:44:14.845 UTC [3767687] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 00:44:14.845 UTC [3767687] STATEMENT:  INSERT INTO small_view VALUES(3, 3);
2023-11-25 00:44:14.932 UTC [3767687] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 00:44:14.932 UTC [3767687] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 00:44:14.932 UTC [3767687] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 00:44:14.932 UTC [3767687] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 00:44:14.932 UTC [3767687] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 00:44:14.932 UTC [3767687] STATEMENT:  DELETE FROM small_view;
2023-11-25 00:44:15.212 UTC [3768051] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:44:15.212 UTC [3768051] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:44:15.212 UTC [3768051] STATEMENT:  SELECT
	  user_id
	FROM
	  users_reference_table
	WHERE
	  NOT EXISTS
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_reference_table.user_id = events_table.user_id
	      )
	LIMIT 3;
2023-11-25 00:44:15.212 UTC [3768051] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a set returning function
2023-11-25 00:44:15.212 UTC [3768051] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:677
2023-11-25 00:44:15.212 UTC [3768051] STATEMENT:  SELECT
	  user_id
	FROM
	  (SELECT user_id FROM generate_series(1,10) AS series(user_id)) users_reference_table
	WHERE
	  NOT EXISTS
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_reference_table.user_id = events_table.user_id
	      )
	LIMIT 3;
2023-11-25 00:44:15.213 UTC [3768051] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 00:44:15.213 UTC [3768051] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 00:44:15.213 UTC [3768051] STATEMENT:  SELECT
	  user_id
	FROM
	  (SELECT  5 AS user_id UNION ALL SELECT 6) users_reference_table
	WHERE
	  NOT EXISTS
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_reference_table.user_id = events_table.user_id
	      )
	LIMIT 3;
2023-11-25 00:44:15.223 UTC [3768052] WARNING:  25001: SET TRANSACTION ISOLATION LEVEL must be called before any query
2023-11-25 00:44:15.223 UTC [3768052] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:15.223 UTC [3768052] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:15.223 UTC [3768052] ERROR:  XX000: failure on connection marked as essential: localhost:57637
2023-11-25 00:44:15.223 UTC [3768052] LOCATION:  MarkRemoteTransactionFailed, remote_transaction.c:840
2023-11-25 00:44:15.223 UTC [3768052] STATEMENT:  SET LOCAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;
2023-11-25 00:44:15.223 UTC [3768052] ERROR:  25006: cannot execute INSERT in a read-only transaction
2023-11-25 00:44:15.223 UTC [3768052] LOCATION:  PreventCommandIfReadOnly, utility.c:414
2023-11-25 00:44:15.223 UTC [3768052] STATEMENT:  INSERT INTO test VALUES (2,2);
2023-11-25 00:44:15.225 UTC [3768051] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 00:44:15.225 UTC [3768051] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 00:44:15.225 UTC [3768051] STATEMENT:  SELECT
	  DISTINCT user_id
	FROM
	  users_table RIGHT JOIN users_reference_table USING (user_id)
	WHERE
	  users_table.value_2 IN
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_table.user_id = events_table.user_id
	      )
	ORDER BY user_id
	LIMIT 3;
2023-11-25 00:44:15.229 UTC [3768052] WARNING:  25001: there is already a transaction in progress
2023-11-25 00:44:15.229 UTC [3768052] LOCATION:  BeginTransactionBlock, xact.c:3778
2023-11-25 00:44:15.230 UTC [3768052] WARNING:  25001: there is already a transaction in progress
2023-11-25 00:44:15.230 UTC [3768052] LOCATION:  BeginTransactionBlock, xact.c:3778
2023-11-25 00:44:15.230 UTC [3768052] ERROR:  25001: SET TRANSACTION ISOLATION LEVEL must be called before any query
2023-11-25 00:44:15.230 UTC [3768052] LOCATION:  call_enum_check_hook, guc.c:12007
2023-11-25 00:44:15.230 UTC [3768052] STATEMENT:  BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
2023-11-25 00:44:15.249 UTC [3768051] ERROR:  0A000: cannot perform a lateral outer join when a distributed subquery references a reference table
2023-11-25 00:44:15.249 UTC [3768051] LOCATION:  DeferredErrorIfUnsupportedRecurringTuplesJoin, query_pushdown_planning.c:913
2023-11-25 00:44:15.249 UTC [3768051] STATEMENT:  SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 1 AND value_1 < 3
	  AND value_2 >= 5
	  AND user_id IN
	  (
			SELECT
			  e1.user_id
			FROM (
			  -- Get the first time each user viewed the homepage.
			  SELECT
			    user_id,
			    1 AS view_homepage,
			    min(time) AS view_homepage_time
			  FROM events_reference_table
			     WHERE
			     event_type IN (1, 2)
			  GROUP BY user_id
			) e1 LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS use_demo,
			    time AS use_demo_time
			  FROM events_table
			  WHERE
			    user_id = e1.user_id AND
			       event_type IN (2, 3)
			  ORDER BY time
			) e2 ON true LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS enter_credit_card,
			    time AS enter_credit_card_time
			  FROM  events_reference_table
			  WHERE
			    user_id = e2.user_id AND
			    event_type IN (3, 4)
			  ORDER BY time
			) e3 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS submit_card_info,
			    user_id,
			    time AS enter_credit_card_time
			  FROM  events_reference_table
			  WHERE
			    user_id = e3.user_id AND
			    event_type IN (4, 5)
			  ORDER BY time
			) e4 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS see_bought_screen
			  FROM  events_reference_table
			  WHERE
			    user_id = e4.user_id AND
			    event_type IN (5, 6)
			  ORDER BY time
			) e5 ON true
			group by e1.user_id
			HAVING sum(submit_card_info) > 0
	)
	ORDER BY 1, 2;
2023-11-25 00:44:15.285 UTC [3768051] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 00:44:15.285 UTC [3768051] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 00:44:15.285 UTC [3768051] STATEMENT:  SELECT user_id,
	       count(*)
	FROM users_reference_table
	WHERE value_2 > ALL
	    (SELECT min(value_2)
	     FROM events_table
	     WHERE event_type > 2 AND users_reference_table.user_id = events_table.user_id
	     GROUP BY user_id)
	GROUP BY user_id
	HAVING count(*) > 3
	ORDER BY 2 DESC,
	         1 DESC
	LIMIT 5;
2023-11-25 00:44:16.140 UTC [3768323] ERROR:  23505: duplicate key value violates unique constraint "test_forcepushdown_pkey_900015"
2023-11-25 00:44:16.140 UTC [3768323] DETAIL:  Key (intcol)=(3) already exists.
2023-11-25 00:44:16.140 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.140 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.140 UTC [3768323] STATEMENT:  SELECT insert_data(3);
2023-11-25 00:44:16.141 UTC [3768323] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:16.141 UTC [3768323] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:16.141 UTC [3768323] STATEMENT:  INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (5);
2023-11-25 00:44:16.142 UTC [3768323] ERROR:  23505: duplicate key value violates unique constraint "test_forcepushdown_pkey_900000"
2023-11-25 00:44:16.142 UTC [3768323] DETAIL:  Key (intcol)=(8) already exists.
2023-11-25 00:44:16.142 UTC [3768323] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:16.142 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.142 UTC [3768323] STATEMENT:  INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (8);
2023-11-25 00:44:16.143 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.143 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.143 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (a+1)"
	PL/pgSQL function forcepushdown_schema.insert_data_non_distarg(integer) line 3 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.143 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.143 UTC [3768323] STATEMENT:  SELECT insert_data_non_distarg(9);
2023-11-25 00:44:16.144 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.144 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.144 UTC [3768323] CONTEXT:  SQL statement "UPDATE forcepushdown_schema.test_forcepushdown SET data = 'non-default'"
	PL/pgSQL function forcepushdown_schema.update_data_nonlocal(integer) line 3 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.144 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.144 UTC [3768323] STATEMENT:  SELECT update_data_nonlocal(12);
2023-11-25 00:44:16.144 UTC [3768323] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:16.144 UTC [3768323] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:16.144 UTC [3768323] STATEMENT:  INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (13);
2023-11-25 00:44:16.147 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.147 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.147 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.147 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.147 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.147 UTC [3768323] STATEMENT:  SELECT insert_data(intcol+17) from test_forcepushdown where intcol = 1;
2023-11-25 00:44:16.147 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.147 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.147 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_noncolocate VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_noncolocation(integer) line 4 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.147 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.147 UTC [3768323] STATEMENT:  SELECT insert_data_noncolocation(19);
2023-11-25 00:44:16.148 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.148 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.148 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_noncolocate VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_noncolocation(integer) line 4 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.148 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.148 UTC [3768323] STATEMENT:  SELECT insert_data_noncolocation(19);
2023-11-25 00:44:16.205 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.205 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.205 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.205 UTC [3768323] CONTEXT:  SQL statement "SELECT max(id)::numeric+1               FROM forcepushdown_schema.test_nested WHERE id = $1"
	PL/pgSQL function forcepushdown_schema.inner_force_delegation_function(integer) line 4 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.205 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.205 UTC [3768323] STATEMENT:  SELECT inner_force_delegation_function(id) FROM test_nested WHERE id = 300;
2023-11-25 00:44:16.206 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.206 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.206 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.206 UTC [3768323] CONTEXT:  SQL statement "SELECT max(id)::numeric+1               FROM forcepushdown_schema.test_nested WHERE id = $1"
	PL/pgSQL function forcepushdown_schema.inner_force_delegation_function(integer) line 4 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.206 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.206 UTC [3768323] STATEMENT:  SELECT inner_force_delegation_function((SELECT id+112 FROM test_nested WHERE id=400));
2023-11-25 00:44:16.283 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.283 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.283 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.283 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown SELECT(a+1)"
	PL/pgSQL function forcepushdown_schema.insert_select_data(integer) line 3 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.283 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.283 UTC [3768323] STATEMENT:  SELECT insert_select_data(20);
2023-11-25 00:44:16.294 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.294 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.294 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.294 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown SELECT(a+1)"
	PL/pgSQL function forcepushdown_schema.insert_select_data(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.294 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.294 UTC [3768323] STATEMENT:  SELECT insert_select_data(22);
2023-11-25 00:44:16.321 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.321 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.321 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.321 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown(intcol)
			SELECT intcol FROM forcepushdown_schema.test_forcepushdown_noncolocate"
	PL/pgSQL function forcepushdown_schema.insert_select_data_nonlocal(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.321 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.321 UTC [3768323] STATEMENT:  SELECT insert_select_data_nonlocal(41);
2023-11-25 00:44:16.426 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.426 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.426 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_char VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_char(character) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.426 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.426 UTC [3768323] STATEMENT:  SELECT insert_data_char('CHAR');
2023-11-25 00:44:16.432 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.432 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.432 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_char VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_char(character) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 00:44:16.432 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.432 UTC [3768323] STATEMENT:  SELECT insert_data_char('CHAR');
2023-11-25 00:44:16.516 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.516 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.516 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.516 UTC [3768323] CONTEXT:  SQL statement "SELECT result          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT data FROM forcepushdown_schema.test_subquery WHERE data = a)"
	PL/pgSQL function forcepushdown_schema.select_data(integer) line 4 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.516 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.516 UTC [3768323] STATEMENT:  SELECT select_data(100);
2023-11-25 00:44:16.523 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.523 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.523 UTC [3768323] CONTEXT:  SQL statement "SELECT data          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT id FROM forcepushdown_schema.test_non_colocated WHERE id = a)"
	PL/pgSQL function forcepushdown_schema.select_data_noncolocate(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.523 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.523 UTC [3768323] STATEMENT:  SELECT select_data_noncolocate(100);
2023-11-25 00:44:16.530 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.530 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.530 UTC [3768323] CONTEXT:  SQL statement "SELECT data          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT id FROM forcepushdown_schema.test_non_colocated WHERE id = a)"
	PL/pgSQL function forcepushdown_schema.select_data_noncolocate(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.530 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.530 UTC [3768323] STATEMENT:  SELECT select_data_noncolocate(100);
2023-11-25 00:44:16.544 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.544 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.544 UTC [3768323] CONTEXT:  SQL statement "WITH ins AS (INSERT INTO forcepushdown_schema.test_subquery VALUES (a+1) RETURNING data)
			SELECT ins.data          FROM forcepushdown_schema.test_subquery, ins WHERE forcepushdown_schema.test_subquery.data = a"
	PL/pgSQL function forcepushdown_schema.insert_data_cte_nondist(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.544 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.544 UTC [3768323] STATEMENT:  SELECT insert_data_cte_nondist(400);
2023-11-25 00:44:16.551 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.551 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.551 UTC [3768323] CONTEXT:  SQL statement "WITH ins AS (INSERT INTO forcepushdown_schema.test_subquery VALUES (a+1) RETURNING data)
			SELECT ins.data          FROM forcepushdown_schema.test_subquery, ins WHERE forcepushdown_schema.test_subquery.data = a"
	PL/pgSQL function forcepushdown_schema.insert_data_cte_nondist(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.551 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.551 UTC [3768323] STATEMENT:  SELECT insert_data_cte_nondist(400);
2023-11-25 00:44:16.573 UTC [3768323] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 00:44:16.573 UTC [3768323] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 00:44:16.573 UTC [3768323] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 00:44:16.573 UTC [3768323] CONTEXT:  SQL statement "SELECT result          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT data FROM forcepushdown_schema.test_subquery WHERE data = a)"
	PL/pgSQL function forcepushdown_schema.select_data(integer) line 4 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.573 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.573 UTC [3768323] STATEMENT:  SELECT 1,2,3 FROM select_data(100);
2023-11-25 00:44:16.593 UTC [3768323] ERROR:  42883: function test_prepare(integer, integer) does not exist
2023-11-25 00:44:16.593 UTC [3768323] LOCATION:  LookupFuncWithArgs, parse_func.c:2444
2023-11-25 00:44:16.593 UTC [3768323] STATEMENT:  DROP FUNCTION test_prepare(int, int);
2023-11-25 00:44:16.597 UTC [3768323] ERROR:  42883: function outer_test_prepare(integer, integer) does not exist
2023-11-25 00:44:16.597 UTC [3768323] LOCATION:  LookupFuncWithArgs, parse_func.c:2444
2023-11-25 00:44:16.597 UTC [3768323] STATEMENT:  DROP FUNCTION outer_test_prepare(int, int);
2023-11-25 00:44:16.611 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.611 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.611 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.table_test_prepare VALUES (y, x)"
	PL/pgSQL function forcepushdown_schema.test_prepare(integer,integer) line 5 at SQL statement
	while executing command on localhost:57638
	SQL statement "SELECT FROM test_prepare(x, y)"
	PL/pgSQL function outer_test_prepare(integer,integer) line 5 at PERFORM
2023-11-25 00:44:16.611 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.611 UTC [3768323] STATEMENT:  SELECT outer_test_prepare(1,2);
2023-11-25 00:44:16.695 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.695 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.695 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (x,x)"
	PL/pgSQL function forcepushdown_schema.inner_fn(integer) line 4 at SQL statement
	SQL statement "SELECT 1 FROM forcepushdown_schema.inner_fn(z)"
	PL/pgSQL function forcepushdown_schema.outer_fn(integer,integer) line 6 at PERFORM
	while executing command on localhost:57638
2023-11-25 00:44:16.695 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.695 UTC [3768323] STATEMENT:  SELECT outer_fn(1, 2);
2023-11-25 00:44:16.702 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.702 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.702 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (x,x)"
	PL/pgSQL function forcepushdown_schema.inner_fn(integer) line 4 at SQL statement
	SQL statement "SELECT 1 FROM forcepushdown_schema.inner_fn(z)"
	PL/pgSQL function forcepushdown_schema.outer_fn(integer,integer) line 6 at PERFORM
	while executing command on localhost:57638
2023-11-25 00:44:16.702 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.702 UTC [3768323] STATEMENT:  SELECT outer_fn(1, 2);
2023-11-25 00:44:16.718 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.718 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.718 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_inner(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_inner(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 00:44:16.718 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.718 UTC [3768323] STATEMENT:  SELECT force_push_outer(7);
2023-11-25 00:44:16.725 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.725 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.725 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_inner(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_inner(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 00:44:16.725 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.725 UTC [3768323] STATEMENT:  SELECT force_push_outer(8);
2023-11-25 00:44:16.726 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.726 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.726 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_inner(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_inner(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 00:44:16.726 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.726 UTC [3768323] STATEMENT:  SELECT force_push_outer(14);
2023-11-25 00:44:16.753 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.753 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.753 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_2(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_2(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_1(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 00:44:16.753 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.753 UTC [3768323] STATEMENT:  SELECT force_push_1(7);
2023-11-25 00:44:16.754 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.754 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.754 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_2(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_2(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_1(integer) line 5 at PERFORM
	while executing command on localhost:57638
2023-11-25 00:44:16.754 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.754 UTC [3768323] STATEMENT:  SELECT force_push_1(13);
2023-11-25 00:44:16.779 UTC [3768323] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 00:44:16.779 UTC [3768323] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 00:44:16.779 UTC [3768323] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (x+1,x+1)"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 00:44:16.779 UTC [3768323] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:16.779 UTC [3768323] STATEMENT:  SELECT force_push_outer(7);
2023-11-25 00:44:17.205 UTC [3768515] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:17.205 UTC [3768515] DETAIL:  Shards of relations in subquery need to have 1-to-1 shard partitioning
2023-11-25 00:44:17.205 UTC [3768515] LOCATION:  ErrorIfUnsupportedShardDistribution, multi_physical_planner.c:2432
2023-11-25 00:44:17.205 UTC [3768515] STATEMENT:  SELECT * FROM test_table_1 full join test_table_2 using(id);
2023-11-25 00:44:17.900 UTC [3769022] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:17.900 UTC [3769022] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:17.900 UTC [3769022] STATEMENT:  SELECT
	  user_id
	FROM
	  users_table
	WHERE
	  value_2 >
	          (SELECT
	              max(value_2)
	           FROM
	              events_table
	           WHERE
	              users_table.user_id > events_table.user_id AND event_type = 1 AND
	              users_table.time = events_table.time
	           GROUP BY
	              user_id
	          )
	GROUP BY user_id
	HAVING count(*) > 1
	ORDER BY user_id
	LIMIT 5;
2023-11-25 00:44:17.961 UTC [3769022] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:17.961 UTC [3769022] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:17.961 UTC [3769022] STATEMENT:  SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 1 AND value_1 < 2
	  AND value_2 >= 1
	  AND user_id IN
	  (
			SELECT
			  e1.user_id
			FROM (
			  -- Get the first time each user viewed the homepage.
			  SELECT
			    user_id,
			    1 AS view_homepage,
			    min(time) AS view_homepage_time
			  FROM events_table
			     WHERE
			     event_type IN (0, 1)
			  GROUP BY user_id
			) e1 LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS use_demo,
			    time AS use_demo_time
			  FROM events_table
			  WHERE
			    user_id = e1.user_id AND
			       event_type IN (1, 2)
			  ORDER BY time
			) e2 ON true LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS enter_credit_card,
			    time AS enter_credit_card_time
			  FROM  events_table
			  WHERE
			    user_id = e2.user_id AND
			    event_type IN (2, 3)
			  ORDER BY time
			) e3 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS submit_card_info,
			    user_id,
			    time AS enter_credit_card_time
			  FROM  events_table
			  WHERE
			    value_2 = e3.user_id AND
			    event_type IN (3, 4)
			  ORDER BY time
			) e4 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS see_bought_screen
			  FROM  events_table
			  WHERE
			    user_id = e4.user_id AND
			    event_type IN (5, 6)
			  ORDER BY time
			) e5 ON true
			group by e1.user_id
			HAVING sum(submit_card_info) > 0
	);
2023-11-25 00:44:17.979 UTC [3769022] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:17.979 UTC [3769022] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:17.979 UTC [3769022] STATEMENT:  SELECT user_id, array_length(events_table, 1)
	FROM (
	  SELECT user_id, array_agg(event ORDER BY time) AS events_table
	  FROM (
	    SELECT
	    	u.user_id, e.event_type::text AS event, e.time
	    FROM
	    	users_table AS u,
	        events_table AS e
	    WHERE u.user_id = e.user_id AND
	    		u.user_id IN
	    		(
	    			SELECT
	    				user_id
	    			FROM
	    				users_table
	    			WHERE value_2 >= 5
				    AND  EXISTS (SELECT user_id FROM events_table WHERE event_type > 1 AND event_type <= 3 AND value_3 > 1 AND user_id = users_table.user_id)
					AND  NOT EXISTS (SELECT user_id FROM events_table WHERE event_type > 3 AND event_type <= 4  AND value_3 > 1 AND user_id != users_table.user_id)
	    		)
	  ) t
	  GROUP BY user_id
	) q
	ORDER BY 2 DESC, 1;
2023-11-25 00:44:18.024 UTC [3769021] ERROR:  0A000: could not create distributed plan
2023-11-25 00:44:18.024 UTC [3769021] DETAIL:  Possibly this is caused by the use of parameters in SQL functions, which is not supported in Citus.
2023-11-25 00:44:18.024 UTC [3769021] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 00:44:18.024 UTC [3769021] CONTEXT:  SQL function "sql_subquery_test" statement 1
2023-11-25 00:44:18.024 UTC [3769021] LOCATION:  CreateDistributedPlannedStmt, distributed_planner.c:751
2023-11-25 00:44:18.024 UTC [3769021] STATEMENT:  SELECT sql_subquery_test(1,1);
2023-11-25 00:44:18.049 UTC [3769022] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:18.049 UTC [3769022] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:18.049 UTC [3769022] STATEMENT:  SELECT user_id, value_2 FROM users_table WHERE
	  value_1 = 1
	  AND value_2 >= 2
	  AND NOT EXISTS (SELECT user_id FROM events_table WHERE event_type=1 AND value_3 > 1 AND test_join_function(events_table.user_id, users_table.user_id))
	ORDER BY 1 DESC, 2 DESC
	LIMIT 3;
2023-11-25 00:44:18.082 UTC [3769019] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:18.082 UTC [3769019] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:18.082 UTC [3769019] STATEMENT:  SELECT user_id, sum(counter)
	FROM (
	    SELECT user_id, sum(value_2) AS counter FROM users_table GROUP BY user_id
	      UNION
	    SELECT events_table.user_id, sum(events_table.value_2) AS counter FROM events_table, users_table WHERE users_table.user_id > events_table.user_id GROUP BY 1
	) user_id
	GROUP BY user_id;
2023-11-25 00:44:18.082 UTC [3769019] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:18.082 UTC [3769019] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:18.082 UTC [3769019] STATEMENT:  SELECT user_id, sum(counter)
	FROM (
	    SELECT user_id, sum(value_2) AS counter FROM users_table GROUP BY user_id
	      UNION ALL
	    SELECT events_table.user_id, sum(events_table.value_2) AS counter FROM events_table, users_table WHERE users_table.user_id > events_table.user_id GROUP BY 1
	) user_id
	GROUP BY user_id;
2023-11-25 00:44:18.140 UTC [3769019] ERROR:  0A000: cannot perform distributed planning on this query because parameterized queries for SQL functions referencing distributed tables are not supported
2023-11-25 00:44:18.140 UTC [3769019] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 00:44:18.140 UTC [3769019] LOCATION:  distributed_planner, distributed_planner.c:301
2023-11-25 00:44:18.140 UTC [3769019] STATEMENT:  SELECT user_id FROM users_table
	UNION SELECT u.user_id FROM users_table, users_udf() u;
2023-11-25 00:44:18.596 UTC [3769020] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 00:44:18.596 UTC [3769020] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:18.596 UTC [3769020] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM t_lock;
2023-11-25 00:44:18.608 UTC [3769020] ERROR:  57014: canceling statement due to statement timeout
2023-11-25 00:44:18.608 UTC [3769020] LOCATION:  ProcessInterrupts, postgres.c:3326
2023-11-25 00:44:18.608 UTC [3769020] STATEMENT:  INSERT INTO t_unrelated SELECT i FROM generate_series(1, 10) i;
2023-11-25 00:44:19.024 UTC [3769274] ERROR:  25001: cannot perform query on placements that were modified in this transaction by a different user
2023-11-25 00:44:19.024 UTC [3769274] LOCATION:  FindPlacementListConnection, placement_connection.c:647
2023-11-25 00:44:19.024 UTC [3769274] STATEMENT:  SELECT * FROM t;
2023-11-25 00:44:19.025 UTC [3769274] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:19.025 UTC [3769274] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:19.025 UTC [3769274] STATEMENT:  INSERT INTO t values (1);
2023-11-25 00:44:19.025 UTC [3769274] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:19.025 UTC [3769274] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:19.025 UTC [3769274] STATEMENT:  SELECT * from t;
2023-11-25 00:44:19.047 UTC [3769274] ERROR:  25001: cannot perform query on placements that were modified in this transaction by a different user
2023-11-25 00:44:19.047 UTC [3769274] LOCATION:  FindPlacementListConnection, placement_connection.c:647
2023-11-25 00:44:19.047 UTC [3769274] STATEMENT:  INSERT INTO t values (2);
2023-11-25 00:44:19.078 UTC [3769274] ERROR:  25001: cannot perform query on placements that were modified in this transaction by a different user
2023-11-25 00:44:19.078 UTC [3769274] CONTEXT:  COPY t, line 1: "1"
2023-11-25 00:44:19.078 UTC [3769274] LOCATION:  FindPlacementListConnection, placement_connection.c:647
2023-11-25 00:44:19.078 UTC [3769274] STATEMENT:  COPY t FROM STDIN;
2023-11-25 00:44:19.224 UTC [3769273] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 00:44:19.224 UTC [3769273] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:19.224 UTC [3769273] STATEMENT:  SELECT
		min(r_custkey), max(r_custkey)
	FROM
		multi_outer_join_left_hash a RIGHT JOIN multi_outer_join_right_reference b ON (l_custkey = r_custkey);
2023-11-25 00:44:19.246 UTC [3769273] ERROR:  XX000: hash partitioned table has overlapping shards
2023-11-25 00:44:19.246 UTC [3769273] LOCATION:  ErrorIfInconsistentShardIntervals, metadata_cache.c:1981
2023-11-25 00:44:19.246 UTC [3769273] STATEMENT:  SELECT
		min(l_custkey), max(l_custkey)
	FROM
		multi_outer_join_left_hash a LEFT JOIN multi_outer_join_right_hash b ON (l_custkey = r_custkey);
2023-11-25 00:44:19.412 UTC [3769273] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:19.412 UTC [3769273] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:19.412 UTC [3769273] STATEMENT:  SELECT
		count(*)
	FROM
		multi_outer_join_left_hash a LEFT JOIN multi_outer_join_right_hash b ON (l_nationkey = r_nationkey);
2023-11-25 00:44:19.432 UTC [3769273] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 00:44:19.432 UTC [3769273] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:19.432 UTC [3769273] STATEMENT:  SELECT
		min(r_custkey), max(r_custkey)
	FROM
		multi_outer_join_left_hash a RIGHT JOIN multi_outer_join_right_reference b ON (l_custkey = r_custkey);
2023-11-25 00:44:19.442 UTC [3769273] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:19.442 UTC [3769273] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:19.442 UTC [3769273] STATEMENT:  SELECT
		*
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_reference r1 ON (l1.l_custkey = r1.r_custkey)
		LEFT JOIN multi_outer_join_right_reference r2 ON (l1.l_custkey  = r2.r_custkey)
		RIGHT JOIN multi_outer_join_left_hash l2 ON (r2.r_custkey = l2.l_custkey);
2023-11-25 00:44:19.443 UTC [3769273] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:19.443 UTC [3769273] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:19.443 UTC [3769273] STATEMENT:  SELECT
		*
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_reference r1 ON (l1.l_custkey = r1.r_custkey)
		LEFT JOIN multi_outer_join_right_reference r2 ON (l1.l_custkey  = r2.r_custkey)
		RIGHT JOIN multi_outer_join_left_hash l2 ON (r2.r_custkey = l2.l_custkey)
	WHERE
		r1.r_custkey is NULL;
2023-11-25 00:44:19.447 UTC [3769273] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 00:44:19.447 UTC [3769273] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:19.447 UTC [3769273] STATEMENT:  SELECT
		l_custkey, r_custkey, t_custkey
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_hash r1 ON (l1.l_custkey = r1.r_custkey)
		RIGHT JOIN multi_outer_join_third_reference t1 ON (r1.r_custkey  = t1.t_custkey)
	ORDER BY 1,2,3;
2023-11-25 00:44:19.448 UTC [3769273] LOG:  00000: join order: [ "multi_outer_join_right_hash" ]
2023-11-25 00:44:19.448 UTC [3769273] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:19.448 UTC [3769273] STATEMENT:  SELECT
		l_custkey, r_custkey, t_custkey
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_hash r1 ON (l1.l_custkey = r1.r_custkey)
		RIGHT JOIN multi_outer_join_third_reference t1 ON (r1.r_custkey  = t1.t_custkey)
	ORDER BY 1,2,3;
2023-11-25 00:44:19.491 UTC [3769273] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 00:44:19.491 UTC [3769273] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:19.491 UTC [3769273] STATEMENT:  SELECT
		l_custkey, t_custkey
	FROM
		multi_outer_join_left_hash l1
		FULL JOIN multi_outer_join_third_reference t1 ON (l1.l_custkey = t1.t_custkey)
	ORDER BY 1,2;
2023-11-25 00:44:19.553 UTC [3769271] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 00:44:19.553 UTC [3769271] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 00:44:19.553 UTC [3769271] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 00:44:19.553 UTC [3769271] STATEMENT:  SELECT SUM(distinct l_partkey) FROM lineitem_hash;
2023-11-25 00:44:19.553 UTC [3769271] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 00:44:19.553 UTC [3769271] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 00:44:19.553 UTC [3769271] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 00:44:19.553 UTC [3769271] STATEMENT:  SELECT l_shipmode, sum(distinct l_partkey) FROM lineitem_hash GROUP BY l_shipmode;
2023-11-25 00:44:19.964 UTC [3769640] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 00:44:19.964 UTC [3769640] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:44:19.964 UTC [3769640] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:19.964 UTC [3769640] STATEMENT:  SELECT * FROM
		test_table_1_rf1 as tt1 INNER JOIN test_table_1_rf1 as tt2 on tt1.id = tt2.id
		ORDER BY 1
		FOR UPDATE;
2023-11-25 00:44:19.964 UTC [3769640] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 00:44:19.964 UTC [3769640] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:19.964 UTC [3769640] STATEMENT:  SELECT * FROM
		test_table_1_rf1 as tt1 INNER JOIN test_table_3_rf2 as tt3 on tt1.id = tt3.id
		WHERE tt1.id = 1
		ORDER BY 1
		FOR UPDATE;
2023-11-25 00:44:19.965 UTC [3769640] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 00:44:19.965 UTC [3769640] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:19.965 UTC [3769640] STATEMENT:  SELECT * FROM
		test_table_1_rf1 as tt1 INNER JOIN test_table_3_rf2 as tt3 on tt1.id = tt3.id
		ORDER BY 1
		FOR UPDATE;
2023-11-25 00:44:19.965 UTC [3769640] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 00:44:19.965 UTC [3769640] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:44:19.965 UTC [3769640] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:19.965 UTC [3769640] STATEMENT:  SELECT * FROM
		test_table_3_rf2 as tt3 INNER JOIN test_table_4_rf2 as tt4 on tt3.id = tt4.id
		WHERE tt3.id = 1
		ORDER BY 1
		FOR UPDATE;
2023-11-25 00:44:20.000 UTC [3769639] ERROR:  23505: duplicate key value violates unique constraint "reference_table_test_fourth_pkey_1250003"
2023-11-25 00:44:20.000 UTC [3769639] DETAIL:  Key (value_2)=(1) already exists.
2023-11-25 00:44:20.000 UTC [3769639] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:20.000 UTC [3769639] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:20.000 UTC [3769639] STATEMENT:  INSERT INTO reference_table_test_fourth VALUES (1, 1.0, '1', '2016-12-01');
2023-11-25 00:44:20.001 UTC [3769639] ERROR:  23502: null value in column "value_2" of relation "reference_table_test_fourth_1250003" violates not-null constraint
2023-11-25 00:44:20.001 UTC [3769639] DETAIL:  Failing row contains (1, null, 1.0, 2016-12-01 00:00:00).
2023-11-25 00:44:20.001 UTC [3769639] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:20.001 UTC [3769639] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:20.001 UTC [3769639] STATEMENT:  INSERT INTO reference_table_test_fourth (value_1, value_3, value_4) VALUES (1, '1.0', '2016-12-01');
2023-11-25 00:44:20.105 UTC [3769639] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ]
2023-11-25 00:44:20.105 UTC [3769639] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:20.105 UTC [3769639] STATEMENT:  SELECT
		reference_table_test.value_1
	FROM
		reference_table_test, colocated_table_test
	WHERE
		colocated_table_test.value_1 = reference_table_test.value_1
	ORDER BY 1;
2023-11-25 00:44:20.113 UTC [3769639] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ]
2023-11-25 00:44:20.113 UTC [3769639] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:20.113 UTC [3769639] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test
	WHERE
		colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY 1;
2023-11-25 00:44:20.119 UTC [3769639] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ]
2023-11-25 00:44:20.119 UTC [3769639] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:20.119 UTC [3769639] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		colocated_table_test, reference_table_test
	WHERE
		reference_table_test.value_1 = colocated_table_test.value_1
	ORDER BY 1;
2023-11-25 00:44:20.128 UTC [3769639] LOG:  00000: join order: [ "colocated_table_test_2" ][ cartesian product reference join "reference_table_test" ][ dual partition join "colocated_table_test" ]
2023-11-25 00:44:20.128 UTC [3769639] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:20.128 UTC [3769639] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY colocated_table_test.value_2;
2023-11-25 00:44:20.303 UTC [3769639] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ][ local partition join "colocated_table_test_2" ]
2023-11-25 00:44:20.303 UTC [3769639] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:20.303 UTC [3769639] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_1 = colocated_table_test_2.value_1 AND colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY 1;
2023-11-25 00:44:20.308 UTC [3769639] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ][ dual partition join "colocated_table_test_2" ]
2023-11-25 00:44:20.308 UTC [3769639] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:20.308 UTC [3769639] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_2 = colocated_table_test_2.value_2 AND colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY colocated_table_test.value_2;
2023-11-25 00:44:20.454 UTC [3769639] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ][ dual partition join "colocated_table_test_2" ]
2023-11-25 00:44:20.454 UTC [3769639] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:20.454 UTC [3769639] STATEMENT:  SELECT
		reference_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_1 = reference_table_test.value_1 AND colocated_table_test_2.value_1 = reference_table_test.value_1
	ORDER BY reference_table_test.value_2;
2023-11-25 00:44:20.654 UTC [3769639] ERROR:  0A000: relation reference_table_test should be a hash distributed table
2023-11-25 00:44:20.654 UTC [3769639] LOCATION:  EnsureHashDistributedTable, metadata_utility.c:2284
2023-11-25 00:44:20.654 UTC [3769639] STATEMENT:  SELECT update_distributed_table_colocation('colocated_table_test_2', colocate_with => 'reference_table_test');
2023-11-25 00:44:20.654 UTC [3769639] ERROR:  0A000: relation reference_table_test_fifth should be a hash distributed table
2023-11-25 00:44:20.654 UTC [3769639] LOCATION:  EnsureHashDistributedTable, metadata_utility.c:2284
2023-11-25 00:44:20.654 UTC [3769639] STATEMENT:  SELECT update_distributed_table_colocation('reference_table_test', colocate_with => 'reference_table_test_fifth');
2023-11-25 00:44:20.797 UTC [3770192] ERROR:  XX000: relation "reference_schema.reference_table_ddl" is a reference table
2023-11-25 00:44:20.797 UTC [3770192] DETAIL:  We currently don't support creating shards on reference tables
2023-11-25 00:44:20.797 UTC [3770192] LOCATION:  master_create_empty_shard, stage_protocol.c:143
2023-11-25 00:44:20.797 UTC [3770192] STATEMENT:  SELECT master_create_empty_shard('reference_schema.reference_table_ddl');
2023-11-25 00:44:21.126 UTC [3770253] ERROR:  42704: type "hll" does not exist at character 51
2023-11-25 00:44:21.126 UTC [3770253] LOCATION:  typenameType, parse_type.c:270
2023-11-25 00:44:21.126 UTC [3770253] STATEMENT:  CREATE TABLE daily_uniques(day date, unique_users hll);
2023-11-25 00:44:21.143 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 33
2023-11-25 00:44:21.143 UTC [3770253] LOCATION:  RangeVarGetRelidExtended, namespace.c:433
2023-11-25 00:44:21.143 UTC [3770253] STATEMENT:  SELECT create_distributed_table('daily_uniques', 'day');
2023-11-25 00:44:21.193 UTC [3770254] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 37
2023-11-25 00:44:21.193 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.193 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.193 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest(latency, 100)
	FROM latencies;
2023-11-25 00:44:21.193 UTC [3770254] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 40
2023-11-25 00:44:21.193 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.193 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.193 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest(latency, 100)
	FROM latencies
	GROUP BY a;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 40
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest(latency, 100)
	FROM latencies
	GROUP BY b;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 37
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(latency, 100, 0.99)
	FROM latencies;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 40
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(latency, 100, 0.99)
	FROM latencies
	GROUP BY a;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 40
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile(latency, 100, 0.99)
	FROM latencies
	GROUP BY b;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 37
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(latency, 100, ARRAY[0.99, 0.95])
	FROM latencies;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 40
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(latency, 100, ARRAY[0.99, 0.95])
	FROM latencies
	GROUP BY a;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 40
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile(latency, 100, ARRAY[0.99, 0.95])
	FROM latencies
	GROUP BY b;
2023-11-25 00:44:21.194 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 37
2023-11-25 00:44:21.194 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.194 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.194 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(latency, 100, 9000)
	FROM latencies;
2023-11-25 00:44:21.195 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 40
2023-11-25 00:44:21.195 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.195 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.195 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(latency, 100, 9000)
	FROM latencies
	GROUP BY a;
2023-11-25 00:44:21.195 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 40
2023-11-25 00:44:21.195 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.195 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.195 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile_of(latency, 100, 9000)
	FROM latencies
	GROUP BY b;
2023-11-25 00:44:21.195 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 37
2023-11-25 00:44:21.195 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.195 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.195 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(latency, 100, ARRAY[9000, 9500])
	FROM latencies;
2023-11-25 00:44:21.195 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 40
2023-11-25 00:44:21.195 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.195 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.195 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(latency, 100, ARRAY[9000, 9500])
	FROM latencies
	GROUP BY a;
2023-11-25 00:44:21.195 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 40
2023-11-25 00:44:21.195 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.195 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.195 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile_of(latency, 100, ARRAY[9000, 9500])
	FROM latencies
	GROUP BY b;
2023-11-25 00:44:21.195 UTC [3770254] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 8
2023-11-25 00:44:21.195 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.195 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.195 UTC [3770254] STATEMENT:  SELECT tdigest(latency, 100) FROM latencies;
2023-11-25 00:44:21.195 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 8
2023-11-25 00:44:21.195 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.195 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.195 UTC [3770254] STATEMENT:  SELECT tdigest_percentile(latency, 100, 0.99) FROM latencies;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 8
2023-11-25 00:44:21.196 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  SELECT tdigest_percentile(latency, 100, ARRAY[0.99, 0.95]) FROM latencies;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 8
2023-11-25 00:44:21.196 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  SELECT tdigest_percentile_of(latency, 100, 9000) FROM latencies;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 8
2023-11-25 00:44:21.196 UTC [3770254] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  SELECT tdigest_percentile_of(latency, 100, ARRAY[9000, 9500]) FROM latencies;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42704: type "tdigest" does not exist at character 47
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  typenameType, parse_type.c:270
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  CREATE TABLE latencies_rollup (a int, tdigest tdigest);
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 33
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  RangeVarGetRelidExtended, namespace.c:433
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  SELECT create_distributed_table('latencies_rollup', 'a', colocate_with => 'latencies');
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 13
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  INSERT INTO latencies_rollup
	SELECT a, tdigest(latency, 100)
	FROM latencies
	GROUP BY a;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 59
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest(tdigest)
	FROM latencies_rollup;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 62
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest(tdigest)
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 76
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(tdigest, 0.99)
	FROM latencies_rollup;
2023-11-25 00:44:21.196 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 79
2023-11-25 00:44:21.196 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.196 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(tdigest, 0.99)
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 89
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(tdigest, ARRAY[0.99, 0.95])
	FROM latencies_rollup;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 92
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(tdigest, ARRAY[0.99, 0.95])
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 79
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(tdigest, 9000)
	FROM latencies_rollup;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 82
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(tdigest, 9000)
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 92
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(tdigest, ARRAY[9000, 9500])
	FROM latencies_rollup;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 95
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(tdigest, ARRAY[9000, 9500])
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 30
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  SELECT tdigest(tdigest) FROM latencies_rollup;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 47
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  SELECT tdigest_percentile(tdigest, 0.99) FROM latencies_rollup;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 60
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  SELECT tdigest_percentile(tdigest, ARRAY[0.99, 0.95]) FROM latencies_rollup;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 50
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  SELECT tdigest_percentile_of(tdigest, 9000) FROM latencies_rollup;
2023-11-25 00:44:21.197 UTC [3770254] ERROR:  42P01: relation "latencies_rollup" does not exist at character 63
2023-11-25 00:44:21.197 UTC [3770254] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.197 UTC [3770254] STATEMENT:  SELECT tdigest_percentile_of(tdigest, ARRAY[9000, 9500]) FROM latencies_rollup;
2023-11-25 00:44:21.207 UTC [3770252] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 00:44:21.207 UTC [3770252] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 00:44:21.207 UTC [3770252] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 00:44:21.207 UTC [3770252] STATEMENT:  select key, sum2(distinct val), sum2_strict(distinct val), psum(distinct val, valf::int), psum_strict(distinct val, valf::int) from aggdata group by key order by key;
2023-11-25 00:44:21.212 UTC [3770252] ERROR:  XX000: unsupported aggregate function sum2
2023-11-25 00:44:21.212 UTC [3770252] LOCATION:  GetAggregateType, multi_logical_optimizer.c:3481
2023-11-25 00:44:21.212 UTC [3770252] STATEMENT:  select key, sum2(val order by valf), sum2_strict(val order by valf), psum(val, valf::int order by valf), psum_strict(val, valf::int order by valf) from aggdata group by key order by key;
2023-11-25 00:44:21.230 UTC [3770253] ERROR:  42883: function hll_hash_integer(integer) does not exist at character 72
2023-11-25 00:44:21.230 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.230 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.230 UTC [3770253] STATEMENT:  SELECT hll_cardinality(hll_union_agg(agg))
	FROM (
	  SELECT hll_add_agg(hll_hash_integer(user_id)) AS agg
	  FROM raw_table)a;
2023-11-25 00:44:21.230 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 13
2023-11-25 00:44:21.230 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.230 UTC [3770253] STATEMENT:  INSERT INTO daily_uniques
	  SELECT day, hll_add_agg(hll_hash_integer(user_id))
	  FROM raw_table
	  GROUP BY 1;
2023-11-25 00:44:21.230 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 48
2023-11-25 00:44:21.230 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.230 UTC [3770253] STATEMENT:  SELECT day, hll_cardinality(unique_users)
	FROM daily_uniques
	WHERE day >= '2018-06-20' and day <= '2018-06-30'
	ORDER BY 2 DESC,1
	LIMIT 10;
2023-11-25 00:44:21.230 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 58
2023-11-25 00:44:21.230 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.230 UTC [3770253] STATEMENT:  SELECT hll_cardinality(hll_union_agg(unique_users))
	FROM daily_uniques
	WHERE day >= '2018-05-24'::date AND day <= '2018-05-31'::date;
2023-11-25 00:44:21.230 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 92
2023-11-25 00:44:21.230 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.230 UTC [3770253] STATEMENT:  SELECT EXTRACT(MONTH FROM day) AS month, hll_cardinality(hll_union_agg(unique_users))
	FROM daily_uniques
	WHERE day >= '2018-06-23' AND day <= '2018-07-01'
	GROUP BY 1
	ORDER BY 1;
2023-11-25 00:44:21.231 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 79
2023-11-25 00:44:21.231 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.231 UTC [3770253] STATEMENT:  SELECT day, hll_cardinality(hll_union_agg(unique_users) OVER seven_days)
	FROM daily_uniques
	WINDOW seven_days AS (ORDER BY day ASC ROWS 6 PRECEDING)
	ORDER BY 1;
2023-11-25 00:44:21.231 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 127
2023-11-25 00:44:21.231 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.231 UTC [3770253] STATEMENT:  SELECT day, (hll_cardinality(hll_union_agg(unique_users) OVER two_days)) - hll_cardinality(unique_users) AS lost_uniques
	FROM daily_uniques
	WINDOW two_days AS (ORDER BY day ASC ROWS 1 PRECEDING)
	ORDER BY 1;
2023-11-25 00:44:21.232 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 69
2023-11-25 00:44:21.232 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.232 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 00:44:21.232 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 69
2023-11-25 00:44:21.232 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.232 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 00:44:21.232 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 100
2023-11-25 00:44:21.232 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.232 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users) || hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 00:44:21.232 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 100
2023-11-25 00:44:21.232 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.232 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users) || hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 00:44:21.233 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 00:44:21.233 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.233 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 00:44:21.233 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 00:44:21.233 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.233 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 00:44:21.233 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 00:44:21.233 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.233 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 00:44:21.233 UTC [3770253] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 00:44:21.233 UTC [3770253] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:21.233 UTC [3770253] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1)
	HAVING hll_cardinality(hll_union_agg(unique_users)) > 1;
2023-11-25 00:44:21.247 UTC [3770253] ERROR:  42P01: table "daily_uniques" does not exist
2023-11-25 00:44:21.247 UTC [3770253] LOCATION:  DropErrorMsgNonExistent, tablecmds.c:1290
2023-11-25 00:44:21.247 UTC [3770253] STATEMENT:  DROP TABLE daily_uniques;
2023-11-25 00:44:21.395 UTC [3770253] ERROR:  42883: function topn_add_agg(text) does not exist at character 42
2023-11-25 00:44:21.395 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.395 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.395 UTC [3770253] STATEMENT:  SELECT (topn(agg, 10)).*
	FROM (
	  SELECT topn_add_agg(user_id::text) AS agg
	  FROM customer_reviews
	  )a
	ORDER BY 2 DESC, 1;
2023-11-25 00:44:21.395 UTC [3770253] ERROR:  42883: function topn_add_agg(text) does not exist at character 44
2023-11-25 00:44:21.395 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.395 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.395 UTC [3770253] STATEMENT:  INSERT INTO popular_reviewer
	  SELECT day, topn_add_agg(user_id::text)
	  FROM customer_reviews
	  GROUP BY 1;
2023-11-25 00:44:21.395 UTC [3770253] ERROR:  42883: function topn(jsonb, integer) does not exist at character 14
2023-11-25 00:44:21.395 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.395 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.395 UTC [3770253] STATEMENT:  SELECT day, (topn(reviewers, 10)).*
	FROM popular_reviewer
	WHERE day >= '2018-06-20' and day <= '2018-06-30'
	ORDER BY 3 DESC, 1, 2
	LIMIT 10;
2023-11-25 00:44:21.395 UTC [3770253] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 41
2023-11-25 00:44:21.395 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.395 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.395 UTC [3770253] STATEMENT:  SELECT (topn(agg, 10)).*
	FROM (
		SELECT topn_union_agg(reviewers) AS agg
		FROM popular_reviewer
		WHERE day >= '2018-05-24'::date AND day <= '2018-05-31'::date
		)a
	ORDER BY 2 DESC, 1;
2023-11-25 00:44:21.396 UTC [3770253] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 81
2023-11-25 00:44:21.396 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.396 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.396 UTC [3770253] STATEMENT:  SELECT month, (topn(agg, 5)).*
	FROM (
		SELECT EXTRACT(MONTH FROM day) AS month, topn_union_agg(reviewers) AS agg
		FROM popular_reviewer
		WHERE day >= '2018-06-23' AND day <= '2018-07-01'
		GROUP BY 1
		ORDER BY 1
		)a
	ORDER BY 1, 3 DESC, 2;
2023-11-25 00:44:21.396 UTC [3770253] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 14
2023-11-25 00:44:21.396 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.396 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.396 UTC [3770253] STATEMENT:  SELECT (topn(topn_union_agg(reviewers), 10)).*
	FROM popular_reviewer
	WHERE day >= '2018-05-24'::date AND day <= '2018-05-31'::date
	ORDER BY 2 DESC, 1;
2023-11-25 00:44:21.396 UTC [3770253] ERROR:  42883: function topn_add_agg(text) does not exist at character 14
2023-11-25 00:44:21.396 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.396 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.396 UTC [3770253] STATEMENT:  SELECT (topn(topn_add_agg(user_id::text), 10)).*
	FROM customer_reviews
	ORDER BY 2 DESC, 1;
2023-11-25 00:44:21.396 UTC [3770253] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 51
2023-11-25 00:44:21.396 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.396 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.396 UTC [3770253] STATEMENT:  SELECT day, (topn(agg, 10)).*
	FROM (
		SELECT day, topn_union_agg(reviewers) OVER seven_days AS agg
		FROM popular_reviewer
		WINDOW seven_days AS (ORDER BY day ASC ROWS 6 PRECEDING)
		)a
	ORDER BY 3 DESC, 1, 2
	LIMIT 10;
2023-11-25 00:44:21.396 UTC [3770253] ERROR:  42883: function topn_add_agg(text) does not exist at character 19
2023-11-25 00:44:21.396 UTC [3770253] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.396 UTC [3770253] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 00:44:21.396 UTC [3770253] STATEMENT:  SELECT day, (topn(topn_add_agg(user_id::text) OVER seven_days, 10)).*
	FROM customer_reviews
	WINDOW seven_days AS (ORDER BY day ASC ROWS 6 PRECEDING)
	ORDER BY 3 DESC, 1, 2
	LIMIT 10;
2023-11-25 00:44:21.580 UTC [3770252] ERROR:  XX000: unsupported aggregate function first
2023-11-25 00:44:21.580 UTC [3770252] LOCATION:  GetAggregateType, multi_logical_optimizer.c:3481
2023-11-25 00:44:21.580 UTC [3770252] STATEMENT:  SELECT key, first(val ORDER BY id), last(val ORDER BY id)
	FROM aggdata GROUP BY key ORDER BY key;
2023-11-25 00:44:21.583 UTC [3770252] ERROR:  XX000: unsupported aggregate function first
2023-11-25 00:44:21.583 UTC [3770252] LOCATION:  GetAggregateType, multi_logical_optimizer.c:3481
2023-11-25 00:44:21.583 UTC [3770252] STATEMENT:  SELECT id%5, first(val ORDER BY key), last(val ORDER BY key)
	FROM aggdata GROUP BY id%5 ORDER BY id%5;
2023-11-25 00:44:21.689 UTC [3770252] ERROR:  0A000: could not run distributed query with GROUPING
2023-11-25 00:44:21.689 UTC [3770252] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:44:21.689 UTC [3770252] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:21.689 UTC [3770252] STATEMENT:  select grouping(id)
	from aggdata group by id order by 1 limit 3;
2023-11-25 00:44:21.689 UTC [3770252] ERROR:  0A000: could not run distributed query with GROUPING
2023-11-25 00:44:21.689 UTC [3770252] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:44:21.689 UTC [3770252] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:21.689 UTC [3770252] STATEMENT:  select key, grouping(val)
	from aggdata group by key, val order by 1, 2;
2023-11-25 00:44:21.689 UTC [3770252] ERROR:  0A000: could not run distributed query with GROUPING
2023-11-25 00:44:21.689 UTC [3770252] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 00:44:21.689 UTC [3770252] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:21.689 UTC [3770252] STATEMENT:  select key, grouping(val), sum(distinct valf)
	from aggdata group by key, val order by 1, 2;
2023-11-25 00:44:21.690 UTC [3770252] ERROR:  XX000: worker_partial_agg_sfunc could not confirm type correctness
2023-11-25 00:44:21.690 UTC [3770252] LOCATION:  worker_partial_agg_sfunc, aggregate_utils.c:517
2023-11-25 00:44:21.690 UTC [3770252] STATEMENT:  select pg_catalog.worker_partial_agg('string_agg(text,text)'::regprocedure, id) from nulltable;
2023-11-25 00:44:21.690 UTC [3770252] ERROR:  XX000: worker_partial_agg_sfunc could not confirm type correctness
2023-11-25 00:44:21.690 UTC [3770252] LOCATION:  worker_partial_agg_sfunc, aggregate_utils.c:517
2023-11-25 00:44:21.690 UTC [3770252] STATEMENT:  select pg_catalog.worker_partial_agg('sum(int8)'::regprocedure, id) from nulltable;
2023-11-25 00:44:21.690 UTC [3770252] ERROR:  XX000: coord_combine_agg_ffunc could not confirm type correctness
2023-11-25 00:44:21.690 UTC [3770252] LOCATION:  coord_combine_agg_ffunc, aggregate_utils.c:817
2023-11-25 00:44:21.690 UTC [3770252] STATEMENT:  select pg_catalog.coord_combine_agg('sum(float8)'::regprocedure, id::text::cstring, null::text) from nulltable;
2023-11-25 00:44:21.690 UTC [3770252] ERROR:  XX000: coord_combine_agg_ffunc could not confirm type correctness
2023-11-25 00:44:21.690 UTC [3770252] LOCATION:  coord_combine_agg_ffunc, aggregate_utils.c:817
2023-11-25 00:44:21.690 UTC [3770252] STATEMENT:  select pg_catalog.coord_combine_agg('avg(float8)'::regprocedure, ARRAY[id,id,id]::text::cstring, null::text) from nulltable;
2023-11-25 00:44:21.726 UTC [3770252] ERROR:  42883: function aggregate_support.square_func(integer) does not exist
2023-11-25 00:44:21.726 UTC [3770252] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.726 UTC [3770252] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:21.726 UTC [3770252] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:21.726 UTC [3770252] STATEMENT:  SELECT square_func(5), a FROM t1 GROUP BY a;
2023-11-25 00:44:21.733 UTC [3770252] ERROR:  42883: function aggregate_support.square_func(integer) does not exist
2023-11-25 00:44:21.733 UTC [3770252] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 00:44:21.733 UTC [3770252] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:21.733 UTC [3770252] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:21.733 UTC [3770252] STATEMENT:  SELECT square_func(5), a, count(a) FROM t1 GROUP BY a;
2023-11-25 00:44:21.787 UTC [3770252] WARNING:  0A000: "function dummy_fnc(dummy_tbl,double precision)" has dependency to "table dummy_tbl" that is not in Citus' metadata
2023-11-25 00:44:21.787 UTC [3770252] DETAIL:  "function dummy_fnc(dummy_tbl,double precision)" will be created only locally
2023-11-25 00:44:21.787 UTC [3770252] HINT:  Distribute "table dummy_tbl" first to distribute "function dummy_fnc(dummy_tbl,double precision)"
2023-11-25 00:44:21.787 UTC [3770252] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:44:21.788 UTC [3770252] WARNING:  0A000: "function dependent_agg(double precision)" has dependency to "table dummy_tbl" that is not in Citus' metadata
2023-11-25 00:44:21.788 UTC [3770252] DETAIL:  "function dependent_agg(double precision)" will be created only locally
2023-11-25 00:44:21.788 UTC [3770252] HINT:  Distribute "table dummy_tbl" first to distribute "function dependent_agg(double precision)"
2023-11-25 00:44:21.788 UTC [3770252] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:44:22.571 UTC [3770630] ERROR:  0A000: array_agg (distinct) is unsupported
2023-11-25 00:44:22.571 UTC [3770630] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4016
2023-11-25 00:44:22.571 UTC [3770630] STATEMENT:  SELECT array_agg(distinct l_orderkey) FROM lineitem;
2023-11-25 00:44:22.571 UTC [3770630] ERROR:  0A000: array_agg with order by is unsupported
2023-11-25 00:44:22.571 UTC [3770630] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4008
2023-11-25 00:44:22.571 UTC [3770630] STATEMENT:  SELECT array_agg(l_orderkey ORDER BY l_partkey) FROM lineitem;
2023-11-25 00:44:22.572 UTC [3770630] ERROR:  0A000: array_agg with order by is unsupported
2023-11-25 00:44:22.572 UTC [3770630] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4008
2023-11-25 00:44:22.572 UTC [3770630] STATEMENT:  SELECT array_agg(distinct l_orderkey ORDER BY l_orderkey) FROM lineitem;
2023-11-25 00:44:22.811 UTC [3770628] ERROR:  0A000: subquery in LIMIT is not supported in multi-shard queries
2023-11-25 00:44:22.811 UTC [3770628] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:22.811 UTC [3770628] STATEMENT:  SELECT l_orderkey FROM lineitem_hash ORDER BY l_orderkey LIMIT (SELECT 10);
2023-11-25 00:44:22.811 UTC [3770628] ERROR:  0A000: subquery in OFFSET is not supported in multi-shard queries
2023-11-25 00:44:22.811 UTC [3770628] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 00:44:22.811 UTC [3770628] STATEMENT:  SELECT l_orderkey FROM lineitem_hash ORDER BY l_orderkey LIMIT 10 OFFSET (SELECT 10);
2023-11-25 00:44:23.018 UTC [3770794] ERROR:  0A000: json_object_agg (distinct) is unsupported
2023-11-25 00:44:23.018 UTC [3770794] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.018 UTC [3770794] STATEMENT:  SELECT json_object_agg(distinct l_shipmode, l_orderkey) FROM lineitem;
2023-11-25 00:44:23.019 UTC [3770793] ERROR:  0A000: jsonb_agg (distinct) is unsupported
2023-11-25 00:44:23.019 UTC [3770793] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.019 UTC [3770793] STATEMENT:  SELECT jsonb_agg(distinct l_orderkey) FROM lineitem;
2023-11-25 00:44:23.019 UTC [3770794] ERROR:  0A000: json_object_agg with order by is unsupported
2023-11-25 00:44:23.019 UTC [3770794] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.019 UTC [3770794] STATEMENT:  SELECT json_object_agg(l_shipmode, l_orderkey ORDER BY l_shipmode) FROM lineitem;
2023-11-25 00:44:23.019 UTC [3770794] ERROR:  0A000: json_object_agg with order by is unsupported
2023-11-25 00:44:23.019 UTC [3770794] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.019 UTC [3770794] STATEMENT:  SELECT json_object_agg(distinct l_orderkey, l_shipmode ORDER BY l_orderkey) FROM lineitem;
2023-11-25 00:44:23.019 UTC [3770793] ERROR:  0A000: jsonb_agg with order by is unsupported
2023-11-25 00:44:23.019 UTC [3770793] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.019 UTC [3770793] STATEMENT:  SELECT jsonb_agg(l_orderkey ORDER BY l_partkey) FROM lineitem;
2023-11-25 00:44:23.019 UTC [3770793] ERROR:  0A000: jsonb_agg with order by is unsupported
2023-11-25 00:44:23.019 UTC [3770793] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.019 UTC [3770793] STATEMENT:  SELECT jsonb_agg(distinct l_orderkey ORDER BY l_orderkey) FROM lineitem;
2023-11-25 00:44:23.039 UTC [3770791] ERROR:  0A000: json_agg (distinct) is unsupported
2023-11-25 00:44:23.039 UTC [3770791] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.039 UTC [3770791] STATEMENT:  SELECT json_agg(distinct l_orderkey) FROM lineitem;
2023-11-25 00:44:23.040 UTC [3770791] ERROR:  0A000: json_agg with order by is unsupported
2023-11-25 00:44:23.040 UTC [3770791] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.040 UTC [3770791] STATEMENT:  SELECT json_agg(l_orderkey ORDER BY l_partkey) FROM lineitem;
2023-11-25 00:44:23.040 UTC [3770791] ERROR:  0A000: json_agg with order by is unsupported
2023-11-25 00:44:23.040 UTC [3770791] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.040 UTC [3770791] STATEMENT:  SELECT json_agg(distinct l_orderkey ORDER BY l_orderkey) FROM lineitem;
2023-11-25 00:44:23.047 UTC [3770789] ERROR:  0A000: jsonb_object_agg (distinct) is unsupported
2023-11-25 00:44:23.047 UTC [3770789] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.047 UTC [3770789] STATEMENT:  SELECT jsonb_object_agg(distinct l_shipmode, l_orderkey) FROM lineitem;
2023-11-25 00:44:23.047 UTC [3770789] ERROR:  0A000: jsonb_object_agg with order by is unsupported
2023-11-25 00:44:23.047 UTC [3770789] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.047 UTC [3770789] STATEMENT:  SELECT jsonb_object_agg(l_shipmode, l_orderkey ORDER BY l_shipmode) FROM lineitem;
2023-11-25 00:44:23.047 UTC [3770789] ERROR:  0A000: jsonb_object_agg with order by is unsupported
2023-11-25 00:44:23.047 UTC [3770789] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 00:44:23.047 UTC [3770789] STATEMENT:  SELECT jsonb_object_agg(distinct l_orderkey, l_shipmode ORDER BY l_orderkey) FROM lineitem;
2023-11-25 00:44:23.213 UTC [3770797] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 00:44:23.213 UTC [3770797] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 00:44:23.213 UTC [3770797] STATEMENT:  select     s_i_id, sum(s_order_cnt) as ordercount
	from     stock s
	where   s_order_cnt > (select sum(s_order_cnt) * .005 as where_query from stock)
	group by s_i_id
	having   (select max(s_order_cnt) > 2 as having_query from stock where s_i_id = s.s_i_id)
	order by s_i_id;
2023-11-25 00:44:23.213 UTC [3770797] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 00:44:23.213 UTC [3770797] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 00:44:23.213 UTC [3770797] STATEMENT:  select     s_i_id, sum(s_order_cnt) as ordercount
	from     stock s
	group by s_i_id
	having   (select max(s_order_cnt) > 2 as having_query from stock where s_i_id = s.s_i_id)
	order by s_i_id;
2023-11-25 00:44:23.363 UTC [3770799] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 00:44:23.363 UTC [3770799] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 00:44:23.363 UTC [3770799] STATEMENT:  SELECT *
	FROM
	    test t1 JOIN test t2 USING (y), -- causes repartition, which makes this not routable or pushdownable
	    test a,
	    test b
	WHERE t2.y - a.x - b.x = 0
	ORDER BY 1,2,3;
2023-11-25 00:44:23.545 UTC [3770796] LOG:  00000: join order: [ "order_line" ]
2023-11-25 00:44:23.545 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.545 UTC [3770796] STATEMENT:  SELECT
	    ol_number,
	    sum(ol_quantity) as sum_qty,
	    sum(ol_amount) as sum_amount,
	    avg(ol_quantity) as avg_qty,
	    avg(ol_amount) as avg_amount,
	    count(*) as count_order
	FROM order_line
	WHERE ol_delivery_d > '2007-01-02 00:00:00.000000'
	GROUP BY ol_number
	ORDER BY ol_number;
2023-11-25 00:44:23.550 UTC [3770796] LOG:  00000: join order: [ "stock" ][ reference join "supplier" ][ reference join "nation" ][ reference join "region" ]
2023-11-25 00:44:23.550 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.550 UTC [3770796] STATEMENT:  SELECT
	    su_suppkey,
	    su_name,
	    n_name,
	    i_id,
	    i_name,
	    su_address,
	    su_phone,
	    su_comment
	FROM
	    item,
	    supplier,
	    stock,
	    nation,
	    region,
	    (SELECT
	         s_i_id AS m_i_id,
	         min(s_quantity) as m_s_quantity
	     FROM
	         stock,
	         supplier,
	         nation,
	         region
	     WHERE mod((s_w_id*s_i_id),10000)=su_suppkey
	       AND su_nationkey=n_nationkey
	       AND n_regionkey=r_regionkey
	       AND r_name LIKE 'Europ%'
	     GROUP BY s_i_id) m
	WHERE i_id = s_i_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND su_nationkey = n_nationkey
	  AND n_regionkey = r_regionkey
	  AND i_data LIKE '%b'
	  AND r_name LIKE 'Europ%'
	  AND i_id = m_i_id
	  AND s_quantity = m_s_quantity
	ORDER BY
	    n_name,
	    su_name,
	    i_id;
2023-11-25 00:44:23.559 UTC [3770796] LOG:  00000: join order: [ "customer" ][ local partition join "oorder" ][ local partition join "new_order" ][ local partition join "order_line" ]
2023-11-25 00:44:23.559 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.559 UTC [3770796] STATEMENT:  SELECT
	    ol_o_id,
	    ol_w_id,
	    ol_d_id,
	    sum(ol_amount) AS revenue,
	    o_entry_d
	FROM
	    customer,
	    new_order,
	    oorder,
	    order_line
	WHERE c_state LIKE 'C%' -- used to ba A%, but C% works with our small data
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND no_w_id = o_w_id
	  AND no_d_id = o_d_id
	  AND no_o_id = o_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND o_entry_d > '2007-01-02 00:00:00.000000'
	GROUP BY
	    ol_o_id,
	    ol_w_id,
	    ol_d_id,
	    o_entry_d
	ORDER BY
	    revenue DESC,
	    o_entry_d;
2023-11-25 00:44:23.568 UTC [3770796] LOG:  00000: join order: [ "customer" ][ local partition join "oorder" ][ local partition join "order_line" ][ local partition join "stock" ][ reference join "supplier" ][ reference join "nation" ][ reference join "region" ]
2023-11-25 00:44:23.568 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.568 UTC [3770796] STATEMENT:  SELECT
	    n_name,
	    sum(ol_amount) AS revenue
	FROM
	    customer,
	    oorder,
	    order_line,
	    stock,
	    supplier,
	    nation,
	    region
	WHERE c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id=o_d_id
	  AND ol_w_id = s_w_id
	  AND ol_i_id = s_i_id
	  AND mod((s_w_id * s_i_id),10000) = su_suppkey
	-- our dataset does not have the supplier in the same nation as the customer causing this
	-- join to filter out all the data. We verify later on that we can actually perform an
	-- ascii(substr(c_state,1,1)) == reference table column join later on so it should not
	-- matter we skip this filter here.
	--AND ascii(substr(c_state,1,1)) = su_nationkey
	  AND su_nationkey = n_nationkey
	  AND n_regionkey = r_regionkey
	  AND r_name = 'Europe'
	  AND o_entry_d >= '2007-01-02 00:00:00.000000'
	GROUP BY n_name
	ORDER BY revenue DESC;
2023-11-25 00:44:23.577 UTC [3770796] LOG:  00000: join order: [ "order_line" ]
2023-11-25 00:44:23.577 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.577 UTC [3770796] STATEMENT:  SELECT
	    sum(ol_amount) AS revenue
	FROM order_line
	WHERE ol_delivery_d >= '1999-01-01 00:00:00.000000'
	  AND ol_delivery_d < '2020-01-01 00:00:00.000000'
	  AND ol_quantity BETWEEN 1 AND 100000;
2023-11-25 00:44:23.583 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "nation" ][ reference join "supplier" ][ dual partition join "stock" ]
2023-11-25 00:44:23.583 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.583 UTC [3770796] STATEMENT:  SELECT
	    su_nationkey as supp_nation,
	    substr(c_state,1,1) as cust_nation,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as revenue
	FROM
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2
	WHERE ol_supply_w_id = s_w_id
	  AND ol_i_id = s_i_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND su_nationkey = n1.n_nationkey
	  AND ascii(substr(c_state,1,1)) = n2.n_nationkey
	  AND (
	         (n1.n_name = 'Germany' AND n2.n_name = 'Cambodia')
	      OR (n1.n_name = 'Cambodia' AND n2.n_name = 'Germany')
	      )
	  AND ol_delivery_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	GROUP BY
	    su_nationkey,
	    substr(c_state,1,1),
	    extract(year from o_entry_d)
	ORDER BY
	    su_nationkey,
	    cust_nation,
	    l_year;
2023-11-25 00:44:23.670 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "region" ][ dual partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 00:44:23.670 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.670 UTC [3770796] STATEMENT:  SELECT
	    extract(year from o_entry_d) as l_year,
	    sum(case when n2.n_name = 'Germany' then ol_amount else 0 end) / sum(ol_amount) as mkt_share
	FROM
	    item,
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2,
	    region
	WHERE i_id = s_i_id
	  AND ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id),10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND n1.n_nationkey = ascii(substr(c_state,1,1))
	  AND n1.n_regionkey = r_regionkey
	  AND ol_i_id < 1000
	  AND r_name = 'Europe'
	  AND su_nationkey = n2.n_nationkey
	  AND o_entry_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	  AND i_data LIKE '%b'
	  AND i_id = ol_i_id
	GROUP BY extract(YEAR FROM o_entry_d)
	ORDER BY l_year;
2023-11-25 00:44:23.755 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ dual partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 00:44:23.755 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.755 UTC [3770796] STATEMENT:  SELECT
	    n_name,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as sum_profit
	FROM
	    item,
	    stock,
	    supplier,
	    order_line,
	    oorder,
	    nation
	WHERE ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND ol_i_id = i_id
	  AND su_nationkey = n_nationkey
	  AND i_data LIKE '%b' -- this used to be %BB but that will not work with our small dataset
	GROUP BY
	    n_name,
	    extract(YEAR FROM o_entry_d)
	ORDER BY
	    n_name,
	    l_year DESC;
2023-11-25 00:44:23.840 UTC [3770796] LOG:  00000: join order: [ "customer" ][ reference join "nation" ][ local partition join "oorder" ][ local partition join "order_line" ]
2023-11-25 00:44:23.840 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.840 UTC [3770796] STATEMENT:  SELECT
	    c_id,
	    c_last,
	    sum(ol_amount) AS revenue,
	    c_city,
	    c_phone,
	    n_name
	FROM
	    customer,
	    oorder,
	    order_line,
	    nation
	WHERE c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND o_entry_d >= '2007-01-02 00:00:00.000000'
	  AND o_entry_d <= ol_delivery_d
	  AND n_nationkey = ascii(substr(c_state,1,1))
	GROUP BY
	    c_id,
	    c_last,
	    c_city,
	    c_phone,
	    n_name
	ORDER BY revenue DESC;
2023-11-25 00:44:23.846 UTC [3770796] LOG:  00000: join order: [ "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 00:44:23.846 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.846 UTC [3770796] STATEMENT:  SELECT
	    s_i_id,
	    sum(s_order_cnt) AS ordercount
	FROM
	    stock,
	    supplier,
	    nation
	WHERE mod((s_w_id * s_i_id),10000) = su_suppkey
	  AND su_nationkey = n_nationkey
	  AND n_name = 'Germany'
	GROUP BY s_i_id
	HAVING sum(s_order_cnt) >
	         (SELECT sum(s_order_cnt) * .005
	          FROM
	              stock,
	              supplier,
	              nation
	          WHERE mod((s_w_id * s_i_id),10000) = su_suppkey
	            AND su_nationkey = n_nationkey
	            AND n_name = 'Germany')
	ORDER BY ordercount DESC;
2023-11-25 00:44:23.851 UTC [3770796] LOG:  00000: join order: [ "oorder" ][ local partition join "order_line" ]
2023-11-25 00:44:23.851 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.851 UTC [3770796] STATEMENT:  SELECT
	    o_ol_cnt,
	    sum(case when o_carrier_id = 1 or o_carrier_id = 2 then 1 else 0 end) as high_line_count,
	    sum(case when o_carrier_id <> 1 and o_carrier_id <> 2 then 1 else 0 end) as low_line_count
	FROM
	    oorder,
	    order_line
	WHERE ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND o_entry_d <= ol_delivery_d
	  AND ol_delivery_d < '2020-01-01 00:00:00.000000'
	GROUP BY o_ol_cnt
	ORDER BY o_ol_cnt;
2023-11-25 00:44:23.859 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ reference join "item" ]
2023-11-25 00:44:23.859 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.859 UTC [3770796] STATEMENT:  SELECT
	    100.00 * sum(CASE WHEN i_data LIKE 'PR%' THEN ol_amount ELSE 0 END) / (1+sum(ol_amount)) AS promo_revenue
	FROM
	    order_line,
	    item
	WHERE ol_i_id = i_id
	  AND ol_delivery_d >= '2007-01-02 00:00:00.000000'
	  AND ol_delivery_d < '2020-01-02 00:00:00.000000';
2023-11-25 00:44:23.862 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ dual partition join "stock" ]
2023-11-25 00:44:23.862 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.862 UTC [3770796] STATEMENT:  WITH revenue (supplier_no, total_revenue) AS (
	    SELECT
	        mod((s_w_id * s_i_id),10000) AS supplier_no,
	        sum(ol_amount) AS total_revenue
	    FROM
	        order_line,
	        stock
	    WHERE ol_i_id = s_i_id
	      AND ol_supply_w_id = s_w_id
	      AND ol_delivery_d >= '2007-01-02 00:00:00.000000'
	    GROUP BY mod((s_w_id * s_i_id),10000))
	SELECT
	    su_suppkey,
	    su_name,
	    su_address,
	    su_phone,
	    total_revenue
	FROM
	    supplier,
	    revenue
	WHERE su_suppkey = supplier_no
	  AND total_revenue = (SELECT max(total_revenue) FROM revenue)
	ORDER BY su_suppkey;
2023-11-25 00:44:23.949 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ reference join "item" ]
2023-11-25 00:44:23.949 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.949 UTC [3770796] STATEMENT:  SELECT
	       sum(ol_amount) / 2.0 AS avg_yearly
	FROM
	    order_line,
	    (SELECT
	         i_id,
	         avg(ol_quantity) AS a
	     FROM
	         item,
	         order_line
	     WHERE i_data LIKE '%b'
	       AND ol_i_id = i_id
	     GROUP BY i_id) t
	WHERE ol_i_id = t.i_id;
2023-11-25 00:44:23.955 UTC [3770796] LOG:  00000: join order: [ "customer" ][ local partition join "oorder" ][ local partition join "order_line" ]
2023-11-25 00:44:23.955 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.955 UTC [3770796] STATEMENT:  SELECT
	    c_last,
	    c_id o_id,
	    o_entry_d,
	    o_ol_cnt,
	    sum(ol_amount)
	FROM
	    customer,
	    oorder,
	    order_line
	WHERE c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	GROUP BY
	    o_id,
	    o_w_id,
	    o_d_id,
	    c_id,
	    c_last,
	    o_entry_d,
	    o_ol_cnt
	HAVING sum(ol_amount) > 5 -- was 200, but thats too big for the dataset
	ORDER BY
	    sum(ol_amount) DESC,
	    o_entry_d;
2023-11-25 00:44:23.958 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ reference join "item" ]
2023-11-25 00:44:23.958 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.958 UTC [3770796] STATEMENT:  SELECT
	    sum(ol_amount) AS revenue
	FROM
	    order_line,
	     item
	WHERE (     ol_i_id = i_id
	        AND i_data LIKE '%a'
	        AND ol_quantity >= 1
	        AND ol_quantity <= 10
	        AND i_price BETWEEN 1 AND 400000
	        AND ol_w_id IN (1,2,3))
	   OR (     ol_i_id = i_id
	        AND i_data LIKE '%b'
	        AND ol_quantity >= 1
	        AND ol_quantity <= 10
	        AND i_price BETWEEN 1 AND 400000
	        AND ol_w_id IN (1,2,4))
	   OR (     ol_i_id = i_id
	        AND i_data LIKE '%c'
	        AND ol_quantity >= 1
	        AND ol_quantity <= 10
	        AND i_price BETWEEN 1 AND 400000
	        AND ol_w_id IN (1,5,3));
2023-11-25 00:44:23.963 UTC [3770796] LOG:  00000: join order: [ "stock" ][ reference join "item" ][ dual partition join "order_line" ]
2023-11-25 00:44:23.963 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:23.963 UTC [3770796] STATEMENT:  SELECT
	    su_name,
	    su_address
	FROM
	    supplier,
	    nation
	WHERE su_suppkey in
	      (SELECT
	           mod(s_i_id * s_w_id, 10000)
	       FROM
	           stock,
	           order_line
	       WHERE s_i_id IN
	             (SELECT i_id
	              FROM item
	              WHERE i_data LIKE 'co%')
	       AND ol_i_id = s_i_id
	       AND ol_delivery_d > '2008-05-23 12:00:00' -- was 2010, but our order is in 2008
	       GROUP BY s_i_id, s_w_id, s_quantity
	       HAVING   2*s_quantity > sum(ol_quantity))
	  AND su_nationkey = n_nationkey
	  AND n_name = 'Germany'
	ORDER BY su_name;
2023-11-25 00:44:24.053 UTC [3770796] LOG:  00000: join order: [ "customer" ]
2023-11-25 00:44:24.053 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:24.053 UTC [3770796] STATEMENT:  SELECT
	    substr(c_state,1,1) AS country,
	    count(*) AS numcust,
	    sum(c_balance) AS totacctbal
	FROM customer
	WHERE substr(c_phone,1,1) in ('1','2','3','4','5','6','7')
	  AND c_balance > (SELECT avg(c_BALANCE)
	                   FROM customer
	                   WHERE  c_balance > 0.00
	                     AND substr(c_phone,1,1) in ('1','2','3','4','5','6','7'))
	  AND NOT exists (SELECT *
	                  FROM oorder
	                  WHERE o_c_id = c_id
	                    AND o_w_id = c_w_id
	                    AND o_d_id = c_d_id)
	GROUP BY substr(c_state,1,1)
	ORDER BY substr(c_state,1,1);
2023-11-25 00:44:24.061 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "nation" ][ reference join "supplier" ][ single hash partition join "stock" ]
2023-11-25 00:44:24.061 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:24.061 UTC [3770796] STATEMENT:  SELECT
	    su_nationkey as supp_nation,
	    substr(c_state,1,1) as cust_nation,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as revenue
	FROM
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2
	WHERE ol_supply_w_id = s_w_id
	  AND ol_i_id = s_i_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND su_nationkey = n1.n_nationkey
	  AND ascii(substr(c_state,1,1)) = n2.n_nationkey
	  AND (
	        (n1.n_name = 'Germany' AND n2.n_name = 'Cambodia')
	        OR (n1.n_name = 'Cambodia' AND n2.n_name = 'Germany')
	    )
	  AND ol_delivery_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	GROUP BY
	    su_nationkey,
	    substr(c_state,1,1),
	    extract(year from o_entry_d)
	ORDER BY
	    su_nationkey,
	    cust_nation,
	    l_year;
2023-11-25 00:44:24.120 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "region" ][ single hash partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 00:44:24.120 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:24.120 UTC [3770796] STATEMENT:  SELECT
	    extract(year from o_entry_d) as l_year,
	    sum(case when n2.n_name = 'Germany' then ol_amount else 0 end) / sum(ol_amount) as mkt_share
	FROM
	    item,
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2,
	    region
	WHERE i_id = s_i_id
	  AND ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id),10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND n1.n_nationkey = ascii(substr(c_state,1,1))
	  AND n1.n_regionkey = r_regionkey
	  AND ol_i_id < 1000
	  AND r_name = 'Europe'
	  AND su_nationkey = n2.n_nationkey
	  AND o_entry_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	  AND i_data LIKE '%b'
	  AND i_id = ol_i_id
	GROUP BY extract(YEAR FROM o_entry_d)
	ORDER BY l_year;
2023-11-25 00:44:24.180 UTC [3770796] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ single hash partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 00:44:24.180 UTC [3770796] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:24.180 UTC [3770796] STATEMENT:  SELECT
	    n_name,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as sum_profit
	FROM
	    item,
	    stock,
	    supplier,
	    order_line,
	    oorder,
	    nation
	WHERE ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND ol_i_id = i_id
	  AND su_nationkey = n_nationkey
	  AND i_data LIKE '%b' -- this used to be %BB but that will not work with our small dataset
	GROUP BY
	    n_name,
	    extract(YEAR FROM o_entry_d)
	ORDER BY
	    n_name,
	    l_year DESC;
2023-11-25 00:44:24.872 UTC [3771681] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:24.872 UTC [3771681] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:24.872 UTC [3771681] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 00:44:24.872 UTC [3771681] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:24.872 UTC [3771681] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:24.872 UTC [3771681] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id not in (select i_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 00:44:24.872 UTC [3771681] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:24.872 UTC [3771681] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:24.872 UTC [3771681] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id not in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 00:44:24.876 UTC [3771681] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:24.876 UTC [3771681] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:24.876 UTC [3771681] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_id from item)
	        AND s_i_id not in (select i_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 00:44:24.876 UTC [3771681] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:24.876 UTC [3771681] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:24.876 UTC [3771681] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_id from item)
	        AND s_i_id not in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 00:44:24.876 UTC [3771681] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:24.876 UTC [3771681] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:24.876 UTC [3771681] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_im_id from item)
	        AND s_i_id not in (select i_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 00:44:24.876 UTC [3771681] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:24.876 UTC [3771681] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:24.876 UTC [3771681] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_im_id from item)
	        AND s_i_id not in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 00:44:25.410 UTC [3772012] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:25.410 UTC [3772012] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:25.410 UTC [3772012] STATEMENT:  SELECT count(*)
	FROM distributed_table u1
	JOIN local_table u2 USING(value)
	JOIN LATERAL
	  (SELECT value,
	          random()
	   FROM distributed_table
	   WHERE u2.value = 15) AS u3 USING (value)
	WHERE (u2.value > 2
	       AND FALSE);
2023-11-25 00:44:25.659 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 00:44:25.659 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.659 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 00:44:25.660 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.660 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.660 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.660 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 00:44:25.660 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_first" ]
2023-11-25 00:44:25.660 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.660 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		t2.sum = t1.id;
2023-11-25 00:44:25.660 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.660 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.660 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.660 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		t2.sum = t1.id;
2023-11-25 00:44:25.661 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_second" ][ reference join "ref_table" ][ single hash partition join "single_hash_repartition_first" ]
2023-11-25 00:44:25.661 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.661 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		ref_table r1, single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		r1.id = t1.id AND t2.sum = t1.id;
2023-11-25 00:44:25.661 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.661 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.661 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.661 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		ref_table r1, single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		r1.id = t1.id AND t2.sum = t1.id;
2023-11-25 00:44:25.661 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ local partition join "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 00:44:25.661 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.661 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.sum = t3.id;
2023-11-25 00:44:25.662 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.662 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.662 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.662 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.sum = t3.id;
2023-11-25 00:44:25.662 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ][ dual partition join "single_hash_repartition_first" ]
2023-11-25 00:44:25.662 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.662 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.sum = t2.sum AND t1.sum = t3.id;
2023-11-25 00:44:25.664 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.664 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.664 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.664 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.sum = t2.sum AND t1.sum = t3.id;
2023-11-25 00:44:25.665 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_second" ][ cartesian product "single_hash_repartition_first" ][ dual partition join "single_hash_repartition_first" ]
2023-11-25 00:44:25.665 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.665 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.avg = t3.id;
2023-11-25 00:44:25.665 UTC [3772127] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 00:44:25.665 UTC [3772127] DETAIL:  Cartesian products are currently unsupported
2023-11-25 00:44:25.665 UTC [3772127] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 00:44:25.665 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.avg = t3.id;
2023-11-25 00:44:25.666 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 00:44:25.666 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.666 UTC [3772127] STATEMENT:  EXPLAIN WITH cte1 AS
	(
		SELECT
			t1.id * t2.avg as data
		FROM
			single_hash_repartition_first t1, single_hash_repartition_second t2
		WHERE
			t1.id = t2.sum
		AND t1.sum > 5000
		ORDER BY 1 DESC
		LIMIT 50
	)
	SELECT
		count(*)
	FROM
		cte1, single_hash_repartition_first
	WHERE
		cte1.data > single_hash_repartition_first.id;
2023-11-25 00:44:25.667 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 00:44:25.667 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.667 UTC [3772127] STATEMENT:  EXPLAIN WITH cte1 AS
	(
		SELECT
			t1.id * t2.avg as data
		FROM
			single_hash_repartition_first t1, single_hash_repartition_second t2
		WHERE
			t1.id = t2.sum
		AND t1.sum > 5000
		ORDER BY 1 DESC
		LIMIT 50
	)
	SELECT
		count(*)
	FROM
		cte1, single_hash_repartition_first
	WHERE
		cte1.data > single_hash_repartition_first.id;
2023-11-25 00:44:25.668 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.668 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.668 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.668 UTC [3772127] STATEMENT:  EXPLAIN WITH cte1 AS
	(
		SELECT
			t1.id * t2.avg as data
		FROM
			single_hash_repartition_first t1, single_hash_repartition_second t2
		WHERE
			t1.id = t2.sum
		AND t1.sum > 5000
		ORDER BY 1 DESC
		LIMIT 50
	)
	SELECT
		count(*)
	FROM
		cte1, single_hash_repartition_first
	WHERE
		cte1.data > single_hash_repartition_first.id;
2023-11-25 00:44:25.668 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 00:44:25.668 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.668 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.sum = t3.id;
2023-11-25 00:44:25.669 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.669 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.669 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.669 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.sum = t3.id;
2023-11-25 00:44:25.669 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_first" ]
2023-11-25 00:44:25.669 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.669 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		avg(t1.avg + t2.avg)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.id = t3.sum
	LIMIT 10;
2023-11-25 00:44:25.670 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.670 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.670 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.670 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		avg(t1.avg + t2.avg)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.id = t3.sum
	LIMIT 10;
2023-11-25 00:44:25.671 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 00:44:25.671 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.671 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 00:44:25.671 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.671 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.671 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.671 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 00:44:25.671 UTC [3772127] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 00:44:25.671 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.671 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.sum = t2.id;
2023-11-25 00:44:25.671 UTC [3772127] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 00:44:25.671 UTC [3772127] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 00:44:25.671 UTC [3772127] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 00:44:25.671 UTC [3772127] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.sum = t2.id;
2023-11-25 00:44:25.676 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.676 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref)
2023-11-25 00:44:25.676 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.676 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM ref,
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.677 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.677 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a VALUES clause
2023-11-25 00:44:25.677 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.677 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM (VALUES (1), (3)) ref(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.677 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.677 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 00:44:25.677 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.677 UTC [3772128] STATEMENT:  WITH ref(a) as (select y from test)
	SELECT count(*)
	FROM ref,
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.677 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.677 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a table function (ref)
2023-11-25 00:44:25.677 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.677 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM generate_series(1, 3) ref(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.678 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.678 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a subquery without FROM (ref)
2023-11-25 00:44:25.678 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.678 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM (SELECT generate_series(1, 3)) ref(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.678 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.678 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref_table)
2023-11-25 00:44:25.678 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.678 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM ref ref_table,
	    (VALUES (1), (3)) rec_values(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref_table.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.678 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.678 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a VALUES clause
2023-11-25 00:44:25.678 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.678 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM ref as ref_table,
	    (VALUES (1), (3)) ref_values(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref_values.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.678 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.678 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref_outer)
2023-11-25 00:44:25.678 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.678 UTC [3772128] STATEMENT:  SELECT count(*) FROM
	    ref ref_outer,
	    LATERAL (
	        SELECT * FROM
	            LATERAL ( SELECT *
	            FROM ref ref_inner,
	                LATERAL (
	                    SELECT
	                        test.y
	                    FROM test
	                    WHERE
	                        test.y = ref_outer.a
	                    LIMIT 2
	                ) q
	            ) q2
	    ) q3;
2023-11-25 00:44:25.678 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.678 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref_inner)
2023-11-25 00:44:25.678 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.678 UTC [3772128] STATEMENT:  SELECT count(*) FROM
	    ref ref_outer,
	    LATERAL (
	        SELECT * FROM
	            LATERAL ( SELECT *
	            FROM ref ref_inner,
	                LATERAL (
	                    SELECT
	                        test.y
	                    FROM test
	                    WHERE
	                        test.y = ref_inner.a
	                    LIMIT 2
	                ) q
	            ) q2
	    ) q3;
2023-11-25 00:44:25.679 UTC [3772128] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:44:25.679 UTC [3772128] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref)
2023-11-25 00:44:25.679 UTC [3772128] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:44:25.679 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM ref,
	    LATERAL (
	        SELECT
	            test.x
	        FROM test
	        WHERE
	            test.x = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 00:44:25.679 UTC [3772128] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:25.679 UTC [3772128] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:25.679 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM test,
	    LATERAL (
	        SELECT
	            test_2.x
	        FROM test test_2
	        WHERE
	            test_2.x = test.y
	        LIMIT 2
	    ) q ;
2023-11-25 00:44:25.679 UTC [3772128] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:25.679 UTC [3772128] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:25.679 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM ref JOIN test on ref.b = test.x,
	    LATERAL (
	        SELECT
	            test_2.x
	        FROM test test_2
	        WHERE
	            test_2.x = ref.a
	        LIMIT 2
	    ) q
	;
2023-11-25 00:44:25.679 UTC [3772128] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:44:25.679 UTC [3772128] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:44:25.679 UTC [3772128] STATEMENT:  SELECT count(*)
	FROM ref JOIN test on ref.b = test.x,
	    LATERAL (
	        SELECT
	            test_2.y
	        FROM test test_2
	        WHERE
	            test_2.y = ref.a
	        LIMIT 2
	    ) q
	;
2023-11-25 00:44:25.716 UTC [3772127] LOG:  00000: join order: [ "test_numeric" ][ single hash partition join "test_numeric" ]
2023-11-25 00:44:25.716 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.716 UTC [3772127] STATEMENT:  SELECT count(*) FROM test_numeric t1 JOIN test_numeric as t2 ON (t1.a = t2.b);
2023-11-25 00:44:25.905 UTC [3772127] LOG:  00000: join order: [ "dist_1" ][ single hash partition join "dist_1" ]
2023-11-25 00:44:25.905 UTC [3772127] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:25.905 UTC [3772127] STATEMENT:  SELECT COUNT(*) FROM dist_1 f, dist_1 s WHERE f.a = s.b;
2023-11-25 00:44:26.788 UTC [3772581] LOG:  00000: join order: [ "lineitem" ]
2023-11-25 00:44:26.788 UTC [3772581] CONTEXT:  PL/pgSQL function public.coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:44:26.788 UTC [3772581] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:26.788 UTC [3772581] STATEMENT:  SELECT public.coordinator_plan($Q$
	EXPLAIN (COSTS FALSE)
	SELECT l_orderkey, l_linenumber, l_shipdate FROM lineitem WHERE l_orderkey = 9030 or l_orderkey = 1;
	$Q$);
2023-11-25 00:44:26.790 UTC [3772581] LOG:  00000: join order: [ "lineitem" ][ local partition join "orders" ]
2023-11-25 00:44:26.790 UTC [3772581] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:26.790 UTC [3772581] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_orderkey = o_orderkey;
2023-11-25 00:44:26.793 UTC [3772581] LOG:  00000: join order: [ "lineitem" ]
2023-11-25 00:44:26.793 UTC [3772581] CONTEXT:  PL/pgSQL function public.coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:44:26.793 UTC [3772581] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:26.793 UTC [3772581] STATEMENT:  SELECT public.coordinator_plan($Q$
	EXPLAIN (COSTS FALSE)
	SELECT l_orderkey, l_linenumber, l_shipdate FROM lineitem WHERE l_orderkey = 9030;
	$Q$);
2023-11-25 00:44:26.794 UTC [3772581] LOG:  00000: join order: [ "lineitem" ][ dual partition join "orders" ]
2023-11-25 00:44:26.794 UTC [3772581] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:26.794 UTC [3772581] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_partkey = o_custkey;
2023-11-25 00:44:26.795 UTC [3772581] LOG:  00000: join order: [ "lineitem" ]
2023-11-25 00:44:26.795 UTC [3772581] CONTEXT:  PL/pgSQL function public.coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 00:44:26.795 UTC [3772581] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:26.795 UTC [3772581] STATEMENT:  SELECT public.coordinator_plan($Q$
	EXPLAIN (COSTS FALSE)
	SELECT l_orderkey, l_linenumber, l_shipdate FROM lineitem WHERE l_orderkey = 9030;
	$Q$);
2023-11-25 00:44:26.797 UTC [3772581] LOG:  00000: join order: [ "lineitem" ][ dual partition join "orders" ]
2023-11-25 00:44:26.797 UTC [3772581] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:26.797 UTC [3772581] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_partkey = o_custkey;
2023-11-25 00:44:26.799 UTC [3772581] LOG:  00000: join order: [ "lineitem" ][ dual partition join "orders" ]
2023-11-25 00:44:26.799 UTC [3772581] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 00:44:26.799 UTC [3772581] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_partkey = o_custkey;
2023-11-25 00:44:27.007 UTC [3772631] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:44:27.007 UTC [3772631] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 00:44:27.007 UTC [3772631] STATEMENT:  UPDATE test SET a = 5, c = 5;
2023-11-25 00:44:27.007 UTC [3772631] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:44:27.007 UTC [3772631] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 00:44:27.007 UTC [3772631] STATEMENT:  UPDATE test SET a = 5, c = d, d =3;
2023-11-25 00:44:27.007 UTC [3772631] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:44:27.007 UTC [3772631] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 00:44:27.007 UTC [3772631] STATEMENT:  UPDATE test SET c = d, d =3;
2023-11-25 00:44:27.007 UTC [3772631] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:44:27.007 UTC [3772631] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 00:44:27.007 UTC [3772631] STATEMENT:  UPDATE test SET d=c, c = d;
2023-11-25 00:44:27.022 UTC [3772631] ERROR:  42601: multiple assignments to same column "c"
2023-11-25 00:44:27.022 UTC [3772631] LOCATION:  process_matched_tle, rewriteHandler.c:1105
2023-11-25 00:44:27.022 UTC [3772631] STATEMENT:  UPDATE test SET c = c, c = 3;
2023-11-25 00:44:27.035 UTC [3772631] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:44:27.035 UTC [3772631] LOCATION:  ErrorIfOnConflictNotSupported, multi_router_planner.c:1255
2023-11-25 00:44:27.035 UTC [3772631] STATEMENT:  INSERT INTO test (c,d) VALUES(3,4) ON CONFLICT(c) DO UPDATE SET c=7;
2023-11-25 00:44:27.038 UTC [3772631] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:44:27.038 UTC [3772631] LOCATION:  ErrorIfOnConflictNotSupported, multi_router_planner.c:1255
2023-11-25 00:44:27.038 UTC [3772631] STATEMENT:  INSERT INTO test (d,c) VALUES(3,4) ON CONFLICT(c) DO UPDATE SET c=7;
2023-11-25 00:44:27.044 UTC [3772632] ERROR:  42501: permission denied for table reference_table_1
2023-11-25 00:44:27.044 UTC [3772632] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:27.044 UTC [3772632] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:27.044 UTC [3772632] STATEMENT:  INSERT INTO reference_table_2 SELECT * FROM reference_table_1;
2023-11-25 00:44:27.061 UTC [3772631] ERROR:  42601: multiple assignments to same column "c"
2023-11-25 00:44:27.061 UTC [3772631] LOCATION:  process_matched_tle, rewriteHandler.c:1105
2023-11-25 00:44:27.061 UTC [3772631] STATEMENT:  UPDATE test SET c = c, c = 3;
2023-11-25 00:44:27.130 UTC [3772631] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 00:44:27.130 UTC [3772631] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 00:44:27.130 UTC [3772631] STATEMENT:  UPDATE test SET a = 5,d  = 2, c = 5 FROM (SELECT * FROM test LIMIT 10) t2 WHERE t2.d = test.c  and test.c = 6;
2023-11-25 00:44:27.369 UTC [3772800] ERROR:  XX000: multi-task query about to be executed
2023-11-25 00:44:27.369 UTC [3772800] HINT:  Queries are split to multiple tasks if they have to be split into several queries on the workers.
2023-11-25 00:44:27.369 UTC [3772800] LOCATION:  FinalizePlan, distributed_planner.c:1392
2023-11-25 00:44:27.369 UTC [3772800] STATEMENT:  SELECT * FROM multi_task_table;
2023-11-25 00:44:27.394 UTC [3772800] ERROR:  XX000: multi-task query about to be executed
2023-11-25 00:44:27.394 UTC [3772800] HINT:  Queries are split to multiple tasks if they have to be split into several queries on the workers.
2023-11-25 00:44:27.394 UTC [3772800] LOCATION:  FinalizePlan, distributed_planner.c:1392
2023-11-25 00:44:27.394 UTC [3772800] STATEMENT:  INSERT INTO summary_table SELECT id, SUM(order_count) FROM raw_table GROUP BY id;
2023-11-25 00:44:27.404 UTC [3772800] ERROR:  XX000: multi-task query about to be executed
2023-11-25 00:44:27.404 UTC [3772800] HINT:  Queries are split to multiple tasks if they have to be split into several queries on the workers.
2023-11-25 00:44:27.404 UTC [3772800] LOCATION:  FinalizePlan, distributed_planner.c:1392
2023-11-25 00:44:27.404 UTC [3772800] STATEMENT:  INSERT INTO summary_table SELECT id, SUM(order_count) FROM raw_table GROUP BY id;
2023-11-25 00:44:27.671 UTC [3772920] ERROR:  42P01: relation "customer_few" does not exist at character 52
2023-11-25 00:44:27.671 UTC [3772920] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 00:44:27.671 UTC [3772920] STATEMENT:  SELECT customer_key, c_name, c_address
	       FROM customer_few ORDER BY customer_key LIMIT 5;
2023-11-25 00:44:27.755 UTC [3772920] ERROR:  34000: cursor "noholdcursor" does not exist
2023-11-25 00:44:27.755 UTC [3772920] LOCATION:  PerformPortalFetch, portalcmds.c:187
2023-11-25 00:44:27.755 UTC [3772920] STATEMENT:  FETCH ABSOLUTE 5 FROM noHoldCursor;
2023-11-25 00:44:27.947 UTC [3772952] ERROR:  XX000: cannot modify table "on_update_fkey_table" because there was a parallel operation on a distributed table in the transaction
2023-11-25 00:44:27.947 UTC [3772952] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:27.947 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:27.947 UTC [3772952] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 00:44:27.947 UTC [3772952] STATEMENT:  ALTER TABLE on_update_fkey_table DROP COLUMN value_1 CASCADE;
2023-11-25 00:44:27.951 UTC [3772952] ERROR:  XX000: cannot modify table "on_update_fkey_table" because there was a parallel operation on a distributed table in the transaction
2023-11-25 00:44:27.951 UTC [3772952] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:27.951 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:27.951 UTC [3772952] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 00:44:27.951 UTC [3772952] STATEMENT:  ALTER TABLE on_update_fkey_table DROP COLUMN value_1 CASCADE;
2023-11-25 00:44:27.955 UTC [3772952] ERROR:  XX000: cannot execute parallel DDL on table "on_update_fkey_table" after SELECT command on reference table "reference_table" because there is a foreign key between them and "reference_table" has been accessed in this transaction
2023-11-25 00:44:27.955 UTC [3772952] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:27.955 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:27.955 UTC [3772952] LOCATION:  CheckConflictingParallelRelationAccesses, relation_access_tracking.c:880
2023-11-25 00:44:27.955 UTC [3772952] STATEMENT:  ALTER TABLE on_update_fkey_table ADD COLUMN X INT;
2023-11-25 00:44:27.960 UTC [3772952] ERROR:  XX000: cannot execute parallel DDL on table "on_update_fkey_table" after SELECT command on reference table "transitive_reference_table" because there is a foreign key between them and "transitive_reference_table" has been accessed in this transaction
2023-11-25 00:44:27.960 UTC [3772952] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:27.960 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:27.960 UTC [3772952] LOCATION:  CheckConflictingParallelRelationAccesses, relation_access_tracking.c:880
2023-11-25 00:44:27.960 UTC [3772952] STATEMENT:  ALTER TABLE on_update_fkey_table ADD COLUMN X INT;
2023-11-25 00:44:27.995 UTC [3772952] ERROR:  23503: insert or update on table "on_update_fkey_table_2380002" violates foreign key constraint "fkey_2380002"
2023-11-25 00:44:27.995 UTC [3772952] DETAIL:  Key (value_1)=(101) is not present in table "reference_table_2380001".
2023-11-25 00:44:27.995 UTC [3772952] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:44:27.995 UTC [3772952] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:44:27.995 UTC [3772952] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 1;
2023-11-25 00:44:27.996 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:27.996 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:27.996 UTC [3772952] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 2;
2023-11-25 00:44:27.996 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:27.996 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:27.996 UTC [3772952] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 3;
2023-11-25 00:44:27.996 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:27.996 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:27.996 UTC [3772952] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 4;
2023-11-25 00:44:28.019 UTC [3772952] ERROR:  XX000: insert or update on table "on_update_fkey_table_2380005" violates foreign key constraint "fkey_2380005"
2023-11-25 00:44:28.019 UTC [3772952] DETAIL:  Key (value_1)=(101) is not present in table "reference_table_2380001".
2023-11-25 00:44:28.019 UTC [3772952] LOCATION:  ReportCopyError, multi_copy.c:1193
2023-11-25 00:44:28.019 UTC [3772952] STATEMENT:  COPY on_update_fkey_table FROM STDIN WITH CSV;
2023-11-25 00:44:28.143 UTC [3772952] ERROR:  XX000: cannot modify table "reference_table" because there was a parallel operation on a distributed table
2023-11-25 00:44:28.143 UTC [3772952] DETAIL:  When there is a foreign key to a reference table or to a local table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:28.143 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.143 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:795
2023-11-25 00:44:28.143 UTC [3772952] STATEMENT:  UPDATE reference_table SET id = 101 WHERE id = 99;
2023-11-25 00:44:28.146 UTC [3772952] ERROR:  XX000: cannot modify table "transitive_reference_table" because there was a parallel operation on a distributed table
2023-11-25 00:44:28.146 UTC [3772952] DETAIL:  When there is a foreign key to a reference table or to a local table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:28.146 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.146 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:795
2023-11-25 00:44:28.146 UTC [3772952] STATEMENT:  UPDATE transitive_reference_table SET id = 101 WHERE id = 99;
2023-11-25 00:44:28.151 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.151 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.151 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.151 UTC [3772952] STATEMENT:  ALTER TABLE reference_table ADD COLUMN X INT;
2023-11-25 00:44:28.155 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.155 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.155 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.155 UTC [3772952] STATEMENT:  ALTER TABLE transitive_reference_table ADD COLUMN X INT;
2023-11-25 00:44:28.163 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.163 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.163 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.163 UTC [3772952] STATEMENT:  ALTER TABLE reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 00:44:28.170 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.170 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.170 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.170 UTC [3772952] STATEMENT:  ALTER TABLE transitive_reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 00:44:28.175 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.175 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.175 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.175 UTC [3772952] STATEMENT:  TRUNCATE reference_table CASCADE;
2023-11-25 00:44:28.180 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.180 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.180 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.180 UTC [3772952] STATEMENT:  TRUNCATE transitive_reference_table CASCADE;
2023-11-25 00:44:28.196 UTC [3772952] ERROR:  XX000: cannot execute DDL on table because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.196 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.196 UTC [3772952] CONTEXT:  SQL statement "SELECT citus_drop_all_shards(v_obj.objid, v_obj.schema_name, v_obj.object_name, drop_shards_metadata_only := false)"
	PL/pgSQL function citus_drop_trigger() line 25 at PERFORM
2023-11-25 00:44:28.196 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:761
2023-11-25 00:44:28.196 UTC [3772952] STATEMENT:  DROP TABLE reference_table CASCADE;
2023-11-25 00:44:28.213 UTC [3772952] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.213 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.213 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.213 UTC [3772952] STATEMENT:  UPDATE reference_table SET id = 160 WHERE id = 15;
2023-11-25 00:44:28.216 UTC [3772952] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.216 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.216 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.216 UTC [3772952] STATEMENT:  UPDATE transitive_reference_table SET id = 160 WHERE id = 15;
2023-11-25 00:44:28.220 UTC [3772952] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.220 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.220 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.220 UTC [3772952] STATEMENT:  UPDATE reference_table SET id = 160 WHERE id = 15;
2023-11-25 00:44:28.224 UTC [3772952] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.224 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.224 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.224 UTC [3772952] STATEMENT:  UPDATE transitive_reference_table SET id = 160 WHERE id = 15;
2023-11-25 00:44:28.228 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.228 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.228 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.228 UTC [3772952] STATEMENT:  ALTER TABLE reference_table ADD COLUMN X INT;
2023-11-25 00:44:28.232 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.232 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.232 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.232 UTC [3772952] STATEMENT:  ALTER TABLE transitive_reference_table ADD COLUMN X INT;
2023-11-25 00:44:28.239 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.239 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.239 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.239 UTC [3772952] STATEMENT:  ALTER TABLE reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 00:44:28.247 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.247 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.247 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.247 UTC [3772952] STATEMENT:  ALTER TABLE transitive_reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 00:44:28.252 UTC [3772952] ERROR:  XX000: cannot execute SELECT on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.252 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.252 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.252 UTC [3772952] STATEMENT:  SELECT count(*) FROM reference_table;
2023-11-25 00:44:28.256 UTC [3772952] ERROR:  XX000: cannot execute SELECT on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.256 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.256 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.256 UTC [3772952] STATEMENT:  SELECT count(*) FROM transitive_reference_table;
2023-11-25 00:44:28.281 UTC [3772952] ERROR:  XX000: cannot execute SELECT on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.281 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.281 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.281 UTC [3772952] STATEMENT:  SELECT count(*) FROM reference_table;
2023-11-25 00:44:28.286 UTC [3772952] ERROR:  XX000: cannot execute SELECT on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.286 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.286 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.286 UTC [3772952] STATEMENT:  SELECT count(*) FROM transitive_reference_table;
2023-11-25 00:44:28.290 UTC [3772952] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.290 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.290 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.290 UTC [3772952] STATEMENT:  UPDATE reference_table SET id = 160 WHERE id = 15;
2023-11-25 00:44:28.294 UTC [3772952] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.294 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.294 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.294 UTC [3772952] STATEMENT:  UPDATE transitive_reference_table SET id = 160 WHERE id = 15;
2023-11-25 00:44:28.299 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.299 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.299 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.299 UTC [3772952] STATEMENT:  ALTER TABLE reference_table ADD COLUMN X int;
2023-11-25 00:44:28.304 UTC [3772952] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.304 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.304 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.304 UTC [3772952] STATEMENT:  ALTER TABLE transitive_reference_table ADD COLUMN X int;
2023-11-25 00:44:28.308 UTC [3772952] ERROR:  XX000: cannot modify table "on_update_fkey_table" because there was a parallel operation on a distributed table in the transaction
2023-11-25 00:44:28.308 UTC [3772952] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:28.308 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.308 UTC [3772952] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 00:44:28.308 UTC [3772952] STATEMENT:  ALTER TABLE on_update_fkey_table ALTER COLUMN value_1 SET DATA TYPE smallint;
2023-11-25 00:44:28.317 UTC [3772952] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.317 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.317 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.317 UTC [3772952] STATEMENT:  DELETE FROM reference_table  WHERE id = 99;
2023-11-25 00:44:28.328 UTC [3772952] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.328 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.328 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.328 UTC [3772952] STATEMENT:  DELETE FROM transitive_reference_table  WHERE id = 99;
2023-11-25 00:44:28.339 UTC [3772952] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.339 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.339 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.339 UTC [3772952] STATEMENT:  UPDATE reference_table SET id = 101 WHERE id = 99;
2023-11-25 00:44:28.348 UTC [3772952] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 00:44:28.348 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.348 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.348 UTC [3772952] STATEMENT:  UPDATE transitive_reference_table SET id = 101 WHERE id = 99;
2023-11-25 00:44:28.352 UTC [3772952] ERROR:  XX000: cannot modify table "reference_table" because there was a parallel operation on a distributed table
2023-11-25 00:44:28.352 UTC [3772952] DETAIL:  When there is a foreign key to a reference table or to a local table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:28.352 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.352 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:795
2023-11-25 00:44:28.352 UTC [3772952] STATEMENT:  UPDATE reference_table SET id = 101 WHERE id = 99;
2023-11-25 00:44:28.353 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.353 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.353 UTC [3772952] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 5 WHERE id != 11;
2023-11-25 00:44:28.390 UTC [3772952] ERROR:  XX000: cannot distribute relation "test_table_2" in this transaction because it has a foreign key to a reference table
2023-11-25 00:44:28.390 UTC [3772952] DETAIL:  If a hash distributed table has a foreign key to a reference table, it has to be created in sequential mode before any parallel commands have been executed in the same transaction
2023-11-25 00:44:28.390 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.390 UTC [3772952] LOCATION:  CanUseExclusiveConnections, create_distributed_table.c:2256
2023-11-25 00:44:28.390 UTC [3772952] STATEMENT:  SELECT create_distributed_table('test_table_2', 'id');
2023-11-25 00:44:28.391 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.391 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.391 UTC [3772952] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 00:44:28.391 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.391 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.391 UTC [3772952] STATEMENT:  DROP TABLE test_table_1 CASCADE;
2023-11-25 00:44:28.427 UTC [3772952] ERROR:  XX000: cannot modify table "test_table_2" because there was a parallel operation on a distributed table in the transaction
2023-11-25 00:44:28.427 UTC [3772952] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:28.427 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.427 UTC [3772952] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 00:44:28.427 UTC [3772952] STATEMENT:  ALTER TABLE test_table_2 ADD CONSTRAINT c_check FOREIGN KEY (value_1) REFERENCES test_table_1(id);
2023-11-25 00:44:28.428 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.428 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.428 UTC [3772952] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 00:44:28.428 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.428 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.428 UTC [3772952] STATEMENT:  DROP TABLE test_table_1, test_table_2;
2023-11-25 00:44:28.465 UTC [3772952] ERROR:  XX000: cannot modify table "test_table_2" because there was a parallel operation on a distributed table in the transaction
2023-11-25 00:44:28.465 UTC [3772952] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 00:44:28.465 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.465 UTC [3772952] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 00:44:28.465 UTC [3772952] STATEMENT:  ALTER TABLE test_table_2 ADD CONSTRAINT c_check FOREIGN KEY (value_1) REFERENCES test_table_1(id);
2023-11-25 00:44:28.466 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.466 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.466 UTC [3772952] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 00:44:28.466 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.466 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.466 UTC [3772952] STATEMENT:  DROP TABLE test_table_1 CASCADE;
2023-11-25 00:44:28.489 UTC [3772952] ERROR:  XX000: cannot distribute "test_table_2" in sequential mode because a parallel query was executed in this transaction
2023-11-25 00:44:28.489 UTC [3772952] HINT:  If you have manually set citus.multi_shard_modify_mode to 'sequential', try with 'parallel' option. 
2023-11-25 00:44:28.489 UTC [3772952] LOCATION:  CanUseExclusiveConnections, create_distributed_table.c:2269
2023-11-25 00:44:28.489 UTC [3772952] STATEMENT:  SELECT create_distributed_table('test_table_2', 'id');
2023-11-25 00:44:28.489 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.489 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.489 UTC [3772952] STATEMENT:  CREATE TABLE test_table_1(id int PRIMARY KEY);
2023-11-25 00:44:28.489 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.489 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.489 UTC [3772952] STATEMENT:  SELECT create_reference_table('test_table_1');
2023-11-25 00:44:28.490 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.490 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.490 UTC [3772952] STATEMENT:  ALTER TABLE test_table_2 ADD CONSTRAINT c_check FOREIGN KEY (value_1) REFERENCES test_table_1(id);
2023-11-25 00:44:28.490 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.490 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.490 UTC [3772952] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 00:44:28.490 UTC [3772952] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:44:28.490 UTC [3772952] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:44:28.490 UTC [3772952] STATEMENT:  DROP TABLE test_table_1 CASCADE;
2023-11-25 00:44:28.608 UTC [3772952] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "distributed_table" in the same transaction
2023-11-25 00:44:28.608 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.608 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.608 UTC [3772952] STATEMENT:  WITH t1 AS (DELETE FROM distributed_table RETURNING id),
		t2 AS (DELETE FROM reference_table RETURNING id)
		SELECT count(*) FROM distributed_table, t1, t2 WHERE  value_1 = t1.id AND value_1 = t2.id;
2023-11-25 00:44:28.611 UTC [3772952] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "distributed_table" in the same transaction
2023-11-25 00:44:28.611 UTC [3772952] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 00:44:28.611 UTC [3772952] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 00:44:28.611 UTC [3772952] STATEMENT:  WITH t1 AS (DELETE FROM distributed_table RETURNING id)
		DELETE FROM reference_table RETURNING id;
2023-11-25 00:44:29.013 UTC [3773122] ERROR:  XX000: you cannot alter access method of a partitioned table
2023-11-25 00:44:29.013 UTC [3773122] LOCATION:  AlterTableSetAccessMethod, alter_table.c:487
2023-11-25 00:44:29.013 UTC [3773122] STATEMENT:  SELECT alter_table_set_access_method('partitioned_table', 'columnar');
2023-11-25 00:44:29.055 UTC [3773122] ERROR:  P0001: partition column of partitioned_table cannot be cast to a timestamptz
2023-11-25 00:44:29.055 UTC [3773122] CONTEXT:  PL/pgSQL function alter_old_partitions_set_access_method(regclass,timestamp with time zone,name) line 14 at RAISE
2023-11-25 00:44:29.055 UTC [3773122] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:44:29.055 UTC [3773122] STATEMENT:  CALL alter_old_partitions_set_access_method('partitioned_table', '2021-01-01', 'columnar');
2023-11-25 00:44:29.412 UTC [3773122] ERROR:  0A000: Foreign keys and AFTER ROW triggers are not supported for columnar tables
2023-11-25 00:44:29.412 UTC [3773122] HINT:  Consider an AFTER STATEMENT trigger instead.
2023-11-25 00:44:29.412 UTC [3773122] CONTEXT:  SQL statement "ALTER TABLE alter_table_set_access_method.test_fk_p ATTACH PARTITION alter_table_set_access_method.test_fk_p1 FOR VALUES FROM (10) TO (20);"
2023-11-25 00:44:29.412 UTC [3773122] LOCATION:  ColumnarTriggerCreateHook, columnar_tableam.c:2140
2023-11-25 00:44:29.412 UTC [3773122] STATEMENT:  select alter_table_set_access_method('test_fk_p1', 'columnar');
2023-11-25 00:44:29.412 UTC [3773122] ERROR:  XX000: the access method of alter_table_set_access_method.same_access_method is already heap
2023-11-25 00:44:29.412 UTC [3773122] LOCATION:  AlterTableSetAccessMethod, alter_table.c:514
2023-11-25 00:44:29.412 UTC [3773122] STATEMENT:  SELECT alter_table_set_access_method('same_access_method', 'heap');
2023-11-25 00:44:29.417 UTC [3773122] WARNING:  0A000: "view v_local" has dependency to "table local" that is not in Citus' metadata
2023-11-25 00:44:29.417 UTC [3773122] DETAIL:  "view v_local" will be created only locally
2023-11-25 00:44:29.417 UTC [3773122] HINT:  Distribute "table local" first to distribute "view v_local"
2023-11-25 00:44:29.417 UTC [3773122] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:44:29.566 UTC [3773122] ERROR:  XX000: you cannot alter access method of a view
2023-11-25 00:44:29.566 UTC [3773122] LOCATION:  AlterTableSetAccessMethod, alter_table.c:492
2023-11-25 00:44:29.566 UTC [3773122] STATEMENT:  select alter_table_set_access_method('view_test_view','columnar');
2023-11-25 00:44:30.053 UTC [3773213] ERROR:  XX000: cannot complete operation because table is a partition
2023-11-25 00:44:30.053 UTC [3773213] HINT:  the parent table is "partitioned_table"
2023-11-25 00:44:30.053 UTC [3773213] LOCATION:  EnsureTableNotPartition, alter_table.c:1172
2023-11-25 00:44:30.053 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('partitioned_table_1_5', shard_count := 10, distribution_column := 'a');
2023-11-25 00:44:30.226 UTC [3773213] WARNING:  01000: foreign key table_with_references_a1_fkey will be dropped
2023-11-25 00:44:30.226 UTC [3773213] LOCATION:  WarningsForDroppingForeignKeysWithDistributedTables, alter_table.c:2096
2023-11-25 00:44:30.226 UTC [3773213] WARNING:  01000: foreign key referencing_dist_table_a_fkey will be dropped
2023-11-25 00:44:30.226 UTC [3773213] LOCATION:  WarningsForDroppingForeignKeysWithDistributedTables, alter_table.c:2096
2023-11-25 00:44:30.734 UTC [3773213] LOG:  00000: performing blocking isolate_tenant_to_new_shard 
2023-11-25 00:44:30.734 UTC [3773213] LOCATION:  SplitShard, shard_split.c:507
2023-11-25 00:44:30.734 UTC [3773213] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:44:30.735 UTC [3773213] LOG:  00000: creating child shards for isolate_tenant_to_new_shard
2023-11-25 00:44:30.735 UTC [3773213] LOCATION:  BlockingShardSplit, shard_split.c:571
2023-11-25 00:44:30.735 UTC [3773213] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:44:30.744 UTC [3773213] LOG:  00000: performing copy for isolate_tenant_to_new_shard
2023-11-25 00:44:30.744 UTC [3773213] LOCATION:  BlockingShardSplit, shard_split.c:577
2023-11-25 00:44:30.744 UTC [3773213] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:44:30.744 UTC [3773213] LOG:  00000: creating auxillary structures (indexes, stats, replicaindentities, triggers) for isolate_tenant_to_new_shard
2023-11-25 00:44:30.744 UTC [3773213] LOCATION:  BlockingShardSplit, shard_split.c:587
2023-11-25 00:44:30.744 UTC [3773213] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:44:30.744 UTC [3773213] LOG:  00000: marking deferred cleanup of source shard(s) for isolate_tenant_to_new_shard
2023-11-25 00:44:30.744 UTC [3773213] LOCATION:  BlockingShardSplit, shard_split.c:609
2023-11-25 00:44:30.744 UTC [3773213] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:44:30.746 UTC [3773213] LOG:  00000: creating foreign key constraints (if any) for isolate_tenant_to_new_shard
2023-11-25 00:44:30.746 UTC [3773213] LOCATION:  BlockingShardSplit, shard_split.c:625
2023-11-25 00:44:30.746 UTC [3773213] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 00:44:30.782 UTC [3773213] ERROR:  XX000: you have to specify at least one of the distribution_column, shard_count or colocate_with parameters
2023-11-25 00:44:30.782 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1813
2023-11-25 00:44:30.782 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table');
2023-11-25 00:44:30.782 UTC [3773213] ERROR:  XX000: you have to specify at least one of the distribution_column, shard_count or colocate_with parameters
2023-11-25 00:44:30.782 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1813
2023-11-25 00:44:30.782 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', cascade_to_colocated := false);
2023-11-25 00:44:30.782 UTC [3773213] ERROR:  XX000: this call doesn't change any properties of the table
2023-11-25 00:44:30.782 UTC [3773213] HINT:  check citus_tables view to see current properties of the table
2023-11-25 00:44:30.782 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1891
2023-11-25 00:44:30.782 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'b');
2023-11-25 00:44:30.782 UTC [3773213] ERROR:  XX000: this call doesn't change any properties of the table
2023-11-25 00:44:30.782 UTC [3773213] HINT:  check citus_tables view to see current properties of the table
2023-11-25 00:44:30.782 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1891
2023-11-25 00:44:30.782 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', shard_count := 10);
2023-11-25 00:44:30.803 UTC [3773213] ERROR:  XX000: this call doesn't change any properties of the table
2023-11-25 00:44:30.803 UTC [3773213] HINT:  check citus_tables view to see current properties of the table
2023-11-25 00:44:30.803 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1891
2023-11-25 00:44:30.803 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'colocation_table');
2023-11-25 00:44:30.854 UTC [3773213] ERROR:  XX000: distribution_column cannot be cascaded to colocated tables
2023-11-25 00:44:30.854 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1873
2023-11-25 00:44:30.854 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'b', cascade_to_colocated := true);
2023-11-25 00:44:30.854 UTC [3773213] ERROR:  XX000: distribution_column cannot be cascaded to colocated tables
2023-11-25 00:44:30.854 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1873
2023-11-25 00:44:30.854 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'b', shard_count:=12, colocate_with:='colocation_table_2', cascade_to_colocated := true);
2023-11-25 00:44:30.855 UTC [3773213] ERROR:  XX000: shard_count or colocate_with is necessary for cascading to colocated tables
2023-11-25 00:44:30.855 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1879
2023-11-25 00:44:30.855 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', cascade_to_colocated := true);
2023-11-25 00:44:30.855 UTC [3773213] ERROR:  XX000: colocate_with := 'none' cannot be cascaded to colocated tables
2023-11-25 00:44:30.855 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1899
2023-11-25 00:44:30.855 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'none', cascade_to_colocated := true);
2023-11-25 00:44:30.855 UTC [3773213] ERROR:  XX000: cascade_to_colocated parameter is necessary
2023-11-25 00:44:30.855 UTC [3773213] DETAIL:  this table is colocated with some other tables
2023-11-25 00:44:30.855 UTC [3773213] HINT:  cascade_to_colocated := false will break the current colocation, cascade_to_colocated := true will change the shard count of colocated tables too.
2023-11-25 00:44:30.855 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1907
2023-11-25 00:44:30.855 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', shard_count := 14);
2023-11-25 00:44:30.887 UTC [3773213] ERROR:  XX000: shard_count cannot be different than the shard count of the table in colocate_with
2023-11-25 00:44:30.887 UTC [3773213] HINT:  if no shard_count is specified shard count will be same with colocate_with table's
2023-11-25 00:44:30.887 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1927
2023-11-25 00:44:30.887 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'colocation_table', shard_count := 16);
2023-11-25 00:44:30.894 UTC [3773213] ERROR:  XX000: cannot colocate with different_type_table because data type of its distribution column is different than dist_table
2023-11-25 00:44:30.894 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1968
2023-11-25 00:44:30.894 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'different_type_table');
2023-11-25 00:44:30.894 UTC [3773213] ERROR:  XX000: cannot colocate with different_type_table and change distribution column to a because data type of column a is different then the distribution column of the different_type_table
2023-11-25 00:44:30.894 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1959
2023-11-25 00:44:30.894 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'a', colocate_with := 'different_type_table');
2023-11-25 00:44:30.894 UTC [3773213] ERROR:  XX000: shard_count cannot be 0
2023-11-25 00:44:30.894 UTC [3773213] HINT:  if you no longer want this to be a distributed table you can try undistribute_table() function
2023-11-25 00:44:30.894 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1864
2023-11-25 00:44:30.894 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', shard_count := 0);
2023-11-25 00:44:30.898 UTC [3773213] ERROR:  XX000: cannot colocate with reference_table because it is not a distributed table
2023-11-25 00:44:30.898 UTC [3773213] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1855
2023-11-25 00:44:30.898 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with:='reference_table');
2023-11-25 00:44:30.899 UTC [3773213] ERROR:  0A000: relation append_table should be a hash distributed table
2023-11-25 00:44:30.899 UTC [3773213] LOCATION:  EnsureHashDistributedTable, metadata_utility.c:2284
2023-11-25 00:44:30.899 UTC [3773213] STATEMENT:  SELECT alter_distributed_table('append_table', shard_count:=6);
2023-11-25 00:44:32.957 UTC [3773409] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 00:44:32.957 UTC [3773409] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 00:44:32.957 UTC [3773409] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 00:44:32.957 UTC [3773409] STATEMENT:  /*
	 * Test that we don't get a crash. See #5248.
	 */
	SELECT   subq_3.c15 AS c0,
	         subq_3.c0  AS c1,
	         subq_3.c15 AS c2,
	         subq_0.c1  AS c3,
	         pg_catalog.String_agg( Cast(
	                                      (
	                                      SELECT tgargs
	                                      FROM   pg_catalog.pg_trigger limit 1 offset 1) AS BYTEA), Cast(
	                                                                                                      (
	                                                                                                      SELECT minimum_value
	                                                                                                      FROM   columnar.chunk limit 1 offset 5) AS BYTEA)) OVER (partition BY subq_3.c10 ORDER BY subq_3.c12,subq_0.c2) AS c4,
	         subq_0.c1                                                                                                                                                                                                    AS c5
	FROM     (
	                    SELECT     ref_1.address                      AS c0,
	                               ref_1.error                        AS c1,
	                               sample_0.NAME                      AS c2,
	                               sample_2.trftosql                  AS c3
	                    FROM       pg_catalog.pg_statio_all_sequences AS ref_0
	                    INNER JOIN pg_catalog.pg_hba_file_rules       AS ref_1
	                    ON         ((
	                                                 SELECT pg_catalog.Max(aggnumdirectargs)
	                                                 FROM   pg_catalog.pg_aggregate) <= ref_0.blks_hit)
	                    INNER JOIN countries  AS sample_0 TABLESAMPLE system (6.4)
	                    INNER JOIN local_data AS sample_1 TABLESAMPLE bernoulli (8)
	                    ON         ((
	                                                     true)
	                               OR         (
	                                                     sample_0.NAME IS NOT NULL))
	                    INNER JOIN pg_catalog.pg_transform AS sample_2 TABLESAMPLE bernoulli (1.2)
	                    INNER JOIN pg_catalog.pg_language  AS ref_2
	                    ON         ((
	                                                 SELECT shard_cost_function
	                                                 FROM   pg_catalog.pg_dist_rebalance_strategy limit 1 offset 1) IS NULL)
	                    RIGHT JOIN pg_catalog.pg_index AS sample_3 TABLESAMPLE system (0.3)
	                    ON         ((
	                                                     cast(NULL AS bpchar) ~<=~ cast(NULL AS bpchar))
	                               OR         ((
	                                                                EXISTS
	                                                                (
	                                                                       SELECT sample_3.indnkeyatts        AS c0,
	                                                                              sample_2.trflang            AS c1,
	                                                                              sample_2.trftype            AS c2
	                                                                       FROM   pg_catalog.pg_statistic_ext AS sample_4 TABLESAMPLE bernoulli (8.6)
	                                                                       WHERE  sample_2.trftype IS NOT NULL))
	                                          AND        (
	                                                                false)))
	                    ON         (
	                                          EXISTS
	                                          (
	                                                 SELECT sample_0.id           AS c0,
	                                                        sample_3.indisprimary AS c1
	                                                 FROM   orgs           AS sample_5 TABLESAMPLE system (5.3)
	                                                 WHERE  false))
	                    ON         (
	                                          cast(NULL AS float8) >
	                                          (
	                                                 SELECT pg_catalog.avg(enumsortorder)
	                                                 FROM   pg_catalog.pg_enum) )
	                    WHERE      cast(COALESCE(
	                               CASE
	                                          WHEN ref_1.auth_method ~>=~ ref_1.auth_method THEN cast(NULL AS path)
	                                          ELSE cast(NULL AS path)
	                               END , cast(NULL AS path)) AS path) = cast(NULL AS path)) AS subq_0,
	         lateral
	         (
	                SELECT
	                       (
	                              SELECT pg_catalog.stddev(total_time)
	                              FROM   pg_catalog.pg_stat_user_functions) AS c0,
	                       subq_0.c1                                        AS c1,
	                       subq_2.c0                                        AS c2,
	                       subq_0.c2                                        AS c3,
	                       subq_0.c0                                        AS c4,
	                       cast(COALESCE(subq_2.c0, subq_2.c0) AS text)     AS c5,
	                       subq_2.c0                                        AS c6,
	                       subq_2.c1                                        AS c7,
	                       subq_2.c1                                        AS c8,
	                       subq_2.c1                                        AS c9,
	                       subq_0.c3                                        AS c10,
	                       pg_catalog.pg_stat_get_db_temp_files( cast(
	                                                                   (
	                                                                   SELECT objoid
	                                                                   FROM   pg_catalog.pg_description limit 1 offset 1) AS oid)) AS c11,
	                       subq_0.c3                                                                                               AS c12,
	                       subq_2.c1                                                                                               AS c13,
	                       subq_0.c0                                                                                               AS c14,
	                       subq_0.c3                                                                                               AS c15,
	                       subq_0.c3                                                                                               AS c16,
	                       subq_0.c1                                                                                               AS c17,
	                       subq_0.c2                                                                                               AS c18
	                FROM   (
	                              SELECT subq_1.c2                        AS c0,
	                                     subq_0.c3                        AS c1
	                              FROM   information_schema.element_types AS ref_3,
	                                     lateral
	                                     (
	                                            SELECT subq_0.c1            AS c0,
	                                                   sample_6.info        AS c1,
	                                                   subq_0.c2            AS c2,
	                                                   subq_0.c3            AS c3,
	                                                   ref_3.domain_default AS c4,
	                                                   sample_6.user_id     AS c5,
	                                                   ref_3.collation_name AS c6
	                                            FROM   orders        AS sample_6 TABLESAMPLE system (3.8)
	                                            WHERE  sample_6.price = sample_6.org_id limit 58) AS subq_1
	                              WHERE  (
	                                            subq_1.c2 <= subq_0.c2)
	                              AND    (
	                                            cast(NULL AS line) ?-| cast(NULL AS line)) limit 59) AS subq_2
	                WHERE  cast(COALESCE(pg_catalog.age( cast(
	                                                           (
	                                                           SELECT pg_catalog.max(event_time)
	                                                           FROM   events) AS "timestamp")),
	                       (
	                              SELECT write_lag
	                              FROM   pg_catalog.pg_stat_replication limit 1 offset 3) ) AS "interval") >
	                       (
	                              SELECT utc_offset
	                              FROM   pg_catalog.pg_timezone_names limit 1 offset 4) limit 91) AS subq_3
	WHERE    pg_catalog.pg_backup_stop() > cast(NULL AS record) limit 100;
2023-11-25 00:44:33.295 UTC [3773524] ERROR:  22023: relation with OID 31960 does not exist
2023-11-25 00:44:33.295 UTC [3773524] LOCATION:  EnsureRelationExists, create_distributed_table.c:969
2023-11-25 00:44:33.295 UTC [3773524] STATEMENT:  SELECT undistribute_table('dist_table'), create_distributed_table('dist_table', 'a');
2023-11-25 00:44:33.363 UTC [3773524] ERROR:  XX000: cannot complete operation because table referenced_table is referenced by a foreign key
2023-11-25 00:44:33.363 UTC [3773524] HINT:  Use cascade option to undistribute all the relations involved in a foreign key relationship with undistribute_table.referenced_table by executing SELECT undistribute_table($$undistribute_table.referenced_table$$, cascade_via_foreign_keys=>true)
2023-11-25 00:44:33.363 UTC [3773524] LOCATION:  EnsureTableNotReferenced, alter_table.c:1129
2023-11-25 00:44:33.363 UTC [3773524] STATEMENT:  SELECT undistribute_table('referenced_table');
2023-11-25 00:44:33.363 UTC [3773524] ERROR:  XX000: cannot complete operation because table referencing_table has a foreign key
2023-11-25 00:44:33.363 UTC [3773524] HINT:  Use cascade option to undistribute all the relations involved in a foreign key relationship with undistribute_table.referencing_table by executing SELECT undistribute_table($$undistribute_table.referencing_table$$, cascade_via_foreign_keys=>true)
2023-11-25 00:44:33.363 UTC [3773524] LOCATION:  EnsureTableNotReferencing, alter_table.c:1100
2023-11-25 00:44:33.363 UTC [3773524] STATEMENT:  SELECT undistribute_table('referencing_table');
2023-11-25 00:44:33.410 UTC [3773524] ERROR:  XX000: cannot complete operation because table is a partition
2023-11-25 00:44:33.410 UTC [3773524] HINT:  the parent table is "partitioned_table"
2023-11-25 00:44:33.410 UTC [3773524] LOCATION:  EnsureTableNotPartition, alter_table.c:1172
2023-11-25 00:44:33.410 UTC [3773524] STATEMENT:  SELECT undistribute_table('partitioned_table_1_5');
2023-11-25 00:44:33.507 UTC [3773524] ERROR:  XX000: cannot alter table because an extension depends on it
2023-11-25 00:44:33.507 UTC [3773524] LOCATION:  ErrorIfUnsupportedCascadeObjects, alter_table.c:1405
2023-11-25 00:44:33.507 UTC [3773524] STATEMENT:  SELECT undistribute_table ('extension_table');
2023-11-25 00:44:33.525 UTC [3773524] ERROR:  XX000: cannot alter table because an extension depends on it
2023-11-25 00:44:33.525 UTC [3773524] LOCATION:  ErrorIfUnsupportedCascadeObjects, alter_table.c:1405
2023-11-25 00:44:33.525 UTC [3773524] STATEMENT:  SELECT undistribute_table('rule_table_2');
2023-11-25 00:44:33.748 UTC [3773595] WARNING:  01000: Error on node with node id 16: failed to connect to localhost:0
2023-11-25 00:44:33.748 UTC [3773595] CONTEXT:  PL/pgSQL function run_command_on_all_nodes(text,boolean,boolean) line 46 at RAISE
2023-11-25 00:44:33.748 UTC [3773595] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:44:33.864 UTC [3773645] ERROR:  P0001: the coordinator is not added to the metadata
2023-11-25 00:44:33.864 UTC [3773645] HINT:  Add the node as a coordinator by using: SELECT citus_set_coordinator_host('<hostname>')
2023-11-25 00:44:33.864 UTC [3773645] CONTEXT:  PL/pgSQL function run_command_on_coordinator(text,boolean) line 36 at RAISE
2023-11-25 00:44:33.864 UTC [3773645] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 00:44:33.864 UTC [3773645] STATEMENT:  SELECT success, result FROM run_command_on_coordinator('select inet_server_port()');
2023-11-25 00:44:34.052 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:44:34.052 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:44:34.053 UTC [3758160] LOG:  00000: parameter "citus.background_task_queue_interval" changed to "1s"
2023-11-25 00:44:34.053 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:44:35.056 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:35.056 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:35.056 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:35.059 UTC [3773705] LOG:  00000: task jobid/taskid started: 1450000/1450000
2023-11-25 00:44:35.059 UTC [3773705] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:35.059 UTC [3773705] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:35.061 UTC [3773705] LOG:  00000: task jobid/taskid succeeded: 1450000/1450000
2023-11-25 00:44:35.061 UTC [3773705] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:35.061 UTC [3773705] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:44:36.065 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:36.065 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:36.065 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:36.068 UTC [3773707] LOG:  00000: task jobid/taskid started: 1450001/1450001
2023-11-25 00:44:36.068 UTC [3773707] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:36.068 UTC [3773707] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:37.061 UTC [3773708] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:37.061 UTC [3773708] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450001/1450001)
2023-11-25 00:44:37.061 UTC [3773708] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:37.061 UTC [3773707] LOG:  00000: task jobid/taskid is cancelled: 1450001/1450001
2023-11-25 00:44:37.061 UTC [3773707] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:37.061 UTC [3773707] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:37.062 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450001/1450001)" (PID 3773708) exited with exit code 1
2023-11-25 00:44:37.062 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:38.066 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:38.066 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:38.066 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:38.068 UTC [3773709] LOG:  00000: task jobid/taskid started: 1450002/1450002
2023-11-25 00:44:38.068 UTC [3773709] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:38.068 UTC [3773709] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:38.070 UTC [3773710] ERROR:  22012: division by zero
2023-11-25 00:44:38.070 UTC [3773710] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450002/1450002)
2023-11-25 00:44:38.070 UTC [3773710] LOCATION:  int4div, int.c:840
2023-11-25 00:44:38.070 UTC [3773709] LOG:  00000: task jobid/taskid failed: 1450002/1450002
2023-11-25 00:44:38.070 UTC [3773709] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:38.070 UTC [3773709] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 00:44:38.071 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450002/1450002)" (PID 3773710) exited with exit code 1
2023-11-25 00:44:38.071 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:41.077 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:41.077 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:41.077 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:41.080 UTC [3773711] LOG:  00000: task jobid/taskid started: 1450003/1450003
2023-11-25 00:44:41.080 UTC [3773711] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:41.080 UTC [3773711] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:41.083 UTC [3773711] LOG:  00000: task jobid/taskid succeeded: 1450003/1450003
2023-11-25 00:44:41.083 UTC [3773711] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:41.083 UTC [3773711] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:44:41.084 UTC [3773711] LOG:  00000: task jobid/taskid started: 1450003/1450004
2023-11-25 00:44:41.084 UTC [3773711] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:41.084 UTC [3773711] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:41.087 UTC [3773711] LOG:  00000: task jobid/taskid succeeded: 1450003/1450004
2023-11-25 00:44:41.087 UTC [3773711] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:41.087 UTC [3773711] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:44:41.088 UTC [3773711] LOG:  00000: task jobid/taskid started: 1450003/1450005
2023-11-25 00:44:41.088 UTC [3773711] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:41.088 UTC [3773711] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:41.091 UTC [3773711] LOG:  00000: task jobid/taskid succeeded: 1450003/1450005
2023-11-25 00:44:41.091 UTC [3773711] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:41.091 UTC [3773711] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:44:42.095 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:42.095 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:42.095 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:42.097 UTC [3773715] LOG:  00000: task jobid/taskid started: 1450004/1450006
2023-11-25 00:44:42.097 UTC [3773715] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:42.097 UTC [3773715] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:42.100 UTC [3773715] LOG:  00000: task jobid/taskid succeeded: 1450004/1450006
2023-11-25 00:44:42.100 UTC [3773715] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:42.100 UTC [3773715] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:44:42.101 UTC [3773715] LOG:  00000: task jobid/taskid started: 1450004/1450007
2023-11-25 00:44:42.101 UTC [3773715] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:42.101 UTC [3773715] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:42.103 UTC [3773717] ERROR:  22012: division by zero
2023-11-25 00:44:42.103 UTC [3773717] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450004/1450007)
2023-11-25 00:44:42.103 UTC [3773717] LOCATION:  int4div, int.c:840
2023-11-25 00:44:42.104 UTC [3773715] LOG:  00000: task jobid/taskid failed: 1450004/1450007
2023-11-25 00:44:42.104 UTC [3773715] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:42.104 UTC [3773715] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 00:44:42.104 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450004/1450007)" (PID 3773717) exited with exit code 1
2023-11-25 00:44:42.104 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:44.109 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:44.109 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:44.109 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:44.112 UTC [3773718] LOG:  00000: task jobid/taskid started: 1450005/1450009
2023-11-25 00:44:44.112 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:44.112 UTC [3773718] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:44.113 UTC [3773718] LOG:  00000: task jobid/taskid started: 1450005/1450010
2023-11-25 00:44:44.113 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:44.113 UTC [3773718] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:44.113 UTC [3773718] LOG:  00000: task jobid/taskid started: 1450005/1450011
2023-11-25 00:44:44.113 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:44.113 UTC [3773718] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:44.113 UTC [3773718] LOG:  00000: task jobid/taskid started: 1450006/1450012
2023-11-25 00:44:44.113 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:44.113 UTC [3773718] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:44.113 UTC [3773718] WARNING:  01000: unable to start background worker for background task execution
2023-11-25 00:44:44.113 UTC [3773718] DETAIL:  Already reached the maximum number of task executors: 4/4
2023-11-25 00:44:44.113 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:44.113 UTC [3773718] LOCATION:  NewExecutorExceedsCitusLimit, background_jobs.c:491
2023-11-25 00:44:45.096 UTC [3773722] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:45.096 UTC [3773722] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450006/1450012)
2023-11-25 00:44:45.096 UTC [3773722] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:45.096 UTC [3773718] LOG:  00000: task jobid/taskid is cancelled: 1450006/1450012
2023-11-25 00:44:45.096 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:45.096 UTC [3773718] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:45.098 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450006/1450012)" (PID 3773722) exited with exit code 1
2023-11-25 00:44:45.098 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:45.098 UTC [3773718] LOG:  00000: able to start a background worker with 0 seconds delay
2023-11-25 00:44:45.098 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:45.098 UTC [3773718] LOCATION:  CheckAndResetLastWorkerAllocationFailure, background_jobs.c:679
2023-11-25 00:44:45.098 UTC [3773718] LOG:  00000: task jobid/taskid started: 1450007/1450013
2023-11-25 00:44:45.098 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:45.098 UTC [3773718] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:46.098 UTC [3773721] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:46.098 UTC [3773721] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450005/1450011)
2023-11-25 00:44:46.098 UTC [3773721] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:46.098 UTC [3773719] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:46.098 UTC [3773719] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450005/1450009)
2023-11-25 00:44:46.098 UTC [3773719] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:46.098 UTC [3773720] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:46.098 UTC [3773720] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450005/1450010)
2023-11-25 00:44:46.098 UTC [3773720] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:46.098 UTC [3773718] LOG:  00000: task jobid/taskid is cancelled: 1450005/1450011
2023-11-25 00:44:46.098 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:46.098 UTC [3773718] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:46.100 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450005/1450009)" (PID 3773719) exited with exit code 1
2023-11-25 00:44:46.100 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:46.100 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450005/1450010)" (PID 3773720) exited with exit code 1
2023-11-25 00:44:46.100 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:46.100 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450005/1450011)" (PID 3773721) exited with exit code 1
2023-11-25 00:44:46.100 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:46.100 UTC [3773718] LOG:  00000: task jobid/taskid is cancelled: 1450005/1450009
2023-11-25 00:44:46.100 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:46.100 UTC [3773718] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:46.100 UTC [3773718] LOG:  00000: task jobid/taskid is cancelled: 1450005/1450010
2023-11-25 00:44:46.100 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:46.100 UTC [3773718] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:46.100 UTC [3773723] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:46.100 UTC [3773723] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450007/1450013)
2023-11-25 00:44:46.100 UTC [3773723] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:46.100 UTC [3773718] LOG:  00000: task jobid/taskid is cancelled: 1450007/1450013
2023-11-25 00:44:46.100 UTC [3773718] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:46.100 UTC [3773718] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:46.101 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450007/1450013)" (PID 3773723) exited with exit code 1
2023-11-25 00:44:46.101 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:47.102 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:47.102 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:47.102 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:47.105 UTC [3773724] LOG:  00000: task jobid/taskid started: 1450008/1450014
2023-11-25 00:44:47.105 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:47.105 UTC [3773724] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:47.105 UTC [3773724] LOG:  00000: task jobid/taskid started: 1450008/1450015
2023-11-25 00:44:47.105 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:47.105 UTC [3773724] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:47.106 UTC [3773724] LOG:  00000: task jobid/taskid started: 1450008/1450016
2023-11-25 00:44:47.106 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:47.106 UTC [3773724] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:47.106 UTC [3773724] LOG:  00000: task jobid/taskid started: 1450009/1450017
2023-11-25 00:44:47.106 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:47.106 UTC [3773724] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:47.106 UTC [3773724] WARNING:  01000: unable to start background worker for background task execution
2023-11-25 00:44:47.106 UTC [3773724] DETAIL:  Already reached the maximum number of task executors: 4/4
2023-11-25 00:44:47.106 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:47.106 UTC [3773724] LOCATION:  NewExecutorExceedsCitusLimit, background_jobs.c:491
2023-11-25 00:44:48.104 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:44:48.104 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:44:48.104 UTC [3758160] LOG:  00000: parameter "citus.max_background_task_executors" changed to "5"
2023-11-25 00:44:48.104 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:44:48.106 UTC [3773724] LOG:  00000: able to start a background worker with 0 seconds delay
2023-11-25 00:44:48.106 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:48.106 UTC [3773724] LOCATION:  CheckAndResetLastWorkerAllocationFailure, background_jobs.c:679
2023-11-25 00:44:48.106 UTC [3773724] LOG:  00000: task jobid/taskid started: 1450010/1450018
2023-11-25 00:44:48.106 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:48.106 UTC [3773724] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:49.107 UTC [3773725] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:49.107 UTC [3773725] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450008/1450014)
2023-11-25 00:44:49.107 UTC [3773725] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:49.107 UTC [3773727] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:49.107 UTC [3773727] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450008/1450016)
2023-11-25 00:44:49.107 UTC [3773727] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:49.107 UTC [3773726] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:49.107 UTC [3773726] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450008/1450015)
2023-11-25 00:44:49.107 UTC [3773726] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:49.107 UTC [3773724] LOG:  00000: task jobid/taskid is cancelled: 1450008/1450015
2023-11-25 00:44:49.107 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:49.107 UTC [3773724] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:49.109 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450008/1450014)" (PID 3773725) exited with exit code 1
2023-11-25 00:44:49.109 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:49.109 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450008/1450015)" (PID 3773726) exited with exit code 1
2023-11-25 00:44:49.109 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:49.109 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450008/1450016)" (PID 3773727) exited with exit code 1
2023-11-25 00:44:49.109 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:49.109 UTC [3773724] LOG:  00000: task jobid/taskid is cancelled: 1450008/1450014
2023-11-25 00:44:49.109 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:49.109 UTC [3773724] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:49.109 UTC [3773724] LOG:  00000: task jobid/taskid is cancelled: 1450008/1450016
2023-11-25 00:44:49.109 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:49.109 UTC [3773724] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:49.109 UTC [3773728] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:49.109 UTC [3773728] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450009/1450017)
2023-11-25 00:44:49.109 UTC [3773728] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:49.109 UTC [3773724] LOG:  00000: task jobid/taskid is cancelled: 1450009/1450017
2023-11-25 00:44:49.109 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:49.109 UTC [3773724] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:49.110 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450009/1450017)" (PID 3773728) exited with exit code 1
2023-11-25 00:44:49.110 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:49.110 UTC [3773724] LOG:  00000: task jobid/taskid is cancelled: 1450010/1450018
2023-11-25 00:44:49.110 UTC [3773724] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:49.110 UTC [3773724] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:49.110 UTC [3773729] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:49.110 UTC [3773729] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450010/1450018)
2023-11-25 00:44:49.110 UTC [3773729] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:49.112 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450010/1450018)" (PID 3773729) exited with exit code 1
2023-11-25 00:44:49.112 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:51.113 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:51.113 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:51.113 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:51.116 UTC [3773732] LOG:  00000: task jobid/taskid started: 1450011/1450019
2023-11-25 00:44:51.116 UTC [3773732] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:51.116 UTC [3773732] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:51.116 UTC [3773732] LOG:  00000: task jobid/taskid started: 1450012/1450020
2023-11-25 00:44:51.116 UTC [3773732] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:51.116 UTC [3773732] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:52.119 UTC [3773732] LOG:  00000: handling termination signal
2023-11-25 00:44:52.119 UTC [3773732] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:52.119 UTC [3773732] LOCATION:  CitusBackgroundTaskQueueMonitorMain, background_jobs.c:1232
2023-11-25 00:44:52.119 UTC [3773734] FATAL:  57P01: terminating background worker "Citus Background Task Queue Executor: regression/postgres for (1450012/1450020)" due to administrator command
2023-11-25 00:44:52.119 UTC [3773734] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450012/1450020)
2023-11-25 00:44:52.119 UTC [3773734] LOCATION:  ProcessInterrupts, postgres.c:3213
2023-11-25 00:44:52.119 UTC [3773733] FATAL:  57P01: terminating background worker "Citus Background Task Queue Executor: regression/postgres for (1450011/1450019)" due to administrator command
2023-11-25 00:44:52.119 UTC [3773733] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450011/1450019)
2023-11-25 00:44:52.119 UTC [3773733] LOCATION:  ProcessInterrupts, postgres.c:3213
2023-11-25 00:44:52.119 UTC [3773732] LOG:  00000: task jobid/taskid failed: 1450012/1450020
2023-11-25 00:44:52.119 UTC [3773732] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:52.119 UTC [3773732] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 00:44:52.121 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450011/1450019)" (PID 3773733) exited with exit code 1
2023-11-25 00:44:52.121 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:52.121 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450012/1450020)" (PID 3773734) exited with exit code 1
2023-11-25 00:44:52.121 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:52.121 UTC [3773732] LOG:  00000: task jobid/taskid failed: 1450011/1450019
2023-11-25 00:44:52.121 UTC [3773732] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:52.121 UTC [3773732] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 00:44:56.129 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:56.129 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:56.129 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:56.132 UTC [3773735] LOG:  00000: task jobid/taskid started: 1450013/1450021
2023-11-25 00:44:56.132 UTC [3773735] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:56.132 UTC [3773735] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:56.132 UTC [3773735] LOG:  00000: task jobid/taskid started: 1450014/1450022
2023-11-25 00:44:56.132 UTC [3773735] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:56.132 UTC [3773735] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:56.135 UTC [3773735] LOG:  00000: handling cancellation signal
2023-11-25 00:44:56.135 UTC [3773735] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:56.135 UTC [3773735] LOCATION:  CitusBackgroundTaskQueueMonitorMain, background_jobs.c:1239
2023-11-25 00:44:56.136 UTC [3773736] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:56.136 UTC [3773736] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450013/1450021)
2023-11-25 00:44:56.136 UTC [3773736] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:56.136 UTC [3773737] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:56.136 UTC [3773737] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450014/1450022)
2023-11-25 00:44:56.136 UTC [3773737] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:56.136 UTC [3773735] LOG:  00000: task jobid/taskid is cancelled: 1450014/1450022
2023-11-25 00:44:56.136 UTC [3773735] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:56.136 UTC [3773735] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:56.137 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450013/1450021)" (PID 3773736) exited with exit code 1
2023-11-25 00:44:56.137 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:56.137 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450014/1450022)" (PID 3773737) exited with exit code 1
2023-11-25 00:44:56.137 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:56.137 UTC [3773735] LOG:  00000: task jobid/taskid is cancelled: 1450013/1450021
2023-11-25 00:44:56.137 UTC [3773735] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:56.137 UTC [3773735] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:57.140 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:57.140 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:57.140 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:57.143 UTC [3773738] LOG:  00000: task jobid/taskid started: 1450015/1450023
2023-11-25 00:44:57.143 UTC [3773738] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:57.143 UTC [3773738] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:57.143 UTC [3773738] LOG:  00000: task jobid/taskid started: 1450016/1450024
2023-11-25 00:44:57.143 UTC [3773738] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:57.143 UTC [3773738] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:57.146 UTC [3773738] LOG:  00000: task jobid/taskid succeeded: 1450016/1450024
2023-11-25 00:44:57.146 UTC [3773738] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:57.146 UTC [3773738] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:44:58.141 UTC [3773739] ERROR:  57014: canceling statement due to user request
2023-11-25 00:44:58.141 UTC [3773739] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450015/1450023)
2023-11-25 00:44:58.141 UTC [3773739] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:44:58.141 UTC [3773738] LOG:  00000: task jobid/taskid is cancelled: 1450015/1450023
2023-11-25 00:44:58.141 UTC [3773738] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:58.141 UTC [3773738] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:44:58.142 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450015/1450023)" (PID 3773739) exited with exit code 1
2023-11-25 00:44:58.142 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:44:59.146 UTC [3758230] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 00:44:59.146 UTC [3758230] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 00:44:59.146 UTC [3758230] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 00:44:59.149 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450025
2023-11-25 00:44:59.149 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:59.149 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:44:59.149 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450026
2023-11-25 00:44:59.149 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:44:59.149 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:01.154 UTC [3773741] LOG:  00000: task jobid/taskid succeeded: 1450017/1450026
2023-11-25 00:45:01.154 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:01.154 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:45:01.155 UTC [3773741] LOG:  00000: task jobid/taskid succeeded: 1450017/1450025
2023-11-25 00:45:01.155 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:01.155 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:45:01.156 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450027
2023-11-25 00:45:01.156 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:01.156 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:02.116 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:02.116 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:02.117 UTC [3758160] LOG:  00000: parameter "citus.max_background_task_executors_per_node" changed to "2"
2023-11-25 00:45:02.117 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:45:02.118 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450028
2023-11-25 00:45:02.118 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:02.118 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:02.119 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450029
2023-11-25 00:45:02.119 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:02.119 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:05.163 UTC [3773741] LOG:  00000: task jobid/taskid succeeded: 1450017/1450027
2023-11-25 00:45:05.163 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:05.163 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:45:05.165 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450030
2023-11-25 00:45:05.165 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:05.165 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:06.124 UTC [3773741] LOG:  00000: task jobid/taskid succeeded: 1450017/1450029
2023-11-25 00:45:06.124 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:06.124 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:45:06.125 UTC [3773741] LOG:  00000: task jobid/taskid succeeded: 1450017/1450028
2023-11-25 00:45:06.125 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:06.125 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:45:06.127 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450031
2023-11-25 00:45:06.127 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:06.127 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:07.126 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:07.126 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:07.127 UTC [3758160] LOG:  00000: parameter "citus.max_background_task_executors_per_node" changed to "3"
2023-11-25 00:45:07.127 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:45:07.128 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450032
2023-11-25 00:45:07.128 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:07.128 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:08.130 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:08.130 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:08.130 UTC [3773749] ERROR:  57014: canceling statement due to user request
2023-11-25 00:45:08.130 UTC [3773749] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)
2023-11-25 00:45:08.130 UTC [3773749] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:45:08.130 UTC [3758160] LOG:  00000: parameter "citus.max_background_task_executors_per_node" removed from configuration file, reset to default
2023-11-25 00:45:08.130 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 00:45:08.130 UTC [3773741] LOG:  00000: task jobid/taskid failed: 1450017/1450030
2023-11-25 00:45:08.130 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:08.130 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 00:45:08.132 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)" (PID 3773749) exited with exit code 1
2023-11-25 00:45:08.132 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:45:12.136 UTC [3773741] LOG:  00000: task jobid/taskid succeeded: 1450017/1450031
2023-11-25 00:45:12.136 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:12.136 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:45:13.138 UTC [3773741] LOG:  00000: task jobid/taskid succeeded: 1450017/1450032
2023-11-25 00:45:13.138 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:13.138 UTC [3773741] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 00:45:13.140 UTC [3773741] LOG:  00000: task jobid/taskid started: 1450017/1450030
2023-11-25 00:45:13.140 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:13.140 UTC [3773741] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 00:45:13.149 UTC [3773754] ERROR:  57014: canceling statement due to user request
2023-11-25 00:45:13.149 UTC [3773754] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)
2023-11-25 00:45:13.149 UTC [3773754] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 00:45:13.149 UTC [3773741] LOG:  00000: task jobid/taskid is cancelled: 1450017/1450030
2023-11-25 00:45:13.149 UTC [3773741] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 00:45:13.149 UTC [3773741] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 00:45:13.151 UTC [3758160] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)" (PID 3773754) exited with exit code 1
2023-11-25 00:45:13.151 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:45:14.151 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:14.151 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:14.162 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:14.162 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:14.162 UTC [3758160] LOG:  00000: parameter "citus.background_task_queue_interval" removed from configuration file, reset to default
2023-11-25 00:45:14.162 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 00:45:14.162 UTC [3758160] LOG:  00000: parameter "citus.max_background_task_executors" removed from configuration file, reset to default
2023-11-25 00:45:14.162 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 00:45:14.275 UTC [3773769] ERROR:  22P02: invalid input syntax for type cluster_clock: "(-1, 100)" at character 39
2023-11-25 00:45:14.275 UTC [3773769] LOCATION:  cluster_clock_in_internal, type_utils.c:71
2023-11-25 00:45:14.275 UTC [3773769] STATEMENT:  INSERT INTO cluster_clock_type values('(-1, 100)');
2023-11-25 00:45:14.275 UTC [3773769] ERROR:  22P02: invalid input syntax for type cluster_clock: "(100, -1)" at character 39
2023-11-25 00:45:14.275 UTC [3773769] LOCATION:  cluster_clock_in_internal, type_utils.c:82
2023-11-25 00:45:14.275 UTC [3773769] STATEMENT:  INSERT INTO cluster_clock_type values('(100, -1)');
2023-11-25 00:45:14.275 UTC [3773769] ERROR:  22P02: invalid input syntax for type cluster_clock: "(4398046511104, 100)" at character 39
2023-11-25 00:45:14.275 UTC [3773769] LOCATION:  cluster_clock_in_internal, type_utils.c:71
2023-11-25 00:45:14.275 UTC [3773769] STATEMENT:  INSERT INTO cluster_clock_type values('(4398046511104, 100)');
2023-11-25 00:45:14.275 UTC [3773769] ERROR:  22P02: invalid input syntax for type cluster_clock: "(0, 4194304)" at character 39
2023-11-25 00:45:14.275 UTC [3773769] LOCATION:  cluster_clock_in_internal, type_utils.c:82
2023-11-25 00:45:14.275 UTC [3773769] STATEMENT:  INSERT INTO cluster_clock_type values('(0, 4194304)');
2023-11-25 00:45:14.278 UTC [3773769] ERROR:  23505: duplicate key value violates unique constraint "cluster_clock_type_cc_key"
2023-11-25 00:45:14.278 UTC [3773769] DETAIL:  Key (cc)=((100,1)) already exists.
2023-11-25 00:45:14.278 UTC [3773769] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 00:45:14.278 UTC [3773769] STATEMENT:  INSERT INTO cluster_clock_type values('(100, 1)');
2023-11-25 00:45:14.279 UTC [3773769] ERROR:  23505: duplicate key value violates unique constraint "cluster_clock_type_cc_key"
2023-11-25 00:45:14.279 UTC [3773769] DETAIL:  Key (cc)=((100,200)) already exists.
2023-11-25 00:45:14.279 UTC [3773769] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 00:45:14.279 UTC [3773769] STATEMENT:  INSERT INTO cluster_clock_type values('(100, 200)');
2023-11-25 00:45:14.279 UTC [3773769] ERROR:  23505: duplicate key value violates unique constraint "cluster_clock_type_cc_key"
2023-11-25 00:45:14.279 UTC [3773769] DETAIL:  Key (cc)=((100,100)) already exists.
2023-11-25 00:45:14.279 UTC [3773769] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 00:45:14.279 UTC [3773769] STATEMENT:  INSERT INTO cluster_clock_type values('(100, 100)');
2023-11-25 00:45:14.394 UTC [3773769] WARNING:  01000: GUC enable_cluster_clock is off
2023-11-25 00:45:14.394 UTC [3773769] LOCATION:  PrepareAndSetTransactionClock, causal_clock.c:419
2023-11-25 00:45:14.397 UTC [3773769] ERROR:  42501: permission denied for sequence pg_dist_clock_logical_seq
2023-11-25 00:45:14.397 UTC [3773769] LOCATION:  do_setval, sequence.c:967
2023-11-25 00:45:14.397 UTC [3773769] STATEMENT:  SELECT setval('pg_dist_clock_logical_seq', 100, true);
2023-11-25 00:45:14.507 UTC [3773813] LOG:  00000: deferred drop of orphaned resource alter_distributed_table.shard_split_table_362791 on localhost:57637 completed
2023-11-25 00:45:14.507 UTC [3773813] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 00:45:14.507 UTC [3773813] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 00:45:14.996 UTC [3773807] WARNING:  0A000: "view pg_source_view" has dependency to "table pg_source" that is not in Citus' metadata
2023-11-25 00:45:14.996 UTC [3773807] DETAIL:  "view pg_source_view" will be created only locally
2023-11-25 00:45:14.996 UTC [3773807] HINT:  Distribute "table pg_source" first to distribute "view pg_source_view"
2023-11-25 00:45:14.996 UTC [3773807] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 00:45:15.162 UTC [3773807] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 00:45:15.162 UTC [3773807] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 00:45:15.162 UTC [3773807] STATEMENT:  MERGE INTO target_serial sda
	USING source_serial sdn
	ON sda.id = sdn.id
	WHEN NOT matched THEN
	       INSERT (id, z) VALUES (id, z);
2023-11-25 00:45:15.174 UTC [3773807] ERROR:  0A000: cannot assign to system column "ctid" at character 110
2023-11-25 00:45:15.174 UTC [3773807] LOCATION:  transformAssignedExpr, parse_target.c:480
2023-11-25 00:45:15.174 UTC [3773807] STATEMENT:  MERGE INTO target_set
	USING source_set AS foo ON target_set.t1 = foo.s1
	WHEN MATCHED THEN
	        UPDATE SET ctid = '(0,100)';
2023-11-25 00:45:15.174 UTC [3773807] ERROR:  0A000: cannot pushdown the subquery since not all subqueries in the UNION have the partition column in the same position
2023-11-25 00:45:15.174 UTC [3773807] DETAIL:  Each leaf query of the UNION should return the partition column in the same position and all joins must be on the partition column
2023-11-25 00:45:15.174 UTC [3773807] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:582
2023-11-25 00:45:15.174 UTC [3773807] STATEMENT:  MERGE INTO target_set
	USING (SELECT s1,s2 FROM source_set UNION SELECT s2,s1 FROM source_set) AS foo ON target_set.t1 = foo.s1
	WHEN MATCHED THEN
	        UPDATE SET t2 = t2 + 1;
2023-11-25 00:45:15.175 UTC [3773807] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:45:15.175 UTC [3773807] DETAIL:  Limit clause is currently unsupported when a subquery references a column from another query
2023-11-25 00:45:15.175 UTC [3773807] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 00:45:15.175 UTC [3773807] STATEMENT:  MERGE INTO target_set
	USING (SELECT 2 as s3, source_set.* FROM (SELECT * FROM source_set LIMIT 1) as foo LEFT JOIN source_set USING( s1)) AS foo
	ON target_set.t1 = foo.s1
	WHEN MATCHED THEN UPDATE SET t2 = t2 + 1
	WHEN NOT MATCHED THEN INSERT VALUES(s1, s3);
2023-11-25 00:45:15.175 UTC [3773807] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:45:15.175 UTC [3773807] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:45:15.175 UTC [3773807] STATEMENT:  EXPLAIN
	WITH cte_1 AS (DELETE FROM target_json)
	MERGE INTO target_json sda
	USING source_json sdn
	ON sda.id = sdn.id
	WHEN NOT matched THEN
		INSERT (id, z) VALUES (sdn.id, 5);
2023-11-25 00:45:15.175 UTC [3773807] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:45:15.175 UTC [3773807] DETAIL:  could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 00:45:15.175 UTC [3773807] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 00:45:15.175 UTC [3773807] STATEMENT:  MERGE INTO citus_target t
	USING (SELECT count(*), id FROM citus_source GROUP BY GROUPING SETS (id, val)) subq
	ON subq.id = t.id
	WHEN MATCHED AND t.id > 350 THEN
	    UPDATE SET val = t.val || 'Updated'
	WHEN NOT MATCHED THEN
	        INSERT VALUES (subq.id, 99)
	WHEN MATCHED AND t.id < 350 THEN
	        DELETE;
2023-11-25 00:45:15.175 UTC [3773807] ERROR:  0A000: cannot push down this subquery
2023-11-25 00:45:15.175 UTC [3773807] DETAIL:  could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 00:45:15.175 UTC [3773807] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 00:45:15.175 UTC [3773807] STATEMENT:  WITH subq AS
	(
	SELECT count(*), id FROM citus_source GROUP BY GROUPING SETS (id, val)
	)
	MERGE INTO citus_target t
	USING subq
	ON subq.id = t.id
	WHEN MATCHED AND t.id > 350 THEN
	    UPDATE SET val = t.val || 'Updated'
	WHEN NOT MATCHED THEN
	        INSERT VALUES (subq.id, 99)
	WHEN MATCHED AND t.id < 350 THEN
	        DELETE;
2023-11-25 00:45:15.175 UTC [3773807] ERROR:  0A000: cannot perform MERGE INSERT with DEFAULTS
2023-11-25 00:45:15.175 UTC [3773807] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:546
2023-11-25 00:45:15.175 UTC [3773807] STATEMENT:  MERGE INTO citus_target t
	USING citus_source s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT DEFAULT VALUES;
2023-11-25 00:45:15.175 UTC [3773807] ERROR:  0A000: MERGE INSERT must refer a source column for distribution column 
2023-11-25 00:45:15.175 UTC [3773807] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:583
2023-11-25 00:45:15.175 UTC [3773807] STATEMENT:  MERGE INTO citus_target t
	USING citus_source s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT VALUES(10000);
2023-11-25 00:45:15.175 UTC [3773807] ERROR:  0A000: MERGE INSERT must refer a source column for distribution column 
2023-11-25 00:45:15.175 UTC [3773807] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:583
2023-11-25 00:45:15.175 UTC [3773807] STATEMENT:  MERGE INTO citus_target t
	USING citus_source s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT (id) VALUES(1000);
2023-11-25 00:45:15.176 UTC [3773807] ERROR:  0A000: MERGE INSERT must use the source table distribution column value
2023-11-25 00:45:15.176 UTC [3773807] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:575
2023-11-25 00:45:15.176 UTC [3773807] STATEMENT:  MERGE INTO t1 t
	USING s1 s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT (id) VALUES(s.val);
2023-11-25 00:45:15.176 UTC [3773807] ERROR:  0A000: MERGE INSERT must have distribution column as value
2023-11-25 00:45:15.176 UTC [3773807] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:592
2023-11-25 00:45:15.176 UTC [3773807] STATEMENT:  MERGE INTO t1 t
	USING s1 s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT (val) VALUES(s.val);
2023-11-25 00:45:15.176 UTC [3773807] ERROR:  0A000: updating the distribution column is not allowed in MERGE actions
2023-11-25 00:45:15.176 UTC [3773807] LOCATION:  MergeQualAndTargetListFunctionsSupported, merge_planner.c:651
2023-11-25 00:45:15.176 UTC [3773807] STATEMENT:  MERGE INTO target_cj t
	  USING source_cj1 s
	  ON t.tid = s.sid1 AND t.tid = 2
	  WHEN MATCHED THEN
	    UPDATE SET tid = tid + 9, src = src || ' updated by merge'
	  WHEN NOT MATCHED THEN
	    INSERT VALUES (sid1, 'inserted by merge', val1);
2023-11-25 00:45:15.176 UTC [3773807] ERROR:  0A000: cannot execute MERGE on relation "foreign_table"
2023-11-25 00:45:15.176 UTC [3773807] DETAIL:  This operation is not supported for foreign tables.
2023-11-25 00:45:15.176 UTC [3773807] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 00:45:15.176 UTC [3773807] STATEMENT:  MERGE INTO foreign_table
		USING ft_target ON (foreign_table.id = ft_target.id)
		WHEN MATCHED THEN
			DELETE
		WHEN NOT MATCHED THEN
			INSERT (id, user_val) VALUES (ft_target.id, ft_target.user_val);
2023-11-25 00:45:15.196 UTC [3773807] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 00:45:15.196 UTC [3773807] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 00:45:15.196 UTC [3773807] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.val) -- val is not a distribution column
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 00:45:15.212 UTC [3773807] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 00:45:15.212 UTC [3773807] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 00:45:15.212 UTC [3773807] STATEMENT:  MERGE INTO t1 USING (SELECT * FROM s1 WHERE true) s1 ON
	  t1.id = s1.id AND s1.id = 2
	   WHEN matched THEN
	 UPDATE SET id = s1.id, val = random();
2023-11-25 00:45:15.213 UTC [3773807] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 00:45:15.213 UTC [3773807] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 00:45:15.213 UTC [3773807] STATEMENT:  MERGE INTO t1
	USING s1 ON t1.id = s1.id
	WHEN NOT MATCHED THEN
		INSERT VALUES(s1.id, add_s(s1.val, 2));
2023-11-25 00:45:15.213 UTC [3773807] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 00:45:15.213 UTC [3773807] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 00:45:15.213 UTC [3773807] STATEMENT:  MERGE INTO t1
	USING s1 ON t1.id = s1.id AND t1.id = 2 AND (merge_when_and_write())
	WHEN MATCHED THEN
	        UPDATE SET val = t1.val + s1.val;
2023-11-25 00:45:15.214 UTC [3773807] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 00:45:15.214 UTC [3773807] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 00:45:15.214 UTC [3773807] STATEMENT:  MERGE INTO t1
	USING s1 ON t1.id = s1.id AND t1.id = 2
	WHEN MATCHED AND (merge_when_and_write()) THEN
	        UPDATE SET val = t1.val + s1.val;
2023-11-25 00:45:15.214 UTC [3773807] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:45:15.214 UTC [3773807] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:45:15.214 UTC [3773807] STATEMENT:  MERGE INTO t1
		USING (SELECT * FROM s1) sub ON (sub.val = t1.id) -- sub.val is not a distribution column
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 00:45:15.214 UTC [3773807] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:45:15.214 UTC [3773807] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:45:15.214 UTC [3773807] STATEMENT:  WITH s1_res AS (
		SELECT * FROM s1
	)
	MERGE INTO t1
		USING s1_res ON (s1_res.val = t1.id)
		WHEN MATCHED AND s1_res.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1_res.id, s1_res.val);
2023-11-25 00:45:15.214 UTC [3773807] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:45:15.214 UTC [3773807] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:45:15.214 UTC [3773807] STATEMENT:  WITH s1_res AS (
		SELECT * FROM s1
	)
	MERGE INTO t1
		USING s1_res ON (TRUE)
		WHEN MATCHED AND s1_res.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1_res.id, s1_res.val);
2023-11-25 00:45:15.214 UTC [3773807] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:45:15.214 UTC [3773807] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:45:15.214 UTC [3773807] STATEMENT:  WITH s1_res AS (
	     SELECT * FROM s1
	 )
	 MERGE INTO t1 USING s1_res ON (s1_res.id = t1.val)
	 WHEN MATCHED THEN DELETE
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1_res.id, s1_res.val);
2023-11-25 00:45:15.236 UTC [3773807] ERROR:  0A000: MERGE command is not supported on reference tables yet
2023-11-25 00:45:15.236 UTC [3773807] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:330
2023-11-25 00:45:15.236 UTC [3773807] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.id)
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 00:45:15.253 UTC [3773807] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 00:45:15.253 UTC [3773807] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 00:45:15.253 UTC [3773807] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.id)
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 00:45:15.253 UTC [3773807] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 00:45:15.253 UTC [3773807] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 00:45:15.253 UTC [3773807] STATEMENT:  MERGE INTO t1
		USING (SELECT * FROM s1) sub ON (sub.id = t1.id)
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 00:45:15.263 UTC [3773807] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 00:45:15.263 UTC [3773807] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 00:45:15.263 UTC [3773807] STATEMENT:  MERGE INTO t1
		USING (SELECT s1.id, pg.val FROM s1, pg) sub ON (sub.id = t1.id)
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 00:45:15.263 UTC [3773807] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 00:45:15.263 UTC [3773807] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 00:45:15.263 UTC [3773807] STATEMENT:  WITH pg_res AS (
		SELECT * FROM pg
	)
	MERGE INTO t1
		USING (SELECT s1.id, pg_res.val FROM s1, pg_res) sub ON (sub.id = t1.id)
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 00:45:15.277 UTC [3773807] ERROR:  21000: MERGE command cannot affect row a second time
2023-11-25 00:45:15.277 UTC [3773807] HINT:  Ensure that not more than one source row matches any one target row.
2023-11-25 00:45:15.277 UTC [3773807] LOCATION:  ExecMergeMatched, nodeModifyTable.c:2932
2023-11-25 00:45:15.277 UTC [3773807] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.id)
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 00:45:15.277 UTC [3773807] ERROR:  0A000: cannot execute MERGE on relation "mv_source"
2023-11-25 00:45:15.277 UTC [3773807] DETAIL:  This operation is not supported for materialized views.
2023-11-25 00:45:15.277 UTC [3773807] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 00:45:15.277 UTC [3773807] STATEMENT:  MERGE INTO mv_source
	USING mv_target
	ON mv_source.id = mv_target.id
	WHEN MATCHED THEN
	    DO NOTHING
	WHEN NOT MATCHED THEN
	    INSERT VALUES(mv_source.id, mv_source.val);
2023-11-25 00:45:15.288 UTC [3773807] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated
2023-11-25 00:45:15.288 UTC [3773807] LOCATION:  ErrorIfDistTablesNotColocated, merge_planner.c:277
2023-11-25 00:45:15.288 UTC [3773807] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 00:45:15.293 UTC [3773807] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 00:45:15.293 UTC [3773807] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 00:45:15.293 UTC [3773807] STATEMENT:  MERGE INTO dist_target
	USING dist_colocated
	ON dist_target.id = dist_colocated.val -- val is not the distribution column
	WHEN MATCHED THEN
	UPDATE SET val = dist_colocated.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_colocated.id, dist_colocated.val);
2023-11-25 00:45:15.293 UTC [3773807] ERROR:  0A000: For MERGE command, both the source and target must be distributed
2023-11-25 00:45:15.293 UTC [3773807] LOCATION:  ErrorIfDistTablesNotColocated, merge_planner.c:269
2023-11-25 00:45:15.293 UTC [3773807] STATEMENT:  MERGE INTO dist_target
	USING (SELECT 100 id) AS source
	ON dist_target.id = source.id AND dist_target.val = 'const'
	WHEN MATCHED THEN
	UPDATE SET val = 'source'
	WHEN NOT MATCHED THEN
	INSERT VALUES(source.id, 'source');
2023-11-25 00:45:15.304 UTC [3773807] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 00:45:15.304 UTC [3773807] HINT:  Consider using hash distribution instead
2023-11-25 00:45:15.304 UTC [3773807] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 00:45:15.304 UTC [3773807] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 00:45:15.307 UTC [3773807] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 00:45:15.307 UTC [3773807] HINT:  Consider using hash distribution instead
2023-11-25 00:45:15.307 UTC [3773807] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 00:45:15.307 UTC [3773807] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 00:45:15.317 UTC [3773807] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 00:45:15.317 UTC [3773807] HINT:  Consider using hash distribution instead
2023-11-25 00:45:15.317 UTC [3773807] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 00:45:15.317 UTC [3773807] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 00:45:15.323 UTC [3773807] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 00:45:15.323 UTC [3773807] HINT:  Consider using hash distribution instead
2023-11-25 00:45:15.323 UTC [3773807] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 00:45:15.323 UTC [3773807] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 00:45:15.730 UTC [3773897] ERROR:  42601: syntax error at or near "RANDOMWORD" at character 21
2023-11-25 00:45:15.730 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.730 UTC [3773897] STATEMENT:  MERGE INTO target t RANDOMWORD
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  42601: syntax error at or near "INSERT" at character 75
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  42601: syntax error at or near "INTO" at character 86
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT INTO target DEFAULT VALUES;
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  42601: syntax error at or near "," at character 98
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT VALUES (1,1), (2,2);
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  42601: syntax error at or near "SELECT" at character 86
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT SELECT (1, 1);
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  42601: syntax error at or near "UPDATE" at character 79
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  42601: syntax error at or near "target" at character 82
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		UPDATE target SET balance = 0;
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  42712: name "target" specified more than once
2023-11-25 00:45:15.731 UTC [3773897] DETAIL:  The name is used both as MERGE target table and data source.
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  transformMergeStmt, parse_merge.c:206
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  MERGE INTO target
	USING target
	ON tid = tid
	WHEN MATCHED THEN DO NOTHING;
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  0A000: MERGE not supported in WITH query at character 6
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  transformWithClause, parse_cte.c:131
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  WITH foo AS (
	  MERGE INTO target USING source ON (true)
	  WHEN MATCHED THEN DELETE
	) SELECT * FROM foo;
2023-11-25 00:45:15.731 UTC [3773897] ERROR:  0A000: MERGE not supported in COPY
2023-11-25 00:45:15.731 UTC [3773897] LOCATION:  DoCopy, copy.c:281
2023-11-25 00:45:15.731 UTC [3773897] STATEMENT:  COPY (
	  MERGE INTO target USING source ON (true)
	  WHEN MATCHED THEN DELETE
	) TO stdout;
2023-11-25 00:45:15.738 UTC [3773897] ERROR:  0A000: cannot execute MERGE on relation "tv"
2023-11-25 00:45:15.738 UTC [3773897] DETAIL:  This operation is not supported for views.
2023-11-25 00:45:15.738 UTC [3773897] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 00:45:15.738 UTC [3773897] STATEMENT:  MERGE INTO tv t
	USING source s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 00:45:15.744 UTC [3773897] ERROR:  0A000: cannot execute MERGE on relation "mv"
2023-11-25 00:45:15.744 UTC [3773897] DETAIL:  This operation is not supported for materialized views.
2023-11-25 00:45:15.744 UTC [3773897] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 00:45:15.744 UTC [3773897] STATEMENT:  MERGE INTO mv t
	USING source s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 00:45:15.745 UTC [3773897] ERROR:  42501: permission denied for table source2
2023-11-25 00:45:15.745 UTC [3773897] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:45:15.745 UTC [3773897] STATEMENT:  MERGE INTO target
	USING source2
	ON target.tid = source2.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 00:45:15.746 UTC [3773897] ERROR:  42501: permission denied for table target
2023-11-25 00:45:15.746 UTC [3773897] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:45:15.746 UTC [3773897] STATEMENT:  MERGE INTO target
	USING source2
	ON target.tid = source2.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 00:45:15.752 UTC [3773897] ERROR:  42501: permission denied for table target2
2023-11-25 00:45:15.752 UTC [3773897] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:45:15.752 UTC [3773897] STATEMENT:  MERGE INTO target2
	USING source
	ON target2.tid = source.sid
	WHEN MATCHED THEN
		DELETE;
2023-11-25 00:45:15.752 UTC [3773897] ERROR:  42501: permission denied for table target2
2023-11-25 00:45:15.752 UTC [3773897] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 00:45:15.752 UTC [3773897] STATEMENT:  MERGE INTO target2
	USING source
	ON target2.tid = source.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 00:45:15.752 UTC [3773897] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 55
2023-11-25 00:45:15.752 UTC [3773897] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 00:45:15.752 UTC [3773897] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 00:45:15.752 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING (SELECT * FROM source WHERE t.tid > sid) s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 00:45:15.767 UTC [3773897] ERROR:  21000: MERGE command cannot affect row a second time
2023-11-25 00:45:15.767 UTC [3773897] HINT:  Ensure that not more than one source row matches any one target row.
2023-11-25 00:45:15.767 UTC [3773897] LOCATION:  ExecMergeMatched, nodeModifyTable.c:2932
2023-11-25 00:45:15.767 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 00:45:15.767 UTC [3773897] ERROR:  21000: MERGE command cannot affect row a second time
2023-11-25 00:45:15.767 UTC [3773897] HINT:  Ensure that not more than one source row matches any one target row.
2023-11-25 00:45:15.767 UTC [3773897] LOCATION:  ExecMergeMatched, nodeModifyTable.c:2932
2023-11-25 00:45:15.767 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		DELETE;
2023-11-25 00:45:15.768 UTC [3773897] ERROR:  23505: duplicate key value violates unique constraint "targetidx_4001000"
2023-11-25 00:45:15.768 UTC [3773897] DETAIL:  Key (tid)=(4) already exists.
2023-11-25 00:45:15.768 UTC [3773897] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 00:45:15.768 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
	  INSERT VALUES (4, NULL);
2023-11-25 00:45:15.768 UTC [3773897] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:45:15.768 UTC [3773897] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:45:15.768 UTC [3773897] STATEMENT:  SELECT * FROM target ORDER BY tid;
2023-11-25 00:45:15.775 UTC [3773897] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 109
2023-11-25 00:45:15.775 UTC [3773897] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 00:45:15.775 UTC [3773897] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 00:45:15.775 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT (tid, balance) VALUES (t.tid, s.delta);
2023-11-25 00:45:15.775 UTC [3773897] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 109
2023-11-25 00:45:15.775 UTC [3773897] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 00:45:15.775 UTC [3773897] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 00:45:15.775 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON (SELECT true)
	WHEN NOT MATCHED THEN
		INSERT (tid, balance) VALUES (t.tid, s.delta);
2023-11-25 00:45:15.775 UTC [3773897] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:45:15.775 UTC [3773897] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:45:15.775 UTC [3773897] STATEMENT:  SELECT * FROM target ORDER BY tid;
2023-11-25 00:45:15.776 UTC [3773897] ERROR:  42601: unreachable WHEN clause specified after unconditional WHEN clause
2023-11-25 00:45:15.776 UTC [3773897] LOCATION:  transformMergeStmt, parse_merge.c:159
2023-11-25 00:45:15.776 UTC [3773897] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN /* Terminal WHEN clause for MATCHED */
		DELETE
	WHEN MATCHED AND s.delta > 0 THEN
		UPDATE SET balance = t.balance - s.delta;
2023-11-25 00:45:15.786 UTC [3773897] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 80
2023-11-25 00:45:15.786 UTC [3773897] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 00:45:15.786 UTC [3773897] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 00:45:15.786 UTC [3773897] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid
	WHEN NOT MATCHED AND t.balance = 100 THEN
		INSERT (tid) VALUES (s.sid);
2023-11-25 00:45:15.786 UTC [3773897] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 00:45:15.786 UTC [3773897] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 00:45:15.786 UTC [3773897] STATEMENT:  SELECT * FROM wq_target;
2023-11-25 00:45:15.789 UTC [3773897] ERROR:  42P10: cannot use system column "xmin" in MERGE WHEN condition at character 76
2023-11-25 00:45:15.789 UTC [3773897] LOCATION:  scanNSItemForColumn, parse_relation.c:709
2023-11-25 00:45:15.789 UTC [3773897] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid
	WHEN MATCHED AND t.xmin = t.xmax THEN
		UPDATE SET balance = t.balance + s.balance;
2023-11-25 00:45:15.793 UTC [3773897] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 00:45:15.793 UTC [3773897] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 00:45:15.793 UTC [3773897] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid
	WHEN MATCHED AND (merge_when_and_write()) THEN
		UPDATE SET balance = t.balance + s.balance;
2023-11-25 00:45:15.793 UTC [3773897] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 00:45:15.793 UTC [3773897] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 00:45:15.793 UTC [3773897] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid AND (merge_when_and_write())
	WHEN MATCHED THEN
		UPDATE SET balance = t.balance + s.balance;
2023-11-25 00:45:15.856 UTC [3773897] ERROR:  42702: column reference "balance" is ambiguous at character 98
2023-11-25 00:45:15.856 UTC [3773897] LOCATION:  colNameToVar, parse_relation.c:898
2023-11-25 00:45:15.856 UTC [3773897] STATEMENT:  MERGE INTO sq_target
	USING v
	ON tid = sid
	WHEN MATCHED AND tid > 2 THEN
	    UPDATE SET balance = balance + delta
	WHEN NOT MATCHED THEN
		INSERT (balance, tid) VALUES (balance + delta, sid)
	WHEN MATCHED AND tid < 2 THEN
		DELETE;
2023-11-25 00:45:15.858 UTC [3773897] ERROR:  42601: syntax error at or near "RETURNING" at character 231
2023-11-25 00:45:15.858 UTC [3773897] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 00:45:15.858 UTC [3773897] STATEMENT:  MERGE INTO sq_target t
	USING v
	ON tid = sid
	WHEN MATCHED AND tid > 2 THEN
	    UPDATE SET balance = t.balance + delta
	WHEN NOT MATCHED THEN
		INSERT (balance, tid) VALUES (balance + delta, sid)
	WHEN MATCHED AND tid < 2 THEN
		DELETE
	RETURNING *;
2023-11-25 00:45:16.217 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:16.217 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:16.218 UTC [3758160] LOG:  00000: parameter "citus.max_cached_conns_per_worker" changed to "0"
2023-11-25 00:45:16.218 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:45:16.218 UTC [3758160] LOG:  00000: parameter "citus.distributed_deadlock_detection_factor" changed to "-1"
2023-11-25 00:45:16.218 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:45:16.218 UTC [3758160] LOG:  00000: parameter "citus.recover_2pc_interval" changed to "1ms"
2023-11-25 00:45:16.218 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:45:16.218 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:16.218 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:16.320 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:16.320 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:16.320 UTC [3758160] LOG:  00000: parameter "citus.recover_2pc_interval" changed to "-1"
2023-11-25 00:45:16.320 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 00:45:16.556 UTC [3758160] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 00:45:16.556 UTC [3758160] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 00:45:16.556 UTC [3758160] LOG:  00000: parameter "citus.distributed_deadlock_detection_factor" removed from configuration file, reset to default
2023-11-25 00:45:16.556 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 00:45:16.556 UTC [3758160] LOG:  00000: parameter "citus.max_cached_conns_per_worker" removed from configuration file, reset to default
2023-11-25 00:45:16.556 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 00:45:16.556 UTC [3758160] LOG:  00000: parameter "citus.recover_2pc_interval" removed from configuration file, reset to default
2023-11-25 00:45:16.556 UTC [3758160] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 00:45:16.696 UTC [3774083] ERROR:  0A000: cannot complete operation on generated_identities.smallint_identity_column with smallint/int identity column
2023-11-25 00:45:16.696 UTC [3774083] HINT:  Use bigint identity column instead.
2023-11-25 00:45:16.696 UTC [3774083] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 00:45:16.696 UTC [3774083] STATEMENT:  SELECT create_distributed_table('smallint_identity_column', 'a');
2023-11-25 00:45:16.842 UTC [3774083] ERROR:  0A000: cannot complete operation on generated_identities.smallint_identity_column with smallint/int identity column
2023-11-25 00:45:16.842 UTC [3774083] HINT:  Use bigint identity column instead.
2023-11-25 00:45:16.842 UTC [3774083] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 00:45:16.842 UTC [3774083] STATEMENT:  SELECT create_distributed_table_concurrently('smallint_identity_column', 'a');
2023-11-25 00:45:16.843 UTC [3774083] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 00:45:16.843 UTC [3774083] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 00:45:16.843 UTC [3774083] STATEMENT:  SELECT create_reference_table('smallint_identity_column');
2023-11-25 00:45:16.851 UTC [3774083] ERROR:  0A000: cannot complete operation on generated_identities.int_identity_column with smallint/int identity column
2023-11-25 00:45:16.851 UTC [3774083] HINT:  Use bigint identity column instead.
2023-11-25 00:45:16.851 UTC [3774083] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 00:45:16.851 UTC [3774083] STATEMENT:  SELECT create_distributed_table('int_identity_column', 'a');
2023-11-25 00:45:16.869 UTC [3774083] ERROR:  0A000: cannot complete operation on generated_identities.int_identity_column with smallint/int identity column
2023-11-25 00:45:16.869 UTC [3774083] HINT:  Use bigint identity column instead.
2023-11-25 00:45:16.869 UTC [3774083] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 00:45:16.869 UTC [3774083] STATEMENT:  SELECT create_distributed_table_concurrently('int_identity_column', 'a');
2023-11-25 00:45:16.869 UTC [3774083] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 00:45:16.869 UTC [3774083] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 00:45:16.869 UTC [3774083] STATEMENT:  SELECT create_reference_table('int_identity_column');
2023-11-25 00:45:16.953 UTC [3774130] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 00:45:16.953 UTC [3774130] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 00:45:16.953 UTC [3774130] STATEMENT:  SELECT alter_distributed_table('bigint_identity_column', 'b');
2023-11-25 00:45:16.953 UTC [3774130] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 00:45:16.953 UTC [3774130] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 00:45:16.953 UTC [3774130] STATEMENT:  SELECT undistribute_table('bigint_identity_column');
2023-11-25 00:45:17.063 UTC [3774147] ERROR:  0A000: alter table command is currently unsupported
2023-11-25 00:45:17.063 UTC [3774147] DETAIL:  Only ADD|DROP COLUMN, SET|DROP NOT NULL, SET|DROP DEFAULT, ADD|DROP|VALIDATE CONSTRAINT, SET (), RESET (), ENABLE|DISABLE|NO FORCE|FORCE ROW LEVEL SECURITY, ATTACH|DETACH PARTITION and TYPE subcommands are supported.
2023-11-25 00:45:17.063 UTC [3774147] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3506
2023-11-25 00:45:17.063 UTC [3774147] STATEMENT:  ALTER TABLE partitioned_table ALTER COLUMN g ADD GENERATED ALWAYS AS IDENTITY;
2023-11-25 00:45:17.063 UTC [3774147] ERROR:  XX000: cannot execute ALTER COLUMN command involving identity column
2023-11-25 00:45:17.063 UTC [3774147] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3306
2023-11-25 00:45:17.063 UTC [3774147] STATEMENT:  ALTER TABLE partitioned_table ALTER COLUMN b TYPE int;
2023-11-25 00:45:17.151 UTC [3774162] ERROR:  42501: must be owner of table color
2023-11-25 00:45:17.151 UTC [3774162] LOCATION:  aclcheck_error, aclchk.c:3788
2023-11-25 00:45:17.151 UTC [3774162] STATEMENT:  SELECT create_distributed_table('color', 'color_id');
2023-11-25 00:45:17.179 UTC [3774162] LOG:  00000: performing non-blocking create_distributed_table_concurrently 
2023-11-25 00:45:17.179 UTC [3774162] LOCATION:  SplitShard, shard_split.c:519
2023-11-25 00:45:17.179 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:17.183 UTC [3774162] LOG:  00000: creating child shards for create_distributed_table_concurrently
2023-11-25 00:45:17.183 UTC [3774162] LOCATION:  NonBlockingShardSplit, shard_split.c:1430
2023-11-25 00:45:17.183 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:17.209 UTC [3774162] LOG:  00000: creating replication artifacts (publications, replication slots, subscriptions for create_distributed_table_concurrently
2023-11-25 00:45:17.209 UTC [3774162] LOCATION:  NonBlockingShardSplit, shard_split.c:1462
2023-11-25 00:45:17.209 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:17.220 UTC [3774172] LOG:  00000: Initializing CDC decoder
2023-11-25 00:45:17.220 UTC [3774172] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 00:45:17.220 UTC [3774172] STATEMENT:  CREATE_REPLICATION_SLOT citus_shard_split_slot_16_10_24 LOGICAL citus EXPORT_SNAPSHOT;
2023-11-25 00:45:17.220 UTC [3774172] LOG:  00000: logical decoding found consistent point at 0/7CA3C20
2023-11-25 00:45:17.220 UTC [3774172] DETAIL:  There are no running transactions.
2023-11-25 00:45:17.220 UTC [3774172] LOCATION:  SnapBuildFindSnapshot, snapbuild.c:1366
2023-11-25 00:45:17.220 UTC [3774172] STATEMENT:  CREATE_REPLICATION_SLOT citus_shard_split_slot_16_10_24 LOGICAL citus EXPORT_SNAPSHOT;
2023-11-25 00:45:17.220 UTC [3774172] LOG:  00000: exported logical decoding snapshot: "00000007-00000840-1" with 0 transaction IDs
2023-11-25 00:45:17.220 UTC [3774172] LOCATION:  SnapBuildExportSnapshot, snapbuild.c:687
2023-11-25 00:45:17.220 UTC [3774172] STATEMENT:  CREATE_REPLICATION_SLOT citus_shard_split_slot_16_10_24 LOGICAL citus EXPORT_SNAPSHOT;
2023-11-25 00:45:17.222 UTC [3774171] LOG:  00000: Initializing CDC decoder
2023-11-25 00:45:17.222 UTC [3774171] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 00:45:17.222 UTC [3774171] STATEMENT:  SELECT pg_catalog.pg_copy_logical_replication_slot('citus_shard_split_slot_16_10_24', 'citus_shard_split_slot_34_10_24')
2023-11-25 00:45:17.243 UTC [3774162] LOG:  00000: performing copy for create_distributed_table_concurrently
2023-11-25 00:45:17.243 UTC [3774162] LOCATION:  NonBlockingShardSplit, shard_split.c:1534
2023-11-25 00:45:17.243 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:17.244 UTC [3774175] LOG:  00000: performing copy from shard generated_identities.color_363176 to [generated_identities.color_363177 (nodeId: 16), generated_identities.color_363178 (nodeId: 34), generated_identities.color_363179 (nodeId: 16), generated_identities.color_363180 (nodeId: 34)]
2023-11-25 00:45:17.244 UTC [3774175] LOCATION:  worker_split_copy, worker_split_copy_udf.c:107
2023-11-25 00:45:17.244 UTC [3774175] STATEMENT:  SELECT pg_catalog.worker_split_copy(363176, 'color_id', ARRAY[ROW(363177, -2147483648, -1073741825, 16)::pg_catalog.split_copy_info,ROW(363178, -1073741824, -1, 34)::pg_catalog.split_copy_info,ROW(363179, 0, 1073741823, 16)::pg_catalog.split_copy_info,ROW(363180, 1073741824, 2147483647, 34)::pg_catalog.split_copy_info]);
2023-11-25 00:45:17.244 UTC [3774162] LOG:  00000: replicating changes for create_distributed_table_concurrently
2023-11-25 00:45:17.244 UTC [3774162] LOCATION:  NonBlockingShardSplit, shard_split.c:1541
2023-11-25 00:45:17.244 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:17.251 UTC [3774180] LOG:  00000: Initializing CDC decoder
2023-11-25 00:45:17.251 UTC [3774180] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 00:45:17.251 UTC [3774180] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_16_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_16_10_24"', binary 'true')
2023-11-25 00:45:17.251 UTC [3774181] LOG:  00000: Initializing CDC decoder
2023-11-25 00:45:17.251 UTC [3774181] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 00:45:17.251 UTC [3774181] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_34_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_34_10_24"', binary 'true')
2023-11-25 00:45:17.251 UTC [3774181] LOG:  00000: starting logical decoding for slot "citus_shard_split_slot_34_10_24"
2023-11-25 00:45:17.251 UTC [3774181] DETAIL:  Streaming transactions committing after 0/7CA3C58, reading WAL from 0/7CA3C20.
2023-11-25 00:45:17.251 UTC [3774181] LOCATION:  CreateDecodingContext, logical.c:569
2023-11-25 00:45:17.251 UTC [3774181] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_34_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_34_10_24"', binary 'true')
2023-11-25 00:45:17.251 UTC [3774180] LOG:  00000: starting logical decoding for slot "citus_shard_split_slot_16_10_24"
2023-11-25 00:45:17.251 UTC [3774180] DETAIL:  Streaming transactions committing after 0/7CA3C58, reading WAL from 0/7CA3C20.
2023-11-25 00:45:17.251 UTC [3774180] LOCATION:  CreateDecodingContext, logical.c:569
2023-11-25 00:45:17.251 UTC [3774180] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_16_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_16_10_24"', binary 'true')
2023-11-25 00:45:17.251 UTC [3774180] LOG:  00000: logical decoding found consistent point at 0/7CA3C20
2023-11-25 00:45:17.251 UTC [3774180] DETAIL:  There are no running transactions.
2023-11-25 00:45:17.251 UTC [3774180] LOCATION:  SnapBuildFindSnapshot, snapbuild.c:1366
2023-11-25 00:45:17.251 UTC [3774180] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_16_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_16_10_24"', binary 'true')
2023-11-25 00:45:17.251 UTC [3774181] LOG:  00000: logical decoding found consistent point at 0/7CA3C20
2023-11-25 00:45:17.251 UTC [3774181] DETAIL:  There are no running transactions.
2023-11-25 00:45:17.251 UTC [3774181] LOCATION:  SnapBuildFindSnapshot, snapbuild.c:1366
2023-11-25 00:45:17.251 UTC [3774181] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_34_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_34_10_24"', binary 'true')
2023-11-25 00:45:18.247 UTC [3774162] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:45:18.247 UTC [3774162] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:45:18.247 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.248 UTC [3774162] LOG:  00000: The LSN of the target subscriptions on node localhost:57637 have caught up with the source LSN 
2023-11-25 00:45:18.248 UTC [3774162] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:45:18.248 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.267 UTC [3774162] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:45:18.267 UTC [3774162] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:45:18.267 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.268 UTC [3774162] LOG:  00000: The LSN of the target subscriptions on node localhost:57637 have caught up with the source LSN 
2023-11-25 00:45:18.268 UTC [3774162] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:45:18.268 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.268 UTC [3774162] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 00:45:18.268 UTC [3774162] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:45:18.268 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.269 UTC [3774162] LOG:  00000: The LSN of the target subscriptions on node localhost:57637 have caught up with the source LSN 
2023-11-25 00:45:18.269 UTC [3774162] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 00:45:18.269 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.269 UTC [3774162] LOG:  00000: marking deferred cleanup of source shard(s) for create_distributed_table_concurrently
2023-11-25 00:45:18.269 UTC [3774162] LOCATION:  NonBlockingShardSplit, shard_split.c:1560
2023-11-25 00:45:18.269 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.271 UTC [3774162] LOG:  00000: creating foreign key constraints (if any) for create_distributed_table_concurrently
2023-11-25 00:45:18.271 UTC [3774162] LOCATION:  NonBlockingShardSplit, shard_split.c:1610
2023-11-25 00:45:18.271 UTC [3774162] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 00:45:18.393 UTC [3774195] ERROR:  0A000: cannot execute ADD COLUMN commands involving identity columns when metadata is synchronized to workers
2023-11-25 00:45:18.393 UTC [3774195] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3182
2023-11-25 00:45:18.393 UTC [3774195] STATEMENT:  ALTER TABLE color ADD COLUMN color_id BIGINT GENERATED ALWAYS AS IDENTITY;
2023-11-25 00:45:18.394 UTC [3774195] ERROR:  XX000: Altering a distributed sequence is currently not supported.
2023-11-25 00:45:18.394 UTC [3774195] LOCATION:  PreprocessAlterSequenceStmt, sequence.c:464
2023-11-25 00:45:18.394 UTC [3774195] STATEMENT:  ALTER SEQUENCE color_color_id_seq RESTART WITH 1000;
2023-11-25 00:45:18.394 UTC [3774195] ERROR:  428C9: cannot insert a non-DEFAULT value into column "color_id"
2023-11-25 00:45:18.394 UTC [3774195] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 00:45:18.394 UTC [3774195] HINT:  Use OVERRIDING SYSTEM VALUE to override.
2023-11-25 00:45:18.394 UTC [3774195] LOCATION:  rewriteTargetListIU, rewriteHandler.c:884
2023-11-25 00:45:18.394 UTC [3774195] STATEMENT:  INSERT INTO color(color_id, color_name) VALUES (1, 'Red');
2023-11-25 00:45:18.394 UTC [3774195] ERROR:  428C9: cannot insert a non-DEFAULT value into column "color_id"
2023-11-25 00:45:18.394 UTC [3774195] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 00:45:18.394 UTC [3774195] HINT:  Use OVERRIDING SYSTEM VALUE to override.
2023-11-25 00:45:18.394 UTC [3774195] LOCATION:  rewriteTargetListIU, rewriteHandler.c:884
2023-11-25 00:45:18.394 UTC [3774195] STATEMENT:  INSERT INTO color(color_id, color_name) VALUES (NULL, 'Red');
2023-11-25 00:45:18.399 UTC [3774195] ERROR:  23505: duplicate key value violates unique constraint "color_color_id_key_12400000"
2023-11-25 00:45:18.399 UTC [3774195] DETAIL:  Key (color_id)=(1) already exists.
2023-11-25 00:45:18.399 UTC [3774195] CONTEXT:  while executing command on localhost:57637
2023-11-25 00:45:18.399 UTC [3774195] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 00:45:18.399 UTC [3774195] STATEMENT:  INSERT INTO color(color_id, color_name) OVERRIDING SYSTEM VALUE VALUES (1, 'Red');
2023-11-25 00:45:18.400 UTC [3774195] ERROR:  428C9: column "color_id" can only be updated to DEFAULT
2023-11-25 00:45:18.400 UTC [3774195] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 00:45:18.400 UTC [3774195] LOCATION:  rewriteTargetListIU, rewriteHandler.c:950
2023-11-25 00:45:18.400 UTC [3774195] STATEMENT:  UPDATE color SET color_id = NULL;
2023-11-25 00:45:18.400 UTC [3774195] ERROR:  428C9: column "color_id" can only be updated to DEFAULT
2023-11-25 00:45:18.400 UTC [3774195] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 00:45:18.400 UTC [3774195] LOCATION:  rewriteTargetListIU, rewriteHandler.c:950
2023-11-25 00:45:18.400 UTC [3774195] STATEMENT:  UPDATE color SET color_id = 1;
2023-11-25 00:45:18.644 UTC [3774218] LOG:  00000: starting maintenance daemon on database 33396 user 10
2023-11-25 00:45:18.644 UTC [3774218] CONTEXT:  Citus maintenance daemon for database 33396 user 10
2023-11-25 00:45:18.644 UTC [3774218] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:373
2023-11-25 00:45:18.765 UTC [3758161] LOG:  00000: checkpoint starting: immediate force wait
2023-11-25 00:45:18.765 UTC [3758161] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 00:45:18.788 UTC [3758161] LOG:  00000: checkpoint complete: wrote 2669 buffers (16.3%); 0 WAL file(s) added, 0 removed, 4 recycled; write=0.011 s, sync=0.001 s, total=0.023 s; sync files=0, longest=0.000 s, average=0.000 s; distance=61809 kB, estimate=61809 kB
2023-11-25 00:45:18.788 UTC [3758161] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 00:45:18.796 UTC [3758161] LOG:  00000: checkpoint starting: immediate force wait
2023-11-25 00:45:18.796 UTC [3758161] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 00:45:18.797 UTC [3758161] LOG:  00000: checkpoint complete: wrote 2 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.001 s; sync files=0, longest=0.000 s, average=0.000 s; distance=1 kB, estimate=55629 kB
2023-11-25 00:45:18.797 UTC [3758161] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 00:45:19.800 UTC [3758160] LOG:  00000: received fast shutdown request
2023-11-25 00:45:19.800 UTC [3758160] LOCATION:  pmdie, postmaster.c:2904
2023-11-25 00:45:19.800 UTC [3758160] LOG:  00000: aborting any active transactions
2023-11-25 00:45:19.800 UTC [3758160] LOCATION:  pmdie, postmaster.c:2922
2023-11-25 00:45:19.802 UTC [3758160] LOG:  00000: background worker "logical replication launcher" (PID 3758166) exited with exit code 1
2023-11-25 00:45:19.802 UTC [3758160] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 00:45:19.803 UTC [3758161] LOG:  00000: shutting down
2023-11-25 00:45:19.803 UTC [3758161] LOCATION:  ShutdownXLOG, xlog.c:6039
2023-11-25 00:45:19.803 UTC [3758161] LOG:  00000: checkpoint starting: shutdown immediate
2023-11-25 00:45:19.803 UTC [3758161] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 00:45:19.803 UTC [3758161] LOG:  00000: checkpoint complete: wrote 11 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.001 s; sync files=0, longest=0.000 s, average=0.000 s; distance=39 kB, estimate=50070 kB
2023-11-25 00:45:19.803 UTC [3758161] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 00:45:19.816 UTC [3758160] LOG:  00000: database system is shut down
2023-11-25 00:45:19.816 UTC [3758160] LOCATION:  UnlinkLockFiles, miscinit.c:977
