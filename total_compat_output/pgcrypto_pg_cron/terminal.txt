The files belonging to this database system will be owned by user "abigalek".
This user must also own the server process.

The database cluster will be initialized with locale "en_US.UTF-8".
The default database encoding has accordingly been set to "UTF8".
The default text search configuration will be set to "english".

Data page checksums are disabled.

creating directory pg-15-data ... ok
creating subdirectories ... ok
selecting dynamic shared memory implementation ... posix
selecting default max_connections ... 100
selecting default shared_buffers ... 128MB
selecting default time zone ... Etc/UTC
creating configuration files ... ok
running bootstrap script ... ok
performing post-bootstrap initialization ... ok
syncing data to disk ... ok

initdb: warning: enabling "trust" authentication for local connections
initdb: hint: You can change this by editing pg_hba.conf or using the option -A, or --auth-local and --auth-host, the next time you run initdb.

Success. You can now start the database server using:

    pg-15-dist/bin/pg_ctl -D pg-15-data -l logfile start

waiting for server to start.... done
server started
(using postmaster on Unix socket, default port)
============== dropping database "contrib_regression" ==============
SET
DROP DATABASE
============== creating database "contrib_regression" ==============
CREATE DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
============== installing pg_cron                     ==============
CREATE EXTENSION
============== running regression test queries        ==============
test init                         ... ok           17 ms
test md5                          ... ok           14 ms
test sha1                         ... ok           14 ms
test hmac-md5                     ... ok           14 ms
test hmac-sha1                    ... ok           14 ms
test blowfish                     ... ok           16 ms
test rijndael                     ... ok           17 ms
test sha2                         ... ok           17 ms
test des                          ... ok           13 ms
test 3des                         ... ok           14 ms
test cast5                        ... ok           14 ms
test crypt-des                    ... ok           26 ms
test crypt-md5                    ... ok           32 ms
test crypt-blowfish               ... ok           83 ms
test crypt-xdes                   ... ok           20 ms
test pgp-armor                    ... ok           15 ms
test pgp-decrypt                  ... ok           30 ms
test pgp-encrypt                  ... ok          410 ms
test pgp-compression              ... ok           14 ms
test pgp-pubkey-decrypt           ... ok           66 ms
test pgp-pubkey-encrypt           ... ok           18 ms
test pgp-info                     ... ok            7 ms

======================
 All 22 tests passed. 
======================

(using postmaster on Unix socket, default port)
============== dropping database "contrib_regression" ==============
SET
DROP DATABASE
============== creating database "contrib_regression" ==============
CREATE DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
ALTER DATABASE
============== installing pgcrypto                    ==============
CREATE EXTENSION
============== running regression test queries        ==============
test pg_cron-test                 ... ok          434 ms

=====================
 All 1 tests passed. 
=====================

CREATE EXTENSION
ERROR:  can only create extension in database postgres
DETAIL:  Jobs must be scheduled from the database configured in cron.database_name, since the pg_cron background worker reads job descriptions from this database.
HINT:  Add cron.database_name = 'pgbench_test' in postgresql.conf to use the current database.
CONTEXT:  PL/pgSQL function inline_code_block line 4 at RAISE
dropping old tables...
NOTICE:  table "pgbench_accounts" does not exist, skipping
NOTICE:  table "pgbench_branches" does not exist, skipping
NOTICE:  table "pgbench_history" does not exist, skipping
NOTICE:  table "pgbench_tellers" does not exist, skipping
creating tables...
generating data (client-side)...
100000 of 1000000 tuples (10%) done (elapsed 0.08 s, remaining 0.71 s)
200000 of 1000000 tuples (20%) done (elapsed 0.14 s, remaining 0.54 s)
300000 of 1000000 tuples (30%) done (elapsed 0.26 s, remaining 0.62 s)
400000 of 1000000 tuples (40%) done (elapsed 0.36 s, remaining 0.54 s)
500000 of 1000000 tuples (50%) done (elapsed 0.47 s, remaining 0.47 s)
600000 of 1000000 tuples (60%) done (elapsed 0.59 s, remaining 0.39 s)
700000 of 1000000 tuples (70%) done (elapsed 0.67 s, remaining 0.29 s)
800000 of 1000000 tuples (80%) done (elapsed 0.79 s, remaining 0.20 s)
900000 of 1000000 tuples (90%) done (elapsed 0.92 s, remaining 0.10 s)
1000000 of 1000000 tuples (100%) done (elapsed 0.98 s, remaining 0.00 s)
vacuuming...
creating primary keys...
done in 1.48 s (drop tables 0.00 s, create tables 0.01 s, client-side generate 1.05 s, vacuum 0.13 s, primary keys 0.30 s).
ERROR:  can only create extension in database postgres
DETAIL:  Jobs must be scheduled from the database configured in cron.database_name, since the pg_cron background worker reads job descriptions from this database.
HINT:  Add cron.database_name = 'pgbench_test' in postgresql.conf to use the current database.
CONTEXT:  PL/pgSQL function inline_code_block line 4 at RAISE
CREATE EXTENSION
dropping old tables...
NOTICE:  table "pgbench_accounts" does not exist, skipping
NOTICE:  table "pgbench_branches" does not exist, skipping
NOTICE:  table "pgbench_history" does not exist, skipping
NOTICE:  table "pgbench_tellers" does not exist, skipping
creating tables...
generating data (client-side)...
100000 of 1000000 tuples (10%) done (elapsed 0.06 s, remaining 0.57 s)
200000 of 1000000 tuples (20%) done (elapsed 0.13 s, remaining 0.53 s)
300000 of 1000000 tuples (30%) done (elapsed 0.20 s, remaining 0.47 s)
400000 of 1000000 tuples (40%) done (elapsed 0.30 s, remaining 0.46 s)
500000 of 1000000 tuples (50%) done (elapsed 0.40 s, remaining 0.40 s)
600000 of 1000000 tuples (60%) done (elapsed 0.47 s, remaining 0.31 s)
700000 of 1000000 tuples (70%) done (elapsed 0.55 s, remaining 0.24 s)
800000 of 1000000 tuples (80%) done (elapsed 0.63 s, remaining 0.16 s)
900000 of 1000000 tuples (90%) done (elapsed 0.73 s, remaining 0.08 s)
1000000 of 1000000 tuples (100%) done (elapsed 0.80 s, remaining 0.00 s)
vacuuming...
creating primary keys...
done in 1.22 s (drop tables 0.00 s, create tables 0.01 s, client-side generate 0.83 s, vacuum 0.11 s, primary keys 0.27 s).
waiting for server to shut down.... done
server stopped
