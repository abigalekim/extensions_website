2023-11-25 13:00:58.194 UTC [3976581] LOG:  00000: number of prepared transactions has not been configured, overriding
2023-11-25 13:00:58.194 UTC [3976581] DETAIL:  max_prepared_transactions is now set to 200
2023-11-25 13:00:58.194 UTC [3976581] LOCATION:  AdjustMaxPreparedTransactions, transaction_management.c:761
2023-11-25 13:00:58.211 UTC [3976581] LOG:  00000: starting PostgreSQL 15.3 on x86_64-pc-linux-gnu, compiled by gcc (Ubuntu 11.3.0-1ubuntu1~22.04.1) 11.3.0, 64-bit
2023-11-25 13:00:58.211 UTC [3976581] LOCATION:  PostmasterMain, postmaster.c:1189
2023-11-25 13:00:58.211 UTC [3976581] LOG:  00000: listening on IPv4 address "127.0.0.1", port 57636
2023-11-25 13:00:58.211 UTC [3976581] LOCATION:  StreamServerPort, pqcomm.c:582
2023-11-25 13:00:58.211 UTC [3976581] LOG:  00000: listening on Unix socket "/tmp/.s.PGSQL.57636"
2023-11-25 13:00:58.211 UTC [3976581] LOCATION:  StreamServerPort, pqcomm.c:577
2023-11-25 13:00:58.212 UTC [3976584] LOG:  00000: database system was shut down at 2023-11-25 13:00:58 UTC
2023-11-25 13:00:58.212 UTC [3976584] LOCATION:  StartupXLOG, xlog.c:4928
2023-11-25 13:00:58.215 UTC [3976581] LOG:  00000: database system is ready to accept connections
2023-11-25 13:00:58.215 UTC [3976581] LOCATION:  reaper, postmaster.c:3117
2023-11-25 13:00:58.963 UTC [3976651] LOG:  00000: starting maintenance daemon on database 16384 user 10
2023-11-25 13:00:58.963 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:00:58.963 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:373
2023-11-25 13:00:58.974 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:00:58.974 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:00:58.975 UTC [3976581] LOG:  00000: parameter "citus.metadata_sync_interval" changed to "3000"
2023-11-25 13:00:58.975 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:00:58.975 UTC [3976581] LOG:  00000: parameter "citus.metadata_sync_retry_interval" changed to "500"
2023-11-25 13:00:58.975 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:00:59.178 UTC [3976685] ERROR:  55000: disabling the first worker node in the metadata is not allowed
2023-11-25 13:00:59.178 UTC [3976685] DETAIL:  Citus uses the first worker node in the metadata for certain internal operations when replicated tables are modified. Synchronous mode ensures that all nodes have the same view of the first worker node, which is used for certain locking operations.
2023-11-25 13:00:59.178 UTC [3976685] HINT:  You can force disabling node, SELECT citus_disable_node('localhost', 57637, synchronous:=true);
2023-11-25 13:00:59.178 UTC [3976685] LOCATION:  citus_disable_node, node_metadata.c:542
2023-11-25 13:00:59.178 UTC [3976685] STATEMENT:  SELECT citus_disable_node('localhost', 57637);
2023-11-25 13:00:59.236 UTC [3976685] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 13:00:59.236 UTC [3976685] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 13:00:59.236 UTC [3976685] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 13:00:59.236 UTC [3976685] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 13:00:59.236 UTC [3976685] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 13:00:59.244 UTC [3976685] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 13:00:59.244 UTC [3976685] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 13:00:59.244 UTC [3976685] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 13:00:59.244 UTC [3976685] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 13:00:59.244 UTC [3976685] STATEMENT:  SELECT citus_remove_node('localhost', 57638);
2023-11-25 13:00:59.244 UTC [3976685] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 13:00:59.244 UTC [3976685] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 13:00:59.244 UTC [3976685] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 13:00:59.244 UTC [3976685] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 13:00:59.244 UTC [3976685] STATEMENT:  SELECT citus_disable_node('localhost', 57638);
2023-11-25 13:00:59.244 UTC [3976685] ERROR:  XX000: node at "localhost.noexist:2345" does not exist
2023-11-25 13:00:59.244 UTC [3976685] LOCATION:  ModifiableWorkerNode, node_metadata.c:732
2023-11-25 13:00:59.244 UTC [3976685] STATEMENT:  SELECT citus_disable_node('localhost.noexist', 2345);
2023-11-25 13:00:59.348 UTC [3976685] ERROR:  42501: permission denied for function master_add_inactive_node
2023-11-25 13:00:59.348 UTC [3976685] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:00:59.348 UTC [3976685] STATEMENT:  SELECT 1 FROM master_add_inactive_node('localhost', 57638 + 1);
2023-11-25 13:00:59.348 UTC [3976685] ERROR:  42501: permission denied for function master_activate_node
2023-11-25 13:00:59.348 UTC [3976685] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:00:59.348 UTC [3976685] STATEMENT:  SELECT 1 FROM master_activate_node('localhost', 57638 + 1);
2023-11-25 13:00:59.349 UTC [3976685] ERROR:  42501: permission denied for function citus_disable_node
2023-11-25 13:00:59.349 UTC [3976685] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:00:59.349 UTC [3976685] STATEMENT:  SELECT 1 FROM citus_disable_node('localhost', 57638 + 1);
2023-11-25 13:00:59.349 UTC [3976685] ERROR:  42501: permission denied for function master_remove_node
2023-11-25 13:00:59.349 UTC [3976685] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:00:59.349 UTC [3976685] STATEMENT:  SELECT 1 FROM master_remove_node('localhost', 57638 + 1);
2023-11-25 13:00:59.349 UTC [3976685] ERROR:  42501: permission denied for function master_add_node
2023-11-25 13:00:59.349 UTC [3976685] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:00:59.349 UTC [3976685] STATEMENT:  SELECT 1 FROM master_add_node('localhost', 57638 + 1);
2023-11-25 13:00:59.349 UTC [3976685] ERROR:  42501: permission denied for function master_add_secondary_node
2023-11-25 13:00:59.349 UTC [3976685] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:00:59.349 UTC [3976685] STATEMENT:  SELECT 1 FROM master_add_secondary_node('localhost', 57638 + 2, 'localhost', 57638);
2023-11-25 13:00:59.349 UTC [3976685] ERROR:  42501: permission denied for function master_update_node
2023-11-25 13:00:59.349 UTC [3976685] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:00:59.349 UTC [3976685] STATEMENT:  SELECT master_update_node(nodeid, 'localhost', 57638 + 3) FROM pg_dist_node WHERE nodeport = 57638;
2023-11-25 13:00:59.349 UTC [3976685] ERROR:  XX000: operation is not allowed
2023-11-25 13:00:59.349 UTC [3976685] HINT:  Run the command with a superuser.
2023-11-25 13:00:59.349 UTC [3976685] LOCATION:  EnsureSuperUser, metadata_utility.c:2299
2023-11-25 13:00:59.349 UTC [3976685] STATEMENT:  SELECT 1 FROM master_add_node('localhost', 57638);
2023-11-25 13:00:59.401 UTC [3976713] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 13:00:59.401 UTC [3976713] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 13:00:59.401 UTC [3976713] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 13:00:59.401 UTC [3976713] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 13:00:59.401 UTC [3976713] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 13:00:59.419 UTC [3976713] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 13:00:59.419 UTC [3976713] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 13:00:59.419 UTC [3976713] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 13:00:59.419 UTC [3976713] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 13:00:59.419 UTC [3976713] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 13:00:59.435 UTC [3976713] ERROR:  XX000: node group 5 does not have a primary node
2023-11-25 13:00:59.435 UTC [3976713] LOCATION:  LookupNodeForGroup, metadata_cache.c:1189
2023-11-25 13:00:59.435 UTC [3976713] STATEMENT:  SELECT * FROM cluster_management_test;
2023-11-25 13:00:59.448 UTC [3976713] ERROR:  XX000: there is a shard placement in node group 5 but there are no nodes in that group
2023-11-25 13:00:59.448 UTC [3976713] LOCATION:  LookupNodeForGroup, metadata_cache.c:1181
2023-11-25 13:00:59.448 UTC [3976713] STATEMENT:  SELECT * FROM cluster_management_test;
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220001
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220003
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220005
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220007
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220009
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220011
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220013
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.454 UTC [3976713] WARNING:  01000: could not find any shard placements for shardId 1220015
2023-11-25 13:00:59.454 UTC [3976713] LOCATION:  ShardPlacementList, metadata_cache.c:1247
2023-11-25 13:00:59.482 UTC [3976713] ERROR:  XX000: cannot remove or disable the node localhost:57638 because because it contains the only shard placement for shard 1220001
2023-11-25 13:00:59.482 UTC [3976713] DETAIL:  One of the table(s) that prevents the operation complete successfully is public.cluster_management_test
2023-11-25 13:00:59.482 UTC [3976713] HINT:  To proceed, either drop the tables or use undistribute_table() function to convert them to local tables
2023-11-25 13:00:59.482 UTC [3976713] LOCATION:  ErrorIfNodeContainsNonRemovablePlacements, node_metadata.c:1947
2023-11-25 13:00:59.482 UTC [3976713] STATEMENT:  SELECT master_remove_node('localhost', 57638);
2023-11-25 13:00:59.707 UTC [3976751] ERROR:  XX000: primaries must be added to the default cluster
2023-11-25 13:00:59.707 UTC [3976751] LOCATION:  AddNodeMetadata, node_metadata.c:2141
2023-11-25 13:00:59.707 UTC [3976751] STATEMENT:  SELECT master_add_node('localhost', 9999, nodecluster => 'olap');
2023-11-25 13:00:59.708 UTC [3976751] ERROR:  XX000: group 14 already has a primary node
2023-11-25 13:00:59.708 UTC [3976751] LOCATION:  AddNodeMetadata, node_metadata.c:2130
2023-11-25 13:00:59.708 UTC [3976751] STATEMENT:  SELECT master_add_node('localhost', 9999, groupid => 14, noderole => 'primary');
2023-11-25 13:00:59.711 UTC [3976751] ERROR:  P0001: there cannot be two primary nodes in a group
2023-11-25 13:00:59.711 UTC [3976751] CONTEXT:  PL/pgSQL function citus_internal.pg_dist_node_trigger_func() line 10 at RAISE
2023-11-25 13:00:59.711 UTC [3976751] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:00:59.711 UTC [3976751] STATEMENT:  INSERT INTO pg_dist_node (nodename, nodeport, groupid, noderole)
	  VALUES ('localhost', 5000, 14, 'primary');
2023-11-25 13:00:59.711 UTC [3976751] ERROR:  P0001: there cannot be two primary nodes in a group
2023-11-25 13:00:59.711 UTC [3976751] CONTEXT:  PL/pgSQL function citus_internal.pg_dist_node_trigger_func() line 18 at RAISE
2023-11-25 13:00:59.711 UTC [3976751] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:00:59.711 UTC [3976751] STATEMENT:  UPDATE pg_dist_node SET noderole = 'primary'
	  WHERE groupid = 14 AND nodeport = 9998;
2023-11-25 13:00:59.712 UTC [3976751] ERROR:  23514: new row for relation "pg_dist_node" violates check constraint "primaries_are_only_allowed_in_the_default_cluster"
2023-11-25 13:00:59.712 UTC [3976751] DETAIL:  Failing row contains (24, 1000, localhost, 5000, default, f, t, primary, olap, f, t).
2023-11-25 13:00:59.712 UTC [3976751] LOCATION:  ExecConstraints, execMain.c:2019
2023-11-25 13:00:59.712 UTC [3976751] STATEMENT:  INSERT INTO pg_dist_node (nodename, nodeport, groupid, noderole, nodecluster)
	  VALUES ('localhost', 5000, 1000, 'primary', 'olap');
2023-11-25 13:00:59.712 UTC [3976751] ERROR:  23514: new row for relation "pg_dist_node" violates check constraint "primaries_are_only_allowed_in_the_default_cluster"
2023-11-25 13:00:59.712 UTC [3976751] DETAIL:  Failing row contains (16, 14, localhost, 57637, default, f, t, primary, olap, f, t).
2023-11-25 13:00:59.712 UTC [3976751] LOCATION:  ExecConstraints, execMain.c:2019
2023-11-25 13:00:59.712 UTC [3976751] STATEMENT:  UPDATE pg_dist_node SET nodecluster = 'olap'
	  WHERE nodeport = 57637;
2023-11-25 13:00:59.713 UTC [3976751] ERROR:  XX000: node at "localhost:2000" does not exist
2023-11-25 13:00:59.713 UTC [3976751] LOCATION:  GroupForNode, node_metadata.c:801
2023-11-25 13:00:59.713 UTC [3976751] STATEMENT:  SELECT master_add_secondary_node('localhost', 9993, 'localhost', 2000);
2023-11-25 13:00:59.714 UTC [3976751] ERROR:  P0002: node 100 not found
2023-11-25 13:00:59.714 UTC [3976751] LOCATION:  citus_update_node, node_metadata.c:1216
2023-11-25 13:00:59.714 UTC [3976751] STATEMENT:  SELECT master_update_node(100, 'localhost', 8000);
2023-11-25 13:00:59.715 UTC [3976751] ERROR:  55000: there is already another node with the specified hostname and port
2023-11-25 13:00:59.715 UTC [3976751] LOCATION:  citus_update_node, node_metadata.c:1207
2023-11-25 13:00:59.715 UTC [3976751] STATEMENT:  SELECT master_update_node(16, 'localhost', 57638);
2023-11-25 13:00:59.786 UTC [3976751] ERROR:  XX000: only the 'shouldhaveshards' property can be set using this function
2023-11-25 13:00:59.786 UTC [3976751] LOCATION:  citus_set_node_property, node_metadata.c:695
2023-11-25 13:00:59.786 UTC [3976751] STATEMENT:  SELECT * from master_set_node_property('localhost', 57638, 'bogusproperty', false);
2023-11-25 13:00:59.828 UTC [3976751] ERROR:  XX000: do not sync metadata in transaction block when the sync mode is nontransactional
2023-11-25 13:00:59.828 UTC [3976751] HINT:  resync after SET citus.metadata_sync_mode TO 'transactional'
2023-11-25 13:00:59.828 UTC [3976751] LOCATION:  ActivateNodeList, node_metadata.c:1061
2023-11-25 13:00:59.828 UTC [3976751] STATEMENT:  SELECT start_metadata_sync_to_all_nodes();
2023-11-25 13:00:59.873 UTC [3976751] ERROR:  XX000: do not add node in transaction block when the sync mode is nontransactional
2023-11-25 13:00:59.873 UTC [3976751] HINT:  add the node after SET citus.metadata_sync_mode TO 'transactional'
2023-11-25 13:00:59.873 UTC [3976751] LOCATION:  citus_add_node, node_metadata.c:322
2023-11-25 13:00:59.873 UTC [3976751] STATEMENT:  SELECT citus_add_node('localhost', 57637);
2023-11-25 13:00:59.972 UTC [3976780] ERROR:  42601: syntax error at or near ""123"" at character 37
2023-11-25 13:00:59.972 UTC [3976780] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:00:59.972 UTC [3976780] STATEMENT:  CREATE ROLE create_role_sysid SYSID "123";
2023-11-25 13:01:00.334 UTC [3976837] ERROR:  42704: role "nonexisting_role_2" does not exist
2023-11-25 13:01:00.334 UTC [3976837] LOCATION:  get_role_oid, acl.c:5184
2023-11-25 13:01:00.334 UTC [3976837] STATEMENT:  GRANT existing_role_1, nonexisting_role_1 TO existing_role_2, nonexisting_role_2;
2023-11-25 13:01:00.342 UTC [3976841] ERROR:  42704: role "nonexisting_role_1" does not exist
2023-11-25 13:01:00.342 UTC [3976841] LOCATION:  DropRole, user.c:951
2023-11-25 13:01:00.342 UTC [3976841] STATEMENT:  DROP ROLE existing_role_1, existing_role_2, nonexisting_role_1, nonexisting_role_2;
2023-11-25 13:01:01.030 UTC [3976970] ERROR:  42P16: cannot distribute relation "data_load_test"
2023-11-25 13:01:01.030 UTC [3976970] DETAIL:  Relation "data_load_test" contains data.
2023-11-25 13:01:01.030 UTC [3976970] HINT:  Empty your table before distributing it.
2023-11-25 13:01:01.030 UTC [3976970] LOCATION:  EnsureLocalTableEmpty, create_distributed_table.c:2032
2023-11-25 13:01:01.030 UTC [3976970] STATEMENT:  SELECT create_distributed_table('data_load_test', 'col1', 'append');
2023-11-25 13:01:01.039 UTC [3976970] ERROR:  42P16: cannot distribute relation "data_load_test"
2023-11-25 13:01:01.039 UTC [3976970] DETAIL:  Relation "data_load_test" contains data.
2023-11-25 13:01:01.039 UTC [3976970] HINT:  Empty your table before distributing it.
2023-11-25 13:01:01.039 UTC [3976970] LOCATION:  EnsureLocalTableEmpty, create_distributed_table.c:2032
2023-11-25 13:01:01.039 UTC [3976970] STATEMENT:  SELECT create_distributed_table('data_load_test', 'col1', 'range');
2023-11-25 13:01:01.187 UTC [3976970] ERROR:  0A000: cannot create a citus table from a catalog table
2023-11-25 13:01:01.187 UTC [3976970] LOCATION:  ErrorIfTableIsACatalogTable, create_distributed_table.c:1968
2023-11-25 13:01:01.187 UTC [3976970] STATEMENT:  SELECT create_distributed_table('pg_class', 'relname');
2023-11-25 13:01:01.187 UTC [3976970] ERROR:  0A000: cannot create a citus table from a catalog table
2023-11-25 13:01:01.187 UTC [3976970] LOCATION:  ErrorIfTableIsACatalogTable, create_distributed_table.c:1968
2023-11-25 13:01:01.187 UTC [3976970] STATEMENT:  SELECT create_reference_table('pg_class');
2023-11-25 13:01:01.198 UTC [3976970] ERROR:  XX000: 0 is outside the valid range for parameter "shard_count" (1 .. 64000)
2023-11-25 13:01:01.198 UTC [3976970] LOCATION:  create_distributed_table, create_distributed_table.c:276
2023-11-25 13:01:01.198 UTC [3976970] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=0);
2023-11-25 13:01:01.198 UTC [3976970] ERROR:  XX000: -100 is outside the valid range for parameter "shard_count" (1 .. 64000)
2023-11-25 13:01:01.198 UTC [3976970] LOCATION:  create_distributed_table, create_distributed_table.c:276
2023-11-25 13:01:01.198 UTC [3976970] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=-100);
2023-11-25 13:01:01.199 UTC [3976970] ERROR:  XX000: 64001 is outside the valid range for parameter "shard_count" (1 .. 64000)
2023-11-25 13:01:01.199 UTC [3976970] LOCATION:  create_distributed_table, create_distributed_table.c:276
2023-11-25 13:01:01.199 UTC [3976970] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=64001);
2023-11-25 13:01:01.199 UTC [3976970] ERROR:  XX000: Cannot use colocate_with with a table and shard_count at the same time
2023-11-25 13:01:01.199 UTC [3976970] LOCATION:  create_distributed_table, create_distributed_table.c:237
2023-11-25 13:01:01.199 UTC [3976970] STATEMENT:  SELECT create_distributed_table('shard_count_table_2', 'a', shard_count:=12, colocate_with:='shard_count');
2023-11-25 13:01:01.244 UTC [3976970] LOG:  00000: performing blocking isolate_tenant_to_new_shard 
2023-11-25 13:01:01.244 UTC [3976970] LOCATION:  SplitShard, shard_split.c:507
2023-11-25 13:01:01.244 UTC [3976970] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:01:01.245 UTC [3976970] LOG:  00000: creating child shards for isolate_tenant_to_new_shard
2023-11-25 13:01:01.245 UTC [3976970] LOCATION:  BlockingShardSplit, shard_split.c:571
2023-11-25 13:01:01.245 UTC [3976970] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:01:01.253 UTC [3976970] LOG:  00000: performing copy for isolate_tenant_to_new_shard
2023-11-25 13:01:01.253 UTC [3976970] LOCATION:  BlockingShardSplit, shard_split.c:577
2023-11-25 13:01:01.253 UTC [3976970] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:01:01.254 UTC [3976970] LOG:  00000: creating auxillary structures (indexes, stats, replicaindentities, triggers) for isolate_tenant_to_new_shard
2023-11-25 13:01:01.254 UTC [3976970] LOCATION:  BlockingShardSplit, shard_split.c:587
2023-11-25 13:01:01.254 UTC [3976970] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:01:01.254 UTC [3976970] LOG:  00000: marking deferred cleanup of source shard(s) for isolate_tenant_to_new_shard
2023-11-25 13:01:01.254 UTC [3976970] LOCATION:  BlockingShardSplit, shard_split.c:609
2023-11-25 13:01:01.254 UTC [3976970] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:01:01.255 UTC [3976970] LOG:  00000: creating foreign key constraints (if any) for isolate_tenant_to_new_shard
2023-11-25 13:01:01.255 UTC [3976970] LOCATION:  BlockingShardSplit, shard_split.c:625
2023-11-25 13:01:01.255 UTC [3976970] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:01:01.314 UTC [3976970] ERROR:  0A000: cannot distribute a temporary table
2023-11-25 13:01:01.314 UTC [3976970] LOCATION:  ErrorIfTemporaryTable, create_distributed_table.c:1950
2023-11-25 13:01:01.314 UTC [3976970] STATEMENT:  select create_distributed_table('temp_table', 'a');
2023-11-25 13:01:01.314 UTC [3976970] ERROR:  0A000: cannot distribute a temporary table
2023-11-25 13:01:01.314 UTC [3976970] LOCATION:  ErrorIfTemporaryTable, create_distributed_table.c:1950
2023-11-25 13:01:01.314 UTC [3976970] STATEMENT:  select create_reference_table('temp_table');
2023-11-25 13:01:02.338 UTC [3977202] WARNING:  0A000: table "uniq_cns_append_tables" has a UNIQUE or EXCLUDE constraint
2023-11-25 13:01:02.338 UTC [3977202] DETAIL:  UNIQUE constraints, EXCLUDE constraints, and PRIMARY KEYs on append-partitioned tables cannot be enforced.
2023-11-25 13:01:02.338 UTC [3977202] HINT:  Consider using hash partitioning.
2023-11-25 13:01:02.338 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:2975
2023-11-25 13:01:02.340 UTC [3977202] WARNING:  0A000: table "excl_cns_append_tables" has a UNIQUE or EXCLUDE constraint
2023-11-25 13:01:02.340 UTC [3977202] DETAIL:  UNIQUE constraints, EXCLUDE constraints, and PRIMARY KEYs on append-partitioned tables cannot be enforced.
2023-11-25 13:01:02.340 UTC [3977202] HINT:  Consider using hash partitioning.
2023-11-25 13:01:02.340 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:2975
2023-11-25 13:01:02.347 UTC [3977202] ERROR:  0A000: cannot create constraint on "pk_on_non_part_col"
2023-11-25 13:01:02.347 UTC [3977202] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 13:01:02.347 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 13:01:02.347 UTC [3977202] STATEMENT:  SELECT create_distributed_table('pk_on_non_part_col', 'partition_col', 'hash');
2023-11-25 13:01:02.399 UTC [3977202] ERROR:  23505: duplicate key value violates unique constraint "pk_on_non_part_col_pkey_365000"
2023-11-25 13:01:02.399 UTC [3977202] DETAIL:  Key (other_col)=(1) already exists.
2023-11-25 13:01:02.399 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.399 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.399 UTC [3977202] STATEMENT:  INSERT INTO pk_on_non_part_col VALUES (1,1);
2023-11-25 13:01:02.410 UTC [3977202] ERROR:  0A000: cannot create constraint on "uq_on_non_part_col"
2023-11-25 13:01:02.410 UTC [3977202] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 13:01:02.410 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 13:01:02.410 UTC [3977202] STATEMENT:  SELECT create_distributed_table('uq_on_non_part_col', 'partition_col', 'hash');
2023-11-25 13:01:02.413 UTC [3977202] ERROR:  0A000: cannot create constraint on "ex_on_non_part_col"
2023-11-25 13:01:02.413 UTC [3977202] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 13:01:02.413 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 13:01:02.413 UTC [3977202] STATEMENT:  SELECT create_distributed_table('ex_on_non_part_col', 'partition_col', 'hash');
2023-11-25 13:01:02.442 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_non_part_col_other_col_excl_365004"
2023-11-25 13:01:02.442 UTC [3977202] DETAIL:  Key (other_col)=(1) conflicts with existing key (other_col)=(1).
2023-11-25 13:01:02.442 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.442 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.442 UTC [3977202] STATEMENT:  INSERT INTO ex_on_non_part_col VALUES (1,1);
2023-11-25 13:01:02.495 UTC [3977202] ERROR:  23505: duplicate key value violates unique constraint "uq_two_columns_partition_col_other_col_key_365016"
2023-11-25 13:01:02.495 UTC [3977202] DETAIL:  Key (partition_col, other_col)=(1, 1) already exists.
2023-11-25 13:01:02.495 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.495 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.495 UTC [3977202] STATEMENT:  INSERT INTO uq_two_columns (partition_col, other_col) VALUES (1,1);
2023-11-25 13:01:02.576 UTC [3977202] ERROR:  0A000: cannot create constraint on "pk_on_two_non_part_cols"
2023-11-25 13:01:02.576 UTC [3977202] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 13:01:02.576 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 13:01:02.576 UTC [3977202] STATEMENT:  SELECT create_distributed_table('pk_on_two_non_part_cols', 'partition_col', 'hash');
2023-11-25 13:01:02.602 UTC [3977202] ERROR:  23505: duplicate key value violates unique constraint "pk_on_two_non_part_cols_pkey_365020"
2023-11-25 13:01:02.602 UTC [3977202] DETAIL:  Key (other_col, other_col_2)=(1, 1) already exists.
2023-11-25 13:01:02.602 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.602 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.602 UTC [3977202] STATEMENT:  INSERT INTO pk_on_two_non_part_cols VALUES (1,1,1);
2023-11-25 13:01:02.625 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_part_col_partition_col_excl_365024"
2023-11-25 13:01:02.625 UTC [3977202] DETAIL:  Key (partition_col)=(1) conflicts with existing key (partition_col)=(1).
2023-11-25 13:01:02.625 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.625 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.625 UTC [3977202] STATEMENT:  INSERT INTO ex_on_part_col (partition_col, other_col) VALUES (1,2);
2023-11-25 13:01:02.640 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_two_columns_partition_col_other_col_excl_365028"
2023-11-25 13:01:02.640 UTC [3977202] DETAIL:  Key (partition_col, other_col)=(1, 1) conflicts with existing key (partition_col, other_col)=(1, 1).
2023-11-25 13:01:02.640 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.640 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.640 UTC [3977202] STATEMENT:  INSERT INTO ex_on_two_columns (partition_col, other_col) VALUES (1,1);
2023-11-25 13:01:02.659 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_two_columns_prt_partition_col_other_col_excl_365032"
2023-11-25 13:01:02.659 UTC [3977202] DETAIL:  Key (partition_col, other_col)=(1, 101) conflicts with existing key (partition_col, other_col)=(1, 101).
2023-11-25 13:01:02.659 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.659 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.659 UTC [3977202] STATEMENT:  INSERT INTO ex_on_two_columns_prt (partition_col, other_col) VALUES (1,101);
2023-11-25 13:01:02.662 UTC [3977202] ERROR:  0A000: cannot create constraint on "ex_wrong_operator"
2023-11-25 13:01:02.662 UTC [3977202] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 13:01:02.662 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 13:01:02.662 UTC [3977202] STATEMENT:  SELECT create_distributed_table('ex_wrong_operator', 'partition_col', 'hash');
2023-11-25 13:01:02.682 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_overlaps_other_col_partition_col_excl_365039"
2023-11-25 13:01:02.682 UTC [3977202] DETAIL:  Key (other_col, partition_col)=(["2016-01-15 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]) conflicts with existing key (other_col, partition_col)=(["2016-01-01 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]).
2023-11-25 13:01:02.682 UTC [3977202] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:02.682 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.682 UTC [3977202] STATEMENT:  INSERT INTO ex_overlaps (partition_col, other_col) VALUES ('[2016-01-01 00:00:00, 2016-02-01 00:00:00]', '[2016-01-15 00:00:00, 2016-02-01 00:00:00]');
2023-11-25 13:01:02.721 UTC [3977202] ERROR:  23505: duplicate key value violates unique constraint "uq_two_columns_named_uniq_365048"
2023-11-25 13:01:02.721 UTC [3977202] DETAIL:  Key (partition_col, other_col)=(1, 1) already exists.
2023-11-25 13:01:02.721 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.721 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.721 UTC [3977202] STATEMENT:  INSERT INTO uq_two_columns_named (partition_col, other_col) VALUES (1,1);
2023-11-25 13:01:02.733 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_part_col_named_exclude_365052"
2023-11-25 13:01:02.733 UTC [3977202] DETAIL:  Key (partition_col)=(1) conflicts with existing key (partition_col)=(1).
2023-11-25 13:01:02.733 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.733 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.733 UTC [3977202] STATEMENT:  INSERT INTO ex_on_part_col_named (partition_col, other_col) VALUES (1,2);
2023-11-25 13:01:02.746 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_on_two_columns_named_exclude_365056"
2023-11-25 13:01:02.746 UTC [3977202] DETAIL:  Key (partition_col, other_col)=(1, 1) conflicts with existing key (partition_col, other_col)=(1, 1).
2023-11-25 13:01:02.746 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.746 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.746 UTC [3977202] STATEMENT:  INSERT INTO ex_on_two_columns_named (partition_col, other_col) VALUES (1,1);
2023-11-25 13:01:02.761 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_multiple_excludes_excl1_365060"
2023-11-25 13:01:02.761 UTC [3977202] DETAIL:  Key (partition_col, other_col)=(1, 1) conflicts with existing key (partition_col, other_col)=(1, 1).
2023-11-25 13:01:02.761 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.761 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.761 UTC [3977202] STATEMENT:  INSERT INTO ex_multiple_excludes (partition_col, other_col, other_other_col) VALUES (1,1,2);
2023-11-25 13:01:02.761 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_multiple_excludes_excl2_365060"
2023-11-25 13:01:02.761 UTC [3977202] DETAIL:  Key (partition_col, other_other_col)=(1, 1) conflicts with existing key (partition_col, other_other_col)=(1, 1).
2023-11-25 13:01:02.761 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.761 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.761 UTC [3977202] STATEMENT:  INSERT INTO ex_multiple_excludes (partition_col, other_col, other_other_col) VALUES (1,2,1);
2023-11-25 13:01:02.763 UTC [3977202] ERROR:  0A000: cannot create constraint on "ex_wrong_operator_named"
2023-11-25 13:01:02.763 UTC [3977202] DETAIL:  Distributed relations cannot have UNIQUE, EXCLUDE, or PRIMARY KEY constraints that do not include the partition column (with an equality operator if EXCLUDE).
2023-11-25 13:01:02.763 UTC [3977202] LOCATION:  ErrorIfUnsupportedConstraint, table.c:3021
2023-11-25 13:01:02.763 UTC [3977202] STATEMENT:  SELECT create_distributed_table('ex_wrong_operator_named', 'partition_col', 'hash');
2023-11-25 13:01:02.776 UTC [3977202] ERROR:  23P01: conflicting key value violates exclusion constraint "ex_overlaps_operator_named_exclude_365067"
2023-11-25 13:01:02.776 UTC [3977202] DETAIL:  Key (other_col, partition_col)=(["2016-01-15 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]) conflicts with existing key (other_col, partition_col)=(["2016-01-01 00:00:00","2016-02-01 00:00:00"], ["2016-01-01 00:00:00","2016-02-01 00:00:00"]).
2023-11-25 13:01:02.776 UTC [3977202] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:02.776 UTC [3977202] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:02.776 UTC [3977202] STATEMENT:  INSERT INTO ex_overlaps_named (partition_col, other_col) VALUES ('[2016-01-01 00:00:00, 2016-02-01 00:00:00]', '[2016-01-15 00:00:00, 2016-02-01 00:00:00]');
2023-11-25 13:01:02.931 UTC [3977298] ERROR:  2BP01: cannot drop table raw_table_1 because other objects depend on it
2023-11-25 13:01:02.931 UTC [3977298] DETAIL:  constraint raw_table_2_user_id_fkey on table raw_table_2 depends on table raw_table_1
2023-11-25 13:01:02.931 UTC [3977298] HINT:  Use DROP ... CASCADE to drop the dependent objects too.
2023-11-25 13:01:02.931 UTC [3977298] LOCATION:  reportDependentObjects, dependency.c:1189
2023-11-25 13:01:02.931 UTC [3977298] STATEMENT:  DROP TABLE raw_table_1;
2023-11-25 13:01:03.171 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:03.171 UTC [3977387] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:03.171 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg)
	SELECT user_id, array_length(events_table, 1)
	FROM (
	  SELECT user_id, array_agg(event ORDER BY time) AS events_table
	  FROM (
	    SELECT u.user_id, e.event_type::text AS event, e.time
	    FROM users_table AS u,
	         events_table AS e
	    WHERE u.user_id != e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (100, 101, 102)
	  ) t
	  GROUP BY user_id
	) q;
2023-11-25 13:01:03.174 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:03.174 UTC [3977387] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:03.174 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg, value_2_agg )
	SELECT user_id, sum(array_length(events_table, 1)), length(hasdone_event)
	FROM (
	  SELECT
	    t1.user_id,
	    array_agg(event ORDER BY time) AS events_table,
	    COALESCE(hasdone_event, 'Has not done event') AS hasdone_event
	  FROM (
	    (
	      SELECT u.user_id, 'step=>1'::text AS event, e.time
	      FROM users_table AS u,
	          events_table AS e
	      WHERE  u.user_id != e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (100, 101, 102)
	    )
	    UNION
	    (
	      SELECT u.user_id, 'step=>2'::text AS event, e.time
	      FROM users_table AS u,
	         events_table AS e
	      WHERE  u.user_id = e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (103, 104, 105)
	    )
	  ) t1 LEFT JOIN (
	      SELECT DISTINCT user_id,
	        'Has done event'::TEXT AS hasdone_event
	      FROM  events_table AS e
	      WHERE  e.user_id >= 10
	      AND e.user_id <= 25
	      AND e.event_type IN (106, 107, 108)
	  ) t2 ON (t1.user_id = t2.user_id)
	  GROUP BY  t1.user_id, hasdone_event
	) t GROUP BY user_id, hasdone_event;
2023-11-25 13:01:03.177 UTC [3977387] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:03.177 UTC [3977387] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:03.177 UTC [3977387] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:03.177 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg, value_2_agg )
	SELECT user_id, sum(array_length(events_table, 1)), length(hasdone_event)
	FROM (
	  SELECT
	    t1.user_id,
	    array_agg(event ORDER BY time) AS events_table,
	    COALESCE(hasdone_event, 'Has not done event') AS hasdone_event
	  FROM (
	    (
	      SELECT u.user_id, 'step=>1'::text AS event, e.time
	      FROM users_table AS u,
	          events_table AS e
	      WHERE  u.user_id = e.user_id
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (100, 101, 102)
	    )
	    UNION
	    (
	      SELECT u.user_id, 'step=>2'::text AS event, e.time
	      FROM users_table AS u,
	         events_table AS e
	      WHERE  u.user_id = e.event_type
	      AND u.user_id >= 10
	      AND u.user_id <= 25
	      AND e.event_type IN (103, 104, 105)
	    )
	  ) t1 LEFT JOIN (
	      SELECT DISTINCT user_id,
	        'Has done event'::TEXT AS hasdone_event
	      FROM  events_table AS e
	      WHERE  e.user_id >= 10
	      AND e.user_id <= 25
	      AND e.event_type IN (106, 107, 108)
	  ) t2 ON (t1.user_id = t2.user_id)
	  GROUP BY  t1.user_id, hasdone_event
	) t GROUP BY user_id, hasdone_event;
2023-11-25 13:01:03.202 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:03.202 UTC [3977387] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:03.202 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third (user_id, value_1_agg, value_2_agg)
	SELECT
	  user_id,
	  avg(array_length(events_table, 1)) AS event_average,
	  count_pay
	  FROM (
	  SELECT
	  subquery_1.user_id,
	  array_agg(event ORDER BY time) AS events_table,
	  COALESCE(count_pay, 0) AS count_pay
	  FROM
	  (
	    (SELECT
	      users_table.user_id,
	      'action=>1'AS event,
	      events_table.time
	    FROM
	      users_table,
	      events_table
	    WHERE
	      users_table.user_id = events_table.user_id AND
	      users_table.user_id >= 10 AND
	      users_table.user_id <= 70 AND
	      events_table.event_type > 10 AND events_table.event_type < 12
	      )
	    UNION
	    (SELECT
	      users_table.user_id,
	      'action=>2'AS event,
	      events_table.time
	    FROM
	      users_table,
	      events_table
	    WHERE
	      users_table.user_id != events_table.user_id AND
	      users_table.user_id >= 10 AND
	      users_table.user_id <= 70 AND
	      events_table.event_type > 12 AND events_table.event_type < 14
	    )
	  ) AS subquery_1
	  LEFT JOIN
	    (SELECT
	       user_id,
	      COUNT(*) AS count_pay
	    FROM
	      users_table
	    WHERE
	      user_id >= 10 AND
	      user_id <= 70 AND
	      users_table.value_1 > 15 AND users_table.value_1 < 17
	    GROUP BY
	      user_id
	    HAVING
	      COUNT(*) > 1) AS subquery_2
	  ON
	    subquery_1.user_id = subquery_2.user_id
	  GROUP BY
	    subquery_1.user_id,
	    count_pay) AS subquery_top
	WHERE
	  array_ndims(events_table) > 0
	GROUP BY
	  count_pay, user_id
	ORDER BY
	  count_pay;
2023-11-25 13:01:03.219 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.219 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.219 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third (user_id, agg_time, value_2_agg)
	SELECT
	    user_id,
	    user_lastseen,
	    array_length(event_array, 1)
	FROM (
	    SELECT
	        user_id,
	        max(u.time) as user_lastseen,
	        array_agg(event_type ORDER BY u.time) AS event_array
	    FROM (
	        SELECT user_id, time
	        FROM users_table
	        WHERE
	        user_id >= 10 AND
	        user_id <= 70 AND
	        users_table.value_1 > 10 AND users_table.value_1 < 12
	        ) u LEFT JOIN LATERAL (
	          SELECT event_type, time
	          FROM events_table
	          WHERE user_id != u.user_id AND
	          events_table.event_type > 10 AND events_table.event_type < 12
	        ) t ON true
	        GROUP BY user_id
	) AS shard_union
	ORDER BY user_lastseen DESC;
2023-11-25 13:01:03.221 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.221 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.221 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third (user_id, agg_time, value_2_agg)
	SELECT
	    user_id,
	    user_lastseen,
	    array_length(event_array, 1)
	FROM (
	    SELECT
	        user_id,
	        max(u.time) as user_lastseen,
	        array_agg(event_type ORDER BY u.time) AS event_array
	    FROM (
	        SELECT user_id, time
	        FROM users_table
	        WHERE
	        user_id >= 10 AND
	        user_id <= 70 AND
	        users_table.value_1 > 10 AND users_table.value_1 < 12
	        ) u LEFT JOIN LATERAL (
	          SELECT event_type, time
	          FROM events_table
	          WHERE event_type = u.user_id AND
	          events_table.event_type > 10 AND events_table.event_type < 12
	        ) t ON true
	        GROUP BY user_id
	) AS shard_union
	ORDER BY user_lastseen DESC;
2023-11-25 13:01:03.222 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.222 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.222 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third (user_id, agg_time, value_2_agg)
	SELECT
	    user_id,
	    user_lastseen,
	    array_length(event_array, 1)
	FROM (
	    SELECT
	        user_id,
	        max(u.time) as user_lastseen,
	        array_agg(event_type ORDER BY u.time) AS event_array
	    FROM (
	        SELECT user_id, time, value_3 as val_3
	        FROM users_table
	        WHERE
	        user_id >= 10 AND
	        user_id <= 70 AND
	        users_table.value_1 > 10 AND users_table.value_1 < 12
	        ) u LEFT JOIN LATERAL (
	          SELECT event_type, time
	          FROM events_table
	          WHERE event_type = u.val_3 AND
	          events_table.event_type > 10 AND events_table.event_type < 12
	        ) t ON true
	        GROUP BY user_id
	) AS shard_union
	ORDER BY user_lastseen DESC;
2023-11-25 13:01:03.246 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.246 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.246 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 101 AND value_1 < 110
	  AND value_2 >= 5
	  AND EXISTS (SELECT user_id FROM events_table WHERE event_type>101  AND event_type < 110 AND value_3 > 100 AND user_id!=users_table.user_id);
2023-11-25 13:01:03.247 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.247 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.247 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 101 AND value_1 < 110
	  AND value_2 >= 5
	  AND EXISTS (SELECT user_id FROM events_table WHERE event_type>101  AND event_type < 110 AND value_3 > 100 AND event_type = users_table.user_id);
2023-11-25 13:01:03.247 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.247 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.247 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 = 101
	  AND value_2 >= 5
	  AND NOT EXISTS (SELECT user_id FROM events_table WHERE event_type=101 AND value_3 > 100 AND user_id!=users_table.user_id);
2023-11-25 13:01:03.248 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.248 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.248 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 = 101
	  AND value_2 >= 5
	  AND NOT EXISTS (SELECT user_id FROM events_table WHERE event_type=101 AND value_3 > 100 AND event_type=users_table.user_id);
2023-11-25 13:01:03.249 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.249 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.249 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 100
	  AND value_2 >= 5
	  AND  EXISTS (SELECT user_id FROM events_table WHERE event_type!=100 AND value_3 > 100 AND user_id=users_table.user_id)
	  AND  EXISTS (SELECT user_id FROM events_table WHERE event_type=101 AND value_3 > 100 AND user_id!=users_table.user_id);
2023-11-25 13:01:03.250 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.250 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.250 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	SELECT user_id, value_2 FROM users_table WHERE
	  value_2 >= 5
	  AND  EXISTS (SELECT user_id FROM events_table WHERE event_type > 100 AND event_type <= 300 AND value_3 > 100 AND user_id!=users_table.user_id)
	  AND  NOT EXISTS (SELECT user_id FROM events_table WHERE event_type > 300 AND event_type <= 350  AND value_3 > 100 AND user_id=users_table.user_id);
2023-11-25 13:01:03.251 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.251 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.251 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	  SELECT user_id,
	         value_2
	  FROM   users_table
	  WHERE  value_1 > 100
	         AND value_1 < 124
	         AND value_2 >= 5
	         AND EXISTS (SELECT user_id
	                     FROM   events_table
	                     WHERE  event_type > 100
	                            AND event_type < 124
	                            AND value_3 > 100
	                            AND user_id != users_table.user_id
	                     GROUP  BY user_id
	                     HAVING Count(*) > 2);
2023-11-25 13:01:03.251 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.251 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.251 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	  SELECT user_id,
	         value_2
	  FROM   users_table
	  WHERE  value_1 > 100
	         AND value_1 < 124
	         AND value_2 >= 5
	         AND EXISTS (SELECT user_id
	                     FROM   events_table
	                     WHERE  event_type > 100
	                            AND event_type < 124
	                            AND value_3 > 100
	                            AND event_type = users_table.user_id
	                     GROUP  BY user_id
	                     HAVING Count(*) > 2);
2023-11-25 13:01:03.252 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.252 UTC [3977387] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.252 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_2_agg)
	  SELECT user_id,
	         value_2
	  FROM   users_table
	  WHERE  value_1 > 100
	         AND value_1 < 124
	         AND value_2 >= 5
	         AND EXISTS (SELECT user_id
	                     FROM   events_table
	                     WHERE  event_type > 100
	                            AND event_type < 124
	                            AND value_3 > 100
	                            AND user_id = users_table.value_1
	                     GROUP  BY user_id
	                     HAVING Count(*) > 2);
2023-11-25 13:01:03.280 UTC [3977387] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:03.280 UTC [3977387] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:03.280 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_1_agg, value_3_agg)
	SELECT
	    users_table.user_id, users_table.value_1, prob
	FROM
	   users_table
	        JOIN
	   (SELECT
	      ma.user_id, (GREATEST(coalesce(ma.value_4 / 250, 0.0) + GREATEST(1.0))) / 2 AS prob
	    FROM
	      users_table AS ma, events_table as short_list
	    WHERE
	      short_list.user_id != ma.user_id and ma.value_1 < 50 and short_list.event_type < 50
	    ) temp
	  ON users_table.user_id = temp.user_id
	  WHERE users_table.value_1 < 50;
2023-11-25 13:01:03.282 UTC [3977387] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:03.282 UTC [3977387] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:03.282 UTC [3977387] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:03.282 UTC [3977387] STATEMENT:  INSERT INTO agg_results_third(user_id, value_1_agg, value_3_agg)
	SELECT
	    users_table.user_id, users_table.value_1, prob
	FROM
	   users_table
	        JOIN
	   (SELECT
	      ma.user_id, (GREATEST(coalesce(ma.value_4 / 250, 0.0) + GREATEST(1.0))) / 2 AS prob
	    FROM
	      users_table AS ma, events_table as short_list
	    WHERE
	      short_list.user_id = ma.value_2 and ma.value_1 < 50 and short_list.event_type < 50
	    ) temp
	  ON users_table.user_id = temp.user_id
	  WHERE users_table.value_1 < 50;
2023-11-25 13:01:03.305 UTC [3977385] ERROR:  23505: duplicate key value violates unique constraint "raw_events_second_user_id_value_1_key_13300004"
2023-11-25 13:01:03.305 UTC [3977385] DETAIL:  Key (user_id, value_1)=(1, 10) already exists.
2023-11-25 13:01:03.305 UTC [3977385] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:03.305 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:03.305 UTC [3977385] STATEMENT:  INSERT INTO raw_events_second  SELECT * FROM raw_events_first;
2023-11-25 13:01:03.351 UTC [3977385] ERROR:  42883: function multi_insert_select.evaluate_on_master(integer) does not exist
2023-11-25 13:01:03.351 UTC [3977385] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:03.351 UTC [3977385] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:03.351 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:03.351 UTC [3977385] STATEMENT:  INSERT INTO raw_events_second (user_id, value_1)
	SELECT
	  user_id, evaluate_on_master(value_1)
	FROM
	  raw_events_first
	WHERE
	  user_id = 0;
2023-11-25 13:01:03.383 UTC [3977385] ERROR:  23505: duplicate key value violates unique constraint "raw_events_second_user_id_value_1_key_13300007"
2023-11-25 13:01:03.383 UTC [3977385] DETAIL:  Key (user_id, value_1)=(9, 90) already exists.
2023-11-25 13:01:03.383 UTC [3977385] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:03.383 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:03.383 UTC [3977385] STATEMENT:  INSERT INTO raw_events_second (user_id, value_1, value_3)
	SELECT
	   user_id, value_1, value_3
	FROM
	   raw_events_first
	WHERE
	   user_id = 9 OR user_id = 16
	RETURNING *;
2023-11-25 13:01:03.407 UTC [3977385] ERROR:  23505: duplicate key value violates unique constraint "agg_events_user_id_value_1_agg_key_13300008"
2023-11-25 13:01:03.407 UTC [3977385] DETAIL:  Key (user_id, value_1_agg)=(1, 10) already exists.
2023-11-25 13:01:03.407 UTC [3977385] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:03.407 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:03.407 UTC [3977385] STATEMENT:  INSERT INTO agg_events (value_3_agg, value_4_agg, value_1_agg, user_id)
	SELECT
	   sum(value_3), count(value_4), sum(value_1), user_id
	FROM
	   raw_events_first
	GROUP BY
	   value_2, user_id
	RETURNING *;
2023-11-25 13:01:03.412 UTC [3977385] ERROR:  23505: duplicate key value violates unique constraint "agg_events_user_id_value_1_agg_key_13300008"
2023-11-25 13:01:03.412 UTC [3977385] DETAIL:  Key (user_id, value_1_agg)=(1, 10) already exists.
2023-11-25 13:01:03.412 UTC [3977385] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:03.412 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:03.412 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	            (value_1_agg,
	             user_id)
	SELECT SUM(value_1),
	       id
	FROM   (SELECT raw_events_second.user_id AS id,
	               raw_events_second.value_1
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id = raw_events_second.user_id) AS foo
	GROUP  BY id
	ORDER  BY id;
2023-11-25 13:01:03.417 UTC [3977385] ERROR:  23505: duplicate key value violates unique constraint "agg_events_user_id_value_1_agg_key_13300008"
2023-11-25 13:01:03.417 UTC [3977385] DETAIL:  Key (user_id, value_1_agg)=(1, 10) already exists.
2023-11-25 13:01:03.417 UTC [3977385] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:03.417 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:03.417 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	            (value_4_agg,
	             value_1_agg,
	             user_id)
	SELECT v4,
	       v1,
	       id
	FROM   (SELECT SUM(raw_events_second.value_4) AS v4,
	               SUM(raw_events_first.value_1) AS v1,
	               raw_events_second.user_id      AS id
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id = raw_events_second.user_id
	        GROUP  BY raw_events_second.user_id) AS foo
	ORDER  BY id;
2023-11-25 13:01:03.809 UTC [3977385] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.809 UTC [3977385] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.809 UTC [3977385] STATEMENT:  INSERT INTO agg_events (user_id)
	 SELECT
	   raw_events_first.user_id
	 FROM
	   raw_events_first LEFT JOIN raw_events_second ON raw_events_first.user_id = raw_events_second.value_1;
2023-11-25 13:01:03.890 UTC [3977385] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:03.890 UTC [3977385] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:03.890 UTC [3977385] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 13:01:03.890 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	             (user_id)
	 SELECT raw_events_second.user_id
	 FROM   raw_events_first,
	        raw_events_second
	 WHERE  raw_events_first.user_id = raw_events_first.value_1;
2023-11-25 13:01:03.890 UTC [3977385] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.890 UTC [3977385] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.890 UTC [3977385] STATEMENT:  INSERT INTO agg_events (user_id)
	 SELECT
	   raw_events_first.user_id
	 FROM
	   raw_events_first LEFT JOIN raw_events_second ON raw_events_first.value_1 = raw_events_second.value_1;
2023-11-25 13:01:03.984 UTC [3977385] ERROR:  XX000: EXPLAIN ANALYZE is currently not supported for INSERT ... SELECT commands via coordinator
2023-11-25 13:01:03.984 UTC [3977385] LOCATION:  NonPushableInsertSelectExplainScan, multi_explain.c:252
2023-11-25 13:01:03.984 UTC [3977385] STATEMENT:  EXPLAIN (costs off, analyze on)
	 INSERT INTO agg_events (user_id)
	 SELECT
	   raw_events_first.user_id
	 FROM
	   raw_events_first INNER JOIN raw_events_second ON raw_events_first.value_1 = raw_events_second.value_1;
2023-11-25 13:01:03.986 UTC [3977385] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:03.986 UTC [3977385] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:03.986 UTC [3977385] STATEMENT:  INSERT INTO agg_events (user_id)
	SELECT
	  raw_events_first.user_id
	FROM
	  raw_events_first LEFT JOIN raw_events_second ON raw_events_first.user_id = raw_events_second.value_1
	WHERE
	  raw_events_first.user_id = 10;
2023-11-25 13:01:03.999 UTC [3977385] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:03.999 UTC [3977385] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:03.999 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	            (value_4_agg,
	             value_1_agg,
	             user_id)
	SELECT v4,
	       v1,
	       id
	FROM   (SELECT SUM(raw_events_second.value_4) AS v4,
	               SUM(raw_events_first.value_1) AS v1,
	               raw_events_second.user_id      AS id
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id != raw_events_second.user_id
	        GROUP  BY raw_events_second.user_id) AS foo;
2023-11-25 13:01:04.003 UTC [3977385] ERROR:  22004: the partition column of table multi_insert_select.agg_events cannot be NULL
2023-11-25 13:01:04.003 UTC [3977385] LOCATION:  ShardIdForTuple, multi_copy.c:2592
2023-11-25 13:01:04.003 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	            (value_4_agg,
	             value_1_agg,
	             user_id)
	SELECT v4,
	       v1,
	       id
	FROM   (SELECT SUM(raw_events_second.value_4) AS v4,
	               SUM(raw_events_first.value_1) AS v1,
	               raw_events_second.value_3      AS id
	        FROM   raw_events_first,
	               raw_events_second
	        WHERE  raw_events_first.user_id = raw_events_second.user_id
	        GROUP  BY raw_events_second.value_3) AS foo;
2023-11-25 13:01:04.004 UTC [3977385] ERROR:  22004: the partition column of table multi_insert_select.raw_events_second should have a value
2023-11-25 13:01:04.004 UTC [3977385] LOCATION:  NonPushableInsertSelectExecScan, insert_select_executor.c:153
2023-11-25 13:01:04.004 UTC [3977385] STATEMENT:  INSERT INTO raw_events_second
	            (value_1)
	SELECT value_1
	FROM   raw_events_first;
2023-11-25 13:01:04.004 UTC [3977385] ERROR:  22004: the partition column of table multi_insert_select.raw_events_second should have a value
2023-11-25 13:01:04.004 UTC [3977385] LOCATION:  NonPushableInsertSelectExecScan, insert_select_executor.c:153
2023-11-25 13:01:04.004 UTC [3977385] STATEMENT:  INSERT INTO raw_events_second
	            (value_1)
	SELECT user_id
	FROM   raw_events_first;
2023-11-25 13:01:04.005 UTC [3977385] ERROR:  22004: the partition column value cannot be NULL
2023-11-25 13:01:04.005 UTC [3977385] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:04.005 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:04.005 UTC [3977385] STATEMENT:  INSERT INTO raw_events_second
	            (user_id)
	SELECT value_1
	FROM   raw_events_first;
2023-11-25 13:01:04.033 UTC [3977385] ERROR:  22004: the partition column value cannot be NULL
2023-11-25 13:01:04.033 UTC [3977385] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:04.033 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:04.033 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	            (value_3_agg,
	             value_4_agg,
	             value_1_agg,
	             value_2_agg,
	             user_id)
	SELECT SUM(value_3),
	       Count(value_4),
	       user_id,
	       SUM(value_1),
	       Avg(value_2)
	FROM   raw_events_first
	GROUP  BY user_id;
2023-11-25 13:01:04.040 UTC [3977385] ERROR:  22004: the partition column value cannot be NULL
2023-11-25 13:01:04.040 UTC [3977385] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:04.040 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:04.040 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	            (value_3_agg,
	             value_4_agg,
	             value_1_agg,
	             value_2_agg,
	             user_id)
	SELECT SUM(value_3),
	       Count(value_4),
	       user_id,
	       SUM(value_1),
	       value_2
	FROM   raw_events_first
	GROUP  BY user_id,
	          value_2;
2023-11-25 13:01:04.133 UTC [3977385] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 13:01:04.133 UTC [3977385] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:04.133 UTC [3977385] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:04.133 UTC [3977385] STATEMENT:  INSERT INTO agg_events
	            (user_id,
	             value_1_agg,
	             value_2_agg)
	SELECT user_id,
	       Sum(value_1) AS sum_val1,
	       Sum(value_2) AS sum_val2
	FROM   raw_events_second
	GROUP  BY grouping sets ( ( user_id ), ( value_1 ), ( user_id, value_1 ), ( ) );
2023-11-25 13:01:04.994 UTC [3977385] ERROR:  0A000: INSERT ... SELECT into an append-distributed table is not supported
2023-11-25 13:01:04.994 UTC [3977385] LOCATION:  NonPushableInsertSelectSupported, insert_select_planner.c:1572
2023-11-25 13:01:04.994 UTC [3977385] STATEMENT:  INSERT INTO insert_append_table (user_id, value_4)
	SELECT user_id, 1 FROM raw_events_second LIMIT 5;
2023-11-25 13:01:05.119 UTC [3977385] ERROR:  XX000: value too long for type character(1)
2023-11-25 13:01:05.119 UTC [3977385] LOCATION:  ReportCopyError, multi_copy.c:1193
2023-11-25 13:01:05.119 UTC [3977385] STATEMENT:  INSERT INTO coerce_agg(user_id, value_1_agg)
	SELECT *
	FROM (
	  SELECT user_id, value_1
	  FROM coerce_events
	) AS ftop
	LIMIT 5;
2023-11-25 13:01:05.141 UTC [3977385] ERROR:  XX000: value too long for type character(1)
2023-11-25 13:01:05.141 UTC [3977385] LOCATION:  ReportCopyError, multi_copy.c:1193
2023-11-25 13:01:05.141 UTC [3977385] STATEMENT:  INSERT INTO coerce_agg(user_id, value_1_agg)
	SELECT *
	FROM (
	  SELECT user_id, value_1
	  FROM coerce_events
	) AS ftop
	LIMIT 5;
2023-11-25 13:01:05.184 UTC [3977385] ERROR:  23514: new row for relation "coerce_agg_13300067" violates check constraint "small_number_13300067"
2023-11-25 13:01:05.184 UTC [3977385] DETAIL:  Failing row contains (10, 10).
2023-11-25 13:01:05.184 UTC [3977385] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:05.184 UTC [3977385] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:05.184 UTC [3977385] STATEMENT:  INSERT INTO coerce_agg(user_id, value_1_agg)
	SELECT *
	FROM (
	  SELECT user_id, value_1
	  FROM coerce_events
	) AS ftop;
2023-11-25 13:01:05.255 UTC [3977385] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:05.255 UTC [3977385] LOCATION:  ErrorIfOnConflictNotSupported, multi_router_planner.c:1255
2023-11-25 13:01:05.255 UTC [3977385] STATEMENT:  INSERT INTO agg_events AS ae
	            (
	                        user_id,
	                        value_1_agg,
	                        agg_time
	            )
	SELECT user_id,
	       value_1,
	       time
	FROM   raw_events_first
	ON conflict (user_id, value_1_agg)
	DO UPDATE
	   SET    user_id = 42
	RETURNING user_id, value_1_agg;
2023-11-25 13:01:05.804 UTC [3978581] ERROR:  42P01: relation "users_copy_table" does not exist at character 26
2023-11-25 13:01:05.804 UTC [3978581] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:05.804 UTC [3978581] STATEMENT:  SELECT SUM(value_3) FROM users_copy_table;
2023-11-25 13:01:06.147 UTC [3978581] ERROR:  21000: more than one row returned by a subquery used as an expression
2023-11-25 13:01:06.147 UTC [3978581] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:06.147 UTC [3978581] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:06.147 UTC [3978581] STATEMENT:  UPDATE users_test_table as utt
	SET    value_1 = 3
	WHERE value_2 > (SELECT value_3 FROM events_test_table as ett WHERE utt.user_id = ett.user_id);
2023-11-25 13:01:06.147 UTC [3978581] ERROR:  0A000: only reference tables may be queried when targeting a reference table with multi shard UPDATE/DELETE queries with multiple tables 
2023-11-25 13:01:06.147 UTC [3978581] LOCATION:  MultiShardUpdateDeleteSupported, multi_router_planner.c:1294
2023-11-25 13:01:06.147 UTC [3978581] STATEMENT:  UPDATE users_reference_copy_table
	SET    value_2 = 5
	FROM   events_test_table
	WHERE  users_reference_copy_table.user_id = events_test_table.user_id;
2023-11-25 13:01:06.147 UTC [3978581] ERROR:  0A000: a join with USING causes an internal naming conflict, use ON instead
2023-11-25 13:01:06.147 UTC [3978581] LOCATION:  MultiShardUpdateDeleteSupported, multi_router_planner.c:1279
2023-11-25 13:01:06.147 UTC [3978581] STATEMENT:  UPDATE events_test_table
	SET value_2 = users_test_table.user_id
	FROM users_test_table
	FULL OUTER JOIN events_test_table e2 USING (user_id)
	WHERE e2.user_id = events_test_table.user_id RETURNING events_test_table.value_2;
2023-11-25 13:01:06.166 UTC [3978581] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:06.166 UTC [3978581] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:06.166 UTC [3978581] STATEMENT:  UPDATE users_test_table
	SET    value_2 = (SELECT value_3
	                  FROM   users_test_table);
2023-11-25 13:01:06.166 UTC [3978581] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:06.166 UTC [3978581] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:06.166 UTC [3978581] STATEMENT:  UPDATE users_test_table
	SET value_2 = 2
	WHERE
	  value_2 >
	          (SELECT
	              max(value_2)
	           FROM
	              events_test_table
	           WHERE
	              users_test_table.user_id > events_test_table.user_id AND
	              users_test_table.value_1 = events_test_table.value_1
	           GROUP BY
	              user_id
	          );
2023-11-25 13:01:06.175 UTC [3978581] ERROR:  0A000: functions used in the WHERE/ON/WHEN clause of modification queries on distributed tables must not be VOLATILE
2023-11-25 13:01:06.175 UTC [3978581] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:616
2023-11-25 13:01:06.175 UTC [3978581] STATEMENT:  UPDATE users_test_table
	SET    value_2 = 5
	FROM   events_test_table
	WHERE  users_test_table.user_id = events_test_table.user_id * random();
2023-11-25 13:01:06.175 UTC [3978581] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 13:01:06.175 UTC [3978581] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:575
2023-11-25 13:01:06.175 UTC [3978581] STATEMENT:  UPDATE users_test_table
	SET    value_2 = 5 * random()
	FROM   events_test_table
	WHERE  users_test_table.user_id = events_test_table.user_id;
2023-11-25 13:01:06.176 UTC [3978581] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 13:01:06.176 UTC [3978581] LOCATION:  SingleShardUpdateDeleteSupported, multi_router_planner.c:1330
2023-11-25 13:01:06.176 UTC [3978581] STATEMENT:  UPDATE users_test_table
	SET    value_1 = 3
	WHERE  user_id = 1 AND value_1 IN (SELECT value_1
	                                   FROM users_test_table
	                                   WHERE user_id = 1 AND value_2 > random());
2023-11-25 13:01:06.176 UTC [3978581] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 13:01:06.176 UTC [3978581] LOCATION:  SingleShardUpdateDeleteSupported, multi_router_planner.c:1330
2023-11-25 13:01:06.176 UTC [3978581] STATEMENT:  UPDATE users_test_table
	SET    value_2 = subquery.random FROM (SELECT user_id, random()
	                                       FROM events_test_table) subquery
	WHERE  users_test_table.user_id = subquery.user_id;
2023-11-25 13:01:06.202 UTC [3978581] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:06.202 UTC [3978581] DETAIL:  Shards of relations in subquery need to have 1-to-1 shard partitioning
2023-11-25 13:01:06.202 UTC [3978581] LOCATION:  ErrorIfUnsupportedShardDistribution, multi_physical_planner.c:2432
2023-11-25 13:01:06.202 UTC [3978581] STATEMENT:  UPDATE users_test_table
	SET    value_2 = 5
	FROM   events_test_table_2
	WHERE  users_test_table.user_id = events_test_table_2.user_id;
2023-11-25 13:01:06.205 UTC [3978581] ERROR:  21000: more than one row returned by a subquery used as an expression
2023-11-25 13:01:06.205 UTC [3978581] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:06.205 UTC [3978581] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:06.205 UTC [3978581] STATEMENT:  DELETE FROM users_test_table
	WHERE  users_test_table.user_id = (SELECT user_id
	                                   FROM   events_test_table);
2023-11-25 13:01:06.212 UTC [3978581] ERROR:  0A000: cannot run DML queries with cursors
2023-11-25 13:01:06.212 UTC [3978581] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:655
2023-11-25 13:01:06.212 UTC [3978581] STATEMENT:  UPDATE users_test_table SET value_2 = 5 WHERE CURRENT OF test_cursor;
2023-11-25 13:01:06.255 UTC [3978581] ERROR:  0A000: functions used in UPDATE queries on distributed tables must not be VOLATILE
2023-11-25 13:01:06.255 UTC [3978581] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:575
2023-11-25 13:01:06.255 UTC [3978581] STATEMENT:  UPDATE test_table_2 SET double_col = random();
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400256 us JOIN public.events_table_1400260 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400257 us JOIN public.events_table_1400261 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400258 us JOIN public.events_table_1400262 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_2 AS worker_column_3 FROM (SELECT us.user_id AS worker_column_1, us.value_1 AS worker_column_2 FROM (public.users_table_1400259 us JOIN public.events_table_1400263 ev ON ((us.user_id OPERATOR(pg_catalog.=) ev.user_id)))) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY worker_column_1, (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) LIMIT '5'::bigint
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.486 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 integer) ORDER BY user_id, sum LIMIT '5'::bigint
2023-11-25 13:01:06.486 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.487 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.487 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.487 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 13 in 3722 microseconds
2023-11-25 13:01:06.487 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.487 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.487 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.487 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 15 in 3677 microseconds
2023-11-25 13:01:06.487 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.488 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 1439 microseconds on worker node localhost:57637
2023-11-25 13:01:06.488 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.488 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 1332 microseconds on worker node localhost:57638
2023-11-25 13:01:06.488 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.489 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 591 microseconds on worker node localhost:57637
2023-11-25 13:01:06.489 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.489 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 588 microseconds on worker node localhost:57638
2023-11-25 13:01:06.489 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.491 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 14 in 4503 microseconds
2023-11-25 13:01:06.491 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.492 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 16 in 5415 microseconds
2023-11-25 13:01:06.492 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.492 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 13: 2 to node localhost:57637
2023-11-25 13:01:06.492 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.492 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 14: 0 to node localhost:57637
2023-11-25 13:01:06.492 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.492 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 15: 2 to node localhost:57638
2023-11-25 13:01:06.492 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.492 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 16: 0 to node localhost:57638
2023-11-25 13:01:06.492 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400256 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400260 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400257 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400261 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400258 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400262 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum FROM (SELECT j.user_id AS worker_column_1, j.value_1 AS worker_column_2 FROM (public.users_table_1400259 us(user_id, "time", value_1, value_2, value_3, value_4) JOIN public.events_table_1400263 ev(user_id, "time", event_type, value_2, value_3, value_4) USING (user_id)) j(user_id, "time", value_1, value_2, value_3, value_4, time_1, event_type, value_2_1, value_3_1, value_4_1)) worker_subquery GROUP BY worker_column_1, worker_column_2 ORDER BY (sum(worker_column_2) OVER (PARTITION BY worker_column_1)) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.493 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.493 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.494 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, value_1, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, sum bigint) ORDER BY sum DESC, value_1 DESC, user_id DESC LIMIT '5'::bigint
2023-11-25 13:01:06.494 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.494 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.494 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.494 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 17 in 3722 microseconds
2023-11-25 13:01:06.494 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.494 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.494 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.494 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 19 in 3677 microseconds
2023-11-25 13:01:06.494 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.495 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 1119 microseconds on worker node localhost:57637
2023-11-25 13:01:06.495 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.495 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 966 microseconds on worker node localhost:57638
2023-11-25 13:01:06.495 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.496 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 832 microseconds on worker node localhost:57637
2023-11-25 13:01:06.496 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.496 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 824 microseconds on worker node localhost:57638
2023-11-25 13:01:06.496 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.497 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 18 in 3724 microseconds
2023-11-25 13:01:06.497 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.498 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 20 in 4050 microseconds
2023-11-25 13:01:06.498 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.498 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 17: 2 to node localhost:57637
2023-11-25 13:01:06.498 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.498 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 18: 0 to node localhost:57637
2023-11-25 13:01:06.498 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.498 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 19: 2 to node localhost:57638
2023-11-25 13:01:06.498 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.498 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 20: 0 to node localhost:57638
2023-11-25 13:01:06.498 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.505 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.505 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.505 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.505 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.505 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.505 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.505 UTC [3978941] DEBUG:  00000: push down of limit count: 10
2023-11-25 13:01:06.505 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.505 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.505 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.505 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.505 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.505 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400256 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 13:01:06.505 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400257 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400258 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS rank FROM (SELECT window_view.user_id AS worker_column_1, window_view.rank AS worker_column_2 FROM (SELECT DISTINCT users_table.user_id, rank() OVER (PARTITION BY users_table.user_id ORDER BY users_table.value_1) AS rank FROM public.users_table_1400259 users_table GROUP BY users_table.user_id, users_table.value_1 HAVING (count(*) OPERATOR(pg_catalog.>) 1)) window_view) worker_subquery ORDER BY worker_column_2 DESC, worker_column_1 LIMIT '10'::bigint
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rank bigint) ORDER BY rank DESC, user_id LIMIT '10'::bigint
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 21 in 3722 microseconds
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.506 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.506 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.507 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 23 in 3677 microseconds
2023-11-25 13:01:06.507 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.507 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1166 microseconds on worker node localhost:57637
2023-11-25 13:01:06.507 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.508 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 619 microseconds on worker node localhost:57638
2023-11-25 13:01:06.508 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.508 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 956 microseconds on worker node localhost:57637
2023-11-25 13:01:06.508 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.508 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 398 microseconds on worker node localhost:57638
2023-11-25 13:01:06.508 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.510 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 22 in 3850 microseconds
2023-11-25 13:01:06.510 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.512 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 24 in 4680 microseconds
2023-11-25 13:01:06.512 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.512 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 21: 2 to node localhost:57637
2023-11-25 13:01:06.512 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.512 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 22: 0 to node localhost:57637
2023-11-25 13:01:06.512 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.512 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 23: 2 to node localhost:57638
2023-11-25 13:01:06.512 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.512 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 24: 0 to node localhost:57638
2023-11-25 13:01:06.512 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.516 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.516 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.516 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.516 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.516 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.516 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.516 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.516 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.516 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.516 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400256 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400257 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400258 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2) AS rank, worker_column_2 AS worker_column_3 FROM (SELECT users_view.user_id AS worker_column_1, users_view.value_1 AS worker_column_2 FROM (SELECT users_table.user_id, users_table."time", users_table.value_1, users_table.value_2, users_table.value_3, users_table.value_4 FROM public.users_table_1400259 users_table) users_view) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 4)
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT user_id, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rank bigint, worker_column_3 integer) ORDER BY rank DESC, user_id
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 25 in 3722 microseconds
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.517 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 27 in 3677 microseconds
2023-11-25 13:01:06.517 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.519 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1348 microseconds on worker node localhost:57637
2023-11-25 13:01:06.519 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.519 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1271 microseconds on worker node localhost:57638
2023-11-25 13:01:06.519 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.520 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 951 microseconds on worker node localhost:57637
2023-11-25 13:01:06.520 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.520 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 917 microseconds on worker node localhost:57638
2023-11-25 13:01:06.520 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.520 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 26 in 3200 microseconds
2023-11-25 13:01:06.520 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 28 in 3284 microseconds
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 25: 2 to node localhost:57637
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 26: 0 to node localhost:57637
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 27: 2 to node localhost:57638
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 28: 0 to node localhost:57638
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: switching to sequential query execution mode
2023-11-25 13:01:06.521 UTC [3978941] DETAIL:  A command for a distributed view is run. To make sure subsequent commands see the view correctly we need to make sure to use only one connection for all future commands
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  EnsureSequentialMode, multi_executor.c:745
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: drop auto-cascades to type window_view
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: drop auto-cascades to type window_view[]
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: drop auto-cascades to rule _RETURN on view window_view
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: drop auto-cascades to type users_view
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: drop auto-cascades to type users_view[]
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.521 UTC [3978941] DEBUG:  00000: drop auto-cascades to rule _RETURN on view users_view
2023-11-25 13:01:06.521 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.522 UTC [3978941] DEBUG:  00000: EventTriggerInvoke 16675
2023-11-25 13:01:06.522 UTC [3978941] LOCATION:  EventTriggerInvoke, event_trigger.c:900
2023-11-25 13:01:06.525 UTC [3978941] DEBUG:  00000: opening 1 new connections to localhost:57637
2023-11-25 13:01:06.525 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.525 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 29 in 3722 microseconds
2023-11-25 13:01:06.525 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.525 UTC [3978941] DEBUG:  00000: opening 1 new connections to localhost:57638
2023-11-25 13:01:06.525 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.525 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 30 in 3677 microseconds
2023-11-25 13:01:06.525 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.530 UTC [3978941] DEBUG:  00000: task execution (0) for placement (0) on anchor shard (0) finished in 4857 microseconds on worker node localhost:57638
2023-11-25 13:01:06.530 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.531 UTC [3978941] DEBUG:  00000: task execution (0) for placement (0) on anchor shard (0) finished in 5615 microseconds on worker node localhost:57637
2023-11-25 13:01:06.531 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.531 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 29: 1 to node localhost:57637
2023-11-25 13:01:06.531 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.531 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 30: 1 to node localhost:57638
2023-11-25 13:01:06.531 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: Distributed planning for a fast-path router query
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2322
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: Creating router plan
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  CreateSingleTaskRouterSelectPlan, multi_router_planner.c:284
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: generating subplan 8_1 for subquery SELECT min(k_no) AS min FROM public.users_ref_test_table
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  RecursivelyPlanSubquery, recursive_planning.c:1551
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: Plan 8 query after replacing subqueries and CTEs: SELECT user_id, count(user_id) OVER (PARTITION BY user_id) AS count FROM public.users_table GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY user_id DESC, (count(user_id) OVER (PARTITION BY user_id)) DESC LIMIT 1
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  GenerateSubplansForSubqueriesAndCTEs, recursive_planning.c:248
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: push down of limit count: 1
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, count(worker_column_1) OVER (PARTITION BY worker_column_1) AS count FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1 HAVING (avg(worker_column_2) OPERATOR(pg_catalog.<) ((SELECT intermediate_result.min FROM read_intermediate_result('8_1'::text, 'binary'::citus_copy_format) intermediate_result(min integer)))::numeric) ORDER BY worker_column_1 DESC, (count(worker_column_1) OVER (PARTITION BY worker_column_1)) DESC LIMIT '1'::bigint
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.533 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.533 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.534 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, count FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, count bigint) ORDER BY user_id DESC, count DESC LIMIT '1'::bigint
2023-11-25 13:01:06.534 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.534 UTC [3978941] DEBUG:  00000: Subplan 8_1 is used in 8
2023-11-25 13:01:06.534 UTC [3978941] LOCATION:  RecordSubplanExecutionsOnNodes, intermediate_result_pruning.c:193
2023-11-25 13:01:06.534 UTC [3978941] DEBUG:  00000: Subplan 8_1 will be sent to localhost:57637
2023-11-25 13:01:06.534 UTC [3978941] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 13:01:06.534 UTC [3978941] DEBUG:  00000: Subplan 8_1 will be sent to localhost:57638
2023-11-25 13:01:06.534 UTC [3978941] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 13:01:06.534 UTC [3978941] DEBUG:  00000: opening 1 new connections to localhost:57637
2023-11-25 13:01:06.534 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.534 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 31 in 3722 microseconds
2023-11-25 13:01:06.534 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.536 UTC [3978941] DEBUG:  00000: task execution (0) for placement (888) on anchor shard (1400284) finished in 1898 microseconds on worker node localhost:57637
2023-11-25 13:01:06.536 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.536 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 31: 1 to node localhost:57637
2023-11-25 13:01:06.536 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.536 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.536 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.536 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 32 in 3722 microseconds
2023-11-25 13:01:06.536 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.537 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.537 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.537 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 34 in 3677 microseconds
2023-11-25 13:01:06.537 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.537 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 871 microseconds on worker node localhost:57637
2023-11-25 13:01:06.537 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.539 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 1178 microseconds on worker node localhost:57637
2023-11-25 13:01:06.539 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.539 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 2476 microseconds on worker node localhost:57638
2023-11-25 13:01:06.539 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.540 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 35 in 3029 microseconds
2023-11-25 13:01:06.540 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.540 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 528 microseconds on worker node localhost:57638
2023-11-25 13:01:06.540 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.541 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 33 in 4691 microseconds
2023-11-25 13:01:06.541 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.541 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 32: 2 to node localhost:57637
2023-11-25 13:01:06.541 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.541 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 33: 0 to node localhost:57637
2023-11-25 13:01:06.541 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.541 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 34: 2 to node localhost:57638
2023-11-25 13:01:06.541 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.541 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 35: 0 to node localhost:57638
2023-11-25 13:01:06.541 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: push down of limit count: 10
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400260 events_table, public.users_table_1400256 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400261 events_table, public.users_table_1400257 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400262 events_table, public.users_table_1400258 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.events_table_1400263 events_table, public.users_table_1400259 users_table WHERE (users_table.user_id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT ON (rnk, user_id) user_id, rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rnk bigint, worker_column_3 timestamp without time zone, worker_column_4 integer) ORDER BY rnk DESC, user_id DESC LIMIT '10'::bigint
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 36 in 3722 microseconds
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.543 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.543 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.544 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 38 in 3677 microseconds
2023-11-25 13:01:06.544 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.546 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 2820 microseconds on worker node localhost:57638
2023-11-25 13:01:06.546 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.547 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 3265 microseconds on worker node localhost:57637
2023-11-25 13:01:06.547 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.547 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 37 in 3826 microseconds
2023-11-25 13:01:06.547 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.547 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 667 microseconds on worker node localhost:57637
2023-11-25 13:01:06.547 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.548 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 1355 microseconds on worker node localhost:57638
2023-11-25 13:01:06.548 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.550 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 39 in 6777 microseconds
2023-11-25 13:01:06.550 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.550 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 36: 2 to node localhost:57637
2023-11-25 13:01:06.550 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.550 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 37: 0 to node localhost:57637
2023-11-25 13:01:06.550 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.550 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 38: 2 to node localhost:57638
2023-11-25 13:01:06.550 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.550 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 39: 0 to node localhost:57638
2023-11-25 13:01:06.550 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: push down of limit count: 10
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400260 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400261 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400262 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: distributed statement: SELECT DISTINCT ON ((rank() OVER my_win), worker_column_1) worker_column_1 AS user_id, rank() OVER my_win AS rnk, worker_column_2 AS worker_column_3, worker_column_3 AS worker_column_4 FROM (SELECT events_table.user_id AS worker_column_1, events_table."time" AS worker_column_2, uref.k_no AS worker_column_3 FROM public.events_table_1400263 events_table, public.users_ref_test_table_1400284 uref WHERE (uref.id OPERATOR(pg_catalog.=) events_table.user_id)) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_1, worker_column_3 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, worker_column_1 DESC LIMIT '10'::bigint
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.551 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT ON (rnk, user_id) user_id, rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rnk bigint, worker_column_3 timestamp without time zone, worker_column_4 integer) ORDER BY rnk DESC, user_id DESC LIMIT '10'::bigint
2023-11-25 13:01:06.551 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.552 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.552 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.552 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 40 in 3722 microseconds
2023-11-25 13:01:06.552 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.552 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.552 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.552 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 42 in 3677 microseconds
2023-11-25 13:01:06.552 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.553 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 657 microseconds on worker node localhost:57638
2023-11-25 13:01:06.553 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.553 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 957 microseconds on worker node localhost:57637
2023-11-25 13:01:06.553 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.553 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 436 microseconds on worker node localhost:57638
2023-11-25 13:01:06.553 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.555 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 43 in 3083 microseconds
2023-11-25 13:01:06.555 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.555 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 41 in 3315 microseconds
2023-11-25 13:01:06.555 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 4810 microseconds on worker node localhost:57637
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 40: 2 to node localhost:57637
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 41: 0 to node localhost:57637
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 42: 2 to node localhost:57638
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 43: 0 to node localhost:57638
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.558 UTC [3978941] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400260 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.558 UTC [3978941] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400261 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.558 UTC [3978941] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400262 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.558 UTC [3978941] DETAIL:  query string: "SELECT events_table.user_id, events_table."time" AS worker_column_2, events_table.value_2 AS worker_column_3, uref.k_no AS worker_column_4 FROM (public.events_table_1400263 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.558 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT ON ((rank() OVER my_win), user_id) user_id, rank() OVER my_win AS rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1 2)'::cstring(0)) remote_scan(user_id integer, worker_column_2 timestamp without time zone, worker_column_3 integer, worker_column_4 integer) WINDOW my_win AS (PARTITION BY worker_column_3, worker_column_4 ORDER BY worker_column_2 DESC) ORDER BY (rank() OVER my_win) DESC, user_id DESC LIMIT '10'::bigint
2023-11-25 13:01:06.558 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.559 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.559 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.559 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 44 in 3722 microseconds
2023-11-25 13:01:06.559 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.559 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.559 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.559 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 46 in 3677 microseconds
2023-11-25 13:01:06.559 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.560 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 871 microseconds on worker node localhost:57637
2023-11-25 13:01:06.560 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.560 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 827 microseconds on worker node localhost:57638
2023-11-25 13:01:06.560 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.560 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 353 microseconds on worker node localhost:57637
2023-11-25 13:01:06.560 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.560 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 429 microseconds on worker node localhost:57638
2023-11-25 13:01:06.560 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.562 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 45 in 3137 microseconds
2023-11-25 13:01:06.562 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.562 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 47 in 3431 microseconds
2023-11-25 13:01:06.562 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.562 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 44: 2 to node localhost:57637
2023-11-25 13:01:06.562 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.562 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 45: 0 to node localhost:57637
2023-11-25 13:01:06.562 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.562 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 46: 2 to node localhost:57638
2023-11-25 13:01:06.562 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.562 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 47: 0 to node localhost:57638
2023-11-25 13:01:06.562 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400260 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400261 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400262 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS rnk, avg(worker_column_2) AS avg_val_2, date_trunc('day'::text, worker_column_3) AS worker_column_4, avg(worker_column_4) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.value_2 AS worker_column_2, events_table."time" AS worker_column_3, events_table.event_type AS worker_column_4 FROM public.events_table_1400263 events_table) worker_subquery GROUP BY worker_column_1, (date_trunc('day'::text, worker_column_3)) WINDOW my_win AS (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_4)) DESC)
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.563 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, rnk, avg_val_2 FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rnk bigint, avg_val_2 numeric, worker_column_4 timestamp without time zone, worker_column_5 numeric) ORDER BY avg_val_2 DESC, rnk DESC, user_id DESC
2023-11-25 13:01:06.563 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.564 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.564 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.564 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 48 in 3722 microseconds
2023-11-25 13:01:06.564 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.564 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.564 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.564 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 50 in 3677 microseconds
2023-11-25 13:01:06.564 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.565 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 1010 microseconds on worker node localhost:57637
2023-11-25 13:01:06.565 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.565 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 892 microseconds on worker node localhost:57638
2023-11-25 13:01:06.565 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.567 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 2170 microseconds on worker node localhost:57637
2023-11-25 13:01:06.567 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.567 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 49 in 3287 microseconds
2023-11-25 13:01:06.567 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.567 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 51 in 3234 microseconds
2023-11-25 13:01:06.567 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.567 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 2645 microseconds on worker node localhost:57638
2023-11-25 13:01:06.567 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.568 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 48: 2 to node localhost:57637
2023-11-25 13:01:06.568 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.568 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 49: 0 to node localhost:57637
2023-11-25 13:01:06.568 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.568 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 50: 2 to node localhost:57638
2023-11-25 13:01:06.568 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.568 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 51: 0 to node localhost:57638
2023-11-25 13:01:06.568 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.569 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.569 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.569 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.569 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.569 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.569 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.569 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.569 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.569 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.569 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.569 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.569 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.569 UTC [3978941] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400256 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.569 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400257 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400258 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: distributed statement: SELECT count(*) OVER (PARTITION BY worker_column_2, (worker_column_2 OPERATOR(pg_catalog.+) 1)) AS count, rank() OVER (PARTITION BY worker_column_2) AS cnt1, count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)))) AS cnt2, date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1)) AS datee, rank() OVER my_win AS rnnk, avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2 AS filtered_count, sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4 AS cnt_with_filter_2, worker_column_2 AS worker_column_8, worker_column_1 AS worker_column_9, (worker_column_3 OPERATOR(pg_catalog.%) 3) AS worker_column_10, worker_column_3 AS worker_column_11, date_trunc('min'::text, worker_column_1) AS worker_column_12, worker_column_4 AS worker_column_13, worker_column_5 AS worker_column_14, (worker_column_2 OPERATOR(pg_catalog.+) 1) AS worker_column_15, abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4)) AS worker_column_16 FROM (SELECT users_table."time" AS worker_column_1, users_table.user_id AS worker_column_2, users_table.value_1 AS worker_column_3, users_table.value_2 AS worker_column_4, users_table.value_3 AS worker_column_5 FROM public.users_table_1400259 users_table) worker_subquery WINDOW my_win AS (PARTITION BY worker_column_2, (worker_column_3 OPERATOR(pg_catalog.%) 3) ORDER BY worker_column_1 DESC), my_win_2 AS (PARTITION BY worker_column_2, worker_column_3 ORDER BY worker_column_1 DESC), my_win_3 AS (PARTITION BY worker_column_2, (date_trunc('min'::text, worker_column_1))), my_win_4 AS (my_win_3 ORDER BY worker_column_4, worker_column_5) ORDER BY (sum(((((worker_column_2)::numeric OPERATOR(pg_catalog.*) (5.0 OPERATOR(pg_catalog./) (((worker_column_3 OPERATOR(pg_catalog.+) worker_column_4))::numeric OPERATOR(pg_catalog.+) 0.1))))::double precision OPERATOR(pg_catalog.*) worker_column_5)) FILTER (WHERE ((worker_column_3)::text OPERATOR(pg_catalog.~~) '%1%'::text)) OVER my_win_4) DESC NULLS LAST, (avg(CASE WHEN (worker_column_2 OPERATOR(pg_catalog.>) 4) THEN worker_column_3 ELSE worker_column_4 END) FILTER (WHERE (worker_column_2 OPERATOR(pg_catalog.>) 2)) OVER my_win_2) DESC NULLS LAST, (date_trunc('min'::text, lag(worker_column_1) OVER (PARTITION BY worker_column_2 ORDER BY worker_column_1))) DESC NULLS LAST, (rank() OVER my_win) DESC, (count(*) OVER (PARTITION BY worker_column_2, (abs((worker_column_3 OPERATOR(pg_catalog.-) worker_column_4))))) DESC, (rank() OVER (PARTITION BY worker_column_2)) DESC, worker_column_2 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: combine query: SELECT count, cnt1, cnt2, datee, rnnk, filtered_count, cnt_with_filter_2 FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(count bigint, cnt1 bigint, cnt2 bigint, datee timestamp without time zone, rnnk bigint, filtered_count numeric, cnt_with_filter_2 double precision, worker_column_8 integer, worker_column_9 timestamp without time zone, worker_column_10 integer, worker_column_11 integer, worker_column_12 timestamp without time zone, worker_column_13 integer, worker_column_14 double precision, worker_column_15 integer, worker_column_16 integer) ORDER BY cnt_with_filter_2 DESC NULLS LAST, filtered_count DESC NULLS LAST, datee DESC NULLS LAST, rnnk DESC, cnt2 DESC, cnt1 DESC, worker_column_8 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.570 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.570 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.571 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 52 in 3722 microseconds
2023-11-25 13:01:06.571 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.571 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.571 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.571 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 54 in 3677 microseconds
2023-11-25 13:01:06.571 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.573 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1983 microseconds on worker node localhost:57637
2023-11-25 13:01:06.573 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.574 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 914 microseconds on worker node localhost:57637
2023-11-25 13:01:06.574 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.574 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 53 in 3179 microseconds
2023-11-25 13:01:06.574 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.574 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 3339 microseconds on worker node localhost:57638
2023-11-25 13:01:06.574 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.575 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 1398 microseconds on worker node localhost:57638
2023-11-25 13:01:06.575 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.576 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 55 in 5349 microseconds
2023-11-25 13:01:06.576 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.576 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 52: 2 to node localhost:57637
2023-11-25 13:01:06.576 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.576 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 53: 0 to node localhost:57637
2023-11-25 13:01:06.576 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.576 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 54: 2 to node localhost:57638
2023-11-25 13:01:06.576 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.576 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 55: 0 to node localhost:57638
2023-11-25 13:01:06.576 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400260 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400261 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.577 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400262 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 13:01:06.577 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER my_win AS my_rank, avg(avg(worker_column_2)) OVER my_win_2 AS avg, max(worker_column_3) AS mx_time, worker_column_4 AS worker_column_5, count(*) AS worker_column_6, max(worker_column_2) AS worker_column_7, avg(worker_column_1) AS worker_column_8 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2, events_table."time" AS worker_column_3, events_table.value_2 AS worker_column_4 FROM public.events_table_1400263 events_table) worker_subquery GROUP BY worker_column_1, worker_column_4 WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC), my_win_2 AS (PARTITION BY worker_column_1, (avg(worker_column_1)) ORDER BY (count(*)) DESC)
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, my_rank, avg, mx_time FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, my_rank bigint, avg numeric, mx_time timestamp without time zone, worker_column_5 integer, worker_column_6 bigint, worker_column_7 integer, worker_column_8 numeric) ORDER BY avg DESC, mx_time DESC, my_rank DESC, user_id DESC
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 56 in 3722 microseconds
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.578 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 58 in 3677 microseconds
2023-11-25 13:01:06.578 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.579 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 668 microseconds on worker node localhost:57637
2023-11-25 13:01:06.579 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.579 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 674 microseconds on worker node localhost:57638
2023-11-25 13:01:06.579 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.579 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 462 microseconds on worker node localhost:57637
2023-11-25 13:01:06.579 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.579 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 483 microseconds on worker node localhost:57638
2023-11-25 13:01:06.579 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.581 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 57 in 3279 microseconds
2023-11-25 13:01:06.581 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 59 in 3569 microseconds
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 56: 2 to node localhost:57637
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 57: 0 to node localhost:57637
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 58: 2 to node localhost:57638
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 59: 0 to node localhost:57638
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.582 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.582 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, rank() OVER (PARTITION BY worker_column_1 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY worker_column_1 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY worker_column_1 ORDER BY (avg(worker_column_2)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank, avg(worker_column_2) AS worker_column_6 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, rank, dense_rank, cume_dist, percent_rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, rank bigint, dense_rank bigint, cume_dist double precision, percent_rank double precision, worker_column_6 numeric) ORDER BY cume_dist DESC, dense_rank DESC, rank DESC, user_id DESC
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 60 in 3722 microseconds
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.583 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 62 in 3677 microseconds
2023-11-25 13:01:06.583 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.584 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 513 microseconds on worker node localhost:57637
2023-11-25 13:01:06.584 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.584 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 363 microseconds on worker node localhost:57637
2023-11-25 13:01:06.584 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.585 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1631 microseconds on worker node localhost:57638
2023-11-25 13:01:06.585 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.585 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 455 microseconds on worker node localhost:57638
2023-11-25 13:01:06.585 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 61 in 3361 microseconds
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 63 in 3215 microseconds
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 60: 2 to node localhost:57637
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 61: 0 to node localhost:57637
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 62: 2 to node localhost:57638
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 63: 0 to node localhost:57638
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.587 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.587 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(worker_column_2) OVER (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, value_1, array_agg, array_agg_1 AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, array_agg integer[], array_agg_1 integer[]) ORDER BY user_id, value_1, array_agg, array_agg_1
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.588 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.588 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.589 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 64 in 3722 microseconds
2023-11-25 13:01:06.589 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.589 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.589 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.589 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 66 in 3677 microseconds
2023-11-25 13:01:06.589 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.590 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1132 microseconds on worker node localhost:57637
2023-11-25 13:01:06.590 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.590 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1112 microseconds on worker node localhost:57638
2023-11-25 13:01:06.590 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.590 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 461 microseconds on worker node localhost:57637
2023-11-25 13:01:06.590 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.591 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 266 microseconds on worker node localhost:57638
2023-11-25 13:01:06.591 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.593 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 65 in 4335 microseconds
2023-11-25 13:01:06.593 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.593 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 67 in 3876 microseconds
2023-11-25 13:01:06.593 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.593 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 64: 2 to node localhost:57637
2023-11-25 13:01:06.593 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.593 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 65: 0 to node localhost:57637
2023-11-25 13:01:06.593 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.593 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 66: 2 to node localhost:57638
2023-11-25 13:01:06.593 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.593 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 67: 0 to node localhost:57638
2023-11-25 13:01:06.593 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.594 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.594 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.594 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.594 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.594 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.594 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER range_window AS array_agg, array_agg(worker_column_2) OVER range_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW range_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, value_1, array_agg, array_agg_1 AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, array_agg integer[], array_agg_1 integer[]) ORDER BY user_id, value_1, array_agg, array_agg_1
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 68 in 3722 microseconds
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.595 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 70 in 3677 microseconds
2023-11-25 13:01:06.595 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.598 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 2492 microseconds on worker node localhost:57637
2023-11-25 13:01:06.598 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.598 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 2468 microseconds on worker node localhost:57638
2023-11-25 13:01:06.598 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.598 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 499 microseconds on worker node localhost:57637
2023-11-25 13:01:06.598 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.598 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 379 microseconds on worker node localhost:57638
2023-11-25 13:01:06.598 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.598 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 69 in 3306 microseconds
2023-11-25 13:01:06.598 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.599 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 71 in 3384 microseconds
2023-11-25 13:01:06.599 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.599 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 68: 2 to node localhost:57637
2023-11-25 13:01:06.599 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.599 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 69: 0 to node localhost:57637
2023-11-25 13:01:06.599 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.599 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 70: 2 to node localhost:57638
2023-11-25 13:01:06.599 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.599 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 71: 0 to node localhost:57638
2023-11-25 13:01:06.599 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.600 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.600 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.600 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.600 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.600 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.600 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.600 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.600 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.600 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.600 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.600 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400256 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.600 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400257 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400258 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, worker_column_2 AS value_1, array_agg(worker_column_2) OVER row_window AS array_agg, array_agg(worker_column_2) OVER row_window_exclude AS array_agg FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2 FROM public.users_table_1400259 users_table WHERE ((users_table.user_id OPERATOR(pg_catalog.>) 2) AND (users_table.user_id OPERATOR(pg_catalog.<) 6))) worker_subquery WINDOW row_window AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING), row_window_exclude AS (PARTITION BY worker_column_1 ORDER BY worker_column_2 ROWS BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW)
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, value_1, array_agg, array_agg_1 AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, value_1 integer, array_agg integer[], array_agg_1 integer[]) ORDER BY user_id, value_1, array_agg, array_agg_1
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.601 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 72 in 3722 microseconds
2023-11-25 13:01:06.601 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.602 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.602 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.602 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 74 in 3677 microseconds
2023-11-25 13:01:06.602 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.602 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 890 microseconds on worker node localhost:57637
2023-11-25 13:01:06.602 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.603 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 948 microseconds on worker node localhost:57638
2023-11-25 13:01:06.603 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.603 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 309 microseconds on worker node localhost:57637
2023-11-25 13:01:06.603 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.603 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 293 microseconds on worker node localhost:57638
2023-11-25 13:01:06.603 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.605 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 73 in 3199 microseconds
2023-11-25 13:01:06.605 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.605 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 75 in 3089 microseconds
2023-11-25 13:01:06.605 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.605 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 72: 2 to node localhost:57637
2023-11-25 13:01:06.605 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.605 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 73: 0 to node localhost:57637
2023-11-25 13:01:06.605 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.605 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 74: 2 to node localhost:57638
2023-11-25 13:01:06.605 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.605 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 75: 0 to node localhost:57638
2023-11-25 13:01:06.605 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.606 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.606 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.606 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.606 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS worker_column_2, count(value_1) AS worker_column_3 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: combine query: SELECT value_2, rank() OVER (PARTITION BY value_2 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS rank, dense_rank() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS dense_rank, cume_dist() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS cume_dist, percent_rank() OVER (PARTITION BY value_2 ORDER BY (pg_catalog.sum(worker_column_2) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_3)) RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS percent_rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, worker_column_2 bigint, worker_column_3 bigint) GROUP BY value_2 ORDER BY (cume_dist() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING)) DESC, (dense_rank() OVER (PARTITION BY value_2 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)) DESC, (rank() OVER (PARTITION BY value_2 ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)) DESC, value_2 DESC
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 76 in 3722 microseconds
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.606 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.606 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.607 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 78 in 3677 microseconds
2023-11-25 13:01:06.607 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.607 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 360 microseconds on worker node localhost:57638
2023-11-25 13:01:06.607 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.607 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 317 microseconds on worker node localhost:57638
2023-11-25 13:01:06.607 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.607 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1006 microseconds on worker node localhost:57637
2023-11-25 13:01:06.607 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.608 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 337 microseconds on worker node localhost:57637
2023-11-25 13:01:06.608 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.609 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 79 in 2794 microseconds
2023-11-25 13:01:06.609 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.610 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 77 in 3706 microseconds
2023-11-25 13:01:06.610 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.610 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 76: 2 to node localhost:57637
2023-11-25 13:01:06.610 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.610 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 77: 0 to node localhost:57637
2023-11-25 13:01:06.610 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.610 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 78: 2 to node localhost:57638
2023-11-25 13:01:06.610 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.610 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 79: 0 to node localhost:57638
2023-11-25 13:01:06.610 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.611 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400256 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.611 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400257 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.611 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400258 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.611 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400259 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: combine query: SELECT value_2, value_1, array_agg(array_agg) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS array_agg, array_agg(array_agg_1) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW) AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, value_1 integer, array_agg integer, array_agg_1 integer) ORDER BY value_2, value_1, (array_agg(array_agg) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)), (array_agg(array_agg_1) OVER (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW EXCLUDE CURRENT ROW))
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 80 in 3722 microseconds
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.611 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 82 in 3677 microseconds
2023-11-25 13:01:06.611 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.612 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1024 microseconds on worker node localhost:57637
2023-11-25 13:01:06.612 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.612 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 910 microseconds on worker node localhost:57638
2023-11-25 13:01:06.612 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.613 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 485 microseconds on worker node localhost:57637
2023-11-25 13:01:06.613 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.613 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 461 microseconds on worker node localhost:57638
2023-11-25 13:01:06.613 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.614 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 81 in 3124 microseconds
2023-11-25 13:01:06.614 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.616 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 83 in 4343 microseconds
2023-11-25 13:01:06.616 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.616 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 80: 2 to node localhost:57637
2023-11-25 13:01:06.616 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.616 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 81: 0 to node localhost:57637
2023-11-25 13:01:06.616 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.616 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 82: 2 to node localhost:57638
2023-11-25 13:01:06.616 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.616 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 83: 0 to node localhost:57638
2023-11-25 13:01:06.616 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.617 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400256 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.617 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400257 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.617 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400258 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.617 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400259 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.617 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.617 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: combine query: SELECT value_2, value_1, array_agg(array_agg) OVER range_window AS array_agg, array_agg(array_agg_1) OVER range_window_exclude AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, value_1 integer, array_agg integer, array_agg_1 integer) WINDOW range_window AS (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), range_window_exclude AS (PARTITION BY value_2 ORDER BY value_1 RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING EXCLUDE CURRENT ROW) ORDER BY value_2, value_1, (array_agg(array_agg) OVER range_window), (array_agg(array_agg_1) OVER range_window_exclude)
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 84 in 3722 microseconds
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 86 in 3677 microseconds
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.618 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 464 microseconds on worker node localhost:57637
2023-11-25 13:01:06.618 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.619 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 442 microseconds on worker node localhost:57638
2023-11-25 13:01:06.619 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.619 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 218 microseconds on worker node localhost:57637
2023-11-25 13:01:06.619 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.619 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 407 microseconds on worker node localhost:57638
2023-11-25 13:01:06.619 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.623 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 87 in 5455 microseconds
2023-11-25 13:01:06.623 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.624 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 85 in 6383 microseconds
2023-11-25 13:01:06.624 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.624 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 84: 2 to node localhost:57637
2023-11-25 13:01:06.624 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.624 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 85: 0 to node localhost:57637
2023-11-25 13:01:06.624 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.624 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 86: 2 to node localhost:57638
2023-11-25 13:01:06.624 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.624 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 87: 0 to node localhost:57638
2023-11-25 13:01:06.624 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.626 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400256 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.626 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400257 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.626 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400258 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.626 UTC [3978941] DETAIL:  query string: "SELECT value_2, value_1, value_1 AS array_agg, value_1 AS array_agg FROM public.users_table_1400259 users_table WHERE ((value_2 OPERATOR(pg_catalog.>) 2) AND (value_2 OPERATOR(pg_catalog.<) 6))"
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: combine query: SELECT value_2, value_1, array_agg(array_agg) OVER row_window AS array_agg, array_agg(array_agg_1) OVER row_window_exclude AS array_agg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, value_1 integer, array_agg integer, array_agg_1 integer) WINDOW row_window AS (PARTITION BY value_2 ORDER BY value_1 ROWS BETWEEN '1'::bigint PRECEDING AND '1'::bigint FOLLOWING), row_window_exclude AS (PARTITION BY value_2 ORDER BY value_1 ROWS BETWEEN '1'::bigint PRECEDING AND '1'::bigint FOLLOWING EXCLUDE CURRENT ROW) ORDER BY value_2, value_1, (array_agg(array_agg) OVER row_window), (array_agg(array_agg_1) OVER row_window_exclude)
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 88 in 3722 microseconds
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.626 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 90 in 3677 microseconds
2023-11-25 13:01:06.626 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.627 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 447 microseconds on worker node localhost:57637
2023-11-25 13:01:06.627 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.627 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 469 microseconds on worker node localhost:57638
2023-11-25 13:01:06.627 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.627 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 273 microseconds on worker node localhost:57637
2023-11-25 13:01:06.627 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.627 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 377 microseconds on worker node localhost:57638
2023-11-25 13:01:06.627 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.629 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 89 in 3013 microseconds
2023-11-25 13:01:06.629 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.630 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 91 in 3441 microseconds
2023-11-25 13:01:06.630 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.630 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 88: 2 to node localhost:57637
2023-11-25 13:01:06.630 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.630 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 89: 0 to node localhost:57637
2023-11-25 13:01:06.630 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.630 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 90: 2 to node localhost:57638
2023-11-25 13:01:06.630 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.630 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 91: 0 to node localhost:57638
2023-11-25 13:01:06.630 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400260 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400261 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400262 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER my_win AS sum, worker_column_2 AS event_type, count(*) AS worker_column_4, max(worker_column_2) AS worker_column_5 FROM (SELECT events_table.user_id AS worker_column_1, events_table.event_type AS worker_column_2 FROM public.events_table_1400263 events_table) worker_subquery GROUP BY worker_column_1, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2) WINDOW my_win AS (PARTITION BY worker_column_1, (max(worker_column_2)) ORDER BY (count(*)) DESC) ORDER BY (sum(worker_column_2) OVER my_win) DESC, worker_column_2 DESC, worker_column_1 DESC LIMIT '5'::bigint
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, sum, event_type FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, event_type integer, worker_column_4 bigint, worker_column_5 integer) ORDER BY sum DESC, event_type DESC, user_id DESC LIMIT '5'::bigint
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.631 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.631 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.632 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 92 in 3722 microseconds
2023-11-25 13:01:06.632 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.632 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.632 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.632 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 94 in 3677 microseconds
2023-11-25 13:01:06.632 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.633 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 1373 microseconds on worker node localhost:57637
2023-11-25 13:01:06.633 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.633 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 1267 microseconds on worker node localhost:57638
2023-11-25 13:01:06.633 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.633 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 450 microseconds on worker node localhost:57637
2023-11-25 13:01:06.633 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.634 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 447 microseconds on worker node localhost:57638
2023-11-25 13:01:06.634 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.636 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 93 in 4191 microseconds
2023-11-25 13:01:06.636 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 95 in 7061 microseconds
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 92: 2 to node localhost:57637
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 93: 0 to node localhost:57637
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 94: 2 to node localhost:57638
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 95: 0 to node localhost:57638
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.639 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.639 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.640 UTC [3978941] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_1"
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.640 UTC [3978941] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_1"
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.640 UTC [3978941] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_1"
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.640 UTC [3978941] DETAIL:  query string: "SELECT value_1, sum(value_3) AS avg, count(value_3) AS avg, sum(value_2) AS worker_column_4, count(value_2) AS worker_column_5 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_1"
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: combine query: SELECT value_1, (sum(avg) OPERATOR(pg_catalog./) (pg_catalog.sum(avg_1))::double precision) AS avg, dense_rank() OVER (PARTITION BY (sum(avg) OPERATOR(pg_catalog./) (pg_catalog.sum(avg_1))::double precision) ORDER BY (pg_catalog.sum(worker_column_4) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_5))) AS dense_rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_1 integer, avg double precision, avg_1 bigint, worker_column_4 bigint, worker_column_5 bigint) GROUP BY value_1 ORDER BY value_1
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 96 in 3722 microseconds
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.640 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.640 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.641 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 98 in 3677 microseconds
2023-11-25 13:01:06.641 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.642 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1132 microseconds on worker node localhost:57637
2023-11-25 13:01:06.642 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.642 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1044 microseconds on worker node localhost:57638
2023-11-25 13:01:06.642 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.642 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 369 microseconds on worker node localhost:57637
2023-11-25 13:01:06.642 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.642 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 343 microseconds on worker node localhost:57638
2023-11-25 13:01:06.642 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.644 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 97 in 3744 microseconds
2023-11-25 13:01:06.644 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.644 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 99 in 3740 microseconds
2023-11-25 13:01:06.644 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.644 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 96: 2 to node localhost:57637
2023-11-25 13:01:06.644 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.644 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 97: 0 to node localhost:57637
2023-11-25 13:01:06.644 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.644 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 98: 2 to node localhost:57638
2023-11-25 13:01:06.644 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.644 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 99: 0 to node localhost:57638
2023-11-25 13:01:06.644 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 integer, worker_column_4 integer) ORDER BY sum DESC, user_id LIMIT '10'::bigint
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.645 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 100 in 3722 microseconds
2023-11-25 13:01:06.645 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.646 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.646 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.646 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 102 in 3677 microseconds
2023-11-25 13:01:06.646 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.646 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 740 microseconds on worker node localhost:57637
2023-11-25 13:01:06.646 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.646 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 616 microseconds on worker node localhost:57638
2023-11-25 13:01:06.646 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.647 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 326 microseconds on worker node localhost:57637
2023-11-25 13:01:06.647 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.647 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 317 microseconds on worker node localhost:57638
2023-11-25 13:01:06.647 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.650 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 101 in 4259 microseconds
2023-11-25 13:01:06.650 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.651 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 103 in 5852 microseconds
2023-11-25 13:01:06.651 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 100: 2 to node localhost:57637
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 101: 0 to node localhost:57637
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 102: 2 to node localhost:57638
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 103: 0 to node localhost:57638
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, worker_column_3, worker_column_2 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.652 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT ON (user_id) user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 integer, worker_column_4 integer) ORDER BY user_id, sum DESC LIMIT '10'::bigint
2023-11-25 13:01:06.652 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.653 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.653 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.653 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 104 in 3722 microseconds
2023-11-25 13:01:06.653 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.653 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.653 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.653 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 106 in 3677 microseconds
2023-11-25 13:01:06.653 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.654 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 894 microseconds on worker node localhost:57637
2023-11-25 13:01:06.654 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.654 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 807 microseconds on worker node localhost:57638
2023-11-25 13:01:06.654 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.654 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 389 microseconds on worker node localhost:57638
2023-11-25 13:01:06.654 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.654 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 487 microseconds on worker node localhost:57637
2023-11-25 13:01:06.654 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.656 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 105 in 2951 microseconds
2023-11-25 13:01:06.656 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 107 in 5120 microseconds
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 104: 2 to node localhost:57637
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 105: 0 to node localhost:57637
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 106: 2 to node localhost:57638
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 107: 0 to node localhost:57638
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.658 UTC [3978942] ERROR:  22004: the partition column of table insert_select_repartition.target_table should have a value
2023-11-25 13:01:06.658 UTC [3978942] LOCATION:  NonPushableInsertSelectExecScan, insert_select_executor.c:153
2023-11-25 13:01:06.658 UTC [3978942] STATEMENT:  INSERT INTO target_table(value) SELECT value FROM source_table;
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.658 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.658 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) OVER (PARTITION BY worker_column_1) AS sum, sum(worker_column_3) OVER (PARTITION BY worker_column_1) AS worker_column_3, worker_column_3 AS worker_column_4, worker_column_2 AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_2 AS worker_column_2, users_table.value_1 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3, worker_column_2 HAVING (count(*) OPERATOR(pg_catalog.>) 2)
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT ON (worker_column_3) user_id, sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, sum bigint, worker_column_3 bigint, worker_column_4 integer, worker_column_5 integer) ORDER BY worker_column_3, sum DESC, user_id LIMIT '10'::bigint
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 108 in 3722 microseconds
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 110 in 3677 microseconds
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 428 microseconds on worker node localhost:57637
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.659 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 431 microseconds on worker node localhost:57638
2023-11-25 13:01:06.659 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.660 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 331 microseconds on worker node localhost:57637
2023-11-25 13:01:06.660 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.660 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 284 microseconds on worker node localhost:57638
2023-11-25 13:01:06.660 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.662 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 109 in 3219 microseconds
2023-11-25 13:01:06.662 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.663 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 111 in 4134 microseconds
2023-11-25 13:01:06.663 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.663 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 108: 2 to node localhost:57637
2023-11-25 13:01:06.663 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.663 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 109: 0 to node localhost:57637
2023-11-25 13:01:06.663 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.663 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 110: 2 to node localhost:57638
2023-11-25 13:01:06.663 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.663 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 111: 0 to node localhost:57638
2023-11-25 13:01:06.663 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, avg_1 AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, avg_1 numeric, worker_column_4 integer, worker_column_5 integer, worker_column_6 integer, worker_column_7 numeric) ORDER BY avg_1 DESC, avg DESC, user_id DESC
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.664 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 112 in 3722 microseconds
2023-11-25 13:01:06.664 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.665 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.665 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.665 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 114 in 3677 microseconds
2023-11-25 13:01:06.665 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.665 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 775 microseconds on worker node localhost:57637
2023-11-25 13:01:06.665 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.666 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 444 microseconds on worker node localhost:57637
2023-11-25 13:01:06.666 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.666 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1089 microseconds on worker node localhost:57638
2023-11-25 13:01:06.666 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.666 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 502 microseconds on worker node localhost:57638
2023-11-25 13:01:06.666 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.670 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 113 in 5536 microseconds
2023-11-25 13:01:06.670 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.670 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 115 in 5468 microseconds
2023-11-25 13:01:06.670 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.670 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 112: 2 to node localhost:57637
2023-11-25 13:01:06.670 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.670 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 113: 0 to node localhost:57637
2023-11-25 13:01:06.670 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.670 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 114: 2 to node localhost:57638
2023-11-25 13:01:06.670 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.670 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 115: 0 to node localhost:57638
2023-11-25 13:01:06.670 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(avg(worker_column_2)) OVER (PARTITION BY worker_column_1, (max(worker_column_1)), (min(worker_column_3))) AS avg, avg(avg(worker_column_1)) OVER (PARTITION BY worker_column_1, (min(worker_column_1)), (avg(worker_column_2))) AS avg, max(worker_column_1) AS worker_column_4, min(worker_column_3) AS worker_column_5, min(worker_column_1) AS worker_column_6, avg(worker_column_2) AS worker_column_7 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.671 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.671 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.671 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.672 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.672 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.672 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.672 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.672 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.672 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.672 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, avg_1 AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, avg_1 numeric, worker_column_4 integer, worker_column_5 integer, worker_column_6 integer, worker_column_7 numeric) ORDER BY avg_1 DESC, avg DESC, user_id DESC
2023-11-25 13:01:06.672 UTC [3978941] CONTEXT:  PL/pgSQL function coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:06.672 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.673 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.673 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.673 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.673 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.673 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.673 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.673 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.673 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.673 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.673 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.673 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.673 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.673 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.673 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.673 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.673 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.674 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.674 UTC [3978941] DETAIL:  query string: "SELECT value_2, sum(value_1) AS avg, count(value_1) AS avg, sum(value_2) AS avg, count(value_2) AS avg, max(value_2) AS worker_column_6, min(value_2) AS worker_column_7, sum(value_1) AS worker_column_8, count(value_1) AS worker_column_9 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_2"
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: combine query: SELECT value_2, avg((pg_catalog.sum(avg) OPERATOR(pg_catalog./) pg_catalog.sum(avg_1))) OVER (PARTITION BY value_2, (max(worker_column_6)), (min(worker_column_7))) AS avg, avg((pg_catalog.sum(avg_2) OPERATOR(pg_catalog./) pg_catalog.sum(avg_3))) OVER (PARTITION BY value_2, (min(worker_column_7)), (pg_catalog.sum(worker_column_8) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_9))) AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, avg bigint, avg_1 bigint, avg_2 bigint, avg_3 bigint, worker_column_6 integer, worker_column_7 integer, worker_column_8 bigint, worker_column_9 bigint) GROUP BY value_2 ORDER BY (avg((pg_catalog.sum(avg_2) OPERATOR(pg_catalog./) pg_catalog.sum(avg_3))) OVER (PARTITION BY value_2, (min(worker_column_7)), (pg_catalog.sum(worker_column_8) OPERATOR(pg_catalog./) pg_catalog.sum(worker_column_9)))) DESC, (avg((pg_catalog.sum(avg) OPERATOR(pg_catalog./) pg_catalog.sum(avg_1))) OVER (PARTITION BY value_2, (max(worker_column_6)), (min(worker_column_7)))) DESC, value_2 DESC
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 116 in 3722 microseconds
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.674 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 118 in 3677 microseconds
2023-11-25 13:01:06.674 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.675 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 727 microseconds on worker node localhost:57637
2023-11-25 13:01:06.675 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.675 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 585 microseconds on worker node localhost:57638
2023-11-25 13:01:06.675 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.675 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 404 microseconds on worker node localhost:57637
2023-11-25 13:01:06.675 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.675 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 359 microseconds on worker node localhost:57638
2023-11-25 13:01:06.675 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.678 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 119 in 3750 microseconds
2023-11-25 13:01:06.678 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 117 in 7585 microseconds
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 116: 2 to node localhost:57637
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 117: 0 to node localhost:57637
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 118: 2 to node localhost:57638
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 119: 0 to node localhost:57638
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.682 UTC [3978941] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400256 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.682 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.682 UTC [3978941] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400257 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 13:01:06.682 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.683 UTC [3978941] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400258 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.683 UTC [3978941] DETAIL:  query string: "SELECT value_2, user_id, avg(value_1) AS avg, avg(value_2) AS avg, max(value_2) AS worker_column_5, min(value_2) AS worker_column_6, avg(value_1) AS worker_column_7 FROM public.users_table_1400259 users_table WHERE true GROUP BY value_2, user_id"
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: combine query: SELECT value_2, user_id, avg(avg) OVER (PARTITION BY value_2, worker_column_5, worker_column_6) AS avg, avg(avg_1) OVER (PARTITION BY user_id, worker_column_6, worker_column_7) AS avg FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(value_2 integer, user_id integer, avg numeric, avg_1 numeric, worker_column_5 integer, worker_column_6 integer, worker_column_7 numeric) ORDER BY (avg(avg) OVER (PARTITION BY value_2, worker_column_5, worker_column_6)) DESC, user_id DESC, value_2 DESC
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 120 in 3722 microseconds
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.683 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 122 in 3677 microseconds
2023-11-25 13:01:06.683 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.684 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 583 microseconds on worker node localhost:57637
2023-11-25 13:01:06.684 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.684 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 472 microseconds on worker node localhost:57638
2023-11-25 13:01:06.684 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.684 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 363 microseconds on worker node localhost:57637
2023-11-25 13:01:06.684 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.684 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 351 microseconds on worker node localhost:57638
2023-11-25 13:01:06.684 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.687 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 123 in 3979 microseconds
2023-11-25 13:01:06.687 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.689 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 121 in 5845 microseconds
2023-11-25 13:01:06.689 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.689 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 120: 2 to node localhost:57637
2023-11-25 13:01:06.689 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.689 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 121: 0 to node localhost:57637
2023-11-25 13:01:06.689 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.689 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 122: 2 to node localhost:57638
2023-11-25 13:01:06.689 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.689 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 123: 0 to node localhost:57638
2023-11-25 13:01:06.689 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.691 UTC [3978941] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400256 users_table WHERE true GROUP BY user_id"
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.691 UTC [3978941] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400257 users_table WHERE true GROUP BY user_id"
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.691 UTC [3978941] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400258 users_table WHERE true GROUP BY user_id"
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.691 UTC [3978941] DETAIL:  query string: "SELECT user_id, avg(user_id) AS sum FROM public.users_table_1400259 users_table WHERE true GROUP BY user_id"
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.691 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.691 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, sum(sum) OVER () AS sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(user_id integer, sum numeric) ORDER BY user_id LIMIT '10'::bigint
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 124 in 3722 microseconds
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 126 in 3677 microseconds
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 368 microseconds on worker node localhost:57637
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 378 microseconds on worker node localhost:57638
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.692 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 264 microseconds on worker node localhost:57637
2023-11-25 13:01:06.692 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.693 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 229 microseconds on worker node localhost:57638
2023-11-25 13:01:06.693 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.695 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 125 in 3172 microseconds
2023-11-25 13:01:06.695 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.695 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 127 in 3157 microseconds
2023-11-25 13:01:06.695 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.695 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 124: 2 to node localhost:57637
2023-11-25 13:01:06.695 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.695 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 125: 0 to node localhost:57637
2023-11-25 13:01:06.695 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.695 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 126: 2 to node localhost:57638
2023-11-25 13:01:06.695 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.695 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 127: 0 to node localhost:57638
2023-11-25 13:01:06.695 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, "?column?", "?column?_1" AS "?column?" FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, "?column?" bigint, "?column?_1" numeric, worker_column_4 integer) ORDER BY user_id, worker_column_4
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 128 in 3722 microseconds
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.696 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 130 in 3677 microseconds
2023-11-25 13:01:06.696 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.697 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 504 microseconds on worker node localhost:57637
2023-11-25 13:01:06.697 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.697 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 286 microseconds on worker node localhost:57637
2023-11-25 13:01:06.697 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.697 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 957 microseconds on worker node localhost:57638
2023-11-25 13:01:06.697 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.698 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 1034 microseconds on worker node localhost:57638
2023-11-25 13:01:06.698 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.700 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 129 in 3553 microseconds
2023-11-25 13:01:06.700 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.701 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 131 in 4699 microseconds
2023-11-25 13:01:06.701 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.701 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 128: 2 to node localhost:57637
2023-11-25 13:01:06.701 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.701 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 129: 0 to node localhost:57637
2023-11-25 13:01:06.701 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.701 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 130: 2 to node localhost:57638
2023-11-25 13:01:06.701 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.701 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 131: 0 to node localhost:57638
2023-11-25 13:01:06.701 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, (1 OPERATOR(pg_catalog.+) sum(worker_column_2)), ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_3) OVER (PARTITION BY worker_column_1)), worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY (1 OPERATOR(pg_catalog.+) sum(worker_column_2)) DESC, worker_column_1 LIMIT '5'::bigint
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, "?column?", "?column?_1" AS "?column?" FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, "?column?" bigint, "?column?_1" numeric, worker_column_4 integer) ORDER BY "?column?" DESC, user_id LIMIT '5'::bigint
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 132 in 3722 microseconds
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.702 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 134 in 3677 microseconds
2023-11-25 13:01:06.702 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.704 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1704 microseconds on worker node localhost:57637
2023-11-25 13:01:06.704 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.704 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 1585 microseconds on worker node localhost:57638
2023-11-25 13:01:06.704 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.704 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 442 microseconds on worker node localhost:57637
2023-11-25 13:01:06.704 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.704 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 471 microseconds on worker node localhost:57638
2023-11-25 13:01:06.704 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.706 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 135 in 3620 microseconds
2023-11-25 13:01:06.706 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.707 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 133 in 4363 microseconds
2023-11-25 13:01:06.707 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.707 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 132: 2 to node localhost:57637
2023-11-25 13:01:06.707 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.707 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 133: 0 to node localhost:57637
2023-11-25 13:01:06.707 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.707 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 134: 2 to node localhost:57638
2023-11-25 13:01:06.707 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.707 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 135: 0 to node localhost:57638
2023-11-25 13:01:06.707 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY worker_column_3) AS rank, worker_column_3 AS worker_column_4 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer) ORDER BY user_id, worker_column_4 DESC
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 136 in 3722 microseconds
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.708 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 138 in 3677 microseconds
2023-11-25 13:01:06.708 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.709 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 926 microseconds on worker node localhost:57637
2023-11-25 13:01:06.709 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.709 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 750 microseconds on worker node localhost:57638
2023-11-25 13:01:06.709 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.710 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 314 microseconds on worker node localhost:57638
2023-11-25 13:01:06.710 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.710 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 401 microseconds on worker node localhost:57637
2023-11-25 13:01:06.710 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.712 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 139 in 3347 microseconds
2023-11-25 13:01:06.712 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.713 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 137 in 5099 microseconds
2023-11-25 13:01:06.713 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.713 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 136: 2 to node localhost:57637
2023-11-25 13:01:06.713 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.713 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 137: 0 to node localhost:57637
2023-11-25 13:01:06.713 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.713 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 138: 2 to node localhost:57638
2023-11-25 13:01:06.713 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.713 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 139: 0 to node localhost:57638
2023-11-25 13:01:06.713 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.714 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC
2023-11-25 13:01:06.714 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.715 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.715 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.715 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 140 in 3722 microseconds
2023-11-25 13:01:06.715 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.715 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.715 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.715 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 142 in 3677 microseconds
2023-11-25 13:01:06.715 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.715 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 561 microseconds on worker node localhost:57637
2023-11-25 13:01:06.715 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.716 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 654 microseconds on worker node localhost:57638
2023-11-25 13:01:06.716 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.716 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 480 microseconds on worker node localhost:57638
2023-11-25 13:01:06.716 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.717 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 1437 microseconds on worker node localhost:57637
2023-11-25 13:01:06.717 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.719 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 143 in 4128 microseconds
2023-11-25 13:01:06.719 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.722 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 141 in 7025 microseconds
2023-11-25 13:01:06.722 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.722 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 140: 2 to node localhost:57637
2023-11-25 13:01:06.722 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.722 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 141: 0 to node localhost:57637
2023-11-25 13:01:06.722 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.722 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 142: 2 to node localhost:57638
2023-11-25 13:01:06.722 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.722 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 143: 0 to node localhost:57638
2023-11-25 13:01:06.722 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.723 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.723 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.724 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.724 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.724 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.724 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.724 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.724 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.724 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.724 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.724 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.724 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.724 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC
2023-11-25 13:01:06.724 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.726 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.726 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.726 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.726 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.726 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.726 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.726 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.726 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.726 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.726 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 144 in 3722 microseconds
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.727 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 146 in 3677 microseconds
2023-11-25 13:01:06.727 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.728 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 851 microseconds on worker node localhost:57638
2023-11-25 13:01:06.728 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.728 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 423 microseconds on worker node localhost:57638
2023-11-25 13:01:06.728 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.728 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1519 microseconds on worker node localhost:57637
2023-11-25 13:01:06.728 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.729 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 528 microseconds on worker node localhost:57637
2023-11-25 13:01:06.729 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.731 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 147 in 4325 microseconds
2023-11-25 13:01:06.731 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.734 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 145 in 6712 microseconds
2023-11-25 13:01:06.734 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.734 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 144: 2 to node localhost:57637
2023-11-25 13:01:06.734 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.734 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 145: 0 to node localhost:57637
2023-11-25 13:01:06.734 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.734 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 146: 2 to node localhost:57638
2023-11-25 13:01:06.734 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.734 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 147: 0 to node localhost:57638
2023-11-25 13:01:06.734 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.735 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 13:01:06.735 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.739 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.739 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.740 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2)))) AS rank, worker_column_3 AS worker_column_4, ((1)::numeric OPERATOR(pg_catalog./) ((1)::numeric OPERATOR(pg_catalog.+) avg(worker_column_2))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.740 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.740 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.740 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.740 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.740 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.740 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.740 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.740 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.740 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.740 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 numeric) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 13:01:06.740 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.743 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.743 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.744 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.744 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.744 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3)))) AS rank, worker_column_3 AS worker_column_4, (1 OPERATOR(pg_catalog./) (1 OPERATOR(pg_catalog.+) sum(worker_column_3))) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.744 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.744 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.744 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.744 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.744 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.744 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.744 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.744 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.744 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.744 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 bigint) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 13:01:06.744 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.748 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.748 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.748 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.748 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.748 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.748 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.748 UTC [3978941] DEBUG:  00000: push down of limit count: 5
2023-11-25 13:01:06.748 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400256 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400257 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400258 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, avg(worker_column_2) AS avg, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_3))) AS rank, worker_column_3 AS worker_column_4, sum(worker_column_3) AS worker_column_5 FROM (SELECT users_table.user_id AS worker_column_1, users_table.value_1 AS worker_column_2, users_table.value_2 AS worker_column_3 FROM public.users_table_1400259 users_table) worker_subquery GROUP BY worker_column_1, worker_column_3 ORDER BY worker_column_1, (avg(worker_column_2)) DESC LIMIT '5'::bigint
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.749 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, avg, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, avg numeric, rank bigint, worker_column_4 integer, worker_column_5 bigint) ORDER BY user_id, avg DESC LIMIT '5'::bigint
2023-11-25 13:01:06.749 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.752 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.752 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.752 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.752 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.752 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.752 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.752 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.752 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.752 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.752 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.755 UTC [3978941] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400256 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.755 UTC [3978941] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400257 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.755 UTC [3978941] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400258 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.755 UTC [3978941] DETAIL:  query string: "SELECT user_id, count(value_1) AS count, stddev(value_1) AS stddev, user_id AS count, random() AS worker_column_5 FROM public.users_table_1400259 users_table WHERE true GROUP BY user_id HAVING (avg(value_1) OPERATOR(pg_catalog.>) '2'::numeric)"
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.755 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.755 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.756 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, count, stddev, count(count_1) OVER (PARTITION BY worker_column_5) AS count FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan(user_id integer, count bigint, stddev numeric, count_1 integer, worker_column_5 double precision) LIMIT '1'::bigint
2023-11-25 13:01:06.756 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  00000: CTE cte is going to be inlined via distributed planning
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  InlineCTEsInQueryTree, cte_inline.c:117
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.759 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.759 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.760 UTC [3978941] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400260 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.760 UTC [3978941] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400261 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.760 UTC [3978941] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400262 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.760 UTC [3978941] DETAIL:  query string: "SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table_1400263 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true GROUP BY uref.id, events_table.value_2"
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, value_2, COALESCE((pg_catalog.sum(c))::bigint, '0'::bigint) AS c FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1 2)'::cstring(0)) remote_scan(user_id integer, value_2 integer, c bigint) GROUP BY user_id, value_2
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: generating subplan 46_1 for subquery SELECT uref.id AS user_id, events_table.value_2, count(*) AS c FROM (public.events_table JOIN public.users_ref_test_table uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) GROUP BY uref.id, events_table.value_2
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  RecursivelyPlanSubquery, recursive_planning.c:1551
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: Plan 46 query after replacing subqueries and CTEs: SELECT DISTINCT cte.value_2, cte.c, sum(cte.value_2) OVER (PARTITION BY cte.c) AS sum FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c)))) ORDER BY cte.value_2
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  GenerateSubplansForSubqueriesAndCTEs, recursive_planning.c:248
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.760 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.760 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400260 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400261 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400262 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS value_2, worker_column_2 AS c, worker_column_1 AS sum FROM (SELECT cte.value_2 AS worker_column_1, cte.c AS worker_column_2 FROM ((SELECT intermediate_result.user_id, intermediate_result.value_2, intermediate_result.c FROM read_intermediate_result('46_1'::text, 'binary'::citus_copy_format) intermediate_result(user_id integer, value_2 integer, c bigint)) cte JOIN public.events_table_1400263 et ON (((et.value_2 OPERATOR(pg_catalog.=) cte.value_2) AND (et.value_2 OPERATOR(pg_catalog.=) cte.c))))) worker_subquery
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: combine query: SELECT DISTINCT value_2, c, sum(sum) OVER (PARTITION BY c) AS sum FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(value_2 integer, c bigint, sum integer) ORDER BY value_2
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: Subplan 46_1 is used in 46
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  RecordSubplanExecutionsOnNodes, intermediate_result_pruning.c:193
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: Subplan 46_1 will be sent to localhost:57637
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: Subplan 46_1 will be sent to localhost:57638
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:422
2023-11-25 13:01:06.761 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.761 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.763 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 148 in 3722 microseconds
2023-11-25 13:01:06.763 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.763 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.763 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.764 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 150 in 3677 microseconds
2023-11-25 13:01:06.764 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.764 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 586 microseconds on worker node localhost:57637
2023-11-25 13:01:06.764 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.765 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 714 microseconds on worker node localhost:57638
2023-11-25 13:01:06.765 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.765 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 593 microseconds on worker node localhost:57637
2023-11-25 13:01:06.765 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.765 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 297 microseconds on worker node localhost:57638
2023-11-25 13:01:06.765 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.767 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 149 in 3615 microseconds
2023-11-25 13:01:06.767 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.770 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 151 in 6835 microseconds
2023-11-25 13:01:06.770 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.770 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 148: 2 to node localhost:57637
2023-11-25 13:01:06.770 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.770 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 149: 0 to node localhost:57637
2023-11-25 13:01:06.770 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.770 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 150: 2 to node localhost:57638
2023-11-25 13:01:06.770 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.770 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 151: 0 to node localhost:57638
2023-11-25 13:01:06.770 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.771 UTC [3978941] DEBUG:  00000: Session 152 (localhost:57637) has an assigned task
2023-11-25 13:01:06.771 UTC [3978941] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 13:01:06.771 UTC [3978941] DEBUG:  00000: Session 153 (localhost:57638) has an assigned task
2023-11-25 13:01:06.771 UTC [3978941] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 13:01:06.771 UTC [3978941] DEBUG:  00000: Session 152 (localhost:57637) has an assigned task
2023-11-25 13:01:06.771 UTC [3978941] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 13:01:06.771 UTC [3978941] DEBUG:  00000: Session 153 (localhost:57638) has an assigned task
2023-11-25 13:01:06.771 UTC [3978941] LOCATION:  AssignTasksToConnectionsOrWorkerPool, adaptive_executor.c:1468
2023-11-25 13:01:06.772 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 631 microseconds on worker node localhost:57638
2023-11-25 13:01:06.772 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.772 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 734 microseconds on worker node localhost:57637
2023-11-25 13:01:06.772 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.772 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 404 microseconds on worker node localhost:57638
2023-11-25 13:01:06.772 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.772 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 348 microseconds on worker node localhost:57637
2023-11-25 13:01:06.772 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.772 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 152: 2 to node localhost:57637
2023-11-25 13:01:06.772 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.772 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 153: 2 to node localhost:57638
2023-11-25 13:01:06.772 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.774 UTC [3978941] DEBUG:  00000: sending sinval catchup signal to PID 3976586
2023-11-25 13:01:06.774 UTC [3978941] LOCATION:  SICleanupQueue, sinvaladt.c:747
2023-11-25 13:01:06.777 UTC [3978941] DEBUG:  00000: FromList item is not empty
2023-11-25 13:01:06.777 UTC [3978941] CONTEXT:  SQL statement "SELECT TRUE FROM public.daily_uniques LIMIT 1"
2023-11-25 13:01:06.777 UTC [3978941] LOCATION:  TryToDelegateFunctionCall, function_call_delegation.c:196
2023-11-25 13:01:06.778 UTC [3978941] DEBUG:  00000: opening 1 new connections to localhost:57637
2023-11-25 13:01:06.778 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.778 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 154 in 3722 microseconds
2023-11-25 13:01:06.778 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.778 UTC [3978941] DEBUG:  00000: opening 1 new connections to localhost:57638
2023-11-25 13:01:06.778 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.778 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 155 in 3677 microseconds
2023-11-25 13:01:06.778 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.780 UTC [3978941] DEBUG:  00000: task execution (1) for placement (1067) on anchor shard (360164) finished in 1310 microseconds on worker node localhost:57637
2023-11-25 13:01:06.780 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.782 UTC [3978941] DEBUG:  00000: task execution (2) for placement (1068) on anchor shard (360164) finished in 3254 microseconds on worker node localhost:57638
2023-11-25 13:01:06.782 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.782 UTC [3978941] DEBUG:  00000: task execution (3) for placement (1069) on anchor shard (360165) finished in 2102 microseconds on worker node localhost:57637
2023-11-25 13:01:06.782 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.783 UTC [3978941] DEBUG:  00000: task execution (5) for placement (1071) on anchor shard (360166) finished in 513 microseconds on worker node localhost:57637
2023-11-25 13:01:06.783 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.783 UTC [3978941] DEBUG:  00000: task execution (4) for placement (1070) on anchor shard (360165) finished in 1179 microseconds on worker node localhost:57638
2023-11-25 13:01:06.783 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.784 UTC [3978941] DEBUG:  00000: task execution (7) for placement (1073) on anchor shard (360167) finished in 756 microseconds on worker node localhost:57637
2023-11-25 13:01:06.784 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.784 UTC [3978941] DEBUG:  00000: task execution (6) for placement (1072) on anchor shard (360166) finished in 863 microseconds on worker node localhost:57638
2023-11-25 13:01:06.784 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.785 UTC [3978941] DEBUG:  00000: task execution (8) for placement (1074) on anchor shard (360167) finished in 584 microseconds on worker node localhost:57638
2023-11-25 13:01:06.785 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.785 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 154: 4 to node localhost:57637
2023-11-25 13:01:06.785 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.785 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 155: 4 to node localhost:57638
2023-11-25 13:01:06.785 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: no shard pruning constraints on daily_uniques found
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: shard count after pruning for daily_uniques: 4
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: push down of limit count: 10
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: no shard pruning constraints on daily_uniques found
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: shard count after pruning for daily_uniques: 4
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360164 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360165 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360166 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, sum(worker_column_2) AS commits, rank() OVER (PARTITION BY worker_column_1 ORDER BY (sum(worker_column_2)) DESC) AS rank FROM (SELECT daily_uniques.user_id AS worker_column_1, daily_uniques.value_2 AS worker_column_2 FROM public.daily_uniques_360167 daily_uniques) worker_subquery GROUP BY worker_column_1 HAVING (sum(worker_column_2) OPERATOR(pg_catalog.>) (0)::double precision) ORDER BY (sum(worker_column_2)) DESC LIMIT '10'::bigint
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.797 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, commits, rank FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id bigint, commits double precision, rank bigint) ORDER BY commits DESC LIMIT '10'::bigint
2023-11-25 13:01:06.797 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.801 UTC [3978941] DEBUG:  00000: drop auto-cascades to type daily_uniques
2023-11-25 13:01:06.801 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.801 UTC [3978941] DEBUG:  00000: drop auto-cascades to type daily_uniques[]
2023-11-25 13:01:06.801 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.801 UTC [3978941] DEBUG:  00000: drop auto-cascades to trigger truncate_trigger_18431 on table daily_uniques
2023-11-25 13:01:06.801 UTC [3978941] LOCATION:  reportDependentObjects, dependency.c:1122
2023-11-25 13:01:06.801 UTC [3978941] DEBUG:  00000: EventTriggerInvoke 16675
2023-11-25 13:01:06.801 UTC [3978941] LOCATION:  EventTriggerInvoke, event_trigger.c:900
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.816 UTC [3978941] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400260 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.816 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.816 UTC [3978941] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400261 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.816 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.817 UTC [3978941] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400262 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.817 UTC [3978941] DETAIL:  query string: "SELECT events_table.value_2, uref.k_no AS rnk, uref.id AS worker_column_3 FROM (public.events_table_1400263 events_table JOIN public.users_ref_test_table_1400284 uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id))) WHERE true"
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: combine query: SELECT value_2, sum(rnk) OVER (PARTITION BY worker_column_3) AS rnk FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1 2)'::cstring(0)) remote_scan(value_2 integer, rnk integer, worker_column_3 integer)
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: generating subplan 49_1 for subquery SELECT events_table.value_2, sum(uref.k_no) OVER (PARTITION BY uref.id) AS rnk FROM (public.events_table JOIN public.users_ref_test_table uref ON ((uref.id OPERATOR(pg_catalog.=) events_table.user_id)))
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  RecursivelyPlanSubquery, recursive_planning.c:1551
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: Plan 49 query after replacing subqueries and CTEs: SELECT DISTINCT value_2, array_agg(rnk ORDER BY rnk) AS array_agg FROM (SELECT intermediate_result.value_2, intermediate_result.rnk FROM read_intermediate_result('49_1'::text, 'binary'::citus_copy_format) intermediate_result(value_2 integer, rnk bigint)) sq GROUP BY value_2 ORDER BY value_2
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  GenerateSubplansForSubqueriesAndCTEs, recursive_planning.c:248
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: Creating router plan
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  CreateSingleTaskRouterSelectPlan, multi_router_planner.c:284
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: Subplan 49_1 is used in 49
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  RecordSubplanExecutionsOnNodes, intermediate_result_pruning.c:193
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: Subplan 49_1 will be written to local file
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  LogIntermediateResultMulticastSummary, intermediate_result_pruning.c:416
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 156 in 3722 microseconds
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.817 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 158 in 3677 microseconds
2023-11-25 13:01:06.817 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.818 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 716 microseconds on worker node localhost:57638
2023-11-25 13:01:06.818 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.819 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 282 microseconds on worker node localhost:57638
2023-11-25 13:01:06.819 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.820 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 2533 microseconds on worker node localhost:57637
2023-11-25 13:01:06.820 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.820 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 288 microseconds on worker node localhost:57637
2023-11-25 13:01:06.820 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.821 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 157 in 4269 microseconds
2023-11-25 13:01:06.821 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.828 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 159 in 10392 microseconds
2023-11-25 13:01:06.828 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.828 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 156: 2 to node localhost:57637
2023-11-25 13:01:06.828 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.828 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 157: 0 to node localhost:57637
2023-11-25 13:01:06.828 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.828 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 158: 2 to node localhost:57638
2023-11-25 13:01:06.828 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.828 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 159: 0 to node localhost:57638
2023-11-25 13:01:06.828 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.830 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.830 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.830 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.830 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.830 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.830 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.830 UTC [3978941] DEBUG:  00000: push down of limit count: 1
2023-11-25 13:01:06.830 UTC [3978941] LOCATION:  WorkerLimitCount, multi_logical_optimizer.c:4778
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: generated sql query for task 1
2023-11-25 13:01:06.831 UTC [3978941] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400256 ut WHERE true LIMIT '1'::bigint"
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: generated sql query for task 2
2023-11-25 13:01:06.831 UTC [3978941] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400257 ut WHERE true LIMIT '1'::bigint"
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: generated sql query for task 3
2023-11-25 13:01:06.831 UTC [3978941] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400258 ut WHERE true LIMIT '1'::bigint"
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: generated sql query for task 4
2023-11-25 13:01:06.831 UTC [3978941] DETAIL:  query string: "SELECT NULL::boolean FROM public.users_table_1400259 ut WHERE true LIMIT '1'::bigint"
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  SqlTaskList, multi_physical_planner.c:2713
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: combine query: SELECT "?column?" FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), '(i 1)'::cstring(0)) remote_scan("?column?" boolean) LIMIT '1'::bigint
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 160 in 3722 microseconds
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.831 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 162 in 3677 microseconds
2023-11-25 13:01:06.831 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.832 UTC [3978941] DEBUG:  00000: task execution (2) for placement (837) on anchor shard (1400257) finished in 654 microseconds on worker node localhost:57638
2023-11-25 13:01:06.832 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.832 UTC [3978941] DEBUG:  00000: task execution (4) for placement (839) on anchor shard (1400259) finished in 228 microseconds on worker node localhost:57638
2023-11-25 13:01:06.832 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.832 UTC [3978941] DEBUG:  00000: task execution (1) for placement (836) on anchor shard (1400256) finished in 1122 microseconds on worker node localhost:57637
2023-11-25 13:01:06.832 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.833 UTC [3978941] DEBUG:  00000: task execution (3) for placement (838) on anchor shard (1400258) finished in 909 microseconds on worker node localhost:57637
2023-11-25 13:01:06.833 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.835 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 161 in 3923 microseconds
2023-11-25 13:01:06.835 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.838 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 163 in 6818 microseconds
2023-11-25 13:01:06.838 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.838 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 160: 2 to node localhost:57637
2023-11-25 13:01:06.838 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.838 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 161: 0 to node localhost:57637
2023-11-25 13:01:06.838 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.838 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 162: 2 to node localhost:57638
2023-11-25 13:01:06.838 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.838 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 163: 0 to node localhost:57638
2023-11-25 13:01:06.838 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  0A000: Router planner cannot handle multi-shard select queries
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PlanRouterQuery, multi_router_planner.c:2344
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: no shard pruning constraints on users_table found
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: shard count after pruning for users_table: 4
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: no shard pruning constraints on events_table found
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:495
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: shard count after pruning for events_table: 4
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  PruneShards, shard_pruning.c:499
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400256 us, public.events_table_1400260 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400257 us, public.events_table_1400261 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400258 us, public.events_table_1400262 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: distributed statement: SELECT worker_column_1 AS user_id, max(worker_column_2) OVER (PARTITION BY worker_column_1, (min(worker_column_3))) AS max, worker_column_2 AS worker_column_3, min(worker_column_3) AS worker_column_4 FROM (SELECT s.user_id AS worker_column_1, s.value_1 AS worker_column_2, s.value_2 AS worker_column_3 FROM (SELECT DISTINCT us.user_id, us.value_2, us.value_1, random() AS r1 FROM public.users_table_1400259 us, public.events_table_1400263 events_table WHERE ((us.user_id OPERATOR(pg_catalog.=) events_table.user_id) AND (events_table.event_type OPERATOR(pg_catalog.=) ANY (ARRAY[1, 2]))) ORDER BY us.user_id, us.value_2) s) worker_subquery GROUP BY worker_column_1, worker_column_2
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  QueryPushdownTaskCreate, multi_physical_planner.c:2559
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: assigned task 1 to node localhost:57637
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: assigned task 2 to node localhost:57638
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: assigned task 3 to node localhost:57637
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: assigned task 4 to node localhost:57638
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  GreedyAssignTask, multi_physical_planner.c:5140
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: combine query: SELECT user_id, max FROM pg_catalog.citus_extradata_container(10, NULL::cstring(0), NULL::cstring(0), NULL::cstring(0)) remote_scan(user_id integer, max integer, worker_column_3 integer, worker_column_4 integer) ORDER BY max DESC, user_id
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  BuildSelectStatementViaStdPlanner, combine_query_planner.c:291
2023-11-25 13:01:06.839 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57637
2023-11-25 13:01:06.839 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.840 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 164 in 3722 microseconds
2023-11-25 13:01:06.840 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.840 UTC [3978941] DEBUG:  00000: opening 2 new connections to localhost:57638
2023-11-25 13:01:06.840 UTC [3978941] LOCATION:  OpenNewConnections, adaptive_executor.c:2572
2023-11-25 13:01:06.840 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 166 in 3677 microseconds
2023-11-25 13:01:06.840 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.841 UTC [3978941] DEBUG:  00000: task execution (1) for placement (840) on anchor shard (1400260) finished in 1124 microseconds on worker node localhost:57637
2023-11-25 13:01:06.841 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.841 UTC [3978941] DEBUG:  00000: task execution (2) for placement (841) on anchor shard (1400261) finished in 1584 microseconds on worker node localhost:57638
2023-11-25 13:01:06.841 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.842 UTC [3978941] DEBUG:  00000: task execution (3) for placement (842) on anchor shard (1400262) finished in 860 microseconds on worker node localhost:57637
2023-11-25 13:01:06.842 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.842 UTC [3978941] DEBUG:  00000: task execution (4) for placement (843) on anchor shard (1400263) finished in 1004 microseconds on worker node localhost:57638
2023-11-25 13:01:06.842 UTC [3978941] LOCATION:  PlacementExecutionDone, adaptive_executor.c:4326
2023-11-25 13:01:06.843 UTC [3978941] DEBUG:  00000: established connection to localhost:57637 for session 165 in 3056 microseconds
2023-11-25 13:01:06.843 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.852 UTC [3978941] DEBUG:  00000: established connection to localhost:57638 for session 167 in 12482 microseconds
2023-11-25 13:01:06.852 UTC [3978941] LOCATION:  HandleMultiConnectionSuccess, adaptive_executor.c:3275
2023-11-25 13:01:06.852 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 164: 2 to node localhost:57637
2023-11-25 13:01:06.852 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.852 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 165: 0 to node localhost:57637
2023-11-25 13:01:06.852 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.852 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 166: 2 to node localhost:57638
2023-11-25 13:01:06.852 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.852 UTC [3978941] DEBUG:  00000: Total number of commands sent over the session 167: 0 to node localhost:57638
2023-11-25 13:01:06.852 UTC [3978941] LOCATION:  CleanUpSessions, adaptive_executor.c:4863
2023-11-25 13:01:06.853 UTC [3978941] DEBUG:  00000: shmem_exit(0): 6 before_shmem_exit callbacks to make
2023-11-25 13:01:06.853 UTC [3978941] LOCATION:  shmem_exit, ipc.c:236
2023-11-25 13:01:06.853 UTC [3978941] DEBUG:  00000: shmem_exit(0): 6 on_shmem_exit callbacks to make
2023-11-25 13:01:06.853 UTC [3978941] LOCATION:  shmem_exit, ipc.c:269
2023-11-25 13:01:06.853 UTC [3978941] DEBUG:  00000: proc_exit(0): 2 callbacks to make
2023-11-25 13:01:06.853 UTC [3978941] LOCATION:  proc_exit_prepare, ipc.c:196
2023-11-25 13:01:06.853 UTC [3978941] DEBUG:  00000: exit(0)
2023-11-25 13:01:06.853 UTC [3978941] LOCATION:  proc_exit, ipc.c:150
2023-11-25 13:01:06.853 UTC [3978941] DEBUG:  00000: shmem_exit(-1): 0 before_shmem_exit callbacks to make
2023-11-25 13:01:06.853 UTC [3978941] LOCATION:  shmem_exit, ipc.c:236
2023-11-25 13:01:06.853 UTC [3978941] DEBUG:  00000: shmem_exit(-1): 0 on_shmem_exit callbacks to make
2023-11-25 13:01:06.853 UTC [3978941] LOCATION:  shmem_exit, ipc.c:269
2023-11-25 13:01:06.853 UTC [3978941] DEBUG:  00000: proc_exit(-1): 0 callbacks to make
2023-11-25 13:01:06.853 UTC [3978941] LOCATION:  proc_exit_prepare, ipc.c:196
2023-11-25 13:01:06.964 UTC [3978940] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:06.964 UTC [3978940] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:06.964 UTC [3978940] STATEMENT:  UPDATE
		second_distributed_table
	SET
		dept = foo.tenant_id::int / 4
	FROM
	(
		SELECT DISTINCT foo_inner_1.tenant_id FROM
		(
			SELECT
				second_distributed_table.dept, second_distributed_table.tenant_id
			FROM
				second_distributed_table, distributed_table
			WHERE
				distributed_table.tenant_id = second_distributed_table.tenant_id
			AND
				second_distributed_table.dept IN (select dept from second_distributed_table))
		foo_inner_1 JOIN LATERAL
		(
			SELECT
				second_distributed_table.tenant_id
			FROM
				second_distributed_table, distributed_table
			WHERE
				distributed_table.tenant_id = second_distributed_table.tenant_id
				AND foo_inner_1.dept = second_distributed_table.dept
			AND
				second_distributed_table.dept IN (4,5)
		) foo_inner_2
		ON (foo_inner_2.tenant_id != foo_inner_1.tenant_id)
		) as foo
	RETURNING *;
2023-11-25 13:01:06.965 UTC [3978940] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:06.965 UTC [3978940] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:06.965 UTC [3978940] STATEMENT:  UPDATE
		second_distributed_table
	SET
		dept = foo.tenant_id::int / 4
	FROM
	(
		SELECT baz.tenant_id FROM
		(
			SELECT
				second_distributed_table.dept, second_distributed_table.tenant_id
			FROM
				second_distributed_table, distributed_table as d1
			WHERE
				d1.tenant_id = second_distributed_table.tenant_id
			AND
				second_distributed_table.dept IN (3,4)
				AND
				second_distributed_table.tenant_id IN
				(
						SELECT s2.tenant_id
						FROM second_distributed_table as s2
						GROUP BY d1.tenant_id, s2.tenant_id
				)
		) as baz
		) as foo WHERE second_distributed_table.tenant_id = foo.tenant_id
	RETURNING *;
2023-11-25 13:01:06.965 UTC [3978940] ERROR:  0A000: subqueries are not supported within INSERT queries
2023-11-25 13:01:06.965 UTC [3978940] HINT:  Try rewriting your queries with 'INSERT INTO ... SELECT' syntax.
2023-11-25 13:01:06.965 UTC [3978940] LOCATION:  ModifyPartialQuerySupported, multi_router_planner.c:696
2023-11-25 13:01:06.965 UTC [3978940] STATEMENT:  INSERT INTO
		second_distributed_table (tenant_id, dept)
	VALUES ('3', (WITH  vals AS (SELECT 3) select * from vals));
2023-11-25 13:01:06.966 UTC [3978940] ERROR:  0A000: subqueries are not supported within INSERT queries
2023-11-25 13:01:06.966 UTC [3978940] HINT:  Try rewriting your queries with 'INSERT INTO ... SELECT' syntax.
2023-11-25 13:01:06.966 UTC [3978940] LOCATION:  ModifyPartialQuerySupported, multi_router_planner.c:696
2023-11-25 13:01:06.966 UTC [3978940] STATEMENT:  INSERT INTO
		second_distributed_table (tenant_id, dept)
	VALUES ('3', (SELECT 3));
2023-11-25 13:01:07.149 UTC [3978942] ERROR:  XX000: EXPLAIN ANALYZE is currently not supported for INSERT ... SELECT commands with repartitioning
2023-11-25 13:01:07.149 UTC [3978942] LOCATION:  NonPushableInsertSelectExplainScan, multi_explain.c:252
2023-11-25 13:01:07.149 UTC [3978942] STATEMENT:  EXPLAIN ANALYZE INSERT INTO target_table SELECT a, max(b) FROM source_table GROUP BY a;
2023-11-25 13:01:07.414 UTC [3978942] ERROR:  23502: null value in column "b" of relation "target_table_4213617" violates not-null constraint
2023-11-25 13:01:07.414 UTC [3978942] DETAIL:  Failing row contains (2, null).
2023-11-25 13:01:07.414 UTC [3978942] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:07.414 UTC [3978942] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:07.414 UTC [3978942] STATEMENT:  INSERT INTO target_table SELECT * FROM source_table;
2023-11-25 13:01:07.480 UTC [3978942] ERROR:  55000: could not find shard for partition column value
2023-11-25 13:01:07.480 UTC [3978942] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:07.480 UTC [3978942] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:07.480 UTC [3978942] STATEMENT:  INSERT INTO target_table SELECT a * 10, b FROM source_table WHERE b IS NOT NULL;
2023-11-25 13:01:08.145 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.145 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.145 UTC [3979744] STATEMENT:  CREATE TRIGGER update_value_dist
	AFTER INSERT ON distributed_table
	FOR EACH ROW EXECUTE FUNCTION update_value();
2023-11-25 13:01:08.146 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.146 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.146 UTC [3979744] STATEMENT:  CREATE TRIGGER update_value_ref
	AFTER INSERT ON reference_table
	FOR EACH ROW EXECUTE FUNCTION update_value();
2023-11-25 13:01:08.169 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.169 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.169 UTC [3979744] STATEMENT:  ALTER TRIGGER update_value_dist ON distributed_table RENAME TO update_value_dist1;
2023-11-25 13:01:08.169 UTC [3979744] ERROR:  XX000: trigger "update_value_dist" depends on an extension and this is not supported for distributed tables and local tables added to metadata
2023-11-25 13:01:08.169 UTC [3979744] DETAIL:  Triggers from extensions are expected to be created on the workers by the extension they depend on.
2023-11-25 13:01:08.169 UTC [3979744] LOCATION:  PreprocessAlterTriggerDependsStmt, trigger.c:552
2023-11-25 13:01:08.169 UTC [3979744] STATEMENT:  ALTER TRIGGER update_value_dist ON distributed_table DEPENDS ON EXTENSION seg;
2023-11-25 13:01:08.169 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.169 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.169 UTC [3979744] STATEMENT:  DROP TRIGGER update_value_dist ON distributed_table;
2023-11-25 13:01:08.169 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.169 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.169 UTC [3979744] STATEMENT:  ALTER TABLE distributed_table DISABLE TRIGGER ALL;
2023-11-25 13:01:08.169 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.169 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.169 UTC [3979744] STATEMENT:  ALTER TABLE distributed_table DISABLE TRIGGER USER;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE distributed_table DISABLE TRIGGER update_value_dist;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE distributed_table ENABLE TRIGGER ALL;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE distributed_table ENABLE TRIGGER USER;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on distributed tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:726
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE distributed_table ENABLE TRIGGER update_value_dist;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TRIGGER update_value_ref ON reference_table RENAME TO update_value_ref1;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: trigger "update_value_ref" depends on an extension and this is not supported for distributed tables and local tables added to metadata
2023-11-25 13:01:08.170 UTC [3979744] DETAIL:  Triggers from extensions are expected to be created on the workers by the extension they depend on.
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  PreprocessAlterTriggerDependsStmt, trigger.c:552
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TRIGGER update_value_ref ON reference_table DEPENDS ON EXTENSION seg;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  DROP TRIGGER update_value_ref ON reference_table;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE reference_table DISABLE TRIGGER ALL;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE reference_table DISABLE TRIGGER USER;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE reference_table DISABLE TRIGGER update_value_ref;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE reference_table ENABLE TRIGGER ALL;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE reference_table ENABLE TRIGGER USER;
2023-11-25 13:01:08.170 UTC [3979744] ERROR:  XX000: triggers are not supported on reference tables
2023-11-25 13:01:08.170 UTC [3979744] LOCATION:  ErrorOutForTriggerIfNotSupported, trigger.c:722
2023-11-25 13:01:08.170 UTC [3979744] STATEMENT:  ALTER TABLE reference_table ENABLE TRIGGER update_value_ref;
2023-11-25 13:01:08.172 UTC [3979744] ERROR:  XX000: cannot distribute relation "distributed_table_1" because it has triggers
2023-11-25 13:01:08.172 UTC [3979744] HINT:  Consider dropping all the triggers on "distributed_table_1" and retry.
2023-11-25 13:01:08.172 UTC [3979744] LOCATION:  EnsureRelationHasNoTriggers, create_distributed_table.c:2095
2023-11-25 13:01:08.172 UTC [3979744] STATEMENT:  SELECT create_distributed_table('distributed_table_1', 'value');
2023-11-25 13:01:08.172 UTC [3979744] ERROR:  XX000: cannot distribute relation "reference_table_1" because it has triggers
2023-11-25 13:01:08.172 UTC [3979744] HINT:  Consider dropping all the triggers on "reference_table_1" and retry.
2023-11-25 13:01:08.172 UTC [3979744] LOCATION:  EnsureRelationHasNoTriggers, create_distributed_table.c:2095
2023-11-25 13:01:08.172 UTC [3979744] STATEMENT:  SELECT create_reference_table('reference_table_1');
2023-11-25 13:01:08.259 UTC [3979745] ERROR:  23503: insert or update on table "target_table_1900001" violates foreign key constraint "fkey_1900001"
2023-11-25 13:01:08.259 UTC [3979745] DETAIL:  Key (col_1)=(3) is not present in table "test_ref_table_1900012".
2023-11-25 13:01:08.259 UTC [3979745] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:08.259 UTC [3979745] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:08.259 UTC [3979745] STATEMENT:  INSERT INTO
			target_table
		SELECT
			col_2,
			col_1
		FROM source_table_1 ON CONFLICT (col_1) DO UPDATE SET col_2 = 55 RETURNING *;
2023-11-25 13:01:08.946 UTC [3979863] ERROR:  XX000: cannot undistribute table because the table is not distributed
2023-11-25 13:01:08.946 UTC [3979863] LOCATION:  UndistributeTable, alter_table.c:379
2023-11-25 13:01:08.946 UTC [3979863] STATEMENT:  SELECT undistribute_table('local_source_table_1');
2023-11-25 13:01:09.098 UTC [3980017] ERROR:  42883: function hll_hash_bigint(bigint) does not exist at character 49
2023-11-25 13:01:09.098 UTC [3980017] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:09.098 UTC [3980017] QUERY:  
	 EXPLAIN SELECT symbol_id,
	        HLL_ADD_AGG(HLL_HASH_BIGINT(event_id)) AS event_hll_hash,
	        HLL_CARDINALITY(HLL_ADD_AGG(HLL_HASH_BIGINT(event_id))) AS event_n_users
	 FROM (
	    SELECT event_time, composite_id, event_id, 4640476 symbol_id FROM "events"
	 UNION ALL
	    SELECT event_time, composite_id, event_id, 4640477 symbol_id FROM "events"
	 ) pushdown_events
	 GROUP BY symbol_id;
	 
2023-11-25 13:01:09.098 UTC [3980017] CONTEXT:  PL/pgSQL function explain_has_distributed_subplan(text) line 5 at FOR over EXECUTE statement
2023-11-25 13:01:09.098 UTC [3980017] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:09.098 UTC [3980017] STATEMENT:  SELECT public.explain_has_distributed_subplan($$
	 EXPLAIN SELECT symbol_id,
	        HLL_ADD_AGG(HLL_HASH_BIGINT(event_id)) AS event_hll_hash,
	        HLL_CARDINALITY(HLL_ADD_AGG(HLL_HASH_BIGINT(event_id))) AS event_n_users
	 FROM (
	    SELECT event_time, composite_id, event_id, 4640476 symbol_id FROM "events"
	 UNION ALL
	    SELECT event_time, composite_id, event_id, 4640477 symbol_id FROM "events"
	 ) pushdown_events
	 GROUP BY symbol_id;
	 $$);
2023-11-25 13:01:09.104 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.104 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.104 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.104 UTC [3980017] STATEMENT:  SELECT count(distinct l_orderkey) FROM lineitem;
2023-11-25 13:01:09.105 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.105 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.105 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.105 UTC [3980017] STATEMENT:  SELECT count(distinct l_orderkey) FROM lineitem;
2023-11-25 13:01:09.105 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.105 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.105 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.105 UTC [3980017] STATEMENT:  SELECT count(distinct l_partkey) FROM lineitem;
2023-11-25 13:01:09.105 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.105 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.105 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.105 UTC [3980017] STATEMENT:  SELECT count(distinct l_extendedprice) FROM lineitem;
2023-11-25 13:01:09.105 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.105 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.105 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.105 UTC [3980017] STATEMENT:  SELECT count(distinct l_shipdate) FROM lineitem;
2023-11-25 13:01:09.105 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.105 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.105 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.105 UTC [3980017] STATEMENT:  SELECT count(distinct l_comment) FROM lineitem;
2023-11-25 13:01:09.106 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.106 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.106 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.106 UTC [3980017] STATEMENT:  SELECT count(distinct (l_orderkey * 2 + 1)) FROM lineitem;
2023-11-25 13:01:09.106 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.106 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.106 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.106 UTC [3980017] STATEMENT:  SELECT count(distinct extract(month from l_shipdate)) AS my_month FROM lineitem;
2023-11-25 13:01:09.106 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.106 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.106 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.106 UTC [3980017] STATEMENT:  SELECT count(distinct l_partkey) / count(distinct l_orderkey) FROM lineitem;
2023-11-25 13:01:09.106 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.106 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.106 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.106 UTC [3980017] STATEMENT:  SELECT count(distinct l_orderkey) FROM lineitem
		WHERE octet_length(l_comment) + octet_length('randomtext'::text) > 40;
2023-11-25 13:01:09.106 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.106 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.106 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.106 UTC [3980017] STATEMENT:  SELECT count(DISTINCT l_orderkey) FROM lineitem, orders
		WHERE l_orderkey = o_orderkey AND l_quantity < 5;
2023-11-25 13:01:09.107 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.107 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.107 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.107 UTC [3980017] STATEMENT:  SELECT count(DISTINCT l_orderkey) as distinct_order_count, l_quantity FROM lineitem
		WHERE l_quantity < 32.0
		GROUP BY l_quantity
		ORDER BY distinct_order_count ASC, l_quantity ASC
		LIMIT 10;
2023-11-25 13:01:09.132 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.132 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.132 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.132 UTC [3980017] STATEMENT:  SELECT COUNT (DISTINCT n_regionkey) FROM test_count_distinct_schema.nation_hash;
2023-11-25 13:01:09.133 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.133 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.133 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.133 UTC [3980017] STATEMENT:  SELECT COUNT (DISTINCT n_regionkey) FROM nation_hash;
2023-11-25 13:01:09.133 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.133 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.133 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.133 UTC [3980017] STATEMENT:  SELECT l_returnflag, count(DISTINCT l_shipdate) as count_distinct, count(*) as total
		FROM lineitem
		GROUP BY l_returnflag
		ORDER BY count_distinct
		LIMIT 10;
2023-11-25 13:01:09.133 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.133 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.133 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.133 UTC [3980017] STATEMENT:  SELECT l_returnflag, count(DISTINCT l_shipdate) as count_distinct, count(*) as total
		FROM lineitem
		GROUP BY l_returnflag
		ORDER BY total
		LIMIT 10;
2023-11-25 13:01:09.133 UTC [3980017] ERROR:  0A000: cannot compute count (distinct) approximation
2023-11-25 13:01:09.133 UTC [3980017] HINT:  You need to have the hll extension loaded.
2023-11-25 13:01:09.133 UTC [3980017] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4133
2023-11-25 13:01:09.133 UTC [3980017] STATEMENT:  SELECT
		l_partkey,
		count(l_partkey) FILTER (WHERE l_shipmode = 'AIR'),
		count(DISTINCT l_partkey) FILTER (WHERE l_shipmode = 'AIR'),
		count(DISTINCT CASE WHEN l_shipmode = 'AIR' THEN l_partkey ELSE NULL END)
		FROM lineitem
		GROUP BY l_partkey
		ORDER BY 2 DESC, 1 DESC
		LIMIT 10;
2023-11-25 13:01:09.838 UTC [3980066] ERROR:  23502: null value in column "b" of relation "target_table_4213652" violates not-null constraint
2023-11-25 13:01:09.838 UTC [3980066] DETAIL:  Failing row contains (75, null).
2023-11-25 13:01:09.838 UTC [3980066] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:09.838 UTC [3980066] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:09.838 UTC [3980066] STATEMENT:  INSERT INTO target_table SELECT a, CASE WHEN a < 50 THEN b ELSE null END  FROM source_table;
2023-11-25 13:01:10.243 UTC [3980191] ERROR:  XX000: "parent_table" is not a partition
2023-11-25 13:01:10.243 UTC [3980191] LOCATION:  GenerateAlterTableAttachPartitionCommand, multi_partitioning_utils.c:1221
2023-11-25 13:01:10.243 UTC [3980191] STATEMENT:  SELECT public.generate_alter_table_attach_partition_command('parent_table');
2023-11-25 13:01:10.243 UTC [3980191] ERROR:  XX000: "child_1" is not a parent table
2023-11-25 13:01:10.243 UTC [3980191] LOCATION:  GeneratePartitioningInformation, multi_partitioning_utils.c:1155
2023-11-25 13:01:10.243 UTC [3980191] STATEMENT:  SELECT public.generate_partition_information('partition_child_1_schema.child_1');
2023-11-25 13:01:10.243 UTC [3980191] ERROR:  XX000: "child_1" is not a parent table
2023-11-25 13:01:10.243 UTC [3980191] LOCATION:  PartitionList, multi_partitioning_utils.c:1075
2023-11-25 13:01:10.243 UTC [3980191] STATEMENT:  SELECT public.print_partitions('partition_child_1_schema.child_1');
2023-11-25 13:01:10.268 UTC [3980191] ERROR:  42809: capitals is not a regular, foreign or partitioned table
2023-11-25 13:01:10.268 UTC [3980191] LOCATION:  EnsureRelationKindSupported, citus_ruleutils.c:635
2023-11-25 13:01:10.268 UTC [3980191] STATEMENT:  SELECT master_get_table_ddl_events('capitals');
2023-11-25 13:01:10.268 UTC [3980191] ERROR:  42809: cities is not a regular, foreign or partitioned table
2023-11-25 13:01:10.268 UTC [3980191] LOCATION:  EnsureRelationKindSupported, citus_ruleutils.c:635
2023-11-25 13:01:10.268 UTC [3980191] STATEMENT:  SELECT master_get_table_ddl_events('cities');
2023-11-25 13:01:10.327 UTC [3980192] ERROR:  23514: no partition of relation "partitioning_hash_test_1660012" found for row
2023-11-25 13:01:10.327 UTC [3980192] DETAIL:  Partition key of the failing row contains (subid) = (5).
2023-11-25 13:01:10.327 UTC [3980192] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:10.327 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:10.327 UTC [3980192] STATEMENT:  INSERT INTO partitioning_hash_test VALUES (8, 5);
2023-11-25 13:01:10.329 UTC [3980192] ERROR:  23514: no partition of relation "partitioning_hash_test_1660015" found for row
2023-11-25 13:01:10.329 UTC [3980192] DETAIL:  Partition key of the failing row contains (subid) = (12).
2023-11-25 13:01:10.329 UTC [3980192] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:10.329 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:10.329 UTC [3980192] STATEMENT:  INSERT INTO partitioning_hash_test VALUES (9, 12);
2023-11-25 13:01:10.346 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.346 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.346 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.346 UTC [3980190] STATEMENT:  INSERT INTO collections_4 (key, ts, collection_id, value) VALUES (4, '2009-01-01', 2, 2);
2023-11-25 13:01:10.347 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.347 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.347 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.347 UTC [3980190] STATEMENT:  UPDATE collections_1 SET ts = now() WHERE key = 1;
2023-11-25 13:01:10.347 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.347 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.347 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.347 UTC [3980190] STATEMENT:  DELETE FROM collections_1 WHERE ts = now() AND key = 1;
2023-11-25 13:01:10.347 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.347 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.347 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.347 UTC [3980190] STATEMENT:  UPDATE collections_1 SET ts = now();
2023-11-25 13:01:10.347 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.347 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.347 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.347 UTC [3980190] STATEMENT:  DELETE FROM collections_1 WHERE ts = now();
2023-11-25 13:01:10.347 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.347 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.347 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.347 UTC [3980190] STATEMENT:  INSERT INTO collections_1 SELECT * FROM collections_1;
2023-11-25 13:01:10.347 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.347 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.347 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.347 UTC [3980190] STATEMENT:  INSERT INTO collections_1 SELECT * FROM collections_1 OFFSET 0;
2023-11-25 13:01:10.347 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.347 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.347 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.347 UTC [3980190] STATEMENT:  COPY collections_1 FROM STDIN;
2023-11-25 13:01:10.348 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.348 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.348 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.348 UTC [3980190] STATEMENT:  CREATE INDEX index_on_partition ON collections_1(key);
2023-11-25 13:01:10.349 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.349 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.349 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.349 UTC [3980190] STATEMENT:  UPDATE collections_1 SET ts = now() WHERE key = 1;
2023-11-25 13:01:10.349 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.349 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.349 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.349 UTC [3980190] STATEMENT:  TRUNCATE collections_1;
2023-11-25 13:01:10.349 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.349 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.349 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.349 UTC [3980190] STATEMENT:  TRUNCATE collections, collections_1;
2023-11-25 13:01:10.349 UTC [3980190] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:10.349 UTC [3980190] HINT:  Run the query on the parent table "collections" instead.
2023-11-25 13:01:10.349 UTC [3980190] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:10.349 UTC [3980190] STATEMENT:  WITH collections_5_cte AS
	(
		DELETE FROM collections_5 RETURNING *
	)
	SELECT * FROM collections_5_cte;
2023-11-25 13:01:10.361 UTC [3980190] ERROR:  0A000: cannot create foreign key constraint
2023-11-25 13:01:10.361 UTC [3980190] DETAIL:  Citus currently supports foreign key constraints only for "citus.shard_replication_factor = 1".
2023-11-25 13:01:10.361 UTC [3980190] HINT:  Please change "citus.shard_replication_factor to 1". To learn more about using foreign keys with other replication factors, please contact us at https://citusdata.com/about/contact_us.
2023-11-25 13:01:10.361 UTC [3980190] LOCATION:  EnsureReferencingTableNotReplicated, foreign_constraint.c:599
2023-11-25 13:01:10.361 UTC [3980190] STATEMENT:  ALTER TABLE
		collections_5
	ADD CONSTRAINT
		fkey_delete FOREIGN KEY(key)
	REFERENCES
		fkey_test(key) ON DELETE CASCADE;
2023-11-25 13:01:10.373 UTC [3980192] ERROR:  XX000: cannot distribute relation "partitioning_test_failure_2009" which is partition of "partitioning_test_failure"
2023-11-25 13:01:10.373 UTC [3980192] DETAIL:  Citus does not support distributing partitions if their parent is not distributed table.
2023-11-25 13:01:10.373 UTC [3980192] HINT:  Distribute the partitioned table "partitioning_test_failure" instead.
2023-11-25 13:01:10.373 UTC [3980192] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1895
2023-11-25 13:01:10.373 UTC [3980192] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure_2009', 'id');
2023-11-25 13:01:10.374 UTC [3980192] ERROR:  0A000: distributing partitioned tables in only supported for hash-distributed tables
2023-11-25 13:01:10.374 UTC [3980192] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1914
2023-11-25 13:01:10.374 UTC [3980192] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure', 'id', 'append');
2023-11-25 13:01:10.374 UTC [3980192] ERROR:  0A000: distributing partitioned tables in only supported for hash-distributed tables
2023-11-25 13:01:10.374 UTC [3980192] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1914
2023-11-25 13:01:10.374 UTC [3980192] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure', 'id', 'range');
2023-11-25 13:01:10.374 UTC [3980192] ERROR:  0A000: distributing partitioned tables in only supported for hash-distributed tables
2023-11-25 13:01:10.374 UTC [3980192] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1914
2023-11-25 13:01:10.374 UTC [3980192] STATEMENT:  SELECT create_reference_table('partitioning_test_failure');
2023-11-25 13:01:10.385 UTC [3980192] ERROR:  XX000: non-citus partitioned tables cannot have citus table partitions
2023-11-25 13:01:10.385 UTC [3980192] HINT:  Distribute the partitioned table "partitioning_test_failure" instead, or add it to metadata
2023-11-25 13:01:10.385 UTC [3980192] LOCATION:  ErrorIfAttachCitusTableToPgLocalTable, table.c:651
2023-11-25 13:01:10.385 UTC [3980192] STATEMENT:  ALTER TABLE partitioning_test_failure ATTACH PARTITION partitioning_test_failure_2009 FOR VALUES FROM ('2009-01-01') TO ('2010-01-01');
2023-11-25 13:01:10.402 UTC [3980192] ERROR:  0A000: distributing multi-level partitioned tables is not supported
2023-11-25 13:01:10.402 UTC [3980192] DETAIL:  Relation "partitioning_test_failure_2009" is partitioned table itself and it is also partition of relation "partitioning_test_failure".
2023-11-25 13:01:10.402 UTC [3980192] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1924
2023-11-25 13:01:10.402 UTC [3980192] STATEMENT:  SELECT create_distributed_table('partitioning_test_failure', 'id');
2023-11-25 13:01:10.410 UTC [3980192] ERROR:  0A000: distributing multi-level partitioned tables is not supported
2023-11-25 13:01:10.410 UTC [3980192] DETAIL:  Relation "partitioning_test_failure_2009" is partitioned table itself and it is also partition of relation "partitioning_test_failure".
2023-11-25 13:01:10.410 UTC [3980192] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1924
2023-11-25 13:01:10.410 UTC [3980192] STATEMENT:  CREATE TABLE partitioning_test_failure_2009 PARTITION OF partitioning_test_failure FOR VALUES FROM ('2009-01-01') TO ('2010-01-01') PARTITION BY RANGE (time);
2023-11-25 13:01:10.437 UTC [3980192] ERROR:  23514: no partition of relation "partitioning_test_1660001" found for row
2023-11-25 13:01:10.437 UTC [3980192] DETAIL:  Partition key of the failing row contains ("time") = (2020-07-07).
2023-11-25 13:01:10.437 UTC [3980192] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:10.437 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:10.437 UTC [3980192] STATEMENT:  UPDATE partitioning_test SET time = '2020-07-07' WHERE id = 7;
2023-11-25 13:01:10.458 UTC [3980190] ERROR:  25001: cannot open new connections after the first modification command within a transaction
2023-11-25 13:01:10.458 UTC [3980190] LOCATION:  EnsureNoModificationsHaveBeenDone, worker_transaction.c:320
2023-11-25 13:01:10.458 UTC [3980190] STATEMENT:  SELECT citus_copy_shard_placement(1760036, 'localhost', 57637, 'localhost', 57638, transfer_mode := 'block_writes');
2023-11-25 13:01:10.470 UTC [3980192] ERROR:  23514: updated partition constraint for default partition "partitioning_test_default_1660054" would be violated by some row
2023-11-25 13:01:10.470 UTC [3980192] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:10.470 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:10.470 UTC [3980192] STATEMENT:  CREATE TABLE partitioning_test_2014 PARTITION OF partitioning_test FOR VALUES FROM ('2014-01-01') TO ('2015-01-01');
2023-11-25 13:01:10.470 UTC [3980322] LOG:  00000: deferred drop of orphaned resource public.shard_split_table_360047 on localhost:57638 completed
2023-11-25 13:01:10.470 UTC [3980322] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 13:01:10.470 UTC [3980322] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:10.514 UTC [3980192] ERROR:  23514: new row for relation "partitioning_test_2009_1660005" violates partition constraint
2023-11-25 13:01:10.514 UTC [3980192] DETAIL:  Failing row contains (3, 2010-03-11).
2023-11-25 13:01:10.514 UTC [3980192] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:10.514 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:10.514 UTC [3980192] STATEMENT:  UPDATE partitioning_test_2009 SET time = time + INTERVAL '6 month';
2023-11-25 13:01:10.566 UTC [3980368] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1760036 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:10.566 UTC [3980368] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:10.566 UTC [3980368] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:10.566 UTC [3980368] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1_1760037 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:10.566 UTC [3980368] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:10.566 UTC [3980368] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:10.566 UTC [3980368] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_2_1760038 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:10.566 UTC [3980368] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:10.566 UTC [3980368] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:10.654 UTC [3980192] ERROR:  2BP01: cannot drop index partitioning_test_2009_id_idx because index partitioning_index requires it
2023-11-25 13:01:10.654 UTC [3980192] HINT:  You can drop index partitioning_index instead.
2023-11-25 13:01:10.654 UTC [3980192] LOCATION:  reportDependentObjects, dependency.c:1055
2023-11-25 13:01:10.654 UTC [3980192] STATEMENT:  DROP INDEX partitioning_test_2009_id_idx;
2023-11-25 13:01:10.676 UTC [3980192] ERROR:  42809: cannot add column to a partition
2023-11-25 13:01:10.676 UTC [3980192] LOCATION:  ATExecAddColumn, tablecmds.c:6753
2023-11-25 13:01:10.676 UTC [3980192] STATEMENT:  ALTER TABLE partitioning_test_2010 ADD new_column_2 int;
2023-11-25 13:01:10.684 UTC [3980192] ERROR:  0A000: unique constraint on partitioned table must include all partitioning columns
2023-11-25 13:01:10.684 UTC [3980192] DETAIL:  PRIMARY KEY constraint on table "partitioning_test" lacks column "time" which is part of the partition key.
2023-11-25 13:01:10.684 UTC [3980192] LOCATION:  DefineIndex, indexcmds.c:1035
2023-11-25 13:01:10.684 UTC [3980192] STATEMENT:  ALTER TABLE partitioning_test ADD CONSTRAINT partitioning_primary PRIMARY KEY (id);
2023-11-25 13:01:10.705 UTC [3980192] ERROR:  55006: cannot ALTER TABLE "partitioning_test_2009" because it is being used by active queries in this session
2023-11-25 13:01:10.705 UTC [3980192] LOCATION:  CheckTableNotInUse, tablecmds.c:4005
2023-11-25 13:01:10.705 UTC [3980192] STATEMENT:  ALTER TABLE partitioning_test ADD CONSTRAINT partitioning_foreign FOREIGN KEY (id) REFERENCES partitioning_test_2009 (id);
2023-11-25 13:01:11.063 UTC [3980192] ERROR:  23514: no partition of relation "multi_column_partitioning_1660133" found for row
2023-11-25 13:01:11.063 UTC [3980192] DETAIL:  Partition key of the failing row contains (c1, c2) = (10, 1).
2023-11-25 13:01:11.063 UTC [3980192] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:11.063 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:11.063 UTC [3980192] STATEMENT:  INSERT INTO multi_column_partitioning VALUES(10, 1);
2023-11-25 13:01:11.077 UTC [3980192] ERROR:  23514: no partition of relation "multi_column_partitioning_1660133" found for row
2023-11-25 13:01:11.077 UTC [3980192] DETAIL:  Partition key of the failing row contains (c1, c2) = (20, -20).
2023-11-25 13:01:11.077 UTC [3980192] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:11.077 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:11.077 UTC [3980192] STATEMENT:  INSERT INTO multi_column_partitioning VALUES(20, -20);
2023-11-25 13:01:11.344 UTC [3980192] ERROR:  23503: insert or update on table "partitioning_test_2010_1660314" violates foreign key constraint "partitioning_reference_fkey_1660302"
2023-11-25 13:01:11.344 UTC [3980192] DETAIL:  Key (id)=(1) is not present in table "reference_table_1660300".
2023-11-25 13:01:11.344 UTC [3980192] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:11.344 UTC [3980192] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:11.344 UTC [3980192] STATEMENT:  ALTER TABLE partitioning_test ATTACH PARTITION partitioning_test_2010
	      FOR VALUES FROM ('2010-01-01') TO ('2011-01-01');
2023-11-25 13:01:11.368 UTC [3980192] ERROR:  42P07: relation "partitioning_test_2011" already exists
2023-11-25 13:01:11.368 UTC [3980192] LOCATION:  heap_create_with_catalog, heap.c:1146
2023-11-25 13:01:11.368 UTC [3980192] STATEMENT:  CREATE TABLE partitioning_test_2011 PARTITION OF partitioning_test FOR VALUES FROM ('2011-01-01') TO ('2012-01-01');
2023-11-25 13:01:11.375 UTC [3980192] ERROR:  42P07: relation "not_partition" already exists
2023-11-25 13:01:11.375 UTC [3980192] LOCATION:  heap_create_with_catalog, heap.c:1146
2023-11-25 13:01:11.375 UTC [3980192] STATEMENT:  CREATE TABLE not_partition PARTITION OF partitioning_test FOR VALUES FROM ('2011-01-01') TO ('2012-01-01');
2023-11-25 13:01:11.377 UTC [3980192] ERROR:  42P07: relation "partition_of_other_table" already exists
2023-11-25 13:01:11.377 UTC [3980192] LOCATION:  heap_create_with_catalog, heap.c:1146
2023-11-25 13:01:11.377 UTC [3980192] STATEMENT:  CREATE TABLE partition_of_other_table PARTITION OF partitioning_test FOR VALUES FROM ('2014-01-01') TO ('2015-01-01');
2023-11-25 13:01:11.379 UTC [3980192] ERROR:  XX000: fix_pre_citus10_partitioned_table_constraint_names can only be called for distributed partitioned tables
2023-11-25 13:01:11.379 UTC [3980192] LOCATION:  fix_pre_citus10_partitioned_table_constraint_names, multi_partitioning_utils.c:105
2023-11-25 13:01:11.379 UTC [3980192] STATEMENT:  SELECT fix_pre_citus10_partitioned_table_constraint_names('public.non_distributed_partitioned_table');
2023-11-25 13:01:11.379 UTC [3980192] ERROR:  XX000: could not fix partition constraints: relation does not exist or is not partitioned
2023-11-25 13:01:11.379 UTC [3980192] LOCATION:  fix_pre_citus10_partitioned_table_constraint_names, multi_partitioning_utils.c:100
2023-11-25 13:01:11.379 UTC [3980192] STATEMENT:  SELECT fix_pre_citus10_partitioned_table_constraint_names('reference_table');
2023-11-25 13:01:11.421 UTC [3980192] ERROR:  XX000: relation "multi_column_partitioned_p1" is a partition with multiple partition columns
2023-11-25 13:01:11.421 UTC [3980192] DETAIL:  time_partition_range can only be used for partitions of range-partitioned tables with a single partition column
2023-11-25 13:01:11.421 UTC [3980192] LOCATION:  time_partition_range, partitioning.c:102
2023-11-25 13:01:11.421 UTC [3980192] STATEMENT:  SELECT * FROM time_partition_range('multi_column_partitioned_p1');
2023-11-25 13:01:11.423 UTC [3980192] ERROR:  XX000: relation "list_partitioned_p1" is not a range partition
2023-11-25 13:01:11.423 UTC [3980192] DETAIL:  time_partition_range can only be used for partitions of range-partitioned tables with a single partition column
2023-11-25 13:01:11.423 UTC [3980192] LOCATION:  time_partition_range, partitioning.c:78
2023-11-25 13:01:11.423 UTC [3980192] STATEMENT:  SELECT * FROM time_partition_range('list_partitioned_p1');
2023-11-25 13:01:11.428 UTC [3980192] ERROR:  XX000: non-distributed tables cannot inherit distributed tables
2023-11-25 13:01:11.428 UTC [3980192] LOCATION:  PostprocessCreateTableStmt, table.c:253
2023-11-25 13:01:11.428 UTC [3980192] STATEMENT:  CREATE TABLE local_inheritance (k int) INHERITS (test_inheritance);
2023-11-25 13:01:11.535 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:11.535 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
2023-11-25 13:01:11.535 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.535 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 13:01:11.536 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:11.536 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
2023-11-25 13:01:11.536 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.536 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 13:01:11.576 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_2021_01_01 with the range from 01-01-2021 to 01-02-2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.576 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.576 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.576 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.576 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 13:01:11.595 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_2021_01_01 with the range from 01-01-2021 to 01-02-2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.595 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.595 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.595 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.595 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 13:01:11.634 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_2021_01_01 with the range from 01-01-2021 to 01-02-2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.634 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.634 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.634 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.634 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 13:01:11.656 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_2021_01_02 with the range from 01-04-2021 to 01-06-2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.656 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.656 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.656 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.656 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('date_partitioned_table', INTERVAL '2 days', '2021-01-15', '2020-12-30');
2023-11-25 13:01:11.687 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:11.687 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.687 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.687 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.687 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.707 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:11.707 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.707 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.707 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.707 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.745 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:11.745 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.745 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.745 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.745 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.763 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_2021_01_02 with the range from Mon Jan 04 00:00:00 2021 PST to Wed Jan 06 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:11.763 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.763 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.763 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.763 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.802 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.802 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.802 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.802 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.802 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.822 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.822 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.822 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.822 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.822 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.859 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.859 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.859 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.859 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.859 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.878 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_2021_01_02 with the range from Mon Jan 04 00:00:00 2021 to Wed Jan 06 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.878 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.878 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:11.878 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.878 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:11.898 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:11.898 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:11.898 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.898 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 13:01:11.899 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:11.899 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:11.899 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.899 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 13:01:11.980 UTC [3980524] ERROR:  P0001: start_from (Mon Feb 01 00:00:00 2021 PST) must be older than end_at (Fri Jan 01 00:00:00 2021 PST)
2023-11-25 13:01:11.980 UTC [3980524] CONTEXT:  PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 12 at RAISE
2023-11-25 13:01:11.980 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.980 UTC [3980524] STATEMENT:  SELECT * FROM create_time_partitions('date_partitioned_table', INTERVAL '1 day', '2021-01-01', '2021-02-01');
2023-11-25 13:01:11.987 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_p2020_12_30 with the range from 12-30-2020 to 12-31-2020 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.987 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.987 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:11.987 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.987 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '2 days', '2021-01-15', '2020-12-25');
2023-11-25 13:01:11.994 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_p2020_12_30 with the range from 12-30-2020 to 12-31-2020 does not align with the initial partition given the partition interval
2023-11-25 13:01:11.994 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:11.994 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:11.994 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:11.994 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '2 days', '2021-01-05', '2020-12-30');
2023-11-25 13:01:12.006 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_2020_01_02 with the range from 01-02-2021 to 01-04-2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:12.006 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.006 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.006 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.006 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '1 day', '2021-01-05', '2020-12-30');
2023-11-25 13:01:12.008 UTC [3980524] ERROR:  P0001: partition date_partitioned_table_2021_01_02 with the range from 01-04-2021 to 01-06-2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:12.008 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.008 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.008 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.008 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_table', INTERVAL '2 days', '2021-01-15', '2020-12-30');
2023-11-25 13:01:12.061 UTC [3980524] ERROR:  P0001: start_from (Tue Jan 05 00:00:00 2021 PST) must be older than end_at (Fri Jan 01 00:00:00 2021 PST)
2023-11-25 13:01:12.061 UTC [3980524] CONTEXT:  PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 12 at RAISE
2023-11-25 13:01:12.061 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.061 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '1 day', '2021-01-01 00:00:00', '2021-01-05 00:00:00');
2023-11-25 13:01:12.067 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 PST to Thu Dec 31 00:00:00 2020 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:12.067 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.067 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
2023-11-25 13:01:12.067 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.067 UTC [3980524] STATEMENT:  SELECT * FROM get_missing_time_partition_ranges('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.074 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 PST to Thu Dec 31 00:00:00 2020 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:12.074 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.074 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.074 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.074 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.084 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_2021_01_01 with the range from Fri Jan 01 00:00:00 2021 PST to Sat Jan 02 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:12.084 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.084 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.084 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.084 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.087 UTC [3980524] ERROR:  P0001: partition tstz_partitioned_table_2021_01_02 with the range from Mon Jan 04 00:00:00 2021 PST to Wed Jan 06 00:00:00 2021 PST does not align with the initial partition given the partition interval
2023-11-25 13:01:12.087 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.087 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.087 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.087 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tstz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.546 UTC [3980524] ERROR:  P0001: start_from (Tue Jan 05 00:00:00 2021 PST) must be older than end_at (Fri Jan 01 00:00:00 2021 PST)
2023-11-25 13:01:12.546 UTC [3980524] CONTEXT:  PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 12 at RAISE
2023-11-25 13:01:12.546 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.546 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '1 day', '2021-01-01 00:00:00', '2021-01-05 00:00:00');
2023-11-25 13:01:12.586 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 to Thu Dec 31 00:00:00 2020 does not align with the initial partition given the partition interval
2023-11-25 13:01:12.586 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.586 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.586 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.586 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.639 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_p2020_12_30 with the range from Wed Dec 30 00:00:00 2020 to Thu Dec 31 00:00:00 2020 does not align with the initial partition given the partition interval
2023-11-25 13:01:12.639 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.639 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.639 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.639 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.721 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_2020_01_01 with the range from Fri Jan 01 00:00:00 2021 to Sat Jan 02 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:12.721 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.721 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.721 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.721 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-05 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.741 UTC [3980524] ERROR:  P0001: partition tswtz_partitioned_table_2020_01_02 with the range from Mon Jan 04 00:00:00 2021 to Wed Jan 06 00:00:00 2021 does not align with the initial partition given the partition interval
2023-11-25 13:01:12.741 UTC [3980524] HINT:  Only use partitions of the same size, without gaps between partitions.
2023-11-25 13:01:12.741 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 150 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.741 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.741 UTC [3980524] STATEMENT:  SELECT create_time_partitions('tswtz_partitioned_table', INTERVAL '2 days', '2021-01-15 00:00:00', '2020-12-30 00:00:00');
2023-11-25 13:01:12.982 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:12.982 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.982 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.982 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_distributed_partitioned_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 13:01:12.983 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:12.983 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:12.983 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:12.983 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_distributed_partitioned_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 13:01:13.624 UTC [3980594] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1760036 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:13.624 UTC [3980594] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:13.624 UTC [3980594] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:13.625 UTC [3980594] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_1_1760037 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:13.625 UTC [3980594] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:13.625 UTC [3980594] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:13.625 UTC [3980594] LOG:  00000: cleaned up orphaned resource partitioned_table_replicated.customer_engagements_2_1760038 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:13.625 UTC [3980594] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:13.625 UTC [3980594] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:13.756 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:13.756 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:13.756 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:13.756 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_citus_local_table', INTERVAL '6 hours', '2022-01-01', '2021-01-01');
2023-11-25 13:01:13.757 UTC [3980524] ERROR:  P0001: partition interval of date partitioned table must be day or multiple days
2023-11-25 13:01:13.757 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 53 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:13.757 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:13.757 UTC [3980524] STATEMENT:  SELECT create_time_partitions('date_partitioned_citus_local_table', INTERVAL '1 week 1 day 1 hour', '2022-01-01', '2021-01-01');
2023-11-25 13:01:15.867 UTC [3980524] ERROR:  P0001: partitioned tables with multiple partition columns are not supported
2023-11-25 13:01:15.867 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 33 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:15.867 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:15.867 UTC [3980524] STATEMENT:  SELECT create_time_partitions('multiple_partition_column_table', INTERVAL '1 month', now() + INTERVAL '1 year');
2023-11-25 13:01:15.867 UTC [3980524] ERROR:  P0001: partitioned tables with multiple partition columns are not supported
2023-11-25 13:01:15.867 UTC [3980524] CONTEXT:  PL/pgSQL function drop_old_time_partitions(regclass,timestamp with time zone) line 17 at RAISE
2023-11-25 13:01:15.867 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:15.867 UTC [3980524] STATEMENT:  CALL drop_old_time_partitions('multiple_partition_column_table', now());
2023-11-25 13:01:15.869 UTC [3980524] ERROR:  P0001: type of the partition column of the table invalid_partition_column_table must be date, timestamp or timestamptz
2023-11-25 13:01:15.869 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 47 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:15.869 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:15.869 UTC [3980524] STATEMENT:  SELECT create_time_partitions('invalid_partition_column_table', INTERVAL '1 month', now() + INTERVAL '1 year');
2023-11-25 13:01:15.869 UTC [3980524] ERROR:  P0001: type of the partition column of the table invalid_partition_column_table must be date, timestamp or timestamptz
2023-11-25 13:01:15.869 UTC [3980524] CONTEXT:  PL/pgSQL function drop_old_time_partitions(regclass,timestamp with time zone) line 29 at RAISE
2023-11-25 13:01:15.869 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:15.869 UTC [3980524] STATEMENT:  CALL drop_old_time_partitions('invalid_partition_column_table', now());
2023-11-25 13:01:15.871 UTC [3980524] ERROR:  P0001: non_partitioned_table is not partitioned
2023-11-25 13:01:15.871 UTC [3980524] CONTEXT:  PL/pgSQL function get_missing_time_partition_ranges(regclass,interval,timestamp with time zone,timestamp with time zone) line 31 at RAISE
	PL/pgSQL function create_time_partitions(regclass,interval,timestamp with time zone,timestamp with time zone) line 20 at FOR over SELECT rows
2023-11-25 13:01:15.871 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:15.871 UTC [3980524] STATEMENT:  SELECT create_time_partitions('non_partitioned_table', INTERVAL '1 month', now() + INTERVAL '1 year');
2023-11-25 13:01:15.871 UTC [3980524] ERROR:  P0001: non_partitioned_table is not partitioned
2023-11-25 13:01:15.871 UTC [3980524] CONTEXT:  PL/pgSQL function drop_old_time_partitions(regclass,timestamp with time zone) line 15 at RAISE
2023-11-25 13:01:15.871 UTC [3980524] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:15.871 UTC [3980524] STATEMENT:  CALL drop_old_time_partitions('non_partitioned_table', now());
2023-11-25 13:01:16.585 UTC [3980691] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:16.585 UTC [3980691] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:16.585 UTC [3980691] STATEMENT:  SELECT (SELECT id FROM dist WHERE dist.id > d1.id GROUP BY id) FROM ref FULL JOIN dist d1 USING (id);
2023-11-25 13:01:17.621 UTC [3980958] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 13:01:17.621 UTC [3980958] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 13:01:17.621 UTC [3980958] STATEMENT:  SELECT
	   bar.user_id
	FROM
	    (
		     WITH RECURSIVE cte AS MATERIALIZED (
		    SELECT
		    	DISTINCT users_table.user_id
		     FROM
		     	users_table, events_table
		     WHERE
		     	users_table.user_id = events_table.user_id AND
		     event_type IN (1,2,3,4)
		     ) SELECT * FROM cte ORDER BY 1 DESC
	     ) as foo,
	    (
		    SELECT
		    	DISTINCT users_table.user_id
		     FROM
		     	users_table, events_table
		     WHERE
		     	users_table.user_id = events_table.user_id AND
		     event_type IN (1,2,3,4)
	     ) as bar
	WHERE foo.user_id = bar.user_id
	ORDER BY 1 DESC;
2023-11-25 13:01:17.713 UTC [3980958] ERROR:  P0001: (3/3) failed to execute one of the tasks
2023-11-25 13:01:17.713 UTC [3980958] CONTEXT:  PL/pgSQL function inline_code_block line 31 at RAISE
2023-11-25 13:01:17.713 UTC [3980958] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:17.713 UTC [3980958] STATEMENT:  DO $$
	DECLARE
		errors_received INTEGER;
	BEGIN
	errors_received := 0;
	FOR i IN 1..3 LOOP
		BEGIN
			WITH cte as (
				SELECT
					user_id, value_2
				from
					events_table
			)
			SELECT * FROM users_table where value_2 < (
				SELECT
					min(cte.value_2)
				FROM
					cte
				WHERE
					users_table.user_id=cte.user_id
				GROUP BY
					user_id, cte.value_2);
		EXCEPTION WHEN OTHERS THEN
			IF SQLERRM LIKE 'more than one row returned by a subquery%%' THEN
				errors_received := errors_received + 1;
			ELSIF SQLERRM LIKE 'failed to execute task%' THEN
				errors_received := errors_received + 1;
			END IF;
		END;
	END LOOP;
	RAISE '(%/3) failed to execute one of the tasks', errors_received;
	END;
	$$;
2023-11-25 13:01:18.097 UTC [3981087] ERROR:  0A000: cannot pushdown the subquery since not all subqueries in the UNION have the partition column in the same position
2023-11-25 13:01:18.097 UTC [3981087] DETAIL:  Each leaf query of the UNION should return the partition column in the same position and all joins must be on the partition column
2023-11-25 13:01:18.097 UTC [3981087] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:582
2023-11-25 13:01:18.097 UTC [3981087] STATEMENT:  SELECT * FROM ((SELECT * FROM test) UNION (SELECT * FROM test)) foo WHERE x IN (SELECT y FROM test);
2023-11-25 13:01:18.148 UTC [3981087] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:18.148 UTC [3981087] DETAIL:  Complex subqueries and CTEs are not supported within a UNION
2023-11-25 13:01:18.148 UTC [3981087] LOCATION:  DeferErrorIfUnsupportedUnionQuery, query_pushdown_planning.c:1362
2023-11-25 13:01:18.148 UTC [3981087] STATEMENT:  SELECT * FROM test a WHERE x IN (SELECT x FROM test b UNION SELECT y FROM test c WHERE a.x = c.x) ORDER BY 1,2;
2023-11-25 13:01:18.165 UTC [3981087] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 13:01:18.165 UTC [3981087] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 13:01:18.165 UTC [3981087] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 13:01:18.165 UTC [3981087] STATEMENT:  select count(DISTINCT t.x) FROM ((SELECT avg(DISTINCT y) FROM test GROUP BY y) UNION (SELECT avg(DISTINCT y) FROM test GROUP BY y)) as t(x) ORDER BY 1;
2023-11-25 13:01:18.752 UTC [3981292] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:18.752 UTC [3981292] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:18.752 UTC [3981292] STATEMENT:  EXPLAIN
	   SELECT
	    (SELECT user_id FROM users_table_part WHERE user_id = e.value_1
	        UNION ALL
	     SELECT user_id FROM users_table_part WHERE user_id = e.value_1)
	  FROM
	    (SELECT * FROM users_table_part) as e;
2023-11-25 13:01:18.777 UTC [3981292] WARNING:  0A000: "view v2" has dependency to "table range_dist_table_2" that is not in Citus' metadata
2023-11-25 13:01:18.777 UTC [3981292] DETAIL:  "view v2" will be created only locally
2023-11-25 13:01:18.777 UTC [3981292] HINT:  Distribute "table range_dist_table_2" first to distribute "view v2"
2023-11-25 13:01:18.777 UTC [3981292] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:18.846 UTC [3981292] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:18.846 UTC [3981292] CONTEXT:  PL/pgSQL function public.explain_has_distributed_subplan(text) line 5 at FOR over EXECUTE statement
2023-11-25 13:01:18.846 UTC [3981292] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:18.846 UTC [3981292] STATEMENT:  SELECT public.explain_has_distributed_subplan($$
	EXPLAIN SELECT * FROM users_table_part u1 WHERE (value_1, user_id) IN
	(
	SELECT u1.user_id, user_id FROM users_table_part
	UNION
	SELECT u1.user_id, user_id FROM users_table_part
	);
	$$);
2023-11-25 13:01:19.032 UTC [3981355] ERROR:  22012: division by zero
2023-11-25 13:01:19.032 UTC [3981355] LOCATION:  int4div, int.c:840
2023-11-25 13:01:19.032 UTC [3981355] STATEMENT:  (SELECT x FROM test) INTERSECT (SELECT i/0 FROM generate_series(0, 100) i) ORDER BY 1 DESC;
2023-11-25 13:01:19.290 UTC [3981486] ERROR:  42P01: relation "events_table_local" does not exist at character 130
2023-11-25 13:01:19.290 UTC [3981486] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:19.290 UTC [3981486] STATEMENT:  SELECT COUNT(user_id) FROM users_table WHERE user_id IN
		(SELECT
			user_id
		 FROM
		 	users_table_local JOIN (SELECT user_id FROM events_table_local) as foo
		 USING (user_id)
		 );
2023-11-25 13:01:19.292 UTC [3981486] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 13:01:19.292 UTC [3981486] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 13:01:19.292 UTC [3981486] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 13:01:19.292 UTC [3981486] STATEMENT:  SELECT
		*
	FROM
	(
		SELECT avg(DISTINCT value_1), random() FROM users_table GROUP BY user_id OFFSET 3
	) as baz,
	(
		SELECT count(DISTINCT value_1), random() FROM users_table GROUP BY value_2 OFFSET 3
	) as bar,
	(
		SELECT avg(DISTINCT value_1), random() FROM users_table GROUP BY value_2 OFFSET 3
	) as foo;
2023-11-25 13:01:19.294 UTC [3981486] ERROR:  0A000: array_agg with order by is unsupported
2023-11-25 13:01:19.294 UTC [3981486] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4008
2023-11-25 13:01:19.294 UTC [3981486] STATEMENT:  SELECT
		*
	FROM
		(
			SELECT
				array_agg(users_table.value_2 ORDER BY users_table.time)
			FROM
				users_table, (SELECT user_id FROM events_table) as evs
			WHERE users_table.user_id = evs.user_id
			GROUP BY users_table.value_2
			LIMIT 5
		) as foo;
2023-11-25 13:01:19.295 UTC [3981486] ERROR:  0A000: cannot handle complex subqueries when the router executor is disabled
2023-11-25 13:01:19.295 UTC [3981486] LOCATION:  QueryPushdownSqlTaskList, multi_physical_planner.c:2182
2023-11-25 13:01:19.295 UTC [3981486] STATEMENT:  SELECT
	   user_id
	FROM
	    (SELECT
	    	DISTINCT users_table.user_id
	     FROM
	     	users_table, events_table
	     WHERE
	     	users_table.user_id = events_table.user_id AND
	     event_type IN (1,2,3,4)
	     ORDER BY 1 DESC LIMIT 5
	     ) as foo
	    ORDER BY 1 DESC;
2023-11-25 13:01:19.311 UTC [3981486] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 13:01:19.311 UTC [3981486] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:19.311 UTC [3981486] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:19.311 UTC [3981486] STATEMENT:  SELECT * FROM (SELECT user_id, value_1 FROM users_table GROUP BY GROUPING SETS ((user_id), (value_1))) s;
2023-11-25 13:01:19.312 UTC [3981486] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 13:01:19.312 UTC [3981486] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:19.312 UTC [3981486] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:19.312 UTC [3981486] STATEMENT:  SELECT * FROM (SELECT user_id, value_1 FROM users_table GROUP BY ROLLUP (user_id, value_1)) s;
2023-11-25 13:01:19.312 UTC [3981486] ERROR:  0A000: could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 13:01:19.312 UTC [3981486] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:19.312 UTC [3981486] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:19.312 UTC [3981486] STATEMENT:  SELECT * FROM (SELECT user_id, value_1 FROM users_table GROUP BY CUBE (user_id, value_1)) s;
2023-11-25 13:01:19.514 UTC [3981483] WARNING:  0A000: "view subquery_and_ctes" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 13:01:19.514 UTC [3981483] DETAIL:  "view subquery_and_ctes" will be created only locally
2023-11-25 13:01:19.514 UTC [3981483] HINT:  Distribute "table users_table_local" first to distribute "view subquery_and_ctes"
2023-11-25 13:01:19.514 UTC [3981483] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:19.532 UTC [3981484] WARNING:  0A000: "view subquery_from_from_where_local_table" has dependency to "table events_table_local" that is not in Citus' metadata
2023-11-25 13:01:19.532 UTC [3981484] DETAIL:  "view subquery_from_from_where_local_table" will be created only locally
2023-11-25 13:01:19.532 UTC [3981484] HINT:  Distribute "table events_table_local" first to distribute "view subquery_from_from_where_local_table"
2023-11-25 13:01:19.532 UTC [3981484] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:19.754 UTC [3981484] WARNING:  0A000: "view all_executors_view" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 13:01:19.754 UTC [3981484] DETAIL:  "view all_executors_view" will be created only locally
2023-11-25 13:01:19.754 UTC [3981484] HINT:  Distribute "table users_table_local" first to distribute "view all_executors_view"
2023-11-25 13:01:19.754 UTC [3981484] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:19.863 UTC [3981484] WARNING:  0A000: "view subquery_and_ctes" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 13:01:19.863 UTC [3981484] DETAIL:  "view subquery_and_ctes" will be created only locally
2023-11-25 13:01:19.863 UTC [3981484] HINT:  Distribute "table users_table_local" first to distribute "view subquery_and_ctes"
2023-11-25 13:01:19.863 UTC [3981484] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:19.883 UTC [3981484] WARNING:  0A000: "view subquery_and_ctes_second" has dependency to "table users_table_local" that is not in Citus' metadata
2023-11-25 13:01:19.883 UTC [3981484] DETAIL:  "view subquery_and_ctes_second" will be created only locally
2023-11-25 13:01:19.883 UTC [3981484] HINT:  Distribute "table users_table_local" first to distribute "view subquery_and_ctes_second"
2023-11-25 13:01:19.883 UTC [3981484] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:20.236 UTC [3981796] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 13:01:20.236 UTC [3981796] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 13:01:20.236 UTC [3981796] STATEMENT:  WITH event_id
	     AS(SELECT user_id AS events_user_id,
	                time    AS events_time,
	                event_type
	         FROM   events_table)
	SELECT Count(*)
	FROM   event_id
	WHERE  events_user_id IN (SELECT user_id
	                          FROM   users_table
	                          WHERE  users_table.time = events_time);
2023-11-25 13:01:20.310 UTC [3981797] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:20.310 UTC [3981797] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:20.310 UTC [3981797] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:20.310 UTC [3981797] STATEMENT:  SELECT key, count(*) FROM (SELECT *, random() FROM append_table a JOIN append_table b USING (key)) u GROUP BY key ORDER BY 1,2 LIMIT 3;
2023-11-25 13:01:20.318 UTC [3981797] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.318 UTC [3981797] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.318 UTC [3981797] STATEMENT:  SELECT key, value FROM append_table a WHERE key IN (SELECT key FROM append_table WHERE value > 100) ORDER BY 1,2;
2023-11-25 13:01:20.333 UTC [3981795] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.333 UTC [3981795] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.333 UTC [3981795] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.user_id GROUP BY user_id)
	FROM users_table u JOIN events_table e USING (value_2)
	ORDER BY 1,2 LIMIT 1;
2023-11-25 13:01:20.333 UTC [3981795] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.333 UTC [3981795] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.333 UTC [3981795] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.value_2)
	FROM events_table e
	ORDER BY 1,2 LIMIT 1;
2023-11-25 13:01:20.334 UTC [3981795] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.334 UTC [3981795] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.334 UTC [3981795] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.value_2 GROUP BY user_id)
	FROM events_table e
	ORDER BY 1,2 LIMIT 1;
2023-11-25 13:01:20.349 UTC [3981797] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.349 UTC [3981797] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.349 UTC [3981797] STATEMENT:  DELETE FROM append_table a USING append_table b WHERE a.key = b.key;
2023-11-25 13:01:20.364 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:20.364 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:20.364 UTC [3981795] STATEMENT:  SELECT (SELECT max(u1.time) FROM users_table u1 JOIN users_reference_table u2 USING (user_id) WHERE u2.user_id = e.user_id GROUP BY user_id), 5
	FROM events_reference_table e
	GROUP BY 1
	ORDER BY 1,2 LIMIT 1;
2023-11-25 13:01:20.364 UTC [3981795] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.364 UTC [3981795] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.364 UTC [3981795] STATEMENT:  SELECT event_type, (SELECT max(time) FROM users_table WHERE user_id = e.user_id GROUP BY user_id)
	FROM users_table u JOIN events_table e USING (value_2)
	ORDER BY 1,2 LIMIT 1;
2023-11-25 13:01:20.368 UTC [3981797] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.368 UTC [3981797] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.368 UTC [3981797] STATEMENT:  UPDATE append_table a sET extra = 1 FROM append_table b WHERE a.key = b.key;
2023-11-25 13:01:20.394 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 13:01:20.394 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 13:01:20.394 UTC [3981795] STATEMENT:  WITH cte_1 AS (SELECT min(user_id) u, max(time) m FROM users_table)
	SELECT count(*), (SELECT max(time) FROM users_table WHERE user_id = cte_1.u GROUP BY user_id)
	FROM cte_1
	GROUP BY 2
	ORDER BY 1,2 LIMIT 1;
2023-11-25 13:01:20.407 UTC [3981795] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 13:01:20.407 UTC [3981795] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 13:01:20.407 UTC [3981795] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 13:01:20.407 UTC [3981795] STATEMENT:  SELECT sum(e.user_id) + (SELECT max(value_3) FROM users_reference_table WHERE value_2 = e.value_2 GROUP BY user_id)
	FROM events_table e
	GROUP BY e.value_2
	ORDER BY 1 LIMIT 3;
2023-11-25 13:01:20.407 UTC [3981795] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 13:01:20.407 UTC [3981795] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 13:01:20.407 UTC [3981795] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 13:01:20.407 UTC [3981795] STATEMENT:  SELECT sum(e.user_id) + (SELECT user_id FROM users_reference_table WHERE user_id = 1 AND value_1 = 1)
	FROM events_table e;
2023-11-25 13:01:20.418 UTC [3981795] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 13:01:20.418 UTC [3981795] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 13:01:20.418 UTC [3981795] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 13:01:20.418 UTC [3981795] STATEMENT:  SELECT e.value_2, sum((SELECT any_value(value_3) FROM users_reference_table WHERE user_id = e.user_id GROUP BY user_id)) OVER (PARTITION BY e.value_2)
	FROM events_table e
	ORDER BY 1, 2 LIMIT 3;
2023-11-25 13:01:20.443 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:20.443 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:20.443 UTC [3981795] STATEMENT:  SELECT (SELECT (SELECT e.user_id + user_id) FROM users_reference_table WHERE user_id = e.user_id GROUP BY user_id)
	FROM events_table e
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 13:01:20.444 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 13:01:20.444 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 13:01:20.444 UTC [3981795] STATEMENT:  WITH cte_1 AS (SELECT user_id FROM users_table ORDER BY 1 LIMIT 1)
	SELECT (SELECT (SELECT e.user_id + user_id) FROM cte_1 WHERE user_id = e.user_id GROUP BY user_id)
	FROM events_table e
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 13:01:20.444 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a subquery without FROM
2023-11-25 13:01:20.444 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:690
2023-11-25 13:01:20.444 UTC [3981795] STATEMENT:  SELECT (SELECT (SELECT e.user_id + user_id) FROM (SELECT 1 AS user_id) s WHERE user_id = e.user_id GROUP BY user_id)
	FROM events_table e
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 13:01:20.446 UTC [3981795] WARNING:  0A000: "view view_1" has dependency on unsupported object "schema pg_temp_7"
2023-11-25 13:01:20.446 UTC [3981795] DETAIL:  "view view_1" will be created only locally
2023-11-25 13:01:20.446 UTC [3981795] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 13:01:20.465 UTC [3981795] WARNING:  0A000: "view view_2" has dependency on unsupported object "schema pg_temp_7"
2023-11-25 13:01:20.465 UTC [3981795] DETAIL:  "view view_2" will be created only locally
2023-11-25 13:01:20.465 UTC [3981795] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 13:01:20.474 UTC [3981795] ERROR:  42704: type "view_1" does not exist
2023-11-25 13:01:20.474 UTC [3981795] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:20.474 UTC [3981795] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:20.474 UTC [3981795] STATEMENT:  SELECT (SELECT view_1)
	FROM view_1
	ORDER BY 1 LIMIT 1;
2023-11-25 13:01:20.477 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a subquery without FROM
2023-11-25 13:01:20.477 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:690
2023-11-25 13:01:20.477 UTC [3981795] STATEMENT:  SELECT (SELECT (SELECT user_id))
	FROM events_table e
	ORDER BY 1 LIMIT 1;
2023-11-25 13:01:20.489 UTC [3981795] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:20.489 UTC [3981795] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:20.489 UTC [3981795] STATEMENT:  SELECT (SELECT (user_id,value_1) FROM users_table u WHERE u.user_id = e.user_id AND time = 'Thu Nov 23 09:26:42.145043 2017')
	FROM events_table e
	WHERE user_id < 3
	GROUP BY 1
	ORDER BY 1 LIMIT 3;
2023-11-25 13:01:20.507 UTC [3981796] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 13:01:20.507 UTC [3981796] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 13:01:20.507 UTC [3981796] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (SELECT min(value_3) v FROM users_table WHERE user_id = e.user_id GROUP BY e.value_2 HAVING min(value_3) > (SELECT e.value_3));
2023-11-25 13:01:20.508 UTC [3981794] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:20.508 UTC [3981794] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:20.508 UTC [3981794] STATEMENT:  SELECT b FROM (SELECT a FROM items a GROUP BY key) b ORDER BY b;
2023-11-25 13:01:20.520 UTC [3981796] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.520 UTC [3981796] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.520 UTC [3981796] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (
	    SELECT min(r.value_3) v FROM users_reference_table r JOIN (SELECT * FROM users_table WHERE value_2 = e.user_id) u USING (user_id)
	    WHERE u.value_2 > 3
	    GROUP BY e.value_2 HAVING min(r.value_3) > e.value_3);
2023-11-25 13:01:20.521 UTC [3981796] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.521 UTC [3981796] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.521 UTC [3981796] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (
	    SELECT min(r.value_3) v FROM users_reference_table r JOIN users_table u USING (user_id)
	    WHERE u.value_2 > 3
	    GROUP BY e.value_2 HAVING min(r.value_3) > e.value_3);
2023-11-25 13:01:20.521 UTC [3981796] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.521 UTC [3981796] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.521 UTC [3981796] STATEMENT:  SELECT
	  count(*)
	FROM
	  events_table e
	WHERE
	  value_3 IN (
	    SELECT min(r.value_3) v FROM users_reference_table r JOIN users_table u USING (user_id)
	    WHERE u.value_2 > 3
	    GROUP BY u.value_2 HAVING min(r.value_3) > e.value_3);
2023-11-25 13:01:20.553 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a subquery without FROM
2023-11-25 13:01:20.553 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:690
2023-11-25 13:01:20.553 UTC [3981795] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table) AND value_2 = a)
	FROM (SELECT 1 AS a) r;
2023-11-25 13:01:20.554 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:20.554 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:20.554 UTC [3981795] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table) AND value_2 = r.user_id)
	FROM users_reference_table r;
2023-11-25 13:01:20.554 UTC [3981795] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.554 UTC [3981795] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.554 UTC [3981795] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table WHERE user_id = a))
	FROM (SELECT 1 AS a) r;
2023-11-25 13:01:20.567 UTC [3981796] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.567 UTC [3981796] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.567 UTC [3981796] STATEMENT:  SELECT
		u1.user_id, u2.user_id
	FROM
		users_table u1, users_table u2
	WHERE
		u1.value_1 < u2.value_1 AND
		(SELECT
			count(*)
		FROM
			events_table e1
		WHERE
			e1.user_id = u2.user_id AND
			u1.user_id = u2.user_id) > 10
	ORDER BY 1,2;
2023-11-25 13:01:20.568 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:20.568 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:20.568 UTC [3981795] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table ))
	FROM (SELECT * FROM users_reference_table WHERE value_2 IN (SELECT value_2 FROM events_table WHERE events_table.user_id = users_reference_table.user_id)) r
	ORDER BY 1 LIMIT 3;
2023-11-25 13:01:20.569 UTC [3981796] WARNING:  0A000: "view correlated_subquery_view" has dependency on unsupported object "schema pg_temp_8"
2023-11-25 13:01:20.569 UTC [3981796] DETAIL:  "view correlated_subquery_view" will be created only locally
2023-11-25 13:01:20.569 UTC [3981796] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 13:01:20.582 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:20.582 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:20.582 UTC [3981795] STATEMENT:  SELECT (SELECT (SELECT user_id FROM users_table WHERE user_id = users_reference_table.user_id GROUP BY user_id)
	        FROM users_reference_table WHERE user_id < 2 GROUP BY user_id)
	FROM users_reference_table r
	ORDER BY 1 LIMIT 3;
2023-11-25 13:01:20.585 UTC [3981795] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.585 UTC [3981795] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.585 UTC [3981795] STATEMENT:  SELECT (SELECT DISTINCT user_id FROM users_table WHERE user_id = (SELECT max(user_id) FROM users_table WHERE user_id = r.user_id))
	FROM (SELECT user_id FROM users_table ORDER BY 1 LIMIT 3) r;
2023-11-25 13:01:20.586 UTC [3981795] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 13:01:20.586 UTC [3981795] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 13:01:20.586 UTC [3981795] STATEMENT:  SELECT (SELECT (SELECT max(user_id) FROM users_table) FROM users_table WHERE user_id = r.user_id)
	FROM (SELECT user_id FROM users_table ORDER BY 1 LIMIT 3) r;
2023-11-25 13:01:20.586 UTC [3981795] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:20.586 UTC [3981795] DETAIL:  For Update/Share commands are currently unsupported
2023-11-25 13:01:20.586 UTC [3981795] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 13:01:20.586 UTC [3981795] STATEMENT:  SELECT count(*) FROM (SELECT
	  (SELECT user_id FROM users_table WHERE user_id = u1.user_id FOR UPDATE)
	FROM users_table u1
	GROUP BY user_id) as foo;
2023-11-25 13:01:20.586 UTC [3981796] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:20.586 UTC [3981796] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:20.586 UTC [3981796] STATEMENT:  SELECT sum(value_1)
	FROM users_table u1
	WHERE (SELECT COUNT(DISTINCT e1.value_2)
	     FROM events_table e1
	     WHERE e1.user_id = u1.user_id AND false
	          ) > 115;
2023-11-25 13:01:21.586 UTC [3982163] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:21.586 UTC [3982163] CONTEXT:  SQL statement "EXPLAIN (FORMAT JSON) 
	
	    SELECT
	        count(*)
	    FROM
	        (users_table u1 JOIN users_table u2 using(value_1)) a JOIN (SELECT value_1, random() FROM users_table) as u3 USING (value_1);
	"
	PL/pgSQL function explain_json_2(text) line 5 at EXECUTE
2023-11-25 13:01:21.586 UTC [3982163] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:21.586 UTC [3982163] STATEMENT:  SELECT true AS valid FROM explain_json_2($$
	
	    SELECT
	        count(*)
	    FROM
	        (users_table u1 JOIN users_table u2 using(value_1)) a JOIN (SELECT value_1, random() FROM users_table) as u3 USING (value_1);
	$$);
2023-11-25 13:01:21.613 UTC [3982163] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:21.613 UTC [3982163] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:21.613 UTC [3982163] STATEMENT:  SELECT *
	FROM
	  (SELECT *
	   FROM users_table
	   OFFSET 0) AS users_table
	JOIN LATERAL
	  (SELECT *
	   FROM
	     (SELECT *
	      FROM events_table
	      WHERE user_id = users_table.user_id) AS bar
	   LEFT JOIN users_table u2 ON u2.user_id = bar.value_2) AS foo ON TRUE;
2023-11-25 13:01:21.613 UTC [3982163] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:21.613 UTC [3982163] CONTEXT:  SQL statement "EXPLAIN (FORMAT JSON) 
	SELECT *
	FROM
	  (SELECT 1 AS user_id) AS users_table
	JOIN LATERAL
	  (SELECT *
	   FROM
	     (SELECT *
	      FROM events_table
	      WHERE user_id = users_table.user_id) AS bar
	   LEFT JOIN users_table u2 ON u2.user_id = bar.value_2) AS foo ON TRUE
	"
	PL/pgSQL function explain_json_2(text) line 5 at EXECUTE
2023-11-25 13:01:21.613 UTC [3982163] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:21.613 UTC [3982163] STATEMENT:  SELECT true AS valid FROM explain_json_2($$
	SELECT *
	FROM
	  (SELECT 1 AS user_id) AS users_table
	JOIN LATERAL
	  (SELECT *
	   FROM
	     (SELECT *
	      FROM events_table
	      WHERE user_id = users_table.user_id) AS bar
	   LEFT JOIN users_table u2 ON u2.user_id = bar.value_2) AS foo ON TRUE
	$$);
2023-11-25 13:01:21.831 UTC [3982217] WARNING:  0A000: "view recursive_defined_non_recursive_view" has dependency to "table local_table" that is not in Citus' metadata
2023-11-25 13:01:21.831 UTC [3982217] DETAIL:  "view recursive_defined_non_recursive_view" will be created only locally
2023-11-25 13:01:21.831 UTC [3982217] HINT:  Distribute "table local_table" first to distribute "view recursive_defined_non_recursive_view"
2023-11-25 13:01:21.831 UTC [3982217] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:21.861 UTC [3982217] ERROR:  0A000: direct joins between distributed and local tables are not supported
2023-11-25 13:01:21.861 UTC [3982217] HINT:  Use CTE's or subqueries to select from local tables and use them in joins
2023-11-25 13:01:21.861 UTC [3982217] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:21.861 UTC [3982217] STATEMENT:  SELECT ref_table.* FROM ref_table WHERE EXISTS (SELECT * FROM local_table l WHERE l.a = ref_table.a);
2023-11-25 13:01:21.898 UTC [3982218] ERROR:  0A000: recursive complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:21.898 UTC [3982218] LOCATION:  CreateDistributedPlan, distributed_planner.c:1092
2023-11-25 13:01:21.898 UTC [3982218] STATEMENT:  SELECT t1.id
	FROM (
	    SELECT t2.id
	    FROM (
	        SELECT t0.id
	        FROM tbl_dist1 t0
	        LIMIT 5
	    ) AS t2
	    INNER JOIN tbl_dist1 AS t3 USING (id)
	) AS t1
	FULL JOIN tbl_dist1 t4 USING (id);
2023-11-25 13:01:21.923 UTC [3982215] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 13:01:21.923 UTC [3982215] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:21.923 UTC [3982215] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:21.923 UTC [3982215] STATEMENT:  WITH cte_1 AS (SELECT * FROM test_table)
	SELECT
		count(*)
	FROM
		cte_1
	WHERE
		key IN (
				SELECT
					key
				FROM
					test_table
	  			 	FOR UPDATE
				);
2023-11-25 13:01:22.029 UTC [3982215] ERROR:  0A000: CTEs that refer to other subqueries are not supported in multi-shard queries
2023-11-25 13:01:22.029 UTC [3982215] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1110
2023-11-25 13:01:22.029 UTC [3982215] STATEMENT:  SELECT count(*)
		FROM
		  (SELECT *
		   FROM test_table) AS test_table_cte
		JOIN LATERAL
		  (WITH bar AS  (SELECT *
		      FROM test_table
		      WHERE key = test_table_cte.key)
		  	SELECT *
		   FROM
		      bar
		   LEFT JOIN test_table u2 ON u2.key = bar.value::int) AS foo ON TRUE;
2023-11-25 13:01:22.057 UTC [3982219] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains VALUES
2023-11-25 13:01:22.057 UTC [3982219] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:697
2023-11-25 13:01:22.057 UTC [3982219] STATEMENT:  SELECT
		*
	FROM
		test_values as t1
			JOIN LATERAL (
				SELECT
					t1.key
				FROM
					(VALUES (1, 'one'), (2, 'two'), (3, 'three')) as t(num, v)
					  WHERE num > (SELECT max(key) FROM test_values)) as foo
		ON (true);
2023-11-25 13:01:22.072 UTC [3982219] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains VALUES
2023-11-25 13:01:22.072 UTC [3982219] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:697
2023-11-25 13:01:22.072 UTC [3982219] STATEMENT:  SELECT
	  count(*)
	FROM
	 (SELECT a, b FROM (VALUES (1, 'one'), (2, 'two'), (3, 'three')) as t(a,b)) as values_data(a,b)
	WHERE
	  NOT EXISTS
	      (SELECT
	          value
	       FROM
	          test_values
	       WHERE
	          test_values.key = values_data.a
	      );
2023-11-25 13:01:22.076 UTC [3982215] ERROR:  21000: more than one row returned by a subquery used as an expression
2023-11-25 13:01:22.076 UTC [3982215] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:22.076 UTC [3982215] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:22.076 UTC [3982215] STATEMENT:  WITH cte_1 AS (SELECT * FROM test_table),
		 cte_2 AS (SELECT * FROM test_table)
	(SELECT *, (SELECT key FROM cte_1) FROM test_table)
	UNION
	(SELECT *, 1 FROM cte_2);
2023-11-25 13:01:22.213 UTC [3982218] ERROR:  0A000: recursive complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:22.213 UTC [3982218] LOCATION:  CreateDistributedPlan, distributed_planner.c:1092
2023-11-25 13:01:22.213 UTC [3982218] STATEMENT:  SELECT avg(avgsub.id) FROM (
	    SELECT table_0.id FROM (
	        SELECT table_1.id FROM (
	            SELECT table_2.id FROM (
	                SELECT table_3.id FROM (
	                    SELECT table_4.id FROM dist0 AS table_4
	                    LEFT JOIN dist1 AS table_5 USING (id)
	                ) AS table_3 INNER JOIN dist0 AS table_6 USING (id)
	            ) AS table_2 WHERE table_2.id < 10 ORDER BY id LIMIT 47
	        ) AS table_1 RIGHT JOIN dist0 AS table_7 USING (id)
	    ) AS table_0 RIGHT JOIN dist1 AS table_8 USING (id)
	) AS avgsub;
2023-11-25 13:01:22.229 UTC [3982218] ERROR:  0A000: recursive complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:22.229 UTC [3982218] LOCATION:  CreateDistributedPlan, distributed_planner.c:1092
2023-11-25 13:01:22.229 UTC [3982218] STATEMENT:  WITH cte_0 AS (
	    SELECT table_0.id FROM dist1 AS table_0 FULL JOIN dist1 AS table_1 USING (id)
	)
	SELECT avg(table_5.id) FROM (
	    SELECT table_6.id FROM (
	        SELECT table_7.id FROM dist0 AS table_7 ORDER BY id LIMIT 87
	    ) AS table_6 INNER JOIN dist0 AS table_8 USING (id) WHERE table_8.id < 0 ORDER BY id
	) AS table_5 INNER JOIN dist0 AS table_9 USING (id);
2023-11-25 13:01:22.981 UTC [3982628] ERROR:  42601: parallel workers for vacuum must be between 0 and 1024 at character 9
2023-11-25 13:01:22.981 UTC [3982628] LOCATION:  ExecVacuum, vacuum.c:188
2023-11-25 13:01:22.981 UTC [3982628] STATEMENT:  VACUUM (PARALLEL -5) dist_table;
2023-11-25 13:01:22.981 UTC [3982628] ERROR:  42601: parallel option requires a value between 0 and 1024 at character 9
2023-11-25 13:01:22.981 UTC [3982628] LOCATION:  ExecVacuum, vacuum.c:176
2023-11-25 13:01:22.981 UTC [3982628] STATEMENT:  VACUUM (PARALLEL) dist_table;
2023-11-25 13:01:22.987 UTC [3982627] ERROR:  0A000: cannot distribute relation: gen2
2023-11-25 13:01:22.987 UTC [3982627] DETAIL:  Distribution column must not use GENERATED ALWAYS AS (...) STORED.
2023-11-25 13:01:22.987 UTC [3982627] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1825
2023-11-25 13:01:22.987 UTC [3982627] STATEMENT:  select create_distributed_table('gen2', 'val2');
2023-11-25 13:01:22.988 UTC [3982628] ERROR:  0A000: alter table command is currently unsupported
2023-11-25 13:01:22.988 UTC [3982628] DETAIL:  Only ADD|DROP COLUMN, SET|DROP NOT NULL, SET|DROP DEFAULT, ADD|DROP|VALIDATE CONSTRAINT, SET (), RESET (), ENABLE|DISABLE|NO FORCE|FORCE ROW LEVEL SECURITY, ATTACH|DETACH PARTITION and TYPE subcommands are supported.
2023-11-25 13:01:22.988 UTC [3982628] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3506
2023-11-25 13:01:22.988 UTC [3982628] STATEMENT:  ALTER TABLE generated_col_table ALTER COLUMN b DROP EXPRESSION;
2023-11-25 13:01:23.013 UTC [3982628] WARNING:  0A000: "function myvarcharin(cstring,oid,integer)" has dependency on unsupported object "type myvarchar"
2023-11-25 13:01:23.013 UTC [3982628] DETAIL:  "function myvarcharin(cstring,oid,integer)" will be created only locally
2023-11-25 13:01:23.013 UTC [3982628] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 13:01:23.013 UTC [3982628] WARNING:  0A000: "function myvarcharout(myvarchar)" has dependency on unsupported object "type myvarchar"
2023-11-25 13:01:23.013 UTC [3982628] DETAIL:  "function myvarcharout(myvarchar)" will be created only locally
2023-11-25 13:01:23.013 UTC [3982628] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 13:01:23.015 UTC [3982628] ERROR:  0A000: "table my_table" has dependency on unsupported object "type myvarchar"
2023-11-25 13:01:23.015 UTC [3982628] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:958
2023-11-25 13:01:23.015 UTC [3982628] STATEMENT:  SELECT create_distributed_table('my_table', 'a');
2023-11-25 13:01:23.025 UTC [3982628] ERROR:  22023: EXPLAIN option WAL requires ANALYZE
2023-11-25 13:01:23.025 UTC [3982628] LOCATION:  ExplainQuery, explain.c:231
2023-11-25 13:01:23.025 UTC [3982628] STATEMENT:  EXPLAIN (WAL) INSERT INTO test_wal VALUES(1,11);
2023-11-25 13:01:23.028 UTC [3982627] ERROR:  XX000: Citus does not support COPY FROM with WHERE
2023-11-25 13:01:23.028 UTC [3982627] LOCATION:  ProcessCopyStmt, multi_copy.c:2934
2023-11-25 13:01:23.028 UTC [3982627] STATEMENT:  copy cptest from STDIN with csv where val < 4;
2023-11-25 13:01:23.028 UTC [3982627] ERROR:  42601: syntax error at or near "1" at character 1
2023-11-25 13:01:23.028 UTC [3982627] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:01:23.028 UTC [3982627] STATEMENT:  1,6
	2,3
	3,2
	4,9
	5,4
	select sum(id), sum(val) from cptest;
2023-11-25 13:01:23.076 UTC [3982627] ERROR:  23503: insert or update on table "collection_users" violates foreign key constraint "collection_users_fkey"
2023-11-25 13:01:23.076 UTC [3982627] DETAIL:  Key (key, collection_id)=(1, 1000) is not present in table "collections_list".
2023-11-25 13:01:23.076 UTC [3982627] LOCATION:  ri_ReportViolation, ri_triggers.c:2596
2023-11-25 13:01:23.076 UTC [3982627] STATEMENT:  INSERT INTO collection_users VALUES (1, 1000, 1);
2023-11-25 13:01:23.115 UTC [3982627] ERROR:  23503: insert or update on table "collection_users_60028" violates foreign key constraint "collection_users_fkey_60028"
2023-11-25 13:01:23.115 UTC [3982627] DETAIL:  Key (key, collection_id)=(1, 1000) is not present in table "collections_list_60016".
2023-11-25 13:01:23.115 UTC [3982627] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:23.115 UTC [3982627] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:23.115 UTC [3982627] STATEMENT:  INSERT INTO collection_users VALUES (1, 1000, 1);
2023-11-25 13:01:23.144 UTC [3982627] ERROR:  25006: cannot execute UPDATE in a read-only transaction
2023-11-25 13:01:23.144 UTC [3982627] LOCATION:  PreventCommandIfReadOnly, utility.c:414
2023-11-25 13:01:23.144 UTC [3982627] STATEMENT:  UPDATE test SET y = 35;
2023-11-25 13:01:23.147 UTC [3982627] ERROR:  25006: cannot execute UPDATE in a read-only transaction
2023-11-25 13:01:23.147 UTC [3982627] LOCATION:  PreventCommandIfReadOnly, utility.c:414
2023-11-25 13:01:23.147 UTC [3982627] STATEMENT:  UPDATE test SET y = 40;
2023-11-25 13:01:23.154 UTC [3982627] ERROR:  0A000: Hash distributed partition columns may not use a non deterministic collation
2023-11-25 13:01:23.154 UTC [3982627] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1864
2023-11-25 13:01:23.154 UTC [3982627] STATEMENT:  select create_distributed_table('col_test', 'val');
2023-11-25 13:01:23.438 UTC [3982627] ERROR:  42501: permission denied for schema test_pg12
2023-11-25 13:01:23.438 UTC [3982627] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:01:23.438 UTC [3982627] STATEMENT:  ALTER TABLE test_pg12.superuser_columnar_table SET(columnar.chunk_group_row_limit = 100);
2023-11-25 13:01:23.438 UTC [3982627] ERROR:  42501: permission denied for schema test_pg12
2023-11-25 13:01:23.438 UTC [3982627] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:01:23.438 UTC [3982627] STATEMENT:  ALTER TABLE test_pg12.superuser_columnar_table RESET (columnar.chunk_group_row_limit);
2023-11-25 13:01:23.619 UTC [3982756] ERROR:  0A000: PROCESS_TOAST required with VACUUM FULL
2023-11-25 13:01:23.619 UTC [3982756] LOCATION:  vacuum, vacuum.c:351
2023-11-25 13:01:23.619 UTC [3982756] STATEMENT:  VACUUM (FULL, PROCESS_TOAST false) t1;
2023-11-25 13:01:23.622 UTC [3982756] ERROR:  42601: index_cleanup requires a Boolean value
2023-11-25 13:01:23.622 UTC [3982756] LOCATION:  defGetBoolean, define.c:152
2023-11-25 13:01:23.622 UTC [3982756] STATEMENT:  VACUUM (INDEX_CLEANUP "AUTOX") t1;
2023-11-25 13:01:23.643 UTC [3982756] ERROR:  42704: tablespace "test_tablespace1" does not exist
2023-11-25 13:01:23.643 UTC [3982756] LOCATION:  get_tablespace_oid, tablespace.c:1484
2023-11-25 13:01:23.643 UTC [3982756] STATEMENT:  reindex(TABLESPACE test_tablespace1) index idx;
2023-11-25 13:01:23.649 UTC [3982756] ERROR:  0A000: only simple column references are allowed in CREATE STATISTICS
2023-11-25 13:01:23.649 UTC [3982756] LOCATION:  AppendColumnNames, deparse_statistics_stmts.c:242
2023-11-25 13:01:23.649 UTC [3982756] STATEMENT:  CREATE STATISTICS s3 (ndistinct) ON date_trunc('month', a), date_trunc('day', a) FROM tbl1;
2023-11-25 13:01:23.659 UTC [3982756] ERROR:  XX000: ALTER TABLE .. DETACH PARTITION .. CONCURRENTLY commands are currently unsupported.
2023-11-25 13:01:23.659 UTC [3982756] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3420
2023-11-25 13:01:23.659 UTC [3982756] STATEMENT:  ALTER TABLE par DETACH PARTITION par_2 CONCURRENTLY;
2023-11-25 13:01:23.659 UTC [3982756] ERROR:  XX000: ALTER TABLE .. DETACH PARTITION .. FINALIZE commands are currently unsupported.
2023-11-25 13:01:23.659 UTC [3982756] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3398
2023-11-25 13:01:23.659 UTC [3982756] STATEMENT:  ALTER TABLE par DETACH PARTITION par_2 FINALIZE;
2023-11-25 13:01:23.733 UTC [3982769] LOG:  00000: deferred drop of orphaned resource pg14.col_compression_980010 on localhost:57637 completed
2023-11-25 13:01:23.733 UTC [3982769] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 13:01:23.733 UTC [3982769] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:23.772 UTC [3982756] LOG:  00000: deferred drop of orphaned resource pg14.col_compression_980010 on localhost:57638 completed
2023-11-25 13:01:23.772 UTC [3982756] CONTEXT:  SQL statement "CALL pg_catalog.citus_cleanup_orphaned_resources()"
	PL/pgSQL function public.wait_for_resource_cleanup() line 7 at CALL
2023-11-25 13:01:23.772 UTC [3982756] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 13:01:23.772 UTC [3982756] STATEMENT:  SELECT public.wait_for_resource_cleanup();
2023-11-25 13:01:24.000 UTC [3982756] ERROR:  22004: jsonb subscript in assignment must not be null
2023-11-25 13:01:24.000 UTC [3982756] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:24.000 UTC [3982756] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:24.000 UTC [3982756] STATEMENT:  update test_jsonb_subscript set test_json[NULL] = '1';
2023-11-25 13:01:24.022 UTC [3982756] ERROR:  42P01: invalid reference to FROM-clause entry for table "j1_tbl" at character 57
2023-11-25 13:01:24.022 UTC [3982756] HINT:  There is an entry for table "j1_tbl", but it cannot be referenced from this part of the query.
2023-11-25 13:01:24.022 UTC [3982756] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 13:01:24.022 UTC [3982756] STATEMENT:  SELECT * FROM (J1_TBL JOIN J2_TBL USING (i)) AS x WHERE J1_TBL.t = 'one' ORDER BY 1,2,3,4;
2023-11-25 13:01:24.022 UTC [3982756] ERROR:  42703: column x.t does not exist at character 55
2023-11-25 13:01:24.022 UTC [3982756] LOCATION:  errorMissingColumn, parse_relation.c:3656
2023-11-25 13:01:24.022 UTC [3982756] STATEMENT:  SELECT * FROM J1_TBL JOIN J2_TBL USING (i) AS x WHERE x.t = 'one' ORDER BY 1,2,3,4;
2023-11-25 13:01:24.022 UTC [3982756] ERROR:  42P01: missing FROM-clause entry for table "x" at character 63
2023-11-25 13:01:24.022 UTC [3982756] LOCATION:  errorMissingRTE, parse_relation.c:3608
2023-11-25 13:01:24.022 UTC [3982756] STATEMENT:  SELECT * FROM (J1_TBL JOIN J2_TBL USING (i) AS x) AS xx WHERE x.i = 1 ORDER BY 1,2,3,4;
2023-11-25 13:01:24.022 UTC [3982756] ERROR:  42712: table name "a1" specified more than once
2023-11-25 13:01:24.022 UTC [3982756] LOCATION:  checkNameSpaceConflicts, parse_relation.c:443
2023-11-25 13:01:24.022 UTC [3982756] STATEMENT:  SELECT * FROM J1_TBL a1 JOIN J2_TBL a2 USING (i) AS a1 ORDER BY 1,2,3,4;
2023-11-25 13:01:24.041 UTC [3982756] ERROR:  0A000: REINDEX TABLE queries on distributed partitioned tables are not supported
2023-11-25 13:01:24.041 UTC [3982756] LOCATION:  PreprocessReindexStmt, index.c:635
2023-11-25 13:01:24.041 UTC [3982756] STATEMENT:  REINDEX TABLE dist_part_table;
2023-11-25 13:01:24.048 UTC [3982756] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 13:01:24.048 UTC [3982756] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 13:01:24.048 UTC [3982756] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph0 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph0 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	SELECT * FROM search_graph ORDER BY seq;
2023-11-25 13:01:24.048 UTC [3982756] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 13:01:24.048 UTC [3982756] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 13:01:24.048 UTC [3982756] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph0 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph0 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	DELETE FROM graph0 WHERE t IN (SELECT t FROM search_graph ORDER BY seq);
2023-11-25 13:01:24.054 UTC [3982756] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 13:01:24.054 UTC [3982756] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 13:01:24.054 UTC [3982756] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph1 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph1 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	SELECT * FROM search_graph ORDER BY seq;
2023-11-25 13:01:24.054 UTC [3982756] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 13:01:24.054 UTC [3982756] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 13:01:24.054 UTC [3982756] STATEMENT:  WITH RECURSIVE search_graph(f, t, label) AS (
	    SELECT * FROM graph1 g WHERE f = 1
	    UNION ALL
	    SELECT g.*
	        FROM graph1 g, search_graph sg
	        WHERE g.f = sg.t and  g.f = 1
	) SEARCH DEPTH FIRST BY f, t SET seq
	DELETE FROM graph1 WHERE t IN (SELECT t FROM search_graph ORDER BY seq);
2023-11-25 13:01:24.054 UTC [3982756] ERROR:  0A000: recursive CTEs are not supported in distributed queries
2023-11-25 13:01:24.054 UTC [3982756] LOCATION:  RecursivelyPlanCTEs, recursive_planning.c:1089
2023-11-25 13:01:24.054 UTC [3982756] STATEMENT:  SELECT * FROM (
	    WITH RECURSIVE search_graph(f, t, label) AS (
	        SELECT *
	        FROM graph0 g
	        WHERE f = 1
	        UNION ALL SELECT g.*
	        FROM graph0 g, search_graph sg
	        WHERE g.f = sg.t AND g.f = 1
	    ) SEARCH DEPTH FIRST BY f, t SET seq
	    SELECT * FROM search_graph ORDER BY seq
	) as foo;
2023-11-25 13:01:24.062 UTC [3982756] ERROR:  42883: function "proc_with_out_param(date,int)" does not exist at character 36
2023-11-25 13:01:24.062 UTC [3982756] LOCATION:  regprocedurein, regproc.c:275
2023-11-25 13:01:24.062 UTC [3982756] STATEMENT:  SELECT create_distributed_function('proc_with_out_param(date,int)');
2023-11-25 13:01:24.333 UTC [3982756] ERROR:  42710: extension "postgres_fdw" already exists
2023-11-25 13:01:24.333 UTC [3982756] LOCATION:  CreateExtension, extension.c:1726
2023-11-25 13:01:24.333 UTC [3982756] STATEMENT:  CREATE EXTENSION postgres_fdw;
2023-11-25 13:01:25.540 UTC [3982863] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:01:25.540 UTC [3982863] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:01:25.540 UTC [3982863] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 13:01:25.540 UTC [3982863] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:01:25.540 UTC [3982863] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:01:25.540 UTC [3982863] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 13:01:25.541 UTC [3982863] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:01:25.541 UTC [3982863] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:01:25.541 UTC [3982863] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 13:01:25.577 UTC [3982878] LOG:  00000: cleaned up orphaned resource pg14.dist_table_1_980042 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:25.577 UTC [3982878] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:25.577 UTC [3982878] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:25.577 UTC [3982878] LOG:  00000: cleaned up orphaned resource pg14.dist_table_2_980044 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:25.577 UTC [3982878] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:25.577 UTC [3982878] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:26.622 UTC [3982863] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:01:26.622 UTC [3982863] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:01:26.622 UTC [3982863] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 13:01:26.623 UTC [3982863] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:01:26.623 UTC [3982863] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:01:26.623 UTC [3982863] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 13:01:26.624 UTC [3982863] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:01:26.624 UTC [3982863] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:01:26.624 UTC [3982863] STATEMENT:  SELECT citus_move_shard_placement(980042, 'localhost', 57637, 'localhost', 57638, shard_transfer_mode := 'force_logical');
2023-11-25 13:01:26.951 UTC [3982926] ERROR:  42P17: parameter "locale" must be specified
2023-11-25 13:01:26.951 UTC [3982926] LOCATION:  DefineCollation, collationcmds.c:242
2023-11-25 13:01:26.951 UTC [3982926] STATEMENT:  CREATE COLLATION german_phonebook_test (provider = icu, lc_collate = 'de-u-co-phonebk');
2023-11-25 13:01:26.951 UTC [3982926] ERROR:  42P17: parameter "locale" must be specified
2023-11-25 13:01:26.951 UTC [3982926] LOCATION:  DefineCollation, collationcmds.c:242
2023-11-25 13:01:26.951 UTC [3982926] STATEMENT:  CREATE COLLATION german_phonebook_test (provider = icu, lc_collate = 'de-u-co-phonebk', lc_ctype = 'de-u-co-phonebk');
2023-11-25 13:01:27.128 UTC [3982926] ERROR:  XX000: cannot rename trigger "new_record_sale_trigger" on table "sale_newyork"
2023-11-25 13:01:27.128 UTC [3982926] HINT:  Rename the trigger on the partitioned table "sale" instead.
2023-11-25 13:01:27.128 UTC [3982926] LOCATION:  renametrig, trigger.c:1567
2023-11-25 13:01:27.128 UTC [3982926] STATEMENT:  ALTER TRIGGER "new_record_sale_trigger" ON "pg15"."sale_newyork" RENAME TO "another_trigger_name";
2023-11-25 13:01:27.135 UTC [3982926] ERROR:  2BP01: cannot drop column col_1 of table generated_stored_ref because other objects depend on it
2023-11-25 13:01:27.135 UTC [3982926] DETAIL:  column col_3 of table generated_stored_ref depends on column col_1 of table generated_stored_ref
	column col_5 of table generated_stored_ref depends on column col_1 of table generated_stored_ref
2023-11-25 13:01:27.135 UTC [3982926] HINT:  Use DROP ... CASCADE to drop the dependent objects too.
2023-11-25 13:01:27.135 UTC [3982926] LOCATION:  reportDependentObjects, dependency.c:1189
2023-11-25 13:01:27.135 UTC [3982926] STATEMENT:  ALTER TABLE generated_stored_ref DROP COLUMN col_1;
2023-11-25 13:01:27.165 UTC [3982962] LOG:  00000: cleaned up orphaned resource pg14.dist_table_1_980042 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:27.165 UTC [3982962] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:27.165 UTC [3982962] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:27.166 UTC [3982962] LOG:  00000: cleaned up orphaned resource pg14.dist_table_2_980044 on localhost:57638 which was left behind after a failed operation
2023-11-25 13:01:27.166 UTC [3982962] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:305
2023-11-25 13:01:27.166 UTC [3982962] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:01:27.327 UTC [3982926] ERROR:  0A000: MERGE command is not supported on reference tables yet
2023-11-25 13:01:27.327 UTC [3982926] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:330
2023-11-25 13:01:27.327 UTC [3982926] STATEMENT:  MERGE INTO tbl1 USING tbl2 ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 13:01:27.334 UTC [3982926] ERROR:  0A000: MERGE command is not supported on reference tables yet
2023-11-25 13:01:27.334 UTC [3982926] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:330
2023-11-25 13:01:27.334 UTC [3982926] STATEMENT:  MERGE INTO tbl1 USING tbl2 ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 13:01:27.396 UTC [3983004] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:27.396 UTC [3983004] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:27.396 UTC [3983004] STATEMENT:  MERGE INTO tbl1 USING tbl2 ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 13:01:27.396 UTC [3983004] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:27.396 UTC [3983004] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:27.396 UTC [3983004] STATEMENT:  WITH targq AS (
	    SELECT * FROM tbl2
	)
	MERGE INTO tbl1 USING targq ON (true)
	WHEN MATCHED THEN DELETE;
2023-11-25 13:01:27.396 UTC [3983004] ERROR:  0A000: MERGE not supported in WITH query at character 6
2023-11-25 13:01:27.396 UTC [3983004] LOCATION:  transformWithClause, parse_cte.c:131
2023-11-25 13:01:27.396 UTC [3983004] STATEMENT:  WITH foo AS (
	  MERGE INTO tbl1 USING tbl2 ON (true)
	  WHEN MATCHED THEN DELETE
	) SELECT * FROM foo;
2023-11-25 13:01:27.396 UTC [3983004] ERROR:  0A000: MERGE not supported in COPY
2023-11-25 13:01:27.396 UTC [3983004] LOCATION:  DoCopy, copy.c:281
2023-11-25 13:01:27.396 UTC [3983004] STATEMENT:  COPY (
	  MERGE INTO tbl1 USING tbl2 ON (true)
	  WHEN MATCHED THEN DELETE
	) TO stdout;
2023-11-25 13:01:27.397 UTC [3983004] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:27.397 UTC [3983004] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:27.397 UTC [3983004] STATEMENT:  MERGE INTO tbl1 t
	USING tbl2
	ON (true)
	WHEN MATCHED THEN
	    DO NOTHING;
2023-11-25 13:01:27.397 UTC [3983004] ERROR:  0A000: updating the distribution column is not allowed in MERGE actions
2023-11-25 13:01:27.397 UTC [3983004] LOCATION:  MergeQualAndTargetListFunctionsSupported, merge_planner.c:651
2023-11-25 13:01:27.397 UTC [3983004] STATEMENT:  MERGE INTO tbl1 t
	USING tbl2
	ON (true)
	WHEN MATCHED THEN
	    UPDATE SET x = (SELECT count(*) FROM tbl2);
2023-11-25 13:01:27.398 UTC [3983004] ERROR:  0A000: cannot distribute relation: numeric_negative_scale
2023-11-25 13:01:27.398 UTC [3983004] DETAIL:  Distribution column must not use numeric type with negative scale
2023-11-25 13:01:27.398 UTC [3983004] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1838
2023-11-25 13:01:27.398 UTC [3983004] STATEMENT:  SELECT create_distributed_table('numeric_negative_scale','numeric_column');
2023-11-25 13:01:27.416 UTC [3983004] ERROR:  0A000: cannot distribute relation: numeric_negative_scale_3037880381
2023-11-25 13:01:27.416 UTC [3983004] DETAIL:  Distribution column must not use numeric type with negative scale
2023-11-25 13:01:27.416 UTC [3983004] LOCATION:  EnsureRelationCanBeDistributed, create_distributed_table.c:1838
2023-11-25 13:01:27.416 UTC [3983004] STATEMENT:  SELECT alter_distributed_table('numeric_negative_scale',
	                                distribution_column := 'numeric_column');
2023-11-25 13:01:27.486 UTC [3983004] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:27.486 UTC [3983004] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:27.486 UTC [3983004] STATEMENT:  SELECT count(*)
	FROM numeric_repartition_first f,
	     numeric_repartition_second s
	WHERE f.id = s.numeric_column;
2023-11-25 13:01:27.695 UTC [3983004] ERROR:  22P04: column name mismatch in header line field 2: got "data", expected "data_"
2023-11-25 13:01:27.695 UTC [3983004] CONTEXT:  COPY copy_test2, line 1: "id	data"
2023-11-25 13:01:27.695 UTC [3983004] LOCATION:  NextCopyFromRawFields, copyfromparse.c:806
2023-11-25 13:01:27.695 UTC [3983004] STATEMENT:  COPY copy_test2 FROM '/tmp/''copy_test.txt' WITH ( HEADER match, FORMAT text);
2023-11-25 13:01:27.762 UTC [3983200] ERROR:  42P01: relation "seq_non_exists" does not exist
2023-11-25 13:01:27.762 UTC [3983200] LOCATION:  RangeVarGetRelidExtended, namespace.c:433
2023-11-25 13:01:27.762 UTC [3983200] STATEMENT:  ALTER SEQUENCE seq_non_exists SET LOGGED;
2023-11-25 13:01:27.834 UTC [3983214] ERROR:  0A000: cannot create foreign key constraint
2023-11-25 13:01:27.834 UTC [3983214] DETAIL:  SET NULL or SET DEFAULT is not supported in ON DELETE operation when distribution key is included in the foreign key constraint
2023-11-25 13:01:27.834 UTC [3983214] LOCATION:  EnsureSupportedFKeyOnDistKey, foreign_constraint.c:548
2023-11-25 13:01:27.834 UTC [3983214] STATEMENT:  SELECT create_distributed_table('FKTABLE', 'tid');
2023-11-25 13:01:27.888 UTC [3983219] ERROR:  23505: duplicate key value violates unique constraint "idx2_null_distinct_test_960150"
2023-11-25 13:01:27.888 UTC [3983219] DETAIL:  Key (id, c2)=(1, null) already exists.
2023-11-25 13:01:27.888 UTC [3983219] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:27.888 UTC [3983219] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:27.888 UTC [3983219] STATEMENT:  INSERT INTO null_distinct_test VALUES (1, NULL, NULL, 'data4') ;
2023-11-25 13:01:27.899 UTC [3983219] ERROR:  23505: could not create unique index "uniq_c1_960150"
2023-11-25 13:01:27.899 UTC [3983219] DETAIL:  Key (id, c1)=(1, null) is duplicated.
2023-11-25 13:01:27.899 UTC [3983219] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:27.899 UTC [3983219] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:27.899 UTC [3983219] STATEMENT:  ALTER TABLE null_distinct_test ADD CONSTRAINT uniq_c1 UNIQUE NULLS NOT DISTINCT (id,c1);
2023-11-25 13:01:27.916 UTC [3983219] ERROR:  23505: duplicate key value violates unique constraint "reference_uniq_test_x_y_key_960154"
2023-11-25 13:01:27.916 UTC [3983219] DETAIL:  Key (x, y)=(1, null) already exists.
2023-11-25 13:01:27.916 UTC [3983219] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:27.916 UTC [3983219] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:27.916 UTC [3983219] STATEMENT:  INSERT INTO reference_uniq_test VALUES (1, NULL);
2023-11-25 13:01:27.916 UTC [3983219] WARNING:  01000: not propagating CLUSTER command for partitioned table to worker nodes
2023-11-25 13:01:27.916 UTC [3983219] HINT:  Provide a child partition table names in order to CLUSTER distributed partitioned tables.
2023-11-25 13:01:27.916 UTC [3983219] LOCATION:  PreprocessClusterStmt, cluster.c:85
2023-11-25 13:01:27.919 UTC [3983219] ERROR:  0A000: modifications on partitions when replication factor is greater than 1 is not supported
2023-11-25 13:01:27.919 UTC [3983219] HINT:  Run the query on the parent table "sale" instead.
2023-11-25 13:01:27.919 UTC [3983219] LOCATION:  DeferErrorIfPartitionTableNotSingleReplicated, distributed_planner.c:1224
2023-11-25 13:01:27.919 UTC [3983219] STATEMENT:  CLUSTER sale_newyork USING sale_newyork_pkey;
2023-11-25 13:01:27.941 UTC [3983219] WARNING:  01000: not propagating CLUSTER command for partitioned table to worker nodes
2023-11-25 13:01:27.941 UTC [3983219] HINT:  Provide a child partition table names in order to CLUSTER distributed partitioned tables.
2023-11-25 13:01:27.941 UTC [3983219] LOCATION:  PreprocessClusterStmt, cluster.c:85
2023-11-25 13:01:28.027 UTC [3983271] ERROR:  42501: permission denied for table events
2023-11-25 13:01:28.027 UTC [3983271] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:01:28.027 UTC [3983271] STATEMENT:  SELECT * FROM sec_invoker_view ORDER BY event_id;
2023-11-25 13:01:28.069 UTC [3983289] ERROR:  42501: permission denied for table events
2023-11-25 13:01:28.069 UTC [3983289] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:01:28.069 UTC [3983289] STATEMENT:  SELECT * FROM sec_definer_view ORDER BY event_id;
2023-11-25 13:01:28.082 UTC [3983289] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 13:01:28.082 UTC [3983289] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 13:01:28.082 UTC [3983289] STATEMENT:  UPDATE sec_invoker_view SET event_id = 5;
2023-11-25 13:01:28.100 UTC [3983289] ERROR:  XX000: cannot create foreign key constraint since Citus does not support ON DELETE / UPDATE SET DEFAULT actions on the columns that default to sequences
2023-11-25 13:01:28.100 UTC [3983289] LOCATION:  ErrorIfUnsupportedForeignConstraintExists, foreign_constraint.c:274
2023-11-25 13:01:28.100 UTC [3983289] STATEMENT:  SELECT create_reference_table('set_on_default_test_referencing');
2023-11-25 13:01:28.362 UTC [3983289] ERROR:  XX000: cannot create foreign key constraint since Citus does not support ON DELETE / UPDATE SET DEFAULT actions on the columns that default to sequences
2023-11-25 13:01:28.362 UTC [3983289] LOCATION:  ErrorIfUnsupportedForeignConstraintExists, foreign_constraint.c:274
2023-11-25 13:01:28.362 UTC [3983289] STATEMENT:  CREATE TABLE set_on_default_test_referencing(
	    col_1 int, col_2 int, col_3 serial, col_4 int,
	    FOREIGN KEY(col_1, col_3)
	    REFERENCES set_on_default_test_referenced(col_1, col_3)
	    ON DELETE SET DEFAULT (col_3)
	);
2023-11-25 13:01:28.388 UTC [3983363] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown at character 77
2023-11-25 13:01:28.388 UTC [3983363] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:28.388 UTC [3983363] LOCATION:  op_error, parse_oper.c:647
2023-11-25 13:01:28.388 UTC [3983363] STATEMENT:  DECLARE c1 CURSOR FOR
	SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 13:01:28.388 UTC [3983289] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown
2023-11-25 13:01:28.388 UTC [3983289] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:28.388 UTC [3983289] CONTEXT:  remote SQL command: SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 13:01:28.388 UTC [3983289] LOCATION:  pgfdw_report_error, connection.c:895
2023-11-25 13:01:28.388 UTC [3983289] STATEMENT:  SELECT * FROM foreign_table WHERE c1 LIKE 'foo' LIMIT 1;
2023-11-25 13:01:28.389 UTC [3983363] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown at character 77
2023-11-25 13:01:28.389 UTC [3983363] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:28.389 UTC [3983363] LOCATION:  op_error, parse_oper.c:647
2023-11-25 13:01:28.389 UTC [3983363] STATEMENT:  DECLARE c1 CURSOR FOR
	SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 13:01:28.389 UTC [3983289] ERROR:  42883: operator does not exist: pg15.user_enum ~~ unknown
2023-11-25 13:01:28.389 UTC [3983289] HINT:  No operator matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:28.389 UTC [3983289] CONTEXT:  remote SQL command: SELECT c0, c1 FROM pg15.foreign_table_test WHERE ((c1 ~~ 'foo')) LIMIT 1::bigint
2023-11-25 13:01:28.389 UTC [3983289] LOCATION:  pgfdw_report_error, connection.c:895
2023-11-25 13:01:28.389 UTC [3983289] STATEMENT:  SELECT * FROM foreign_table WHERE c1::text LIKE 'foo' LIMIT 1;
2023-11-25 13:01:28.425 UTC [3976582] LOG:  00000: checkpoint starting: immediate force wait
2023-11-25 13:01:28.425 UTC [3976582] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 13:01:28.466 UTC [3976582] LOG:  00000: checkpoint complete: wrote 2887 buffers (17.6%); 0 WAL file(s) added, 0 removed, 3 recycled; write=0.011 s, sync=0.001 s, total=0.042 s; sync files=0, longest=0.000 s, average=0.000 s; distance=54941 kB, estimate=54941 kB
2023-11-25 13:01:28.466 UTC [3976582] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 13:01:28.839 UTC [3983392] ERROR:  22P02: invalid input syntax for type jsonpath: ""
2023-11-25 13:01:28.839 UTC [3983392] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:28.839 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.839 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '';
2023-11-25 13:01:28.846 UTC [3983392] ERROR:  22P02: invalid input syntax for type jsonpath: ""
2023-11-25 13:01:28.846 UTC [3983392] LOCATION:  jsonPathFromCstring, jsonpath.c:180
2023-11-25 13:01:28.846 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.847 UTC [3983392] ERROR:  42601: LAST is allowed only in array subscripts
2023-11-25 13:01:28.847 UTC [3983392] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:28.847 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.847 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = 'last';
2023-11-25 13:01:28.856 UTC [3983392] ERROR:  42601: LAST is allowed only in array subscripts
2023-11-25 13:01:28.856 UTC [3983392] LOCATION:  flattenJsonPathParseItem, jsonpath.c:366
2023-11-25 13:01:28.856 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = 'last' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.857 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "1.t" of jsonpath input
2023-11-25 13:01:28.857 UTC [3983392] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:28.857 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.857 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '1.type()';
2023-11-25 13:01:28.865 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "1.t" of jsonpath input
2023-11-25 13:01:28.865 UTC [3983392] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 13:01:28.865 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '1.type()' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.866 UTC [3983392] ERROR:  2201B: invalid regular expression: parentheses () not balanced
2023-11-25 13:01:28.866 UTC [3983392] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:28.866 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.866 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "(invalid pattern")';
2023-11-25 13:01:28.873 UTC [3983392] ERROR:  2201B: invalid regular expression: parentheses () not balanced
2023-11-25 13:01:28.873 UTC [3983392] LOCATION:  RE_compile_and_cache, regexp.c:207
2023-11-25 13:01:28.873 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "(invalid pattern")' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.874 UTC [3983392] ERROR:  0A000: XQuery "x" flag (expanded regular expressions) is not implemented
2023-11-25 13:01:28.874 UTC [3983392] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:28.874 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.874 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "pattern" flag "xsms")';
2023-11-25 13:01:28.883 UTC [3983392] ERROR:  0A000: XQuery "x" flag (expanded regular expressions) is not implemented
2023-11-25 13:01:28.883 UTC [3983392] LOCATION:  jspConvertRegexFlags, jsonpath_gram.y:582
2023-11-25 13:01:28.883 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '$ ? (@ like_regex "pattern" flag "xsms")' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.884 UTC [3983392] ERROR:  42601: @ is not allowed in root expressions
2023-11-25 13:01:28.884 UTC [3983392] CONTEXT:  while executing command on localhost:57638
2023-11-25 13:01:28.884 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.884 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '@ + 1';
2023-11-25 13:01:28.894 UTC [3983392] ERROR:  42601: @ is not allowed in root expressions
2023-11-25 13:01:28.894 UTC [3983392] LOCATION:  flattenJsonPathParseItem, jsonpath.c:360
2023-11-25 13:01:28.894 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '@ + 1' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.895 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "00" of jsonpath input
2023-11-25 13:01:28.895 UTC [3983392] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:28.895 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.895 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '00';
2023-11-25 13:01:28.904 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "00" of jsonpath input
2023-11-25 13:01:28.904 UTC [3983392] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 13:01:28.904 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '00' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.905 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "1.e" of jsonpath input
2023-11-25 13:01:28.905 UTC [3983392] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:28.905 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.905 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '1.e';
2023-11-25 13:01:28.912 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "1.e" of jsonpath input
2023-11-25 13:01:28.912 UTC [3983392] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 13:01:28.912 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '1.e' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:28.913 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "1.2e3a" of jsonpath input
2023-11-25 13:01:28.913 UTC [3983392] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:28.913 UTC [3983392] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:28.913 UTC [3983392] STATEMENT:  SELECT sample, sample::jsonpath FROM jsonpath_test WHERE sample = '1.2e3a';
2023-11-25 13:01:28.920 UTC [3983392] ERROR:  42601: trailing junk after numeric literal at or near "1.2e3a" of jsonpath input
2023-11-25 13:01:28.920 UTC [3983392] LOCATION:  jsonpath_yyerror, jsonpath_scan.l:286
2023-11-25 13:01:28.920 UTC [3983392] STATEMENT:  WITH samples as (SELECT id, sample FROM jsonpath_test WHERE sample = '1.2e3a' OFFSET 0)
	SELECT sample, sample::jsonpath FROM samples;
2023-11-25 13:01:29.743 UTC [3983391] ERROR:  08006: connection to the remote node localhost:57637 failed with the following error: connection not open
2023-11-25 13:01:29.743 UTC [3983391] LOCATION:  ReportConnectionError, remote_commands.c:266
2023-11-25 13:01:29.743 UTC [3983391] STATEMENT:  SELECT count(*) FROM socket_test_table;
2023-11-25 13:01:30.946 UTC [3983748] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:30.946 UTC [3983748] LOCATION:  fake_tuple_insert, fake_am.c:204
2023-11-25 13:01:30.956 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.956 UTC [3983748] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_hash_dist LIMIT 1"
2023-11-25 13:01:30.956 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.965 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.965 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.965 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.965 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.967 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.967 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.967 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.967 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.967 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.967 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.967 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.967 UTC [3983748] DETAIL:  from localhost:57638
2023-11-25 13:01:30.967 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.967 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.967 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.967 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.967 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.967 UTC [3983748] DETAIL:  from localhost:57638
2023-11-25 13:01:30.967 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.970 UTC [3983748] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:30.970 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.970 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.970 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.970 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.970 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.970 UTC [3983748] ERROR:  XX000: fake_tuple_delete not implemented
2023-11-25 13:01:30.970 UTC [3983748] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:30.970 UTC [3983748] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:30.970 UTC [3983748] STATEMENT:  delete from test_hash_dist where id=1;
2023-11-25 13:01:30.972 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.972 UTC [3983748] DETAIL:  from localhost:57638
2023-11-25 13:01:30.972 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.973 UTC [3983748] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:30.973 UTC [3983748] LOCATION:  fake_tuple_insert, fake_am.c:204
2023-11-25 13:01:30.973 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.973 UTC [3983748] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_ref LIMIT 1"
2023-11-25 13:01:30.973 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.980 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.980 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.980 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.980 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.981 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.981 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.981 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.981 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.981 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.981 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.982 UTC [3983748] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:30.982 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.982 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.982 UTC [3983748] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:30.982 UTC [3983748] DETAIL:  from localhost:57638
2023-11-25 13:01:30.982 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.983 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.983 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.983 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.983 UTC [3983748] ERROR:  XX000: fake_tuple_delete not implemented
2023-11-25 13:01:30.983 UTC [3983748] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:30.983 UTC [3983748] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:30.983 UTC [3983748] STATEMENT:  delete from test_ref;
2023-11-25 13:01:30.985 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.985 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.985 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.985 UTC [3983748] ERROR:  XX000: fake_fetch_row_version not implemented
2023-11-25 13:01:30.985 UTC [3983748] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:30.985 UTC [3983748] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:30.985 UTC [3983748] STATEMENT:  update test_ref set a=2;
2023-11-25 13:01:30.986 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.986 UTC [3983748] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_range_dist LIMIT 1"
2023-11-25 13:01:30.986 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.986 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.986 UTC [3983748] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_range_dist LIMIT 1"
2023-11-25 13:01:30.986 UTC [3983748] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:30.993 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.993 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.993 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.993 UTC [3983748] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:30.993 UTC [3983748] DETAIL:  from localhost:57638
2023-11-25 13:01:30.993 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:30.993 UTC [3983748] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:30.993 UTC [3983748] DETAIL:  from localhost:57637
2023-11-25 13:01:30.993 UTC [3983748] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.040 UTC [3983775] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:31.040 UTC [3983775] LOCATION:  fake_tuple_insert, fake_am.c:204
2023-11-25 13:01:31.061 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.061 UTC [3983775] CONTEXT:  SQL statement "SELECT TRUE FROM test_tableam.test_partitioned_p2 LIMIT 1"
2023-11-25 13:01:31.061 UTC [3983775] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:31.066 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.066 UTC [3983775] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:31.067 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.067 UTC [3983775] LOCATION:  fake_scan_getnextslot, fake_am.c:88
2023-11-25 13:01:31.070 UTC [3983775] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:31.070 UTC [3983775] DETAIL:  from localhost:57637
2023-11-25 13:01:31.070 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.070 UTC [3983775] WARNING:  01000: fake_tuple_insert
2023-11-25 13:01:31.070 UTC [3983775] DETAIL:  from localhost:57638
2023-11-25 13:01:31.070 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.072 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.072 UTC [3983775] DETAIL:  from localhost:57638
2023-11-25 13:01:31.072 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.072 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.072 UTC [3983775] DETAIL:  from localhost:57638
2023-11-25 13:01:31.072 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.072 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.072 UTC [3983775] DETAIL:  from localhost:57637
2023-11-25 13:01:31.072 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.072 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.072 UTC [3983775] DETAIL:  from localhost:57638
2023-11-25 13:01:31.072 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.072 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.072 UTC [3983775] DETAIL:  from localhost:57638
2023-11-25 13:01:31.072 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.072 UTC [3983775] WARNING:  01000: fake_scan_getnextslot
2023-11-25 13:01:31.072 UTC [3983775] DETAIL:  from localhost:57637
2023-11-25 13:01:31.072 UTC [3983775] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:174
2023-11-25 13:01:31.088 UTC [3983775] ERROR:  0A000: specifying a table access method is not supported on a partitioned table
2023-11-25 13:01:31.088 UTC [3983775] LOCATION:  DefineRelation, tablecmds.c:947
2023-11-25 13:01:31.088 UTC [3983775] STATEMENT:  CREATE TABLE test_partitioned(id int, p int, val int)
	PARTITION BY RANGE (p) USING fake_am;
2023-11-25 13:01:31.155 UTC [3983810] ERROR:  XX000: the backend has already been assigned a transaction id
2023-11-25 13:01:31.155 UTC [3983810] LOCATION:  assign_distributed_transaction_id, backend_data.c:168
2023-11-25 13:01:31.155 UTC [3983810] STATEMENT:  SELECT assign_distributed_transaction_id(51, 51, '2017-01-01 00:00:00+0');
2023-11-25 13:01:31.155 UTC [3983810] ERROR:  22012: division by zero
2023-11-25 13:01:31.155 UTC [3983810] LOCATION:  int4div, int.c:840
2023-11-25 13:01:31.155 UTC [3983810] STATEMENT:  SELECT 5 / 0;
2023-11-25 13:01:31.162 UTC [3983811] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 2 kB)
2023-11-25 13:01:31.162 UTC [3983811] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 13:01:31.162 UTC [3983811] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 13:01:31.162 UTC [3983811] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 13:01:31.162 UTC [3983811] STATEMENT:  WITH cte AS MATERIALIZED
	(
		SELECT * FROM users_table
	),
	cte2 AS MATERIALIZED (
		SELECT * FROM events_table
	)
	SELECT cte.user_id, cte.value_2 FROM cte,cte2 ORDER BY 1,2 LIMIT 10;
2023-11-25 13:01:31.168 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.168 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.237 UTC [3983809] ERROR:  CIINF: Query could not find the intermediate result file "squares", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.237 UTC [3983809] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:148
2023-11-25 13:01:31.237 UTC [3983809] STATEMENT:  SELECT x, x2
	FROM interesting_squares JOIN (SELECT * FROM read_intermediate_result('squares', 'binary') AS res (x text, x2 int)) squares ON (x = interested_in)
	WHERE user_id = 'jon' OR true
	ORDER BY x;
2023-11-25 13:01:31.238 UTC [3983809] ERROR:  CIINF: Query could not find the intermediate result file "squares", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.238 UTC [3983809] LOCATION:  DefaultCitusNoticeReceiver, worker_log_messages.c:148
2023-11-25 13:01:31.238 UTC [3983809] STATEMENT:  SELECT x, x2
	FROM interesting_squares JOIN (SELECT * FROM read_intermediate_result('squares', 'binary') AS res (x text, x2 int)) squares ON (x = interested_in)
	WHERE user_id = 'jon'
	ORDER BY x;
2023-11-25 13:01:31.239 UTC [3983809] ERROR:  22021: invalid byte sequence for encoding "UTF8": 0x00
2023-11-25 13:01:31.239 UTC [3983809] LOCATION:  report_invalid_encoding, mbutils.c:1665
2023-11-25 13:01:31.239 UTC [3983809] STATEMENT:  SELECT * FROM read_intermediate_result('squares', 'binary') AS res (x text, x2 int);
2023-11-25 13:01:31.240 UTC [3983809] ERROR:  22P02: invalid input syntax for type integer: "PGCOPY"
2023-11-25 13:01:31.240 UTC [3983809] LOCATION:  pg_strtoint32, numutils.c:232
2023-11-25 13:01:31.240 UTC [3983809] STATEMENT:  SELECT * FROM read_intermediate_result('squares', 'csv') AS res (x int, x2 int);
2023-11-25 13:01:31.249 UTC [3983809] ERROR:  22P04: COPY file signature not recognized
2023-11-25 13:01:31.249 UTC [3983809] LOCATION:  ReceiveCopyBinaryHeader, copyfromparse.c:198
2023-11-25 13:01:31.249 UTC [3983809] STATEMENT:  SELECT * FROM read_intermediate_result('stored_squares', 'binary') AS res (s intermediate_results.square_type);
BEGIN
COPY 0
SELECT 5
COMMIT
2023-11-25 13:01:31.283 UTC [3983809] ERROR:  XX000: cannot execute utility commands
2023-11-25 13:01:31.283 UTC [3983809] LOCATION:  ExecuteQueryIntoDestReceiver, multi_executor.c:664
2023-11-25 13:01:31.283 UTC [3983809] STATEMENT:  select broadcast_intermediate_result('a', 'create table foo(int serial)');
2023-11-25 13:01:31.284 UTC [3983809] ERROR:  XX000: cannot execute utility commands
2023-11-25 13:01:31.284 UTC [3983809] LOCATION:  ExecuteQueryIntoDestReceiver, multi_executor.c:664
2023-11-25 13:01:31.284 UTC [3983809] STATEMENT:  select broadcast_intermediate_result('a', 'prepare foo as select 1');
2023-11-25 13:01:31.285 UTC [3983809] ERROR:  XX000: cannot execute utility commands
2023-11-25 13:01:31.285 UTC [3983809] LOCATION:  ExecuteQueryIntoDestReceiver, multi_executor.c:664
2023-11-25 13:01:31.285 UTC [3983809] STATEMENT:  select create_intermediate_result('a', 'create table foo(int serial)');
2023-11-25 13:01:31.288 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.288 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.288 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "notexistingfile", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.288 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.289 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "notexistingfile", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.289 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.289 UTC [3983809] ERROR:  22004: null array element not allowed in this context
2023-11-25 13:01:31.289 UTC [3983809] LOCATION:  deconstruct_array, arrayfuncs.c:3525
2023-11-25 13:01:31.289 UTC [3983809] STATEMENT:  SELECT * FROM read_intermediate_results(ARRAY['squares_1', NULL], 'binary') AS res (x int, x2 int);
2023-11-25 13:01:31.290 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.290 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.310 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.310 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.310 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_2", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.310 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.311 UTC [3983809] ERROR:  XX000: cannot connect to localhost:57635 to fetch intermediate results
2023-11-25 13:01:31.311 UTC [3983809] LOCATION:  fetch_intermediate_results, intermediate_results.c:929
2023-11-25 13:01:31.311 UTC [3983809] STATEMENT:  SELECT * FROM fetch_intermediate_results(ARRAY['squares_1', 'squares_2']::text[], 'localhost', 57635);
2023-11-25 13:01:31.315 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.315 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.315 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_2", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.315 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.320 UTC [3983811] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 2 kB)
2023-11-25 13:01:31.320 UTC [3983811] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 13:01:31.320 UTC [3983811] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 13:01:31.320 UTC [3983811] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 13:01:31.320 UTC [3983811] STATEMENT:  WITH cte AS MATERIALIZED (SELECT * FROM users_table WHERE user_id IN (1,2,3,4,5))
	SELECT * FROM cte ORDER BY 1,2,3,4,5 LIMIT 10;
2023-11-25 13:01:31.322 UTC [3983811] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 0 kB)
2023-11-25 13:01:31.322 UTC [3983811] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 13:01:31.322 UTC [3983811] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 13:01:31.322 UTC [3983811] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 13:01:31.322 UTC [3983811] STATEMENT:  WITH cte AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=1),
	cte2 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=2),
	cte3 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=3),
	cte4 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=4),
	cte5 AS MATERIALIZED (SELECT * FROM users_table WHERE user_id=5)
	SELECT * FROM (
	(SELECT * FROM cte)
	UNION
	(SELECT * FROM cte2)
	UNION
	(SELECT * FROM cte3)
	UNION
	(SELECT * FROM cte4)
	UNION
	(SELECT * FROM cte5)
	)a ORDER BY 1,2,3,4,5 LIMIT 10;
2023-11-25 13:01:31.328 UTC [3983809] ERROR:  22004: worker array object cannot contain null values
2023-11-25 13:01:31.328 UTC [3983809] LOCATION:  DeconstructArrayObject, array_type.c:43
2023-11-25 13:01:31.328 UTC [3983809] STATEMENT:  SELECT * FROM fetch_intermediate_results(ARRAY[NULL, 'squares_1', 'squares_2']::text[], 'localhost', 57637);
2023-11-25 13:01:31.330 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_1", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.330 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.330 UTC [3983809] WARNING:  CIINF: Query could not find the intermediate result file "squares_2", it was mostly likely deleted due to an error in a parallel process within the same distributed transaction
2023-11-25 13:01:31.330 UTC [3983809] LOCATION:  ReadIntermediateResultsIntoFuncOutput, intermediate_results.c:869
2023-11-25 13:01:31.338 UTC [3983811] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 3 kB)
2023-11-25 13:01:31.338 UTC [3983811] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 13:01:31.338 UTC [3983811] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 13:01:31.338 UTC [3983811] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 13:01:31.338 UTC [3983811] STATEMENT:  WITH cte AS MATERIALIZED (
		WITH cte2 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id IN (3,4,5,6)
		),
		cte3 AS MATERIALIZED(
			SELECT * FROM events_table WHERE event_type = 1
		)
		SELECT * FROM cte2, cte3 WHERE cte2.value_1 IN (SELECT value_2 FROM cte3)
	)
	SELECT count(*) FROM cte;
2023-11-25 13:01:31.342 UTC [3983811] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 2 kB)
2023-11-25 13:01:31.342 UTC [3983811] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 13:01:31.342 UTC [3983811] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 13:01:31.342 UTC [3983811] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 13:01:31.342 UTC [3983811] STATEMENT:  WITH cte AS MATERIALIZED (
		WITH cte2 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id IN (1, 2)
		),
		cte3 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id = 3
		)
		SELECT * FROM cte2 UNION (SELECT * FROM cte3)
	),
	cte4 AS MATERIALIZED (
		SELECT * FROM events_table
	)
	SELECT * FROM cte UNION ALL
	SELECT * FROM cte4 ORDER BY 1,2,3,4,5 LIMIT 5;
2023-11-25 13:01:31.344 UTC [3983811] ERROR:  XX000: the intermediate result size exceeds citus.max_intermediate_result_size (currently 1 kB)
2023-11-25 13:01:31.344 UTC [3983811] DETAIL:  Citus restricts the size of intermediate results of complex subqueries and CTEs to avoid accidentally pulling large result sets into once place.
2023-11-25 13:01:31.344 UTC [3983811] HINT:  To run the current query, set citus.max_intermediate_result_size to a higher value or -1 to disable.
2023-11-25 13:01:31.344 UTC [3983811] LOCATION:  EnsureIntermediateSizeLimitNotExceeded, tuple_destination.c:164
2023-11-25 13:01:31.344 UTC [3983811] STATEMENT:  WITH cte AS MATERIALIZED (
		WITH cte2 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id IN (1, 2)
		),
		cte3 AS MATERIALIZED (
			SELECT * FROM users_table WHERE user_id = 3
		)
		SELECT * FROM cte2 UNION (SELECT * FROM cte3)
	),
	cte4 AS MATERIALIZED (
		SELECT * FROM events_table
	)
	SELECT * FROM cte UNION ALL
	SELECT * FROM cte4 ORDER BY 1,2,3,4,5 LIMIT 5;
2023-11-25 13:01:31.984 UTC [3984107] ERROR:  XX000: query must be distributed and shouldn't require any merging on the coordinator.
2023-11-25 13:01:31.984 UTC [3984107] LOCATION:  partition_task_list_results, distributed_intermediate_results.c:60
2023-11-25 13:01:31.984 UTC [3984107] STATEMENT:  SELECT partition_task_list_results('test', $$ SELECT avg(a) FROM source_table $$, 'target_table');
2023-11-25 13:01:31.985 UTC [3984107] ERROR:  XX000: query must be distributed and shouldn't require any merging on the coordinator.
2023-11-25 13:01:31.985 UTC [3984107] LOCATION:  partition_task_list_results, distributed_intermediate_results.c:60
2023-11-25 13:01:31.985 UTC [3984107] STATEMENT:  SELECT partition_task_list_results('test', $$ SELECT * FROM generate_series(1, 2) $$, 'target_table');
2023-11-25 13:01:32.103 UTC [3984109] ERROR:  25001: cannot perform query with placements that were modified over multiple connections
2023-11-25 13:01:32.103 UTC [3984109] LOCATION:  FindPlacementListConnection, placement_connection.c:613
2023-11-25 13:01:32.103 UTC [3984109] STATEMENT:  SELECT COUNT(*) FROM test_table JOIN ref_test_table USING (id);
2023-11-25 13:01:32.493 UTC [3984249] ERROR:  0A000: repartitioning results of a tasklist is only supported when target relation is hash or range partitioned.
2023-11-25 13:01:32.493 UTC [3984249] LOCATION:  PartitionTasklistResults, distributed_intermediate_results.c:152
2023-11-25 13:01:32.493 UTC [3984249] STATEMENT:  CREATE TABLE distributed_result_info AS
	  SELECT * FROM redistribute_task_list_results('test', $$ SELECT * FROM source_table $$, 'target_table_reference');
2023-11-25 13:01:32.495 UTC [3984249] ERROR:  0A000: repartitioning results of a tasklist is only supported when target relation is hash or range partitioned.
2023-11-25 13:01:32.495 UTC [3984249] LOCATION:  PartitionTasklistResults, distributed_intermediate_results.c:152
2023-11-25 13:01:32.495 UTC [3984249] STATEMENT:  CREATE TABLE distributed_result_info AS
	  SELECT * FROM redistribute_task_list_results('test', $$ SELECT * FROM source_table $$, 'target_table_append');
2023-11-25 13:01:32.525 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:01:32.525 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:01:32.526 UTC [3976581] LOG:  00000: parameter "deadlock_timeout" changed to "250ms"
2023-11-25 13:01:32.526 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:01:32.697 UTC [3984106] ERROR:  XX000: cannot EXPLAIN ANALYZE multiple queries
2023-11-25 13:01:32.697 UTC [3984106] LOCATION:  worker_save_query_explain_analyze, multi_explain.c:1048
2023-11-25 13:01:32.697 UTC [3984106] STATEMENT:  SELECT * FROM worker_save_query_explain_analyze('SELECT 1; SELECT 2', '{"costs": false, "timing": false, "summary": false}'::jsonb) as (a int);
2023-11-25 13:01:32.697 UTC [3984106] ERROR:  42703: column "x" does not exist at character 8
2023-11-25 13:01:32.697 UTC [3984106] LOCATION:  errorMissingColumn, parse_relation.c:3656
2023-11-25 13:01:32.697 UTC [3984106] STATEMENT:  SELECT * FROM worker_save_query_explain_analyze('SELECT x', '{"costs": false, "timing": false, "summary": false}'::jsonb) as (a int);
2023-11-25 13:01:32.697 UTC [3984106] ERROR:  XX000: Invalid explain analyze format: "invlaid_format"
2023-11-25 13:01:32.697 UTC [3984106] LOCATION:  ExtractFieldExplainFormat, multi_explain.c:1163
2023-11-25 13:01:32.697 UTC [3984106] STATEMENT:  SELECT * FROM worker_save_query_explain_analyze('SELECT 1', '{"format": "invlaid_format"}') as (a int);
2023-11-25 13:01:33.023 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.023 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.023 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.049 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.049 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.049 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.074 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.074 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.074 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.099 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.099 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.099 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.125 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.125 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.125 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.150 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.150 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.150 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.176 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.176 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.176 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.201 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.201 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.201 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.226 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.226 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.226 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.252 UTC [3984109] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:33.252 UTC [3984109] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:33.252 UTC [3984109] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM test_table;
2023-11-25 13:01:33.427 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:01:33.427 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:01:33.428 UTC [3976581] LOG:  00000: parameter "deadlock_timeout" removed from configuration file, reset to default
2023-11-25 13:01:33.428 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 13:01:33.795 UTC [3984108] ERROR:  XX000: worker_partition_query_result can only be used in a transaction block
2023-11-25 13:01:33.795 UTC [3984108] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:151
2023-11-25 13:01:33.795 UTC [3984108] STATEMENT:  SELECT * FROM worker_partition_query_result('squares_range',
	                                            'SELECT i, i * i FROM generate_series(1, 10) i',
	                                            1, 'range', '{0}'::text[], '{20}'::text[], true);
2023-11-25 13:01:33.795 UTC [3984108] ERROR:  42601: syntax error at or near "SELECxT" at character 1
2023-11-25 13:01:33.795 UTC [3984108] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:01:33.795 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECxT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.796 UTC [3984108] ERROR:  42602: result key "squares_range/a/" contains invalid character
2023-11-25 13:01:33.796 UTC [3984108] HINT:  Result keys may only contain letters, numbers, underscores and hyphens.
2023-11-25 13:01:33.796 UTC [3984108] LOCATION:  QueryResultFileName, intermediate_results.c:652
2023-11-25 13:01:33.796 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range/a/',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.796 UTC [3984108] ERROR:  22023: number of partitions cannot be 0
2023-11-25 13:01:33.796 UTC [3984108] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:176
2023-11-25 13:01:33.796 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range', ARRAY[]::text[], ARRAY[]::text[], true);
2023-11-25 13:01:33.796 UTC [3984108] ERROR:  22023: only hash and range partitiong schemes are supported
2023-11-25 13:01:33.796 UTC [3984108] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:135
2023-11-25 13:01:33.796 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'append',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.797 UTC [3984108] ERROR:  22023: query must generate a set of rows
2023-11-25 13:01:33.797 UTC [3984108] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:187
2023-11-25 13:01:33.797 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'INSERT INTO t VALUES (1), (2)',
	                                     1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.797 UTC [3984108] ERROR:  22023: partition column index must be between 0 and 1
2023-11-25 13:01:33.797 UTC [3984108] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:193
2023-11-25 13:01:33.797 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     -1, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.797 UTC [3984108] ERROR:  22023: partition column index must be between 0 and 1
2023-11-25 13:01:33.797 UTC [3984108] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:193
2023-11-25 13:01:33.797 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     2, 'range',
	                                     '{0,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.798 UTC [3984108] ERROR:  22023: min values and max values must have the same number of elements
2023-11-25 13:01:33.798 UTC [3984108] LOCATION:  worker_partition_query_result, partitioned_intermediate_results.c:167
2023-11-25 13:01:33.798 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_range',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'range',
	                                     '{0,21,41,61,101}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.798 UTC [3984108] ERROR:  XX000: hash partitioned table has uninitialized shards
2023-11-25 13:01:33.798 UTC [3984108] LOCATION:  ErrorIfInconsistentShardIntervals, metadata_cache.c:1976
2023-11-25 13:01:33.798 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_hash',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i',
	                                     1, 'hash',
	                                     '{NULL,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:33.798 UTC [3984108] ERROR:  XX000: cannot execute multiple utility events
2023-11-25 13:01:33.798 UTC [3984108] LOCATION:  ParseTreeRawStmt, worker_data_fetch_protocol.c:319
2023-11-25 13:01:33.798 UTC [3984108] STATEMENT:  SELECT worker_partition_query_result('squares_hash',
	                                     'SELECT i, i * i FROM generate_series(1, 10) i; SELECT 4, 16;',
	                                     1, 'hash',
	                                     '{NULL,21,41,61}'::text[],
	                                     '{20,40,60,100}'::text[],
	                                     true);
2023-11-25 13:01:34.323 UTC [3984108] ERROR:  55000: could not find shard for partition column value
2023-11-25 13:01:34.323 UTC [3984108] CONTEXT:  SQL statement "INSERT INTO t SELECT x, x * x * x FROM generate_series(1, 105) x"
	PL/pgSQL function test_partition_query_results(regclass,text,boolean) line 35 at EXECUTE
2023-11-25 13:01:34.323 UTC [3984108] LOCATION:  ShardIdForTuple, multi_copy.c:2614
2023-11-25 13:01:34.323 UTC [3984108] STATEMENT:  CALL test_partition_query_results('t', 'SELECT x, x * x * x FROM generate_series(1, 105) x');
2023-11-25 13:01:34.900 UTC [3984773] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:34.900 UTC [3984773] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:34.900 UTC [3984773] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 13:01:34.900 UTC [3984773] STATEMENT:  SELECT count(*) FROM events_reference_table e1 CROSS JOIN events_table e2 CROSS JOIN users_table u;
2023-11-25 13:01:34.901 UTC [3984773] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:34.901 UTC [3984773] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:34.901 UTC [3984773] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 13:01:34.901 UTC [3984773] STATEMENT:  SELECT count(*) FROM events_reference_table e1, events_table e2, users_table u;
2023-11-25 13:01:34.960 UTC [3984772] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:34.960 UTC [3984772] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:34.960 UTC [3984772] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 13:01:34.960 UTC [3984772] STATEMENT:  SELECT
		avg(unit_price)
	FROM
		(SELECT
			l_orderkey,
			avg(o_totalprice / l_quantity) AS unit_price
		FROM
			lineitem_subquery,
			orders_subquery
		GROUP BY
			l_orderkey) AS unit_prices;
2023-11-25 13:01:35.117 UTC [3984776] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:35.117 UTC [3984776] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:35.117 UTC [3984776] STATEMENT:  SELECT count(*) FROM lineitem, orders WHERE l_orderkey + 1 = o_orderkey;
2023-11-25 13:01:35.150 UTC [3984773] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.150 UTC [3984773] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.150 UTC [3984773] STATEMENT:  SELECT count(*) FROM users_table u1 CROSS JOIN users_ref_test_table ref2 LEFT JOIN users_table u2 ON (ref2.id = u2.user_id);
2023-11-25 13:01:35.150 UTC [3984773] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.150 UTC [3984773] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.150 UTC [3984773] STATEMENT:  SELECT count(*) FROM users_table u1 CROSS JOIN users_ref_test_table ref2 FULL JOIN users_table u2 ON (ref2.id = u2.user_id);
2023-11-25 13:01:35.151 UTC [3984773] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.151 UTC [3984773] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.151 UTC [3984773] STATEMENT:  SELECT count(*) FROM users_table u1 CROSS JOIN users_ref_test_table ref2 RIGHT JOIN users_table u2 ON (ref2.id = u2.user_id);
2023-11-25 13:01:35.162 UTC [3984777] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:35.162 UTC [3984777] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:35.162 UTC [3984777] STATEMENT:  SELECT ("final_query"."event_types") as types, count(*) AS sumOfEventType
	FROM
	  ( SELECT *, random()
	   FROM
	     ( SELECT "t"."user_id", "t"."time", unnest("t"."collected_events") AS "event_types"
	      FROM
	        ( SELECT "t1"."user_id", min("t1"."time") AS "time", array_agg(("t1"."event") ORDER BY TIME ASC, event DESC) AS collected_events
	         FROM (
	                 (SELECT
	                    *
	                  FROM
	                   (SELECT
	                      "events"."user_id", "events"."time", 0 AS event
	                    FROM
	                      events_table as  "events"
	                    WHERE
	                      event_type IN (1, 2) ) events_subquery_1)
	                 UNION
	                 (SELECT
	                    *
	                  FROM
	                    (SELECT
	                        "events"."user_id", "events"."time", 1 AS event
	                     FROM
	                        events_table as "events"
	                     WHERE
	                      event_type IN (3, 4) ) events_subquery_2)
	               UNION
	                 (SELECT
	                    *
	                  FROM
	                    (SELECT
	                        "events"."user_id", "events"."time", 2 AS event
	                     FROM
	                        events_table as  "events",  users_table as "users"
	                     WHERE
	                      event_type IN (5, 6)  AND users.user_id != events.user_id ) events_subquery_3)
	                UNION
	                  (SELECT
	                      *
	                   FROM
	                    (SELECT
	                        "events"."user_id", "events"."time", 3 AS event
	                     FROM
	                      events_table as "events"
	                     WHERE
	                      event_type IN (4, 5)) events_subquery_4)) t1
	         GROUP BY "t1"."user_id") AS t) "q"
	INNER JOIN
	     (SELECT
	        "users"."user_id"
	      FROM
	        users_table as "users"
	      WHERE
	        value_1 > 0 and value_1 < 4) AS t
	    ON (t.user_id = q.user_id)) as final_query
	GROUP BY
	  types
	ORDER BY
	  types;
2023-11-25 13:01:35.272 UTC [3984772] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.272 UTC [3984772] DETAIL:  Limit in subquery without limit in the outermost query is unsupported
2023-11-25 13:01:35.272 UTC [3984772] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 13:01:35.272 UTC [3984772] STATEMENT:  SELECT
		avg(o_totalprice/l_quantity)
	FROM
			(SELECT
				l_orderkey,
				l_quantity
			FROM
				lineitem_subquery
			ORDER BY
				l_orderkey, l_quantity
			LIMIT 10
			) lineitem_quantities
		JOIN LATERAL
			(SELECT
				o_totalprice
			FROM
				orders_subquery
			WHERE
				lineitem_quantities.l_orderkey = o_orderkey) orders_price ON true;
2023-11-25 13:01:35.317 UTC [3984772] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:35.317 UTC [3984772] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:35.317 UTC [3984772] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey::int8 = o_orderkey::int4)
	WHERE
		(o_orderkey < l_quantity + 3)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 13:01:35.319 UTC [3984772] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:35.319 UTC [3984772] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:35.319 UTC [3984772] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey::int4 = o_orderkey::int8)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 13:01:35.329 UTC [3984774] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.329 UTC [3984774] DETAIL:  Distinct on columns without partition column is currently unsupported
2023-11-25 13:01:35.329 UTC [3984774] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:35.329 UTC [3984774] STATEMENT:  SELECT a.user_id, avg(b.value_2) as subquery_avg
	FROM
		(SELECT
	      user_id
	   FROM
	      users_table
		 WHERE
	      (value_1 > 2)
		 GROUP BY
	      user_id
		 HAVING
	      count(distinct value_1) > 2
		) as a
		LEFT JOIN
		(SELECT
	      DISTINCT ON (value_2) value_2 , user_id, value_3
		 FROM
	      users_table
		 WHERE
	      (value_1 > 3)
		 ORDER BY
	      1,2,3
		) AS b
		USING (user_id)
	GROUP BY user_id;
2023-11-25 13:01:35.337 UTC [3984772] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:35.337 UTC [3984772] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:35.337 UTC [3984772] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey = o_orderkey + 1)
	WHERE
		(o_orderkey < l_quantity)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 13:01:35.337 UTC [3984772] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:35.337 UTC [3984772] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:35.337 UTC [3984772] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey = o_orderkey + 1)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 13:01:35.337 UTC [3984772] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:35.337 UTC [3984772] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:35.337 UTC [3984772] STATEMENT:  SELECT l_orderkey
	FROM
		lineitem_subquery l
	JOIN
		orders_subquery o
	ON (l_orderkey < o_orderkey)
	WHERE
		(o_orderkey < l_quantity)
	ORDER BY l_orderkey DESC
	LIMIT 10;
2023-11-25 13:01:35.349 UTC [3984777] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.349 UTC [3984777] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 13:01:35.349 UTC [3984777] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:35.349 UTC [3984777] STATEMENT:  SELECT "some_users_data".user_id, lastseen
	FROM
	     (SELECT user_id, max(time) AS lastseen
	      FROM
	        (SELECT user_id, time
	         FROM
	           (SELECT
	              user_id, time
	            FROM
	              events_table as "events"
	            WHERE
	              user_id > 1 and user_id < 4) "events_1"
	         ORDER BY
	           time DESC
	         LIMIT 1000) "recent_events_1"
	      GROUP BY
	        user_id
	      ORDER BY
	        max(TIME) DESC) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table as "users"
	      WHERE
	        "users"."value_1" = "some_recent_users"."user_id" AND
	        users.value_2 > 1 and users.value_2 < 3
	      ORDER BY 1 LIMIT 1) "some_users_data"
	     ON TRUE
	ORDER BY
	  user_id
	limit 50;
2023-11-25 13:01:35.351 UTC [3984777] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.351 UTC [3984777] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 13:01:35.351 UTC [3984777] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:35.351 UTC [3984777] STATEMENT:  SELECT "some_users_data".user_id, lastseen
	FROM
	     (SELECT 2 * user_id as user_id, max(time) AS lastseen
	      FROM
	        (SELECT user_id, time
	         FROM
	           (SELECT
	              user_id, time
	            FROM
	              events_table as "events"
	            WHERE
	              user_id > 1 and user_id < 4) "events_1"
	         ORDER BY
	           time DESC
	         LIMIT 1000) "recent_events_1"
	      GROUP BY
	        user_id
	      ORDER BY
	        max(TIME) DESC) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        users.value_2 > 1 and users.value_2 < 3
	      ORDER BY 1 LIMIT 1) "some_users_data"
	     ON TRUE
	ORDER BY
	  user_id
	limit 50;
2023-11-25 13:01:35.352 UTC [3984772] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.352 UTC [3984772] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.352 UTC [3984772] STATEMENT:  SELECT DISTINCT ON (t1.user_id) t1.user_id, t2.value_1, t2.value_2, t2.value_3
	FROM events_table t1
	LEFT JOIN users_table t2 ON t1.user_id > t2.user_id
	ORDER BY 1 DESC, 2 DESC, 3 DESC, 4 DESC
	LIMIT 5;
2023-11-25 13:01:35.372 UTC [3984777] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.372 UTC [3984777] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 13:01:35.372 UTC [3984777] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:35.372 UTC [3984777] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4  and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id != "user_where_1_join_1".user_id)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 4 and user_id = filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 13:01:35.375 UTC [3984777] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.375 UTC [3984777] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 13:01:35.375 UTC [3984777] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:35.375 UTC [3984777] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id", "users"."value_1"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 4 and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id = "user_where_1_join_1".value_1)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 4 and user_id = filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 13:01:35.377 UTC [3984777] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.377 UTC [3984777] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.377 UTC [3984777] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id", "users"."value_1"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id = "user_where_1_join_1".user_id)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 3 and user_id != filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."user_id" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 13:01:35.378 UTC [3984772] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.378 UTC [3984772] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.378 UTC [3984772] STATEMENT:  SELECT DISTINCT ON (t1.user_id) t1.user_id, t2.value_1, t2.value_2, t2.value_3
	 FROM
	 users_table t0 LEFT JOIN
	 events_table t1  ON t0.user_id = trunc(t1.user_id)
	 LEFT JOIN users_reference_table t2 ON t1.user_id = trunc(t2.user_id)
	 ORDER BY 1 DESC, 2 DESC, 3 DESC, 4 DESC
	 LIMIT 5;
2023-11-25 13:01:35.380 UTC [3984777] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.380 UTC [3984777] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 13:01:35.380 UTC [3984777] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:35.380 UTC [3984777] STATEMENT:  SELECT user_id, lastseen
	FROM
	  (SELECT
	      "some_users_data".user_id, lastseen
	   FROM
	     (SELECT
	        filter_users_1.user_id, time AS lastseen
	      FROM
	        (SELECT
	            user_where_1_1.user_id
	         FROM
	           (SELECT
	              "users"."user_id"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_1 > 2) user_where_1_1
	         INNER JOIN
	           (SELECT
	              "users"."user_id", "users"."value_1"
	            FROM
	              users_table as "users"
	            WHERE
	              user_id > 1 and user_id < 3 and value_2 > 3) user_where_1_join_1
	           ON ("user_where_1_1".user_id = "user_where_1_join_1".user_id)) filter_users_1
	      JOIN LATERAL
	        (SELECT
	            user_id, time
	         FROM
	          events_table as "events"
	         WHERE
	          user_id > 1 and user_id < 3 and user_id = filter_users_1.user_id
	         ORDER BY
	          time DESC
	         LIMIT 1) "last_events_1" ON true
	      ORDER BY time DESC
	      LIMIT 10) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table  as "users"
	      WHERE
	        "users"."value_1" = "some_recent_users"."user_id" AND
	        "users"."value_2" > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    lastseen DESC
	   LIMIT 10) "some_users"
	ORDER BY
	  user_id DESC, lastseen DESC
	LIMIT 10;
2023-11-25 13:01:35.430 UTC [3984772] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 13:01:35.430 UTC [3984772] DETAIL:  Only count(distinct) aggregate is supported in subqueries
2023-11-25 13:01:35.430 UTC [3984772] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4111
2023-11-25 13:01:35.430 UTC [3984772] STATEMENT:  SELECT
		sum(DISTINCT a)
	FROM (
		SELECT
			count(*) a
		FROM
			lineitem_subquery
		GROUP BY
		   l_orderkey
	) z;
2023-11-25 13:01:35.431 UTC [3984772] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 13:01:35.431 UTC [3984772] DETAIL:  Only count(distinct) aggregate is supported in subqueries
2023-11-25 13:01:35.431 UTC [3984772] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4111
2023-11-25 13:01:35.431 UTC [3984772] STATEMENT:  SELECT
		avg(DISTINCT a)
	FROM (
		SELECT
			count(*) a
		FROM
			lineitem_subquery
		GROUP BY
		   l_orderkey
	) z;
2023-11-25 13:01:35.457 UTC [3984774] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.457 UTC [3984774] DETAIL:  Subqueries without a FROM clause can only contain immutable functions
2023-11-25 13:01:35.457 UTC [3984774] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 13:01:35.457 UTC [3984774] STATEMENT:  SELECT count(*) as subquery_count
	FROM (
	  SELECT
	      user_id
	    FROM
	    users_table
	  WHERE
	    (value_1 = '1' OR value_1 = '3')
	  GROUP BY user_id
	  HAVING count(distinct value_1) = 2
	  ) as a
	  INNER JOIN (
	  SELECT
	    random()::int as user_id
	  ) AS b
	  ON a.user_id = b.user_id
	WHERE b.user_id IS NULL
	GROUP BY a.user_id;
2023-11-25 13:01:35.487 UTC [3984772] ERROR:  0A000: shard counts of co-located tables do not match
2023-11-25 13:01:35.487 UTC [3984772] LOCATION:  QueryPushdownSqlTaskList, multi_physical_planner.c:2210
2023-11-25 13:01:35.487 UTC [3984772] STATEMENT:  SELECT
		avg(unit_price)
	FROM
		(SELECT
			l_orderkey,
			avg(o_totalprice / l_quantity) AS unit_price
		FROM
			lineitem_subquery,
			orders_subquery
		WHERE
			l_orderkey = o_orderkey
		GROUP BY
			l_orderkey) AS unit_prices;
2023-11-25 13:01:35.498 UTC [3984777] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:35.498 UTC [3984777] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 13:01:35.498 UTC [3984777] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:35.498 UTC [3984777] STATEMENT:  SELECT *
	FROM
	  (SELECT
	      "some_users_data".user_id, value_2
	   FROM
	     (SELECT user_id, max(value_2) AS value_2
	      FROM
	        (SELECT user_id, value_2
	         FROM
	           (SELECT
	              user_id, value_2
	            FROM
	              events_table as "events"
	            WHERE
	              user_id > 1 and user_id < 3) "events_1"
	         ORDER BY
	          value_2 DESC
	         LIMIT 10000) "recent_events_1"
	      GROUP BY
	        user_id
	      ORDER BY
	        max(value_2) DESC) "some_recent_users"
	   JOIN LATERAL
	     (SELECT
	        "users".user_id
	      FROM
	        users_table as "users"
	      WHERE
	        "users"."value_2" = "some_recent_users"."user_id" AND
	        value_2 > 4
	      ORDER BY 1 LIMIT 1) "some_users_data" ON true
	   ORDER BY
	    value_2 DESC
	   LIMIT 10) "some_users"
	ORDER BY
	    value_2 DESC, user_id DESC
	LIMIT 10;
2023-11-25 13:01:35.516 UTC [3984774] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.516 UTC [3984774] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.516 UTC [3984774] STATEMENT:  SELECT user_id, array_length(events_table, 1)
	FROM (
	  SELECT user_id, array_agg(event ORDER BY time) AS events_table
	  FROM (
	    SELECT u.user_id, e.event_type::text AS event, e.time
	    FROM users_table AS u,
	         events_table AS e
	    WHERE test_join_function_2(u.user_id, e.user_id)
	  ) t
	  GROUP BY user_id
	) q
	ORDER BY 2 DESC, 1;
2023-11-25 13:01:35.520 UTC [3984772] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 13:01:35.520 UTC [3984772] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 13:01:35.520 UTC [3984772] STATEMENT:  WITH cte_1 AS (SELECT b max FROM subquery_pruning_varchar_test_table)
	SELECT a
	FROM subquery_pruning_varchar_test_table
	JOIN cte_1 ON a = max::text
	GROUP BY a HAVING a = (SELECT a)
	ORDER BY 1;
2023-11-25 13:01:35.537 UTC [3984774] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.537 UTC [3984774] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.537 UTC [3984774] STATEMENT:  SELECT
	  count(*)
	FROM
	  (SELECT
	    event_type, random()
	  FROM
	    events_table, users_table
	  WHERE
	    events_table.user_id > users_table.user_id AND
	    events_table.time = users_table.time AND
	    events_table.value_2 IN (0, 4)
	  ) as foo;
2023-11-25 13:01:35.548 UTC [3984774] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:35.548 UTC [3984774] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:35.548 UTC [3984774] STATEMENT:  SELECT
	  count(*)
	FROM
	  (SELECT
	    event_type, random()
	  FROM
	    events_table, users_table
	  WHERE
	    events_table.user_id = users_table.user_id AND
	    events_table.value_2 IN (0, 4)
	  ) as foo,
	(SELECT
	    event_type, random()
	  FROM
	    events_table, users_table
	  WHERE
	    events_table.user_id = users_table.user_id AND
	    events_table.value_2 IN (1, 5)
	  ) as bar
	WHERE foo.event_type = bar.event_type;
2023-11-25 13:01:35.594 UTC [3984773] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:35.594 UTC [3984773] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:35.594 UTC [3984773] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 13:01:35.594 UTC [3984773] STATEMENT:  SELECT dist2.c0 FROM dist1, dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 13:01:35.595 UTC [3984773] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:35.595 UTC [3984773] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:35.595 UTC [3984773] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 13:01:35.595 UTC [3984773] STATEMENT:  SELECT 1 FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 13:01:35.595 UTC [3984773] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:35.595 UTC [3984773] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:35.595 UTC [3984773] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 13:01:35.595 UTC [3984773] STATEMENT:  SELECT  FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 13:01:35.595 UTC [3984773] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:35.595 UTC [3984773] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:35.595 UTC [3984773] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 13:01:35.595 UTC [3984773] STATEMENT:  SELECT dist2.c0 FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 13:01:35.596 UTC [3984773] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:35.596 UTC [3984773] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:35.596 UTC [3984773] LOCATION:  QueryTargetList, multi_physical_planner.c:818
2023-11-25 13:01:35.596 UTC [3984773] STATEMENT:  SELECT dist2.* FROM dist3, dist4, dist2 WHERE (dist3.c0) IN (dist4.c0);
2023-11-25 13:01:41.575 UTC [3985308] ERROR:  0A000: cannot perform distributed planning on this query because parameterized queries for SQL functions referencing distributed tables are not supported
2023-11-25 13:01:41.575 UTC [3985308] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 13:01:41.575 UTC [3985308] LOCATION:  distributed_planner, distributed_planner.c:301
2023-11-25 13:01:41.575 UTC [3985308] STATEMENT:  SELECT * FROM test_parameterized_sql_function(1);
2023-11-25 13:01:41.576 UTC [3985308] ERROR:  0A000: cannot perform distributed planning on this query because parameterized queries for SQL functions referencing distributed tables are not supported
2023-11-25 13:01:41.576 UTC [3985308] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 13:01:41.576 UTC [3985308] LOCATION:  GetRTEIdentity, distributed_planner.c:533
2023-11-25 13:01:41.576 UTC [3985308] STATEMENT:  SELECT (SELECT 1 FROM test_parameterized_sql limit 1) FROM test_parameterized_sql_function(1);
2023-11-25 13:01:41.576 UTC [3985308] ERROR:  0A000: could not create distributed plan
2023-11-25 13:01:41.576 UTC [3985308] DETAIL:  Possibly this is caused by the use of parameters in SQL functions, which is not supported in Citus.
2023-11-25 13:01:41.576 UTC [3985308] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 13:01:41.576 UTC [3985308] CONTEXT:  SQL function "test_parameterized_sql_function_in_subquery_where" statement 1
2023-11-25 13:01:41.576 UTC [3985308] LOCATION:  CreateDistributedPlannedStmt, distributed_planner.c:751
2023-11-25 13:01:41.576 UTC [3985308] STATEMENT:  SELECT test_parameterized_sql_function_in_subquery_where(1);
2023-11-25 13:01:41.623 UTC [3985308] ERROR:  23505: duplicate key value violates unique constraint "table_with_unique_constraint_a_key_1230009"
2023-11-25 13:01:41.623 UTC [3985308] DETAIL:  Key (a)=(4) already exists.
2023-11-25 13:01:41.623 UTC [3985308] CONTEXT:  while executing command on localhost:57638
	SQL function "insert_twice" statement 2
2023-11-25 13:01:41.623 UTC [3985308] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:41.623 UTC [3985308] STATEMENT:  SELECT insert_twice();
2023-11-25 13:01:42.092 UTC [3985310] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:42.092 UTC [3985310] DETAIL:  Limit in subquery without limit in the outermost query is unsupported
2023-11-25 13:01:42.092 UTC [3985310] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 13:01:42.092 UTC [3985310] STATEMENT:  SELECT * FROM recent_10_users;
2023-11-25 13:01:42.092 UTC [3985310] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:42.092 UTC [3985310] DETAIL:  Limit in subquery without limit in the outermost query is unsupported
2023-11-25 13:01:42.092 UTC [3985310] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 13:01:42.092 UTC [3985310] STATEMENT:  SELECT et.* FROM recent_10_users JOIN events_table et USING(user_id);
2023-11-25 13:01:42.550 UTC [3985306] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:42.550 UTC [3985306] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:42.550 UTC [3985306] STATEMENT:  SELECT
	  u1.user_id, count(*)
	FROM
	  events_table as e1, users_table as u1
	WHERE
	  event_type IN
	            (SELECT
	                event_type
	             FROM
	              events_reference_table as e2
	             WHERE
	              value_2 = 1 AND
	              value_3 > 3 AND
	              e1.value_2 > e2.value_2
	            )
	            AND u1.user_id > e1.user_id
	GROUP BY 1
	ORDER BY 2 DESC, 1 DESC
	LIMIT 5;
2023-11-25 13:01:42.655 UTC [3985310] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 13:01:42.655 UTC [3985310] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 13:01:42.655 UTC [3985310] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 13:01:42.655 UTC [3985310] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 13:01:42.655 UTC [3985310] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 13:01:42.655 UTC [3985310] STATEMENT:  DELETE FROM small_view;
2023-11-25 13:01:42.655 UTC [3985310] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 13:01:42.655 UTC [3985310] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 13:01:42.655 UTC [3985310] STATEMENT:  INSERT INTO small_view VALUES(8, 5) ON CONFLICT(tenant_id) DO UPDATE SET tenant_id=99;
2023-11-25 13:01:42.759 UTC [3985310] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 13:01:42.759 UTC [3985310] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 13:01:42.759 UTC [3985310] STATEMENT:  INSERT INTO small_view VALUES(3, 3);
2023-11-25 13:01:42.776 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.776 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.776 UTC [3985306] STATEMENT:  SELECT count(*) FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id FULL JOIN user_buy_test_table ON (ref1.id > 5);
2023-11-25 13:01:42.777 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.777 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.777 UTC [3985306] STATEMENT:  SELECT count(*) FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id FULL JOIN user_buy_test_table ON (user_buy_test_table.user_id > 5);
2023-11-25 13:01:42.818 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.818 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.818 UTC [3985306] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id ON (ref1.id > 5);
2023-11-25 13:01:42.819 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.819 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.819 UTC [3985306] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id ON (user_buy_test_table.user_id > 5);
2023-11-25 13:01:42.855 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.855 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.855 UTC [3985306] STATEMENT:  SELECT count(*) FROM (SELECT ref1.*, random() FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo FULL JOIN user_buy_test_table ON (foo.id > 5);
2023-11-25 13:01:42.856 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.856 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.856 UTC [3985306] STATEMENT:  SELECT count(*) FROM (SELECT ref1.*, random() FROM users_ref_test_table ref1 LEFT JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo FULL JOIN user_buy_test_table ON (user_buy_test_table.user_id > 19);
2023-11-25 13:01:42.880 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.880 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.880 UTC [3985306] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN (SELECT ref1.*, random() FROM users_ref_test_table ref1 INNER JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo ON (foo.id > 5);
2023-11-25 13:01:42.880 UTC [3985306] ERROR:  0A000: FULL JOIN is only supported with merge-joinable or hash-joinable join conditions
2023-11-25 13:01:42.880 UTC [3985306] LOCATION:  populate_joinrel_with_paths, joinrels.c:853
2023-11-25 13:01:42.880 UTC [3985306] STATEMENT:  SELECT count(*) FROM user_buy_test_table FULL JOIN (SELECT ref1.*, random() FROM users_ref_test_table ref1 LEFT JOIN users_ref_test_table ref2 on ref1.id = ref2.id) as foo ON (user_buy_test_table.user_id > 19);
2023-11-25 13:01:42.887 UTC [3985310] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 13:01:42.887 UTC [3985310] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 13:01:42.887 UTC [3985310] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 13:01:42.887 UTC [3985310] ERROR:  0A000: cannot modify views when the query contains citus tables
2023-11-25 13:01:42.887 UTC [3985310] LOCATION:  DeferErrorIfModifyView, multi_router_planner.c:1137
2023-11-25 13:01:42.887 UTC [3985310] STATEMENT:  DELETE FROM small_view;
2023-11-25 13:01:43.103 UTC [3985310] ERROR:  55000: cannot insert into view "small_view"
2023-11-25 13:01:43.103 UTC [3985310] DETAIL:  Views that do not select from a single table or view are not automatically updatable.
2023-11-25 13:01:43.103 UTC [3985310] HINT:  To enable inserting into the view, provide an INSTEAD OF INSERT trigger or an unconditional ON INSERT DO INSTEAD rule.
2023-11-25 13:01:43.103 UTC [3985310] LOCATION:  rewriteTargetView, rewriteHandler.c:3096
2023-11-25 13:01:43.103 UTC [3985310] STATEMENT:  INSERT INTO small_view VALUES(3, 3);
2023-11-25 13:01:43.606 UTC [3986115] ERROR:  0A000: COMMIT is not allowed in an SQL function
2023-11-25 13:01:43.606 UTC [3986115] CONTEXT:  SQL function "test_procedure_commit" during startup
2023-11-25 13:01:43.606 UTC [3986115] LOCATION:  init_execution_state, functions.c:517
2023-11-25 13:01:43.606 UTC [3986115] STATEMENT:  CALL test_procedure_commit(2,5);
2023-11-25 13:01:43.618 UTC [3986115] ERROR:  0A000: ROLLBACK is not allowed in an SQL function
2023-11-25 13:01:43.618 UTC [3986115] CONTEXT:  SQL function "test_procedure_rollback" during startup
2023-11-25 13:01:43.618 UTC [3986115] LOCATION:  init_execution_state, functions.c:517
2023-11-25 13:01:43.618 UTC [3986115] STATEMENT:  CALL test_procedure_rollback(2,15);
2023-11-25 13:01:43.682 UTC [3986115] ERROR:  23505: duplicate key value violates unique constraint "idx_table_100503"
2023-11-25 13:01:43.682 UTC [3986115] DETAIL:  Key (id, org_id)=(2, 12) already exists.
2023-11-25 13:01:43.682 UTC [3986115] CONTEXT:  while executing command on localhost:57637
	SQL statement "INSERT INTO test_table VALUES (tt_id, tt_org_id)"
	PL/pgSQL function test_procedure_modify_insert(integer,integer) line 5 at SQL statement
2023-11-25 13:01:43.682 UTC [3986115] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:43.682 UTC [3986115] STATEMENT:  CALL test_procedure_modify_insert(2,12);
2023-11-25 13:01:43.684 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.684 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.684 UTC [3986116] STATEMENT:  SELECT ARRAY[(x,(y,x),y),(y,(x,y))] FROM test ORDER BY x, y;
2023-11-25 13:01:43.697 UTC [3986115] ERROR:  23505: duplicate key value violates unique constraint "idx_table_100503"
2023-11-25 13:01:43.697 UTC [3986115] DETAIL:  Key (id, org_id)=(2, 30) already exists.
2023-11-25 13:01:43.697 UTC [3986115] CONTEXT:  while executing command on localhost:57637
	SQL statement "INSERT INTO test_table VALUES (tt_id, tt_org_id)"
	PL/pgSQL function test_procedure_modify_insert_commit(integer,integer) line 5 at SQL statement
2023-11-25 13:01:43.697 UTC [3986115] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:43.697 UTC [3986115] STATEMENT:  CALL test_procedure_modify_insert_commit(2,30);
2023-11-25 13:01:43.701 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.701 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.701 UTC [3986116] STATEMENT:  SELECT ARRAY[[(x,(y,x))],[((x,x),y)]] FROM test ORDER BY x, y;
2023-11-25 13:01:43.706 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.706 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.706 UTC [3986116] STATEMENT:  SELECT CASE x WHEN 2 THEN (x, y, x) ELSE (y, x) END FROM test ORDER BY x, y;
2023-11-25 13:01:43.717 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.717 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.717 UTC [3986116] STATEMENT:  SELECT identity_returner((x, y)) FROM test ORDER BY x, y;
2023-11-25 13:01:43.736 UTC [3986118] ERROR:  P0001: Task failed to execute
2023-11-25 13:01:43.736 UTC [3986118] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 13:01:43.736 UTC [3986118] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:43.736 UTC [3986118] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  WITH one_row AS (
	      SELECT * FROM table1 WHERE id=52
	      )
	  SELECT table1.id, table1.data
	  FROM one_row, table1, next_k_integers(one_row.id, 5) next_five_ids
	  WHERE table1.id = next_five_ids;
	$$);
2023-11-25 13:01:43.740 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.740 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.740 UTC [3986116] STATEMENT:  SELECT array_agg((x, y)) FROM test;
2023-11-25 13:01:43.747 UTC [3986118] ERROR:  P0001: Task failed to execute
2023-11-25 13:01:43.747 UTC [3986118] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 13:01:43.747 UTC [3986118] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:43.747 UTC [3986118] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  SELECT * FROM table1 JOIN the_answer_to_life() the_answer ON (id = the_answer);
	$$);
2023-11-25 13:01:43.754 UTC [3986118] ERROR:  P0001: Task failed to execute
2023-11-25 13:01:43.754 UTC [3986118] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 13:01:43.754 UTC [3986118] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:43.754 UTC [3986118] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  SELECT *
	  FROM table1
	         JOIN next_k_integers(10,5) WITH ORDINALITY next_integers
	           ON (id = next_integers.result);
	$$);
2023-11-25 13:01:43.759 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.759 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.759 UTC [3986116] STATEMENT:  SELECT ARRAY[(x,(y,x),y),(y,(x,y))] FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 13:01:43.761 UTC [3986118] ERROR:  P0001: Task failed to execute
2023-11-25 13:01:43.761 UTC [3986118] CONTEXT:  PL/pgSQL function raise_failed_execution_func_join(text) line 8 at RAISE
2023-11-25 13:01:43.761 UTC [3986118] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:43.761 UTC [3986118] STATEMENT:  SELECT raise_failed_execution_func_join($$
	  SELECT *
	  FROM table1
	         JOIN next_k_integers(10,5) WITH ORDINALITY next_integers
	           ON (id = next_integers.result)
	  ORDER BY id ASC;
	$$);
2023-11-25 13:01:43.768 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.768 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.768 UTC [3986116] STATEMENT:  SELECT ARRAY[[(x,(y,x))],[((x,x),y)]] FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 13:01:43.778 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.778 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.778 UTC [3986116] STATEMENT:  SELECT CASE x WHEN 2 THEN (x, y, x) ELSE (y, x) END FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 13:01:43.794 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.794 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.794 UTC [3986116] STATEMENT:  SELECT identity_returner((x, y)) FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 13:01:43.802 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.802 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.802 UTC [3986116] STATEMENT:  SELECT array_agg((x, y)) FROM test WHERE x = 1;
2023-11-25 13:01:43.815 UTC [3986116] ERROR:  0A000: input of anonymous composite types is not implemented
2023-11-25 13:01:43.815 UTC [3986116] LOCATION:  record_in, rowtypes.c:103
2023-11-25 13:01:43.815 UTC [3986116] STATEMENT:  SELECT (x,table_returner(x)) FROM test WHERE x = 1 ORDER BY x, y;
2023-11-25 13:01:44.378 UTC [3986117] ERROR:  55000: materialized view "materialized_view" has not been populated
2023-11-25 13:01:44.378 UTC [3986117] HINT:  Use the REFRESH MATERIALIZED VIEW command.
2023-11-25 13:01:44.378 UTC [3986117] LOCATION:  ExecOpenScanRelation, execUtils.c:740
2023-11-25 13:01:44.378 UTC [3986117] STATEMENT:  SELECT count(*) FROM materialized_view;
2023-11-25 13:01:44.482 UTC [3986117] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 13:01:44.482 UTC [3986117] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 13:01:44.482 UTC [3986117] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 13:01:44.504 UTC [3986117] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 13:01:44.504 UTC [3986117] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 13:01:44.504 UTC [3986117] STATEMENT:  INSERT INTO small_view VALUES(3, 3);
2023-11-25 13:01:44.585 UTC [3986117] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 13:01:44.585 UTC [3986117] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 13:01:44.585 UTC [3986117] STATEMENT:  UPDATE small_view SET id = 1;
2023-11-25 13:01:44.585 UTC [3986117] ERROR:  42809: cannot change materialized view "small_view"
2023-11-25 13:01:44.585 UTC [3986117] LOCATION:  CheckValidResultRel, execMain.c:1060
2023-11-25 13:01:44.585 UTC [3986117] STATEMENT:  DELETE FROM small_view;
2023-11-25 13:01:44.869 UTC [3986475] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:44.869 UTC [3986475] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:44.869 UTC [3986475] STATEMENT:  SELECT
	  user_id
	FROM
	  users_reference_table
	WHERE
	  NOT EXISTS
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_reference_table.user_id = events_table.user_id
	      )
	LIMIT 3;
2023-11-25 13:01:44.869 UTC [3986475] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a set returning function
2023-11-25 13:01:44.869 UTC [3986475] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:677
2023-11-25 13:01:44.869 UTC [3986475] STATEMENT:  SELECT
	  user_id
	FROM
	  (SELECT user_id FROM generate_series(1,10) AS series(user_id)) users_reference_table
	WHERE
	  NOT EXISTS
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_reference_table.user_id = events_table.user_id
	      )
	LIMIT 3;
2023-11-25 13:01:44.870 UTC [3986475] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 13:01:44.870 UTC [3986475] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 13:01:44.870 UTC [3986475] STATEMENT:  SELECT
	  user_id
	FROM
	  (SELECT  5 AS user_id UNION ALL SELECT 6) users_reference_table
	WHERE
	  NOT EXISTS
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_reference_table.user_id = events_table.user_id
	      )
	LIMIT 3;
2023-11-25 13:01:44.873 UTC [3986476] WARNING:  25001: SET TRANSACTION ISOLATION LEVEL must be called before any query
2023-11-25 13:01:44.873 UTC [3986476] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:44.873 UTC [3986476] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:44.873 UTC [3986476] ERROR:  XX000: failure on connection marked as essential: localhost:57637
2023-11-25 13:01:44.873 UTC [3986476] LOCATION:  MarkRemoteTransactionFailed, remote_transaction.c:840
2023-11-25 13:01:44.873 UTC [3986476] STATEMENT:  SET LOCAL TRANSACTION ISOLATION LEVEL REPEATABLE READ;
2023-11-25 13:01:44.874 UTC [3986476] ERROR:  25006: cannot execute INSERT in a read-only transaction
2023-11-25 13:01:44.874 UTC [3986476] LOCATION:  PreventCommandIfReadOnly, utility.c:414
2023-11-25 13:01:44.874 UTC [3986476] STATEMENT:  INSERT INTO test VALUES (2,2);
2023-11-25 13:01:44.879 UTC [3986475] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a CTE or subquery
2023-11-25 13:01:44.879 UTC [3986475] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:684
2023-11-25 13:01:44.879 UTC [3986475] STATEMENT:  SELECT
	  DISTINCT user_id
	FROM
	  users_table RIGHT JOIN users_reference_table USING (user_id)
	WHERE
	  users_table.value_2 IN
	      (SELECT
	          value_2
	       FROM
	          events_table
	       WHERE
	          users_table.user_id = events_table.user_id
	      )
	ORDER BY user_id
	LIMIT 3;
2023-11-25 13:01:44.879 UTC [3986476] WARNING:  25001: there is already a transaction in progress
2023-11-25 13:01:44.879 UTC [3986476] LOCATION:  BeginTransactionBlock, xact.c:3778
2023-11-25 13:01:44.879 UTC [3986476] WARNING:  25001: there is already a transaction in progress
2023-11-25 13:01:44.879 UTC [3986476] LOCATION:  BeginTransactionBlock, xact.c:3778
2023-11-25 13:01:44.879 UTC [3986476] ERROR:  25001: SET TRANSACTION ISOLATION LEVEL must be called before any query
2023-11-25 13:01:44.879 UTC [3986476] LOCATION:  call_enum_check_hook, guc.c:12007
2023-11-25 13:01:44.879 UTC [3986476] STATEMENT:  BEGIN TRANSACTION ISOLATION LEVEL REPEATABLE READ;
2023-11-25 13:01:44.904 UTC [3986475] ERROR:  0A000: cannot perform a lateral outer join when a distributed subquery references a reference table
2023-11-25 13:01:44.904 UTC [3986475] LOCATION:  DeferredErrorIfUnsupportedRecurringTuplesJoin, query_pushdown_planning.c:913
2023-11-25 13:01:44.904 UTC [3986475] STATEMENT:  SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 1 AND value_1 < 3
	  AND value_2 >= 5
	  AND user_id IN
	  (
			SELECT
			  e1.user_id
			FROM (
			  -- Get the first time each user viewed the homepage.
			  SELECT
			    user_id,
			    1 AS view_homepage,
			    min(time) AS view_homepage_time
			  FROM events_reference_table
			     WHERE
			     event_type IN (1, 2)
			  GROUP BY user_id
			) e1 LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS use_demo,
			    time AS use_demo_time
			  FROM events_table
			  WHERE
			    user_id = e1.user_id AND
			       event_type IN (2, 3)
			  ORDER BY time
			) e2 ON true LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS enter_credit_card,
			    time AS enter_credit_card_time
			  FROM  events_reference_table
			  WHERE
			    user_id = e2.user_id AND
			    event_type IN (3, 4)
			  ORDER BY time
			) e3 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS submit_card_info,
			    user_id,
			    time AS enter_credit_card_time
			  FROM  events_reference_table
			  WHERE
			    user_id = e3.user_id AND
			    event_type IN (4, 5)
			  ORDER BY time
			) e4 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS see_bought_screen
			  FROM  events_reference_table
			  WHERE
			    user_id = e4.user_id AND
			    event_type IN (5, 6)
			  ORDER BY time
			) e5 ON true
			group by e1.user_id
			HAVING sum(submit_card_info) > 0
	)
	ORDER BY 1, 2;
2023-11-25 13:01:44.942 UTC [3986475] ERROR:  0A000: correlated subqueries are not supported when the FROM clause contains a reference table
2023-11-25 13:01:44.942 UTC [3986475] LOCATION:  DeferErrorIfFromClauseRecurs, query_pushdown_planning.c:671
2023-11-25 13:01:44.942 UTC [3986475] STATEMENT:  SELECT user_id,
	       count(*)
	FROM users_reference_table
	WHERE value_2 > ALL
	    (SELECT min(value_2)
	     FROM events_table
	     WHERE event_type > 2 AND users_reference_table.user_id = events_table.user_id
	     GROUP BY user_id)
	GROUP BY user_id
	HAVING count(*) > 3
	ORDER BY 2 DESC,
	         1 DESC
	LIMIT 5;
2023-11-25 13:01:45.781 UTC [3986747] ERROR:  23505: duplicate key value violates unique constraint "test_forcepushdown_pkey_900015"
2023-11-25 13:01:45.781 UTC [3986747] DETAIL:  Key (intcol)=(3) already exists.
2023-11-25 13:01:45.781 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:45.781 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.781 UTC [3986747] STATEMENT:  SELECT insert_data(3);
2023-11-25 13:01:45.782 UTC [3986747] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:45.782 UTC [3986747] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:45.782 UTC [3986747] STATEMENT:  INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (5);
2023-11-25 13:01:45.783 UTC [3986747] ERROR:  23505: duplicate key value violates unique constraint "test_forcepushdown_pkey_900000"
2023-11-25 13:01:45.783 UTC [3986747] DETAIL:  Key (intcol)=(8) already exists.
2023-11-25 13:01:45.783 UTC [3986747] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:45.783 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.783 UTC [3986747] STATEMENT:  INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (8);
2023-11-25 13:01:45.784 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:45.784 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:45.784 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (a+1)"
	PL/pgSQL function forcepushdown_schema.insert_data_non_distarg(integer) line 3 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:45.784 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.784 UTC [3986747] STATEMENT:  SELECT insert_data_non_distarg(9);
2023-11-25 13:01:45.785 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:45.785 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:45.785 UTC [3986747] CONTEXT:  SQL statement "UPDATE forcepushdown_schema.test_forcepushdown SET data = 'non-default'"
	PL/pgSQL function forcepushdown_schema.update_data_nonlocal(integer) line 3 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:45.785 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.785 UTC [3986747] STATEMENT:  SELECT update_data_nonlocal(12);
2023-11-25 13:01:45.785 UTC [3986747] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:45.785 UTC [3986747] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:45.785 UTC [3986747] STATEMENT:  INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (13);
2023-11-25 13:01:45.787 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:45.787 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:45.787 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:45.787 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:45.787 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.787 UTC [3986747] STATEMENT:  SELECT insert_data(intcol+17) from test_forcepushdown where intcol = 1;
2023-11-25 13:01:45.788 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:45.788 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:45.788 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_noncolocate VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_noncolocation(integer) line 4 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:45.788 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.788 UTC [3986747] STATEMENT:  SELECT insert_data_noncolocation(19);
2023-11-25 13:01:45.789 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:45.789 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:45.789 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_noncolocate VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_noncolocation(integer) line 4 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:45.789 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.789 UTC [3986747] STATEMENT:  SELECT insert_data_noncolocation(19);
2023-11-25 13:01:45.843 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:45.843 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:45.843 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:45.843 UTC [3986747] CONTEXT:  SQL statement "SELECT max(id)::numeric+1               FROM forcepushdown_schema.test_nested WHERE id = $1"
	PL/pgSQL function forcepushdown_schema.inner_force_delegation_function(integer) line 4 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:45.843 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.843 UTC [3986747] STATEMENT:  SELECT inner_force_delegation_function(id) FROM test_nested WHERE id = 300;
2023-11-25 13:01:45.843 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:45.843 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:45.843 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:45.843 UTC [3986747] CONTEXT:  SQL statement "SELECT max(id)::numeric+1               FROM forcepushdown_schema.test_nested WHERE id = $1"
	PL/pgSQL function forcepushdown_schema.inner_force_delegation_function(integer) line 4 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:45.843 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.843 UTC [3986747] STATEMENT:  SELECT inner_force_delegation_function((SELECT id+112 FROM test_nested WHERE id=400));
2023-11-25 13:01:45.928 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:45.928 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:45.928 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:45.928 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown SELECT(a+1)"
	PL/pgSQL function forcepushdown_schema.insert_select_data(integer) line 3 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:45.928 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.928 UTC [3986747] STATEMENT:  SELECT insert_select_data(20);
2023-11-25 13:01:45.939 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:45.939 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:45.939 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:45.939 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown SELECT(a+1)"
	PL/pgSQL function forcepushdown_schema.insert_select_data(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:45.939 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.939 UTC [3986747] STATEMENT:  SELECT insert_select_data(22);
2023-11-25 13:01:45.965 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:45.965 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:45.965 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:45.965 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown(intcol)
			SELECT intcol FROM forcepushdown_schema.test_forcepushdown_noncolocate"
	PL/pgSQL function forcepushdown_schema.insert_select_data_nonlocal(integer) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:45.965 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:45.965 UTC [3986747] STATEMENT:  SELECT insert_select_data_nonlocal(41);
2023-11-25 13:01:46.087 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.087 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.087 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_char VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_char(character) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:46.087 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.087 UTC [3986747] STATEMENT:  SELECT insert_data_char('CHAR');
2023-11-25 13:01:46.094 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.094 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.094 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.test_forcepushdown_char VALUES (a)"
	PL/pgSQL function forcepushdown_schema.insert_data_char(character) line 3 at SQL statement
	while executing command on localhost:57638
2023-11-25 13:01:46.094 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.094 UTC [3986747] STATEMENT:  SELECT insert_data_char('CHAR');
2023-11-25 13:01:46.179 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:46.179 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:46.179 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:46.179 UTC [3986747] CONTEXT:  SQL statement "SELECT result          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT data FROM forcepushdown_schema.test_subquery WHERE data = a)"
	PL/pgSQL function forcepushdown_schema.select_data(integer) line 4 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:46.179 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.179 UTC [3986747] STATEMENT:  SELECT select_data(100);
2023-11-25 13:01:46.186 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.186 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.186 UTC [3986747] CONTEXT:  SQL statement "SELECT data          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT id FROM forcepushdown_schema.test_non_colocated WHERE id = a)"
	PL/pgSQL function forcepushdown_schema.select_data_noncolocate(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:46.186 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.186 UTC [3986747] STATEMENT:  SELECT select_data_noncolocate(100);
2023-11-25 13:01:46.194 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.194 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.194 UTC [3986747] CONTEXT:  SQL statement "SELECT data          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT id FROM forcepushdown_schema.test_non_colocated WHERE id = a)"
	PL/pgSQL function forcepushdown_schema.select_data_noncolocate(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:46.194 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.194 UTC [3986747] STATEMENT:  SELECT select_data_noncolocate(100);
2023-11-25 13:01:46.207 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.207 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.207 UTC [3986747] CONTEXT:  SQL statement "WITH ins AS (INSERT INTO forcepushdown_schema.test_subquery VALUES (a+1) RETURNING data)
			SELECT ins.data          FROM forcepushdown_schema.test_subquery, ins WHERE forcepushdown_schema.test_subquery.data = a"
	PL/pgSQL function forcepushdown_schema.insert_data_cte_nondist(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:46.207 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.207 UTC [3986747] STATEMENT:  SELECT insert_data_cte_nondist(400);
2023-11-25 13:01:46.214 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.214 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.214 UTC [3986747] CONTEXT:  SQL statement "WITH ins AS (INSERT INTO forcepushdown_schema.test_subquery VALUES (a+1) RETURNING data)
			SELECT ins.data          FROM forcepushdown_schema.test_subquery, ins WHERE forcepushdown_schema.test_subquery.data = a"
	PL/pgSQL function forcepushdown_schema.insert_data_cte_nondist(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:46.214 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.214 UTC [3986747] STATEMENT:  SELECT insert_data_cte_nondist(400);
2023-11-25 13:01:46.237 UTC [3986747] ERROR:  XX000: cannot execute a distributed query from a query on a shard
2023-11-25 13:01:46.237 UTC [3986747] DETAIL:  Executing a distributed query in a function call that may be pushed to a remote node can lead to incorrect results.
2023-11-25 13:01:46.237 UTC [3986747] HINT:  Avoid nesting of distributed queries or use alter user current_user set citus.allow_nested_distributed_execution to on to allow it with possible incorrectness.
2023-11-25 13:01:46.237 UTC [3986747] CONTEXT:  SQL statement "SELECT result          FROM forcepushdown_schema.test_subquery WHERE data =
			(SELECT data FROM forcepushdown_schema.test_subquery WHERE data = a)"
	PL/pgSQL function forcepushdown_schema.select_data(integer) line 4 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:46.237 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.237 UTC [3986747] STATEMENT:  SELECT 1,2,3 FROM select_data(100);
2023-11-25 13:01:46.257 UTC [3986747] ERROR:  42883: function test_prepare(integer, integer) does not exist
2023-11-25 13:01:46.257 UTC [3986747] LOCATION:  LookupFuncWithArgs, parse_func.c:2444
2023-11-25 13:01:46.257 UTC [3986747] STATEMENT:  DROP FUNCTION test_prepare(int, int);
2023-11-25 13:01:46.261 UTC [3986747] ERROR:  42883: function outer_test_prepare(integer, integer) does not exist
2023-11-25 13:01:46.261 UTC [3986747] LOCATION:  LookupFuncWithArgs, parse_func.c:2444
2023-11-25 13:01:46.261 UTC [3986747] STATEMENT:  DROP FUNCTION outer_test_prepare(int, int);
2023-11-25 13:01:46.275 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.275 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.275 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.table_test_prepare VALUES (y, x)"
	PL/pgSQL function forcepushdown_schema.test_prepare(integer,integer) line 5 at SQL statement
	while executing command on localhost:57638
	SQL statement "SELECT FROM test_prepare(x, y)"
	PL/pgSQL function outer_test_prepare(integer,integer) line 5 at PERFORM
2023-11-25 13:01:46.275 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.275 UTC [3986747] STATEMENT:  SELECT outer_test_prepare(1,2);
2023-11-25 13:01:46.358 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.358 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.358 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (x,x)"
	PL/pgSQL function forcepushdown_schema.inner_fn(integer) line 4 at SQL statement
	SQL statement "SELECT 1 FROM forcepushdown_schema.inner_fn(z)"
	PL/pgSQL function forcepushdown_schema.outer_fn(integer,integer) line 6 at PERFORM
	while executing command on localhost:57638
2023-11-25 13:01:46.358 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.358 UTC [3986747] STATEMENT:  SELECT outer_fn(1, 2);
2023-11-25 13:01:46.365 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.365 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.365 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (x,x)"
	PL/pgSQL function forcepushdown_schema.inner_fn(integer) line 4 at SQL statement
	SQL statement "SELECT 1 FROM forcepushdown_schema.inner_fn(z)"
	PL/pgSQL function forcepushdown_schema.outer_fn(integer,integer) line 6 at PERFORM
	while executing command on localhost:57638
2023-11-25 13:01:46.365 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.365 UTC [3986747] STATEMENT:  SELECT outer_fn(1, 2);
2023-11-25 13:01:46.381 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.381 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.381 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_inner(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_inner(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 13:01:46.381 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.381 UTC [3986747] STATEMENT:  SELECT force_push_outer(7);
2023-11-25 13:01:46.388 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.388 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.388 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_inner(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_inner(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 13:01:46.388 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.388 UTC [3986747] STATEMENT:  SELECT force_push_outer(8);
2023-11-25 13:01:46.389 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.389 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.389 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_inner(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_inner(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 13:01:46.389 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.389 UTC [3986747] STATEMENT:  SELECT force_push_outer(14);
2023-11-25 13:01:46.416 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.416 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.416 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_2(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_2(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_1(integer) line 5 at PERFORM
	while executing command on localhost:57637
2023-11-25 13:01:46.416 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.416 UTC [3986747] STATEMENT:  SELECT force_push_1(7);
2023-11-25 13:01:46.417 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.417 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.417 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (y,y)"
	PL/pgSQL function forcepushdown_schema.force_push_2(integer) line 4 at SQL statement
	SQL statement "SELECT forcepushdown_schema.force_push_2(x+1) LIMIT 1"
	PL/pgSQL function forcepushdown_schema.force_push_1(integer) line 5 at PERFORM
	while executing command on localhost:57638
2023-11-25 13:01:46.417 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.417 UTC [3986747] STATEMENT:  SELECT force_push_1(13);
2023-11-25 13:01:46.440 UTC [3986747] ERROR:  0A000: queries must filter by the distribution argument in the same colocation group when using the forced function pushdown
2023-11-25 13:01:46.440 UTC [3986747] HINT:  consider disabling forced delegation through create_distributed_table(..., force_delegation := false)
2023-11-25 13:01:46.440 UTC [3986747] CONTEXT:  SQL statement "INSERT INTO forcepushdown_schema.testnested_table VALUES (x+1,x+1)"
	PL/pgSQL function forcepushdown_schema.force_push_outer(integer) line 5 at SQL statement
	while executing command on localhost:57637
2023-11-25 13:01:46.440 UTC [3986747] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:46.440 UTC [3986747] STATEMENT:  SELECT force_push_outer(7);
2023-11-25 13:01:46.865 UTC [3986939] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:46.865 UTC [3986939] DETAIL:  Shards of relations in subquery need to have 1-to-1 shard partitioning
2023-11-25 13:01:46.865 UTC [3986939] LOCATION:  ErrorIfUnsupportedShardDistribution, multi_physical_planner.c:2432
2023-11-25 13:01:46.865 UTC [3986939] STATEMENT:  SELECT * FROM test_table_1 full join test_table_2 using(id);
2023-11-25 13:01:47.552 UTC [3987443] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:47.552 UTC [3987443] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:47.552 UTC [3987443] STATEMENT:  SELECT
	  user_id
	FROM
	  users_table
	WHERE
	  value_2 >
	          (SELECT
	              max(value_2)
	           FROM
	              events_table
	           WHERE
	              users_table.user_id > events_table.user_id AND event_type = 1 AND
	              users_table.time = events_table.time
	           GROUP BY
	              user_id
	          )
	GROUP BY user_id
	HAVING count(*) > 1
	ORDER BY user_id
	LIMIT 5;
2023-11-25 13:01:47.617 UTC [3987443] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:47.617 UTC [3987443] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:47.617 UTC [3987443] STATEMENT:  SELECT user_id, value_2 FROM users_table WHERE
	  value_1 > 1 AND value_1 < 2
	  AND value_2 >= 1
	  AND user_id IN
	  (
			SELECT
			  e1.user_id
			FROM (
			  -- Get the first time each user viewed the homepage.
			  SELECT
			    user_id,
			    1 AS view_homepage,
			    min(time) AS view_homepage_time
			  FROM events_table
			     WHERE
			     event_type IN (0, 1)
			  GROUP BY user_id
			) e1 LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS use_demo,
			    time AS use_demo_time
			  FROM events_table
			  WHERE
			    user_id = e1.user_id AND
			       event_type IN (1, 2)
			  ORDER BY time
			) e2 ON true LEFT JOIN LATERAL (
			  SELECT
			    user_id,
			    1 AS enter_credit_card,
			    time AS enter_credit_card_time
			  FROM  events_table
			  WHERE
			    user_id = e2.user_id AND
			    event_type IN (2, 3)
			  ORDER BY time
			) e3 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS submit_card_info,
			    user_id,
			    time AS enter_credit_card_time
			  FROM  events_table
			  WHERE
			    value_2 = e3.user_id AND
			    event_type IN (3, 4)
			  ORDER BY time
			) e4 ON true LEFT JOIN LATERAL (
			  SELECT
			    1 AS see_bought_screen
			  FROM  events_table
			  WHERE
			    user_id = e4.user_id AND
			    event_type IN (5, 6)
			  ORDER BY time
			) e5 ON true
			group by e1.user_id
			HAVING sum(submit_card_info) > 0
	);
2023-11-25 13:01:47.637 UTC [3987443] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:47.637 UTC [3987443] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:47.637 UTC [3987443] STATEMENT:  SELECT user_id, array_length(events_table, 1)
	FROM (
	  SELECT user_id, array_agg(event ORDER BY time) AS events_table
	  FROM (
	    SELECT
	    	u.user_id, e.event_type::text AS event, e.time
	    FROM
	    	users_table AS u,
	        events_table AS e
	    WHERE u.user_id = e.user_id AND
	    		u.user_id IN
	    		(
	    			SELECT
	    				user_id
	    			FROM
	    				users_table
	    			WHERE value_2 >= 5
				    AND  EXISTS (SELECT user_id FROM events_table WHERE event_type > 1 AND event_type <= 3 AND value_3 > 1 AND user_id = users_table.user_id)
					AND  NOT EXISTS (SELECT user_id FROM events_table WHERE event_type > 3 AND event_type <= 4  AND value_3 > 1 AND user_id != users_table.user_id)
	    		)
	  ) t
	  GROUP BY user_id
	) q
	ORDER BY 2 DESC, 1;
2023-11-25 13:01:47.682 UTC [3987445] ERROR:  0A000: could not create distributed plan
2023-11-25 13:01:47.682 UTC [3987445] DETAIL:  Possibly this is caused by the use of parameters in SQL functions, which is not supported in Citus.
2023-11-25 13:01:47.682 UTC [3987445] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 13:01:47.682 UTC [3987445] CONTEXT:  SQL function "sql_subquery_test" statement 1
2023-11-25 13:01:47.682 UTC [3987445] LOCATION:  CreateDistributedPlannedStmt, distributed_planner.c:751
2023-11-25 13:01:47.682 UTC [3987445] STATEMENT:  SELECT sql_subquery_test(1,1);
2023-11-25 13:01:47.705 UTC [3987443] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:47.705 UTC [3987443] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:47.705 UTC [3987443] STATEMENT:  SELECT user_id, value_2 FROM users_table WHERE
	  value_1 = 1
	  AND value_2 >= 2
	  AND NOT EXISTS (SELECT user_id FROM events_table WHERE event_type=1 AND value_3 > 1 AND test_join_function(events_table.user_id, users_table.user_id))
	ORDER BY 1 DESC, 2 DESC
	LIMIT 3;
2023-11-25 13:01:47.732 UTC [3987444] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:47.732 UTC [3987444] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:47.732 UTC [3987444] STATEMENT:  SELECT user_id, sum(counter)
	FROM (
	    SELECT user_id, sum(value_2) AS counter FROM users_table GROUP BY user_id
	      UNION
	    SELECT events_table.user_id, sum(events_table.value_2) AS counter FROM events_table, users_table WHERE users_table.user_id > events_table.user_id GROUP BY 1
	) user_id
	GROUP BY user_id;
2023-11-25 13:01:47.732 UTC [3987444] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:47.732 UTC [3987444] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:47.732 UTC [3987444] STATEMENT:  SELECT user_id, sum(counter)
	FROM (
	    SELECT user_id, sum(value_2) AS counter FROM users_table GROUP BY user_id
	      UNION ALL
	    SELECT events_table.user_id, sum(events_table.value_2) AS counter FROM events_table, users_table WHERE users_table.user_id > events_table.user_id GROUP BY 1
	) user_id
	GROUP BY user_id;
2023-11-25 13:01:47.790 UTC [3987444] ERROR:  0A000: cannot perform distributed planning on this query because parameterized queries for SQL functions referencing distributed tables are not supported
2023-11-25 13:01:47.790 UTC [3987444] HINT:  Consider using PL/pgSQL functions instead.
2023-11-25 13:01:47.790 UTC [3987444] LOCATION:  distributed_planner, distributed_planner.c:301
2023-11-25 13:01:47.790 UTC [3987444] STATEMENT:  SELECT user_id FROM users_table
	UNION SELECT u.user_id FROM users_table, users_udf() u;
2023-11-25 13:01:48.697 UTC [3987446] ERROR:  40P01: canceling the transaction since it was involved in a distributed deadlock
2023-11-25 13:01:48.697 UTC [3987446] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:01:48.697 UTC [3987446] STATEMENT:  SELECT id, pg_advisory_lock(15) FROM t_lock;
2023-11-25 13:01:48.709 UTC [3987446] ERROR:  57014: canceling statement due to statement timeout
2023-11-25 13:01:48.709 UTC [3987446] LOCATION:  ProcessInterrupts, postgres.c:3326
2023-11-25 13:01:48.709 UTC [3987446] STATEMENT:  INSERT INTO t_unrelated SELECT i FROM generate_series(1, 10) i;
2023-11-25 13:01:49.153 UTC [3987698] ERROR:  25001: cannot perform query on placements that were modified in this transaction by a different user
2023-11-25 13:01:49.153 UTC [3987698] LOCATION:  FindPlacementListConnection, placement_connection.c:647
2023-11-25 13:01:49.153 UTC [3987698] STATEMENT:  SELECT * FROM t;
2023-11-25 13:01:49.154 UTC [3987698] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:49.154 UTC [3987698] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:49.154 UTC [3987698] STATEMENT:  INSERT INTO t values (1);
2023-11-25 13:01:49.154 UTC [3987698] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:49.154 UTC [3987698] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:49.154 UTC [3987698] STATEMENT:  SELECT * from t;
2023-11-25 13:01:49.172 UTC [3987698] ERROR:  25001: cannot perform query on placements that were modified in this transaction by a different user
2023-11-25 13:01:49.172 UTC [3987698] LOCATION:  FindPlacementListConnection, placement_connection.c:647
2023-11-25 13:01:49.172 UTC [3987698] STATEMENT:  INSERT INTO t values (2);
2023-11-25 13:01:49.207 UTC [3987698] ERROR:  25001: cannot perform query on placements that were modified in this transaction by a different user
2023-11-25 13:01:49.207 UTC [3987698] CONTEXT:  COPY t, line 1: "1"
2023-11-25 13:01:49.207 UTC [3987698] LOCATION:  FindPlacementListConnection, placement_connection.c:647
2023-11-25 13:01:49.207 UTC [3987698] STATEMENT:  COPY t FROM STDIN;
2023-11-25 13:01:49.318 UTC [3987695] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 13:01:49.318 UTC [3987695] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:49.318 UTC [3987695] STATEMENT:  SELECT
		min(r_custkey), max(r_custkey)
	FROM
		multi_outer_join_left_hash a RIGHT JOIN multi_outer_join_right_reference b ON (l_custkey = r_custkey);
2023-11-25 13:01:49.333 UTC [3987695] ERROR:  XX000: hash partitioned table has overlapping shards
2023-11-25 13:01:49.333 UTC [3987695] LOCATION:  ErrorIfInconsistentShardIntervals, metadata_cache.c:1981
2023-11-25 13:01:49.333 UTC [3987695] STATEMENT:  SELECT
		min(l_custkey), max(l_custkey)
	FROM
		multi_outer_join_left_hash a LEFT JOIN multi_outer_join_right_hash b ON (l_custkey = r_custkey);
2023-11-25 13:01:49.501 UTC [3987695] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:49.501 UTC [3987695] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:49.501 UTC [3987695] STATEMENT:  SELECT
		count(*)
	FROM
		multi_outer_join_left_hash a LEFT JOIN multi_outer_join_right_hash b ON (l_nationkey = r_nationkey);
2023-11-25 13:01:49.521 UTC [3987695] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 13:01:49.521 UTC [3987695] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:49.521 UTC [3987695] STATEMENT:  SELECT
		min(r_custkey), max(r_custkey)
	FROM
		multi_outer_join_left_hash a RIGHT JOIN multi_outer_join_right_reference b ON (l_custkey = r_custkey);
2023-11-25 13:01:49.532 UTC [3987695] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:49.532 UTC [3987695] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:49.532 UTC [3987695] STATEMENT:  SELECT
		*
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_reference r1 ON (l1.l_custkey = r1.r_custkey)
		LEFT JOIN multi_outer_join_right_reference r2 ON (l1.l_custkey  = r2.r_custkey)
		RIGHT JOIN multi_outer_join_left_hash l2 ON (r2.r_custkey = l2.l_custkey);
2023-11-25 13:01:49.532 UTC [3987695] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:49.532 UTC [3987695] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:49.532 UTC [3987695] STATEMENT:  SELECT
		*
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_reference r1 ON (l1.l_custkey = r1.r_custkey)
		LEFT JOIN multi_outer_join_right_reference r2 ON (l1.l_custkey  = r2.r_custkey)
		RIGHT JOIN multi_outer_join_left_hash l2 ON (r2.r_custkey = l2.l_custkey)
	WHERE
		r1.r_custkey is NULL;
2023-11-25 13:01:49.537 UTC [3987695] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 13:01:49.537 UTC [3987695] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:49.537 UTC [3987695] STATEMENT:  SELECT
		l_custkey, r_custkey, t_custkey
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_hash r1 ON (l1.l_custkey = r1.r_custkey)
		RIGHT JOIN multi_outer_join_third_reference t1 ON (r1.r_custkey  = t1.t_custkey)
	ORDER BY 1,2,3;
2023-11-25 13:01:49.537 UTC [3987695] LOG:  00000: join order: [ "multi_outer_join_right_hash" ]
2023-11-25 13:01:49.537 UTC [3987695] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:49.537 UTC [3987695] STATEMENT:  SELECT
		l_custkey, r_custkey, t_custkey
	FROM
		multi_outer_join_left_hash l1
		LEFT JOIN multi_outer_join_right_hash r1 ON (l1.l_custkey = r1.r_custkey)
		RIGHT JOIN multi_outer_join_third_reference t1 ON (r1.r_custkey  = t1.t_custkey)
	ORDER BY 1,2,3;
2023-11-25 13:01:49.580 UTC [3987695] LOG:  00000: join order: [ "multi_outer_join_left_hash" ]
2023-11-25 13:01:49.580 UTC [3987695] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:49.580 UTC [3987695] STATEMENT:  SELECT
		l_custkey, t_custkey
	FROM
		multi_outer_join_left_hash l1
		FULL JOIN multi_outer_join_third_reference t1 ON (l1.l_custkey = t1.t_custkey)
	ORDER BY 1,2;
2023-11-25 13:01:49.641 UTC [3987696] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 13:01:49.641 UTC [3987696] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 13:01:49.641 UTC [3987696] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 13:01:49.641 UTC [3987696] STATEMENT:  SELECT SUM(distinct l_partkey) FROM lineitem_hash;
2023-11-25 13:01:49.642 UTC [3987696] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 13:01:49.642 UTC [3987696] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 13:01:49.642 UTC [3987696] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 13:01:49.642 UTC [3987696] STATEMENT:  SELECT l_shipmode, sum(distinct l_partkey) FROM lineitem_hash GROUP BY l_shipmode;
2023-11-25 13:01:50.043 UTC [3988065] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 13:01:50.043 UTC [3988065] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:50.043 UTC [3988065] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:50.043 UTC [3988065] STATEMENT:  SELECT * FROM
		test_table_1_rf1 as tt1 INNER JOIN test_table_1_rf1 as tt2 on tt1.id = tt2.id
		ORDER BY 1
		FOR UPDATE;
2023-11-25 13:01:50.044 UTC [3988065] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 13:01:50.044 UTC [3988065] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:50.044 UTC [3988065] STATEMENT:  SELECT * FROM
		test_table_1_rf1 as tt1 INNER JOIN test_table_3_rf2 as tt3 on tt1.id = tt3.id
		WHERE tt1.id = 1
		ORDER BY 1
		FOR UPDATE;
2023-11-25 13:01:50.044 UTC [3988065] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 13:01:50.044 UTC [3988065] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:50.044 UTC [3988065] STATEMENT:  SELECT * FROM
		test_table_1_rf1 as tt1 INNER JOIN test_table_3_rf2 as tt3 on tt1.id = tt3.id
		ORDER BY 1
		FOR UPDATE;
2023-11-25 13:01:50.045 UTC [3988065] ERROR:  0A000: could not run distributed query with FOR UPDATE/SHARE commands
2023-11-25 13:01:50.045 UTC [3988065] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:50.045 UTC [3988065] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:50.045 UTC [3988065] STATEMENT:  SELECT * FROM
		test_table_3_rf2 as tt3 INNER JOIN test_table_4_rf2 as tt4 on tt3.id = tt4.id
		WHERE tt3.id = 1
		ORDER BY 1
		FOR UPDATE;
2023-11-25 13:01:50.089 UTC [3988063] ERROR:  23505: duplicate key value violates unique constraint "reference_table_test_fourth_pkey_1250003"
2023-11-25 13:01:50.089 UTC [3988063] DETAIL:  Key (value_2)=(1) already exists.
2023-11-25 13:01:50.089 UTC [3988063] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:50.089 UTC [3988063] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:50.089 UTC [3988063] STATEMENT:  INSERT INTO reference_table_test_fourth VALUES (1, 1.0, '1', '2016-12-01');
2023-11-25 13:01:50.090 UTC [3988063] ERROR:  23502: null value in column "value_2" of relation "reference_table_test_fourth_1250003" violates not-null constraint
2023-11-25 13:01:50.090 UTC [3988063] DETAIL:  Failing row contains (1, null, 1.0, 2016-12-01 00:00:00).
2023-11-25 13:01:50.090 UTC [3988063] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:50.090 UTC [3988063] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:50.090 UTC [3988063] STATEMENT:  INSERT INTO reference_table_test_fourth (value_1, value_3, value_4) VALUES (1, '1.0', '2016-12-01');
2023-11-25 13:01:50.192 UTC [3988063] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ]
2023-11-25 13:01:50.192 UTC [3988063] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:50.192 UTC [3988063] STATEMENT:  SELECT
		reference_table_test.value_1
	FROM
		reference_table_test, colocated_table_test
	WHERE
		colocated_table_test.value_1 = reference_table_test.value_1
	ORDER BY 1;
2023-11-25 13:01:50.200 UTC [3988063] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ]
2023-11-25 13:01:50.200 UTC [3988063] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:50.200 UTC [3988063] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test
	WHERE
		colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY 1;
2023-11-25 13:01:50.206 UTC [3988063] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ]
2023-11-25 13:01:50.206 UTC [3988063] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:50.206 UTC [3988063] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		colocated_table_test, reference_table_test
	WHERE
		reference_table_test.value_1 = colocated_table_test.value_1
	ORDER BY 1;
2023-11-25 13:01:50.212 UTC [3988063] LOG:  00000: join order: [ "colocated_table_test_2" ][ cartesian product reference join "reference_table_test" ][ dual partition join "colocated_table_test" ]
2023-11-25 13:01:50.212 UTC [3988063] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:50.212 UTC [3988063] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY colocated_table_test.value_2;
2023-11-25 13:01:50.369 UTC [3988063] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ][ local partition join "colocated_table_test_2" ]
2023-11-25 13:01:50.369 UTC [3988063] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:50.369 UTC [3988063] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_1 = colocated_table_test_2.value_1 AND colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY 1;
2023-11-25 13:01:50.374 UTC [3988063] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ][ dual partition join "colocated_table_test_2" ]
2023-11-25 13:01:50.374 UTC [3988063] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:50.374 UTC [3988063] STATEMENT:  SELECT
		colocated_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_2 = colocated_table_test_2.value_2 AND colocated_table_test.value_2 = reference_table_test.value_2
	ORDER BY colocated_table_test.value_2;
2023-11-25 13:01:50.516 UTC [3988063] LOG:  00000: join order: [ "colocated_table_test" ][ reference join "reference_table_test" ][ dual partition join "colocated_table_test_2" ]
2023-11-25 13:01:50.516 UTC [3988063] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:50.516 UTC [3988063] STATEMENT:  SELECT
		reference_table_test.value_2
	FROM
		reference_table_test, colocated_table_test, colocated_table_test_2
	WHERE
		colocated_table_test.value_1 = reference_table_test.value_1 AND colocated_table_test_2.value_1 = reference_table_test.value_1
	ORDER BY reference_table_test.value_2;
2023-11-25 13:01:50.703 UTC [3988063] ERROR:  0A000: relation reference_table_test should be a hash distributed table
2023-11-25 13:01:50.703 UTC [3988063] LOCATION:  EnsureHashDistributedTable, metadata_utility.c:2284
2023-11-25 13:01:50.703 UTC [3988063] STATEMENT:  SELECT update_distributed_table_colocation('colocated_table_test_2', colocate_with => 'reference_table_test');
2023-11-25 13:01:50.704 UTC [3988063] ERROR:  0A000: relation reference_table_test_fifth should be a hash distributed table
2023-11-25 13:01:50.704 UTC [3988063] LOCATION:  EnsureHashDistributedTable, metadata_utility.c:2284
2023-11-25 13:01:50.704 UTC [3988063] STATEMENT:  SELECT update_distributed_table_colocation('reference_table_test', colocate_with => 'reference_table_test_fifth');
2023-11-25 13:01:50.852 UTC [3988616] ERROR:  XX000: relation "reference_schema.reference_table_ddl" is a reference table
2023-11-25 13:01:50.852 UTC [3988616] DETAIL:  We currently don't support creating shards on reference tables
2023-11-25 13:01:50.852 UTC [3988616] LOCATION:  master_create_empty_shard, stage_protocol.c:143
2023-11-25 13:01:50.852 UTC [3988616] STATEMENT:  SELECT master_create_empty_shard('reference_schema.reference_table_ddl');
2023-11-25 13:01:51.182 UTC [3988678] ERROR:  42704: type "hll" does not exist at character 51
2023-11-25 13:01:51.182 UTC [3988678] LOCATION:  typenameType, parse_type.c:270
2023-11-25 13:01:51.182 UTC [3988678] STATEMENT:  CREATE TABLE daily_uniques(day date, unique_users hll);
2023-11-25 13:01:51.198 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 33
2023-11-25 13:01:51.198 UTC [3988678] LOCATION:  RangeVarGetRelidExtended, namespace.c:433
2023-11-25 13:01:51.198 UTC [3988678] STATEMENT:  SELECT create_distributed_table('daily_uniques', 'day');
2023-11-25 13:01:51.254 UTC [3988677] ERROR:  0A000: cannot compute aggregate (distinct)
2023-11-25 13:01:51.254 UTC [3988677] DETAIL:  table partitioning is unsuitable for aggregate (distinct)
2023-11-25 13:01:51.254 UTC [3988677] LOCATION:  DeferErrorIfUnsupportedAggregateDistinct, multi_logical_optimizer.c:4205
2023-11-25 13:01:51.254 UTC [3988677] STATEMENT:  select key, sum2(distinct val), sum2_strict(distinct val), psum(distinct val, valf::int), psum_strict(distinct val, valf::int) from aggdata group by key order by key;
2023-11-25 13:01:51.258 UTC [3988677] ERROR:  XX000: unsupported aggregate function sum2
2023-11-25 13:01:51.258 UTC [3988677] LOCATION:  GetAggregateType, multi_logical_optimizer.c:3481
2023-11-25 13:01:51.258 UTC [3988677] STATEMENT:  select key, sum2(val order by valf), sum2_strict(val order by valf), psum(val, valf::int order by valf), psum_strict(val, valf::int order by valf) from aggdata group by key order by key;
2023-11-25 13:01:51.262 UTC [3988676] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 37
2023-11-25 13:01:51.262 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.262 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.262 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest(latency, 100)
	FROM latencies;
2023-11-25 13:01:51.262 UTC [3988676] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 40
2023-11-25 13:01:51.262 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.262 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.262 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest(latency, 100)
	FROM latencies
	GROUP BY a;
2023-11-25 13:01:51.262 UTC [3988676] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 40
2023-11-25 13:01:51.262 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.262 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.262 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest(latency, 100)
	FROM latencies
	GROUP BY b;
2023-11-25 13:01:51.262 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 37
2023-11-25 13:01:51.262 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.262 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.262 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(latency, 100, 0.99)
	FROM latencies;
2023-11-25 13:01:51.262 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 40
2023-11-25 13:01:51.262 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.262 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.262 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(latency, 100, 0.99)
	FROM latencies
	GROUP BY a;
2023-11-25 13:01:51.262 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 40
2023-11-25 13:01:51.262 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.262 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.262 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile(latency, 100, 0.99)
	FROM latencies
	GROUP BY b;
2023-11-25 13:01:51.263 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 37
2023-11-25 13:01:51.263 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.263 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.263 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(latency, 100, ARRAY[0.99, 0.95])
	FROM latencies;
2023-11-25 13:01:51.263 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 40
2023-11-25 13:01:51.263 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.263 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.263 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(latency, 100, ARRAY[0.99, 0.95])
	FROM latencies
	GROUP BY a;
2023-11-25 13:01:51.263 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 40
2023-11-25 13:01:51.263 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.263 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.263 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile(latency, 100, ARRAY[0.99, 0.95])
	FROM latencies
	GROUP BY b;
2023-11-25 13:01:51.263 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 37
2023-11-25 13:01:51.263 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.263 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.263 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(latency, 100, 9000)
	FROM latencies;
2023-11-25 13:01:51.263 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 40
2023-11-25 13:01:51.263 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.263 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.263 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(latency, 100, 9000)
	FROM latencies
	GROUP BY a;
2023-11-25 13:01:51.263 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 40
2023-11-25 13:01:51.263 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.263 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.263 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile_of(latency, 100, 9000)
	FROM latencies
	GROUP BY b;
2023-11-25 13:01:51.263 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 37
2023-11-25 13:01:51.263 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.263 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.263 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(latency, 100, ARRAY[9000, 9500])
	FROM latencies;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 40
2023-11-25 13:01:51.264 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(latency, 100, ARRAY[9000, 9500])
	FROM latencies
	GROUP BY a;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 40
2023-11-25 13:01:51.264 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT b, tdigest_percentile_of(latency, 100, ARRAY[9000, 9500])
	FROM latencies
	GROUP BY b;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42883: function tdigest(double precision, integer) does not exist at character 8
2023-11-25 13:01:51.264 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  SELECT tdigest(latency, 100) FROM latencies;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric) does not exist at character 8
2023-11-25 13:01:51.264 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  SELECT tdigest_percentile(latency, 100, 0.99) FROM latencies;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42883: function tdigest_percentile(double precision, integer, numeric[]) does not exist at character 8
2023-11-25 13:01:51.264 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  SELECT tdigest_percentile(latency, 100, ARRAY[0.99, 0.95]) FROM latencies;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer) does not exist at character 8
2023-11-25 13:01:51.264 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  SELECT tdigest_percentile_of(latency, 100, 9000) FROM latencies;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42883: function tdigest_percentile_of(double precision, integer, integer[]) does not exist at character 8
2023-11-25 13:01:51.264 UTC [3988676] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  SELECT tdigest_percentile_of(latency, 100, ARRAY[9000, 9500]) FROM latencies;
2023-11-25 13:01:51.264 UTC [3988676] ERROR:  42704: type "tdigest" does not exist at character 47
2023-11-25 13:01:51.264 UTC [3988676] LOCATION:  typenameType, parse_type.c:270
2023-11-25 13:01:51.264 UTC [3988676] STATEMENT:  CREATE TABLE latencies_rollup (a int, tdigest tdigest);
2023-11-25 13:01:51.265 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 33
2023-11-25 13:01:51.265 UTC [3988676] LOCATION:  RangeVarGetRelidExtended, namespace.c:433
2023-11-25 13:01:51.265 UTC [3988676] STATEMENT:  SELECT create_distributed_table('latencies_rollup', 'a', colocate_with => 'latencies');
2023-11-25 13:01:51.265 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 13
2023-11-25 13:01:51.265 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.265 UTC [3988676] STATEMENT:  INSERT INTO latencies_rollup
	SELECT a, tdigest(latency, 100)
	FROM latencies
	GROUP BY a;
2023-11-25 13:01:51.265 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 59
2023-11-25 13:01:51.265 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.265 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest(tdigest)
	FROM latencies_rollup;
2023-11-25 13:01:51.265 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 62
2023-11-25 13:01:51.265 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.265 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest(tdigest)
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 13:01:51.265 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 76
2023-11-25 13:01:51.265 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.265 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(tdigest, 0.99)
	FROM latencies_rollup;
2023-11-25 13:01:51.265 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 79
2023-11-25 13:01:51.265 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.265 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(tdigest, 0.99)
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 13:01:51.265 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 89
2023-11-25 13:01:51.265 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.265 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile(tdigest, ARRAY[0.99, 0.95])
	FROM latencies_rollup;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 92
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile(tdigest, ARRAY[0.99, 0.95])
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 79
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(tdigest, 9000)
	FROM latencies_rollup;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 82
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(tdigest, 9000)
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 92
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT tdigest_percentile_of(tdigest, ARRAY[9000, 9500])
	FROM latencies_rollup;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 95
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  EXPLAIN (COSTS OFF, VERBOSE)
	SELECT a, tdigest_percentile_of(tdigest, ARRAY[9000, 9500])
	FROM latencies_rollup
	GROUP BY a;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 30
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  SELECT tdigest(tdigest) FROM latencies_rollup;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 47
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  SELECT tdigest_percentile(tdigest, 0.99) FROM latencies_rollup;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 60
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  SELECT tdigest_percentile(tdigest, ARRAY[0.99, 0.95]) FROM latencies_rollup;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 50
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  SELECT tdigest_percentile_of(tdigest, 9000) FROM latencies_rollup;
2023-11-25 13:01:51.266 UTC [3988676] ERROR:  42P01: relation "latencies_rollup" does not exist at character 63
2023-11-25 13:01:51.266 UTC [3988676] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.266 UTC [3988676] STATEMENT:  SELECT tdigest_percentile_of(tdigest, ARRAY[9000, 9500]) FROM latencies_rollup;
2023-11-25 13:01:51.291 UTC [3988678] ERROR:  42883: function hll_hash_integer(integer) does not exist at character 72
2023-11-25 13:01:51.291 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.291 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.291 UTC [3988678] STATEMENT:  SELECT hll_cardinality(hll_union_agg(agg))
	FROM (
	  SELECT hll_add_agg(hll_hash_integer(user_id)) AS agg
	  FROM raw_table)a;
2023-11-25 13:01:51.291 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 13
2023-11-25 13:01:51.291 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.291 UTC [3988678] STATEMENT:  INSERT INTO daily_uniques
	  SELECT day, hll_add_agg(hll_hash_integer(user_id))
	  FROM raw_table
	  GROUP BY 1;
2023-11-25 13:01:51.291 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 48
2023-11-25 13:01:51.291 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.291 UTC [3988678] STATEMENT:  SELECT day, hll_cardinality(unique_users)
	FROM daily_uniques
	WHERE day >= '2018-06-20' and day <= '2018-06-30'
	ORDER BY 2 DESC,1
	LIMIT 10;
2023-11-25 13:01:51.291 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 58
2023-11-25 13:01:51.291 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.291 UTC [3988678] STATEMENT:  SELECT hll_cardinality(hll_union_agg(unique_users))
	FROM daily_uniques
	WHERE day >= '2018-05-24'::date AND day <= '2018-05-31'::date;
2023-11-25 13:01:51.291 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 92
2023-11-25 13:01:51.291 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.291 UTC [3988678] STATEMENT:  SELECT EXTRACT(MONTH FROM day) AS month, hll_cardinality(hll_union_agg(unique_users))
	FROM daily_uniques
	WHERE day >= '2018-06-23' AND day <= '2018-07-01'
	GROUP BY 1
	ORDER BY 1;
2023-11-25 13:01:51.291 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 79
2023-11-25 13:01:51.291 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.291 UTC [3988678] STATEMENT:  SELECT day, hll_cardinality(hll_union_agg(unique_users) OVER seven_days)
	FROM daily_uniques
	WINDOW seven_days AS (ORDER BY day ASC ROWS 6 PRECEDING)
	ORDER BY 1;
2023-11-25 13:01:51.291 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 127
2023-11-25 13:01:51.291 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.291 UTC [3988678] STATEMENT:  SELECT day, (hll_cardinality(hll_union_agg(unique_users) OVER two_days)) - hll_cardinality(unique_users) AS lost_uniques
	FROM daily_uniques
	WINDOW two_days AS (ORDER BY day ASC ROWS 1 PRECEDING)
	ORDER BY 1;
2023-11-25 13:01:51.292 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 69
2023-11-25 13:01:51.292 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.292 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 13:01:51.292 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 69
2023-11-25 13:01:51.292 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.292 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 13:01:51.293 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 100
2023-11-25 13:01:51.293 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.293 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users) || hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 13:01:51.293 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 100
2023-11-25 13:01:51.293 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.293 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_union_agg(unique_users) || hll_union_agg(unique_users)
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 13:01:51.293 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 13:01:51.293 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.293 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 13:01:51.293 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 13:01:51.293 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.293 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 13:01:51.293 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 13:01:51.293 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.293 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1);
2023-11-25 13:01:51.294 UTC [3988678] ERROR:  42P01: relation "daily_uniques" does not exist at character 86
2023-11-25 13:01:51.294 UTC [3988678] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:51.294 UTC [3988678] STATEMENT:  EXPLAIN(COSTS OFF)
	SELECT
	  day, hll_cardinality(hll_union_agg(unique_users))
	FROM
	  daily_uniques
	GROUP BY(1)
	HAVING hll_cardinality(hll_union_agg(unique_users)) > 1;
2023-11-25 13:01:51.308 UTC [3988678] ERROR:  42P01: table "daily_uniques" does not exist
2023-11-25 13:01:51.308 UTC [3988678] LOCATION:  DropErrorMsgNonExistent, tablecmds.c:1290
2023-11-25 13:01:51.308 UTC [3988678] STATEMENT:  DROP TABLE daily_uniques;
2023-11-25 13:01:51.464 UTC [3988678] ERROR:  42883: function topn_add_agg(text) does not exist at character 42
2023-11-25 13:01:51.464 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.464 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.464 UTC [3988678] STATEMENT:  SELECT (topn(agg, 10)).*
	FROM (
	  SELECT topn_add_agg(user_id::text) AS agg
	  FROM customer_reviews
	  )a
	ORDER BY 2 DESC, 1;
2023-11-25 13:01:51.464 UTC [3988678] ERROR:  42883: function topn_add_agg(text) does not exist at character 44
2023-11-25 13:01:51.464 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.464 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.464 UTC [3988678] STATEMENT:  INSERT INTO popular_reviewer
	  SELECT day, topn_add_agg(user_id::text)
	  FROM customer_reviews
	  GROUP BY 1;
2023-11-25 13:01:51.464 UTC [3988678] ERROR:  42883: function topn(jsonb, integer) does not exist at character 14
2023-11-25 13:01:51.464 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.464 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.464 UTC [3988678] STATEMENT:  SELECT day, (topn(reviewers, 10)).*
	FROM popular_reviewer
	WHERE day >= '2018-06-20' and day <= '2018-06-30'
	ORDER BY 3 DESC, 1, 2
	LIMIT 10;
2023-11-25 13:01:51.464 UTC [3988678] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 41
2023-11-25 13:01:51.464 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.464 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.464 UTC [3988678] STATEMENT:  SELECT (topn(agg, 10)).*
	FROM (
		SELECT topn_union_agg(reviewers) AS agg
		FROM popular_reviewer
		WHERE day >= '2018-05-24'::date AND day <= '2018-05-31'::date
		)a
	ORDER BY 2 DESC, 1;
2023-11-25 13:01:51.465 UTC [3988678] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 81
2023-11-25 13:01:51.465 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.465 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.465 UTC [3988678] STATEMENT:  SELECT month, (topn(agg, 5)).*
	FROM (
		SELECT EXTRACT(MONTH FROM day) AS month, topn_union_agg(reviewers) AS agg
		FROM popular_reviewer
		WHERE day >= '2018-06-23' AND day <= '2018-07-01'
		GROUP BY 1
		ORDER BY 1
		)a
	ORDER BY 1, 3 DESC, 2;
2023-11-25 13:01:51.465 UTC [3988678] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 14
2023-11-25 13:01:51.465 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.465 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.465 UTC [3988678] STATEMENT:  SELECT (topn(topn_union_agg(reviewers), 10)).*
	FROM popular_reviewer
	WHERE day >= '2018-05-24'::date AND day <= '2018-05-31'::date
	ORDER BY 2 DESC, 1;
2023-11-25 13:01:51.465 UTC [3988678] ERROR:  42883: function topn_add_agg(text) does not exist at character 14
2023-11-25 13:01:51.465 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.465 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.465 UTC [3988678] STATEMENT:  SELECT (topn(topn_add_agg(user_id::text), 10)).*
	FROM customer_reviews
	ORDER BY 2 DESC, 1;
2023-11-25 13:01:51.465 UTC [3988678] ERROR:  42883: function topn_union_agg(jsonb) does not exist at character 51
2023-11-25 13:01:51.465 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.465 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.465 UTC [3988678] STATEMENT:  SELECT day, (topn(agg, 10)).*
	FROM (
		SELECT day, topn_union_agg(reviewers) OVER seven_days AS agg
		FROM popular_reviewer
		WINDOW seven_days AS (ORDER BY day ASC ROWS 6 PRECEDING)
		)a
	ORDER BY 3 DESC, 1, 2
	LIMIT 10;
2023-11-25 13:01:51.465 UTC [3988678] ERROR:  42883: function topn_add_agg(text) does not exist at character 19
2023-11-25 13:01:51.465 UTC [3988678] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.465 UTC [3988678] LOCATION:  ParseFuncOrColumn, parse_func.c:629
2023-11-25 13:01:51.465 UTC [3988678] STATEMENT:  SELECT day, (topn(topn_add_agg(user_id::text) OVER seven_days, 10)).*
	FROM customer_reviews
	WINDOW seven_days AS (ORDER BY day ASC ROWS 6 PRECEDING)
	ORDER BY 3 DESC, 1, 2
	LIMIT 10;
2023-11-25 13:01:51.624 UTC [3988677] ERROR:  XX000: unsupported aggregate function first
2023-11-25 13:01:51.624 UTC [3988677] LOCATION:  GetAggregateType, multi_logical_optimizer.c:3481
2023-11-25 13:01:51.624 UTC [3988677] STATEMENT:  SELECT key, first(val ORDER BY id), last(val ORDER BY id)
	FROM aggdata GROUP BY key ORDER BY key;
2023-11-25 13:01:51.626 UTC [3988677] ERROR:  XX000: unsupported aggregate function first
2023-11-25 13:01:51.626 UTC [3988677] LOCATION:  GetAggregateType, multi_logical_optimizer.c:3481
2023-11-25 13:01:51.626 UTC [3988677] STATEMENT:  SELECT id%5, first(val ORDER BY key), last(val ORDER BY key)
	FROM aggdata GROUP BY id%5 ORDER BY id%5;
2023-11-25 13:01:51.729 UTC [3988677] ERROR:  0A000: could not run distributed query with GROUPING
2023-11-25 13:01:51.729 UTC [3988677] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:51.729 UTC [3988677] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:51.729 UTC [3988677] STATEMENT:  select grouping(id)
	from aggdata group by id order by 1 limit 3;
2023-11-25 13:01:51.729 UTC [3988677] ERROR:  0A000: could not run distributed query with GROUPING
2023-11-25 13:01:51.729 UTC [3988677] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:51.729 UTC [3988677] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:51.729 UTC [3988677] STATEMENT:  select key, grouping(val)
	from aggdata group by key, val order by 1, 2;
2023-11-25 13:01:51.729 UTC [3988677] ERROR:  0A000: could not run distributed query with GROUPING
2023-11-25 13:01:51.729 UTC [3988677] HINT:  Consider using an equality filter on the distributed table's partition column.
2023-11-25 13:01:51.729 UTC [3988677] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:51.729 UTC [3988677] STATEMENT:  select key, grouping(val), sum(distinct valf)
	from aggdata group by key, val order by 1, 2;
2023-11-25 13:01:51.730 UTC [3988677] ERROR:  XX000: worker_partial_agg_sfunc could not confirm type correctness
2023-11-25 13:01:51.730 UTC [3988677] LOCATION:  worker_partial_agg_sfunc, aggregate_utils.c:517
2023-11-25 13:01:51.730 UTC [3988677] STATEMENT:  select pg_catalog.worker_partial_agg('string_agg(text,text)'::regprocedure, id) from nulltable;
2023-11-25 13:01:51.730 UTC [3988677] ERROR:  XX000: worker_partial_agg_sfunc could not confirm type correctness
2023-11-25 13:01:51.730 UTC [3988677] LOCATION:  worker_partial_agg_sfunc, aggregate_utils.c:517
2023-11-25 13:01:51.730 UTC [3988677] STATEMENT:  select pg_catalog.worker_partial_agg('sum(int8)'::regprocedure, id) from nulltable;
2023-11-25 13:01:51.730 UTC [3988677] ERROR:  XX000: coord_combine_agg_ffunc could not confirm type correctness
2023-11-25 13:01:51.730 UTC [3988677] LOCATION:  coord_combine_agg_ffunc, aggregate_utils.c:817
2023-11-25 13:01:51.730 UTC [3988677] STATEMENT:  select pg_catalog.coord_combine_agg('sum(float8)'::regprocedure, id::text::cstring, null::text) from nulltable;
2023-11-25 13:01:51.730 UTC [3988677] ERROR:  XX000: coord_combine_agg_ffunc could not confirm type correctness
2023-11-25 13:01:51.730 UTC [3988677] LOCATION:  coord_combine_agg_ffunc, aggregate_utils.c:817
2023-11-25 13:01:51.730 UTC [3988677] STATEMENT:  select pg_catalog.coord_combine_agg('avg(float8)'::regprocedure, ARRAY[id,id,id]::text::cstring, null::text) from nulltable;
2023-11-25 13:01:51.766 UTC [3988677] ERROR:  42883: function aggregate_support.square_func(integer) does not exist
2023-11-25 13:01:51.766 UTC [3988677] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.766 UTC [3988677] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:51.766 UTC [3988677] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:51.766 UTC [3988677] STATEMENT:  SELECT square_func(5), a FROM t1 GROUP BY a;
2023-11-25 13:01:51.773 UTC [3988677] ERROR:  42883: function aggregate_support.square_func(integer) does not exist
2023-11-25 13:01:51.773 UTC [3988677] HINT:  No function matches the given name and argument types. You might need to add explicit type casts.
2023-11-25 13:01:51.773 UTC [3988677] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:51.773 UTC [3988677] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:51.773 UTC [3988677] STATEMENT:  SELECT square_func(5), a, count(a) FROM t1 GROUP BY a;
2023-11-25 13:01:51.822 UTC [3988677] WARNING:  0A000: "function dummy_fnc(dummy_tbl,double precision)" has dependency to "table dummy_tbl" that is not in Citus' metadata
2023-11-25 13:01:51.822 UTC [3988677] DETAIL:  "function dummy_fnc(dummy_tbl,double precision)" will be created only locally
2023-11-25 13:01:51.822 UTC [3988677] HINT:  Distribute "table dummy_tbl" first to distribute "function dummy_fnc(dummy_tbl,double precision)"
2023-11-25 13:01:51.822 UTC [3988677] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:51.823 UTC [3988677] WARNING:  0A000: "function dependent_agg(double precision)" has dependency to "table dummy_tbl" that is not in Citus' metadata
2023-11-25 13:01:51.823 UTC [3988677] DETAIL:  "function dependent_agg(double precision)" will be created only locally
2023-11-25 13:01:51.823 UTC [3988677] HINT:  Distribute "table dummy_tbl" first to distribute "function dependent_agg(double precision)"
2023-11-25 13:01:51.823 UTC [3988677] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:52.605 UTC [3989053] ERROR:  0A000: array_agg (distinct) is unsupported
2023-11-25 13:01:52.605 UTC [3989053] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4016
2023-11-25 13:01:52.605 UTC [3989053] STATEMENT:  SELECT array_agg(distinct l_orderkey) FROM lineitem;
2023-11-25 13:01:52.605 UTC [3989053] ERROR:  0A000: array_agg with order by is unsupported
2023-11-25 13:01:52.605 UTC [3989053] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4008
2023-11-25 13:01:52.605 UTC [3989053] STATEMENT:  SELECT array_agg(l_orderkey ORDER BY l_partkey) FROM lineitem;
2023-11-25 13:01:52.605 UTC [3989053] ERROR:  0A000: array_agg with order by is unsupported
2023-11-25 13:01:52.605 UTC [3989053] LOCATION:  DeferErrorIfUnsupportedArrayAggregate, multi_logical_optimizer.c:4008
2023-11-25 13:01:52.605 UTC [3989053] STATEMENT:  SELECT array_agg(distinct l_orderkey ORDER BY l_orderkey) FROM lineitem;
2023-11-25 13:01:52.843 UTC [3989052] ERROR:  0A000: subquery in LIMIT is not supported in multi-shard queries
2023-11-25 13:01:52.843 UTC [3989052] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:52.843 UTC [3989052] STATEMENT:  SELECT l_orderkey FROM lineitem_hash ORDER BY l_orderkey LIMIT (SELECT 10);
2023-11-25 13:01:52.843 UTC [3989052] ERROR:  0A000: subquery in OFFSET is not supported in multi-shard queries
2023-11-25 13:01:52.843 UTC [3989052] LOCATION:  DeferErrorIfQueryNotSupported, multi_logical_planner.c:945
2023-11-25 13:01:52.843 UTC [3989052] STATEMENT:  SELECT l_orderkey FROM lineitem_hash ORDER BY l_orderkey LIMIT 10 OFFSET (SELECT 10);
2023-11-25 13:01:53.047 UTC [3989212] ERROR:  0A000: jsonb_agg (distinct) is unsupported
2023-11-25 13:01:53.047 UTC [3989212] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.047 UTC [3989212] STATEMENT:  SELECT jsonb_agg(distinct l_orderkey) FROM lineitem;
2023-11-25 13:01:53.048 UTC [3989212] ERROR:  0A000: jsonb_agg with order by is unsupported
2023-11-25 13:01:53.048 UTC [3989212] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.048 UTC [3989212] STATEMENT:  SELECT jsonb_agg(l_orderkey ORDER BY l_partkey) FROM lineitem;
2023-11-25 13:01:53.048 UTC [3989212] ERROR:  0A000: jsonb_agg with order by is unsupported
2023-11-25 13:01:53.048 UTC [3989212] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.048 UTC [3989212] STATEMENT:  SELECT jsonb_agg(distinct l_orderkey ORDER BY l_orderkey) FROM lineitem;
2023-11-25 13:01:53.053 UTC [3989216] ERROR:  0A000: json_agg (distinct) is unsupported
2023-11-25 13:01:53.053 UTC [3989216] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.053 UTC [3989216] STATEMENT:  SELECT json_agg(distinct l_orderkey) FROM lineitem;
2023-11-25 13:01:53.053 UTC [3989216] ERROR:  0A000: json_agg with order by is unsupported
2023-11-25 13:01:53.053 UTC [3989216] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.053 UTC [3989216] STATEMENT:  SELECT json_agg(l_orderkey ORDER BY l_partkey) FROM lineitem;
2023-11-25 13:01:53.054 UTC [3989216] ERROR:  0A000: json_agg with order by is unsupported
2023-11-25 13:01:53.054 UTC [3989216] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.054 UTC [3989216] STATEMENT:  SELECT json_agg(distinct l_orderkey ORDER BY l_orderkey) FROM lineitem;
2023-11-25 13:01:53.056 UTC [3989217] ERROR:  0A000: json_object_agg (distinct) is unsupported
2023-11-25 13:01:53.056 UTC [3989217] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.056 UTC [3989217] STATEMENT:  SELECT json_object_agg(distinct l_shipmode, l_orderkey) FROM lineitem;
2023-11-25 13:01:53.057 UTC [3989217] ERROR:  0A000: json_object_agg with order by is unsupported
2023-11-25 13:01:53.057 UTC [3989217] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.057 UTC [3989217] STATEMENT:  SELECT json_object_agg(l_shipmode, l_orderkey ORDER BY l_shipmode) FROM lineitem;
2023-11-25 13:01:53.057 UTC [3989217] ERROR:  0A000: json_object_agg with order by is unsupported
2023-11-25 13:01:53.057 UTC [3989217] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.057 UTC [3989217] STATEMENT:  SELECT json_object_agg(distinct l_orderkey, l_shipmode ORDER BY l_orderkey) FROM lineitem;
2023-11-25 13:01:53.082 UTC [3989214] ERROR:  0A000: jsonb_object_agg (distinct) is unsupported
2023-11-25 13:01:53.082 UTC [3989214] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.082 UTC [3989214] STATEMENT:  SELECT jsonb_object_agg(distinct l_shipmode, l_orderkey) FROM lineitem;
2023-11-25 13:01:53.082 UTC [3989214] ERROR:  0A000: jsonb_object_agg with order by is unsupported
2023-11-25 13:01:53.082 UTC [3989214] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.082 UTC [3989214] STATEMENT:  SELECT jsonb_object_agg(l_shipmode, l_orderkey ORDER BY l_shipmode) FROM lineitem;
2023-11-25 13:01:53.082 UTC [3989214] ERROR:  0A000: jsonb_object_agg with order by is unsupported
2023-11-25 13:01:53.082 UTC [3989214] LOCATION:  DeferErrorIfUnsupportedJsonAggregate, multi_logical_optimizer.c:4051
2023-11-25 13:01:53.082 UTC [3989214] STATEMENT:  SELECT jsonb_object_agg(distinct l_orderkey, l_shipmode ORDER BY l_orderkey) FROM lineitem;
2023-11-25 13:01:53.204 UTC [3989219] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 13:01:53.204 UTC [3989219] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 13:01:53.204 UTC [3989219] STATEMENT:  select     s_i_id, sum(s_order_cnt) as ordercount
	from     stock s
	where   s_order_cnt > (select sum(s_order_cnt) * .005 as where_query from stock)
	group by s_i_id
	having   (select max(s_order_cnt) > 2 as having_query from stock where s_i_id = s.s_i_id)
	order by s_i_id;
2023-11-25 13:01:53.205 UTC [3989219] ERROR:  0A000: Subqueries in HAVING cannot refer to outer query
2023-11-25 13:01:53.205 UTC [3989219] LOCATION:  RecursivelyPlanSubqueriesAndCTEs, recursive_planning.c:323
2023-11-25 13:01:53.205 UTC [3989219] STATEMENT:  select     s_i_id, sum(s_order_cnt) as ordercount
	from     stock s
	group by s_i_id
	having   (select max(s_order_cnt) > 2 as having_query from stock where s_i_id = s.s_i_id)
	order by s_i_id;
2023-11-25 13:01:53.403 UTC [3989222] ERROR:  0A000: complex joins are only supported when all distributed tables are joined on their distribution columns with equal operator
2023-11-25 13:01:53.403 UTC [3989222] LOCATION:  JoinOrderList, multi_join_order.c:310
2023-11-25 13:01:53.403 UTC [3989222] STATEMENT:  SELECT *
	FROM
	    test t1 JOIN test t2 USING (y), -- causes repartition, which makes this not routable or pushdownable
	    test a,
	    test b
	WHERE t2.y - a.x - b.x = 0
	ORDER BY 1,2,3;
2023-11-25 13:01:53.599 UTC [3989220] LOG:  00000: join order: [ "order_line" ]
2023-11-25 13:01:53.599 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.599 UTC [3989220] STATEMENT:  SELECT
	    ol_number,
	    sum(ol_quantity) as sum_qty,
	    sum(ol_amount) as sum_amount,
	    avg(ol_quantity) as avg_qty,
	    avg(ol_amount) as avg_amount,
	    count(*) as count_order
	FROM order_line
	WHERE ol_delivery_d > '2007-01-02 00:00:00.000000'
	GROUP BY ol_number
	ORDER BY ol_number;
2023-11-25 13:01:53.603 UTC [3989220] LOG:  00000: join order: [ "stock" ][ reference join "supplier" ][ reference join "nation" ][ reference join "region" ]
2023-11-25 13:01:53.603 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.603 UTC [3989220] STATEMENT:  SELECT
	    su_suppkey,
	    su_name,
	    n_name,
	    i_id,
	    i_name,
	    su_address,
	    su_phone,
	    su_comment
	FROM
	    item,
	    supplier,
	    stock,
	    nation,
	    region,
	    (SELECT
	         s_i_id AS m_i_id,
	         min(s_quantity) as m_s_quantity
	     FROM
	         stock,
	         supplier,
	         nation,
	         region
	     WHERE mod((s_w_id*s_i_id),10000)=su_suppkey
	       AND su_nationkey=n_nationkey
	       AND n_regionkey=r_regionkey
	       AND r_name LIKE 'Europ%'
	     GROUP BY s_i_id) m
	WHERE i_id = s_i_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND su_nationkey = n_nationkey
	  AND n_regionkey = r_regionkey
	  AND i_data LIKE '%b'
	  AND r_name LIKE 'Europ%'
	  AND i_id = m_i_id
	  AND s_quantity = m_s_quantity
	ORDER BY
	    n_name,
	    su_name,
	    i_id;
2023-11-25 13:01:53.612 UTC [3989220] LOG:  00000: join order: [ "customer" ][ local partition join "oorder" ][ local partition join "new_order" ][ local partition join "order_line" ]
2023-11-25 13:01:53.612 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.612 UTC [3989220] STATEMENT:  SELECT
	    ol_o_id,
	    ol_w_id,
	    ol_d_id,
	    sum(ol_amount) AS revenue,
	    o_entry_d
	FROM
	    customer,
	    new_order,
	    oorder,
	    order_line
	WHERE c_state LIKE 'C%' -- used to ba A%, but C% works with our small data
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND no_w_id = o_w_id
	  AND no_d_id = o_d_id
	  AND no_o_id = o_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND o_entry_d > '2007-01-02 00:00:00.000000'
	GROUP BY
	    ol_o_id,
	    ol_w_id,
	    ol_d_id,
	    o_entry_d
	ORDER BY
	    revenue DESC,
	    o_entry_d;
2023-11-25 13:01:53.622 UTC [3989220] LOG:  00000: join order: [ "customer" ][ local partition join "oorder" ][ local partition join "order_line" ][ local partition join "stock" ][ reference join "supplier" ][ reference join "nation" ][ reference join "region" ]
2023-11-25 13:01:53.622 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.622 UTC [3989220] STATEMENT:  SELECT
	    n_name,
	    sum(ol_amount) AS revenue
	FROM
	    customer,
	    oorder,
	    order_line,
	    stock,
	    supplier,
	    nation,
	    region
	WHERE c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id=o_d_id
	  AND ol_w_id = s_w_id
	  AND ol_i_id = s_i_id
	  AND mod((s_w_id * s_i_id),10000) = su_suppkey
	-- our dataset does not have the supplier in the same nation as the customer causing this
	-- join to filter out all the data. We verify later on that we can actually perform an
	-- ascii(substr(c_state,1,1)) == reference table column join later on so it should not
	-- matter we skip this filter here.
	--AND ascii(substr(c_state,1,1)) = su_nationkey
	  AND su_nationkey = n_nationkey
	  AND n_regionkey = r_regionkey
	  AND r_name = 'Europe'
	  AND o_entry_d >= '2007-01-02 00:00:00.000000'
	GROUP BY n_name
	ORDER BY revenue DESC;
2023-11-25 13:01:53.631 UTC [3989220] LOG:  00000: join order: [ "order_line" ]
2023-11-25 13:01:53.631 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.631 UTC [3989220] STATEMENT:  SELECT
	    sum(ol_amount) AS revenue
	FROM order_line
	WHERE ol_delivery_d >= '1999-01-01 00:00:00.000000'
	  AND ol_delivery_d < '2020-01-01 00:00:00.000000'
	  AND ol_quantity BETWEEN 1 AND 100000;
2023-11-25 13:01:53.637 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "nation" ][ reference join "supplier" ][ dual partition join "stock" ]
2023-11-25 13:01:53.637 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.637 UTC [3989220] STATEMENT:  SELECT
	    su_nationkey as supp_nation,
	    substr(c_state,1,1) as cust_nation,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as revenue
	FROM
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2
	WHERE ol_supply_w_id = s_w_id
	  AND ol_i_id = s_i_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND su_nationkey = n1.n_nationkey
	  AND ascii(substr(c_state,1,1)) = n2.n_nationkey
	  AND (
	         (n1.n_name = 'Germany' AND n2.n_name = 'Cambodia')
	      OR (n1.n_name = 'Cambodia' AND n2.n_name = 'Germany')
	      )
	  AND ol_delivery_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	GROUP BY
	    su_nationkey,
	    substr(c_state,1,1),
	    extract(year from o_entry_d)
	ORDER BY
	    su_nationkey,
	    cust_nation,
	    l_year;
2023-11-25 13:01:53.721 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "region" ][ dual partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 13:01:53.721 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.721 UTC [3989220] STATEMENT:  SELECT
	    extract(year from o_entry_d) as l_year,
	    sum(case when n2.n_name = 'Germany' then ol_amount else 0 end) / sum(ol_amount) as mkt_share
	FROM
	    item,
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2,
	    region
	WHERE i_id = s_i_id
	  AND ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id),10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND n1.n_nationkey = ascii(substr(c_state,1,1))
	  AND n1.n_regionkey = r_regionkey
	  AND ol_i_id < 1000
	  AND r_name = 'Europe'
	  AND su_nationkey = n2.n_nationkey
	  AND o_entry_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	  AND i_data LIKE '%b'
	  AND i_id = ol_i_id
	GROUP BY extract(YEAR FROM o_entry_d)
	ORDER BY l_year;
2023-11-25 13:01:53.802 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ dual partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 13:01:53.802 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.802 UTC [3989220] STATEMENT:  SELECT
	    n_name,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as sum_profit
	FROM
	    item,
	    stock,
	    supplier,
	    order_line,
	    oorder,
	    nation
	WHERE ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND ol_i_id = i_id
	  AND su_nationkey = n_nationkey
	  AND i_data LIKE '%b' -- this used to be %BB but that will not work with our small dataset
	GROUP BY
	    n_name,
	    extract(YEAR FROM o_entry_d)
	ORDER BY
	    n_name,
	    l_year DESC;
2023-11-25 13:01:53.880 UTC [3989220] LOG:  00000: join order: [ "customer" ][ reference join "nation" ][ local partition join "oorder" ][ local partition join "order_line" ]
2023-11-25 13:01:53.880 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.880 UTC [3989220] STATEMENT:  SELECT
	    c_id,
	    c_last,
	    sum(ol_amount) AS revenue,
	    c_city,
	    c_phone,
	    n_name
	FROM
	    customer,
	    oorder,
	    order_line,
	    nation
	WHERE c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND o_entry_d >= '2007-01-02 00:00:00.000000'
	  AND o_entry_d <= ol_delivery_d
	  AND n_nationkey = ascii(substr(c_state,1,1))
	GROUP BY
	    c_id,
	    c_last,
	    c_city,
	    c_phone,
	    n_name
	ORDER BY revenue DESC;
2023-11-25 13:01:53.885 UTC [3989220] LOG:  00000: join order: [ "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 13:01:53.885 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.885 UTC [3989220] STATEMENT:  SELECT
	    s_i_id,
	    sum(s_order_cnt) AS ordercount
	FROM
	    stock,
	    supplier,
	    nation
	WHERE mod((s_w_id * s_i_id),10000) = su_suppkey
	  AND su_nationkey = n_nationkey
	  AND n_name = 'Germany'
	GROUP BY s_i_id
	HAVING sum(s_order_cnt) >
	         (SELECT sum(s_order_cnt) * .005
	          FROM
	              stock,
	              supplier,
	              nation
	          WHERE mod((s_w_id * s_i_id),10000) = su_suppkey
	            AND su_nationkey = n_nationkey
	            AND n_name = 'Germany')
	ORDER BY ordercount DESC;
2023-11-25 13:01:53.891 UTC [3989220] LOG:  00000: join order: [ "oorder" ][ local partition join "order_line" ]
2023-11-25 13:01:53.891 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.891 UTC [3989220] STATEMENT:  SELECT
	    o_ol_cnt,
	    sum(case when o_carrier_id = 1 or o_carrier_id = 2 then 1 else 0 end) as high_line_count,
	    sum(case when o_carrier_id <> 1 and o_carrier_id <> 2 then 1 else 0 end) as low_line_count
	FROM
	    oorder,
	    order_line
	WHERE ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND o_entry_d <= ol_delivery_d
	  AND ol_delivery_d < '2020-01-01 00:00:00.000000'
	GROUP BY o_ol_cnt
	ORDER BY o_ol_cnt;
2023-11-25 13:01:53.898 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ reference join "item" ]
2023-11-25 13:01:53.898 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.898 UTC [3989220] STATEMENT:  SELECT
	    100.00 * sum(CASE WHEN i_data LIKE 'PR%' THEN ol_amount ELSE 0 END) / (1+sum(ol_amount)) AS promo_revenue
	FROM
	    order_line,
	    item
	WHERE ol_i_id = i_id
	  AND ol_delivery_d >= '2007-01-02 00:00:00.000000'
	  AND ol_delivery_d < '2020-01-02 00:00:00.000000';
2023-11-25 13:01:53.902 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ dual partition join "stock" ]
2023-11-25 13:01:53.902 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.902 UTC [3989220] STATEMENT:  WITH revenue (supplier_no, total_revenue) AS (
	    SELECT
	        mod((s_w_id * s_i_id),10000) AS supplier_no,
	        sum(ol_amount) AS total_revenue
	    FROM
	        order_line,
	        stock
	    WHERE ol_i_id = s_i_id
	      AND ol_supply_w_id = s_w_id
	      AND ol_delivery_d >= '2007-01-02 00:00:00.000000'
	    GROUP BY mod((s_w_id * s_i_id),10000))
	SELECT
	    su_suppkey,
	    su_name,
	    su_address,
	    su_phone,
	    total_revenue
	FROM
	    supplier,
	    revenue
	WHERE su_suppkey = supplier_no
	  AND total_revenue = (SELECT max(total_revenue) FROM revenue)
	ORDER BY su_suppkey;
2023-11-25 13:01:53.985 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ reference join "item" ]
2023-11-25 13:01:53.985 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.985 UTC [3989220] STATEMENT:  SELECT
	       sum(ol_amount) / 2.0 AS avg_yearly
	FROM
	    order_line,
	    (SELECT
	         i_id,
	         avg(ol_quantity) AS a
	     FROM
	         item,
	         order_line
	     WHERE i_data LIKE '%b'
	       AND ol_i_id = i_id
	     GROUP BY i_id) t
	WHERE ol_i_id = t.i_id;
2023-11-25 13:01:53.990 UTC [3989220] LOG:  00000: join order: [ "customer" ][ local partition join "oorder" ][ local partition join "order_line" ]
2023-11-25 13:01:53.990 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.990 UTC [3989220] STATEMENT:  SELECT
	    c_last,
	    c_id o_id,
	    o_entry_d,
	    o_ol_cnt,
	    sum(ol_amount)
	FROM
	    customer,
	    oorder,
	    order_line
	WHERE c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	GROUP BY
	    o_id,
	    o_w_id,
	    o_d_id,
	    c_id,
	    c_last,
	    o_entry_d,
	    o_ol_cnt
	HAVING sum(ol_amount) > 5 -- was 200, but thats too big for the dataset
	ORDER BY
	    sum(ol_amount) DESC,
	    o_entry_d;
2023-11-25 13:01:53.993 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ reference join "item" ]
2023-11-25 13:01:53.993 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.993 UTC [3989220] STATEMENT:  SELECT
	    sum(ol_amount) AS revenue
	FROM
	    order_line,
	     item
	WHERE (     ol_i_id = i_id
	        AND i_data LIKE '%a'
	        AND ol_quantity >= 1
	        AND ol_quantity <= 10
	        AND i_price BETWEEN 1 AND 400000
	        AND ol_w_id IN (1,2,3))
	   OR (     ol_i_id = i_id
	        AND i_data LIKE '%b'
	        AND ol_quantity >= 1
	        AND ol_quantity <= 10
	        AND i_price BETWEEN 1 AND 400000
	        AND ol_w_id IN (1,2,4))
	   OR (     ol_i_id = i_id
	        AND i_data LIKE '%c'
	        AND ol_quantity >= 1
	        AND ol_quantity <= 10
	        AND i_price BETWEEN 1 AND 400000
	        AND ol_w_id IN (1,5,3));
2023-11-25 13:01:53.997 UTC [3989220] LOG:  00000: join order: [ "stock" ][ reference join "item" ][ dual partition join "order_line" ]
2023-11-25 13:01:53.997 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:53.997 UTC [3989220] STATEMENT:  SELECT
	    su_name,
	    su_address
	FROM
	    supplier,
	    nation
	WHERE su_suppkey in
	      (SELECT
	           mod(s_i_id * s_w_id, 10000)
	       FROM
	           stock,
	           order_line
	       WHERE s_i_id IN
	             (SELECT i_id
	              FROM item
	              WHERE i_data LIKE 'co%')
	       AND ol_i_id = s_i_id
	       AND ol_delivery_d > '2008-05-23 12:00:00' -- was 2010, but our order is in 2008
	       GROUP BY s_i_id, s_w_id, s_quantity
	       HAVING   2*s_quantity > sum(ol_quantity))
	  AND su_nationkey = n_nationkey
	  AND n_name = 'Germany'
	ORDER BY su_name;
2023-11-25 13:01:54.083 UTC [3989220] LOG:  00000: join order: [ "customer" ]
2023-11-25 13:01:54.083 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:54.083 UTC [3989220] STATEMENT:  SELECT
	    substr(c_state,1,1) AS country,
	    count(*) AS numcust,
	    sum(c_balance) AS totacctbal
	FROM customer
	WHERE substr(c_phone,1,1) in ('1','2','3','4','5','6','7')
	  AND c_balance > (SELECT avg(c_BALANCE)
	                   FROM customer
	                   WHERE  c_balance > 0.00
	                     AND substr(c_phone,1,1) in ('1','2','3','4','5','6','7'))
	  AND NOT exists (SELECT *
	                  FROM oorder
	                  WHERE o_c_id = c_id
	                    AND o_w_id = c_w_id
	                    AND o_d_id = c_d_id)
	GROUP BY substr(c_state,1,1)
	ORDER BY substr(c_state,1,1);
2023-11-25 13:01:54.092 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "nation" ][ reference join "supplier" ][ single hash partition join "stock" ]
2023-11-25 13:01:54.092 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:54.092 UTC [3989220] STATEMENT:  SELECT
	    su_nationkey as supp_nation,
	    substr(c_state,1,1) as cust_nation,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as revenue
	FROM
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2
	WHERE ol_supply_w_id = s_w_id
	  AND ol_i_id = s_i_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND su_nationkey = n1.n_nationkey
	  AND ascii(substr(c_state,1,1)) = n2.n_nationkey
	  AND (
	        (n1.n_name = 'Germany' AND n2.n_name = 'Cambodia')
	        OR (n1.n_name = 'Cambodia' AND n2.n_name = 'Germany')
	    )
	  AND ol_delivery_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	GROUP BY
	    su_nationkey,
	    substr(c_state,1,1),
	    extract(year from o_entry_d)
	ORDER BY
	    su_nationkey,
	    cust_nation,
	    l_year;
2023-11-25 13:01:54.150 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ local partition join "customer" ][ reference join "nation" ][ reference join "region" ][ single hash partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 13:01:54.150 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:54.150 UTC [3989220] STATEMENT:  SELECT
	    extract(year from o_entry_d) as l_year,
	    sum(case when n2.n_name = 'Germany' then ol_amount else 0 end) / sum(ol_amount) as mkt_share
	FROM
	    item,
	    supplier,
	    stock,
	    order_line,
	    oorder,
	    customer,
	    nation n1,
	    nation n2,
	    region
	WHERE i_id = s_i_id
	  AND ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id),10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND c_id = o_c_id
	  AND c_w_id = o_w_id
	  AND c_d_id = o_d_id
	  AND n1.n_nationkey = ascii(substr(c_state,1,1))
	  AND n1.n_regionkey = r_regionkey
	  AND ol_i_id < 1000
	  AND r_name = 'Europe'
	  AND su_nationkey = n2.n_nationkey
	  AND o_entry_d BETWEEN '2007-01-02 00:00:00.000000' AND '2012-01-02 00:00:00.000000'
	  AND i_data LIKE '%b'
	  AND i_id = ol_i_id
	GROUP BY extract(YEAR FROM o_entry_d)
	ORDER BY l_year;
2023-11-25 13:01:54.205 UTC [3989220] LOG:  00000: join order: [ "order_line" ][ reference join "item" ][ local partition join "oorder" ][ single hash partition join "stock" ][ reference join "supplier" ][ reference join "nation" ]
2023-11-25 13:01:54.205 UTC [3989220] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:54.205 UTC [3989220] STATEMENT:  SELECT
	    n_name,
	    extract(year from o_entry_d) as l_year,
	    sum(ol_amount) as sum_profit
	FROM
	    item,
	    stock,
	    supplier,
	    order_line,
	    oorder,
	    nation
	WHERE ol_i_id = s_i_id
	  AND ol_supply_w_id = s_w_id
	  AND mod((s_w_id * s_i_id), 10000) = su_suppkey
	  AND ol_w_id = o_w_id
	  AND ol_d_id = o_d_id
	  AND ol_o_id = o_id
	  AND ol_i_id = i_id
	  AND su_nationkey = n_nationkey
	  AND i_data LIKE '%b' -- this used to be %BB but that will not work with our small dataset
	GROUP BY
	    n_name,
	    extract(YEAR FROM o_entry_d)
	ORDER BY
	    n_name,
	    l_year DESC;
2023-11-25 13:01:54.916 UTC [3990105] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:54.916 UTC [3990105] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:54.916 UTC [3990105] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 13:01:54.916 UTC [3990105] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:54.916 UTC [3990105] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:54.916 UTC [3990105] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id not in (select i_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 13:01:54.917 UTC [3990105] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:54.917 UTC [3990105] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:54.917 UTC [3990105] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id not in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 13:01:54.920 UTC [3990105] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:54.920 UTC [3990105] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:54.920 UTC [3990105] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_id from item)
	        AND s_i_id not in (select i_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 13:01:54.920 UTC [3990105] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:54.920 UTC [3990105] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:54.920 UTC [3990105] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_id from item)
	        AND s_i_id not in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 13:01:54.920 UTC [3990105] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:54.920 UTC [3990105] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:54.920 UTC [3990105] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_im_id from item)
	        AND s_i_id not in (select i_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 13:01:54.921 UTC [3990105] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:54.921 UTC [3990105] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:54.921 UTC [3990105] STATEMENT:  select  s_i_id
	    from stock, order_line
	    where
	        s_i_id in (select i_im_id from item)
	        AND s_i_id not in (select i_im_id from item)
	        AND s_i_id = ol_i_id;
2023-11-25 13:01:55.444 UTC [3990434] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:55.444 UTC [3990434] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:55.444 UTC [3990434] STATEMENT:  SELECT count(*)
	FROM distributed_table u1
	JOIN local_table u2 USING(value)
	JOIN LATERAL
	  (SELECT value,
	          random()
	   FROM distributed_table
	   WHERE u2.value = 15) AS u3 USING (value)
	WHERE (u2.value > 2
	       AND FALSE);
2023-11-25 13:01:55.691 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 13:01:55.691 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.691 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 13:01:55.692 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.692 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.692 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.692 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 13:01:55.692 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_first" ]
2023-11-25 13:01:55.692 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.692 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		t2.sum = t1.id;
2023-11-25 13:01:55.693 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.693 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.693 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.693 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		t2.sum = t1.id;
2023-11-25 13:01:55.693 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_second" ][ reference join "ref_table" ][ single hash partition join "single_hash_repartition_first" ]
2023-11-25 13:01:55.693 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.693 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		ref_table r1, single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		r1.id = t1.id AND t2.sum = t1.id;
2023-11-25 13:01:55.693 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.693 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.693 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.693 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		ref_table r1, single_hash_repartition_second t1, single_hash_repartition_first t2
	WHERE
		r1.id = t1.id AND t2.sum = t1.id;
2023-11-25 13:01:55.693 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ local partition join "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 13:01:55.693 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.693 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.sum = t3.id;
2023-11-25 13:01:55.694 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.694 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.694 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.694 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.sum = t3.id;
2023-11-25 13:01:55.694 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ][ dual partition join "single_hash_repartition_first" ]
2023-11-25 13:01:55.694 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.694 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.sum = t2.sum AND t1.sum = t3.id;
2023-11-25 13:01:55.695 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.695 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.695 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.695 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.sum = t2.sum AND t1.sum = t3.id;
2023-11-25 13:01:55.697 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_second" ][ cartesian product "single_hash_repartition_first" ][ dual partition join "single_hash_repartition_first" ]
2023-11-25 13:01:55.697 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.697 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.avg = t3.id;
2023-11-25 13:01:55.697 UTC [3990553] ERROR:  0A000: cannot perform distributed planning on this query
2023-11-25 13:01:55.697 UTC [3990553] DETAIL:  Cartesian products are currently unsupported
2023-11-25 13:01:55.697 UTC [3990553] LOCATION:  JoinSequenceArray, multi_physical_planner.c:3589
2023-11-25 13:01:55.697 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_first t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.id AND t1.avg = t3.id;
2023-11-25 13:01:55.697 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 13:01:55.697 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.697 UTC [3990553] STATEMENT:  EXPLAIN WITH cte1 AS
	(
		SELECT
			t1.id * t2.avg as data
		FROM
			single_hash_repartition_first t1, single_hash_repartition_second t2
		WHERE
			t1.id = t2.sum
		AND t1.sum > 5000
		ORDER BY 1 DESC
		LIMIT 50
	)
	SELECT
		count(*)
	FROM
		cte1, single_hash_repartition_first
	WHERE
		cte1.data > single_hash_repartition_first.id;
2023-11-25 13:01:55.698 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 13:01:55.698 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.698 UTC [3990553] STATEMENT:  EXPLAIN WITH cte1 AS
	(
		SELECT
			t1.id * t2.avg as data
		FROM
			single_hash_repartition_first t1, single_hash_repartition_second t2
		WHERE
			t1.id = t2.sum
		AND t1.sum > 5000
		ORDER BY 1 DESC
		LIMIT 50
	)
	SELECT
		count(*)
	FROM
		cte1, single_hash_repartition_first
	WHERE
		cte1.data > single_hash_repartition_first.id;
2023-11-25 13:01:55.699 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.699 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.699 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.699 UTC [3990553] STATEMENT:  EXPLAIN WITH cte1 AS
	(
		SELECT
			t1.id * t2.avg as data
		FROM
			single_hash_repartition_first t1, single_hash_repartition_second t2
		WHERE
			t1.id = t2.sum
		AND t1.sum > 5000
		ORDER BY 1 DESC
		LIMIT 50
	)
	SELECT
		count(*)
	FROM
		cte1, single_hash_repartition_first
	WHERE
		cte1.data > single_hash_repartition_first.id;
2023-11-25 13:01:55.700 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 13:01:55.700 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.700 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.sum = t3.id;
2023-11-25 13:01:55.701 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.701 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.701 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.701 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.sum = t3.id;
2023-11-25 13:01:55.701 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_second" ][ single hash partition join "single_hash_repartition_first" ]
2023-11-25 13:01:55.701 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.701 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		avg(t1.avg + t2.avg)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.id = t3.sum
	LIMIT 10;
2023-11-25 13:01:55.702 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.702 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.702 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.702 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		avg(t1.avg + t2.avg)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2, single_hash_repartition_second t3
	WHERE
		t1.id = t2.sum AND t2.id = t3.sum
	LIMIT 10;
2023-11-25 13:01:55.702 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 13:01:55.702 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.702 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 13:01:55.703 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.703 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.703 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.703 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.id = t2.sum;
2023-11-25 13:01:55.703 UTC [3990553] LOG:  00000: join order: [ "single_hash_repartition_first" ][ single hash partition join "single_hash_repartition_second" ]
2023-11-25 13:01:55.703 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.703 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.sum = t2.id;
2023-11-25 13:01:55.703 UTC [3990553] ERROR:  XX000: the query contains a join that requires repartitioning
2023-11-25 13:01:55.703 UTC [3990553] HINT:  Set citus.enable_repartition_joins to on to enable repartitioning
2023-11-25 13:01:55.703 UTC [3990553] LOCATION:  JobExecutorType, multi_server_executor.c:68
2023-11-25 13:01:55.703 UTC [3990553] STATEMENT:  EXPLAIN SELECT
		count(*)
	FROM
		single_hash_repartition_first t1, single_hash_repartition_second t2
	WHERE
		t1.sum = t2.id;
2023-11-25 13:01:55.709 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.709 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref)
2023-11-25 13:01:55.709 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.709 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM ref,
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.710 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.710 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a VALUES clause
2023-11-25 13:01:55.710 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.710 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM (VALUES (1), (3)) ref(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.710 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.710 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from complex subqueries, CTEs or local tables
2023-11-25 13:01:55.710 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.710 UTC [3990552] STATEMENT:  WITH ref(a) as (select y from test)
	SELECT count(*)
	FROM ref,
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.710 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.710 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a table function (ref)
2023-11-25 13:01:55.710 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.710 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM generate_series(1, 3) ref(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.711 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.711 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a subquery without FROM (ref)
2023-11-25 13:01:55.711 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.711 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM (SELECT generate_series(1, 3)) ref(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.711 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.711 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref_table)
2023-11-25 13:01:55.711 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.711 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM ref ref_table,
	    (VALUES (1), (3)) rec_values(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref_table.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.711 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.711 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a VALUES clause
2023-11-25 13:01:55.711 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.711 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM ref as ref_table,
	    (VALUES (1), (3)) ref_values(a),
	    LATERAL (
	        SELECT
	            test.y
	        FROM test
	        WHERE
	            test.y = ref_values.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.711 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.711 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref_outer)
2023-11-25 13:01:55.711 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.711 UTC [3990552] STATEMENT:  SELECT count(*) FROM
	    ref ref_outer,
	    LATERAL (
	        SELECT * FROM
	            LATERAL ( SELECT *
	            FROM ref ref_inner,
	                LATERAL (
	                    SELECT
	                        test.y
	                    FROM test
	                    WHERE
	                        test.y = ref_outer.a
	                    LIMIT 2
	                ) q
	            ) q2
	    ) q3;
2023-11-25 13:01:55.712 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.712 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref_inner)
2023-11-25 13:01:55.712 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.712 UTC [3990552] STATEMENT:  SELECT count(*) FROM
	    ref ref_outer,
	    LATERAL (
	        SELECT * FROM
	            LATERAL ( SELECT *
	            FROM ref ref_inner,
	                LATERAL (
	                    SELECT
	                        test.y
	                    FROM test
	                    WHERE
	                        test.y = ref_inner.a
	                    LIMIT 2
	                ) q
	            ) q2
	    ) q3;
2023-11-25 13:01:55.712 UTC [3990552] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:01:55.712 UTC [3990552] DETAIL:  Limit clause is currently unsupported when a lateral subquery references a column from a reference table (ref)
2023-11-25 13:01:55.712 UTC [3990552] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:01:55.712 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM ref,
	    LATERAL (
	        SELECT
	            test.x
	        FROM test
	        WHERE
	            test.x = ref.a
	        LIMIT 2
	    ) q;
2023-11-25 13:01:55.712 UTC [3990552] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:55.712 UTC [3990552] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:55.712 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM test,
	    LATERAL (
	        SELECT
	            test_2.x
	        FROM test test_2
	        WHERE
	            test_2.x = test.y
	        LIMIT 2
	    ) q ;
2023-11-25 13:01:55.713 UTC [3990552] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:55.713 UTC [3990552] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:55.713 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM ref JOIN test on ref.b = test.x,
	    LATERAL (
	        SELECT
	            test_2.x
	        FROM test test_2
	        WHERE
	            test_2.x = ref.a
	        LIMIT 2
	    ) q
	;
2023-11-25 13:01:55.713 UTC [3990552] ERROR:  0A000: complex joins are only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:01:55.713 UTC [3990552] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:01:55.713 UTC [3990552] STATEMENT:  SELECT count(*)
	FROM ref JOIN test on ref.b = test.x,
	    LATERAL (
	        SELECT
	            test_2.y
	        FROM test test_2
	        WHERE
	            test_2.y = ref.a
	        LIMIT 2
	    ) q
	;
2023-11-25 13:01:55.745 UTC [3990553] LOG:  00000: join order: [ "test_numeric" ][ single hash partition join "test_numeric" ]
2023-11-25 13:01:55.745 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.745 UTC [3990553] STATEMENT:  SELECT count(*) FROM test_numeric t1 JOIN test_numeric as t2 ON (t1.a = t2.b);
2023-11-25 13:01:55.930 UTC [3990553] LOG:  00000: join order: [ "dist_1" ][ single hash partition join "dist_1" ]
2023-11-25 13:01:55.930 UTC [3990553] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:55.930 UTC [3990553] STATEMENT:  SELECT COUNT(*) FROM dist_1 f, dist_1 s WHERE f.a = s.b;
2023-11-25 13:01:56.804 UTC [3991006] LOG:  00000: join order: [ "lineitem" ]
2023-11-25 13:01:56.804 UTC [3991006] CONTEXT:  PL/pgSQL function public.coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:56.804 UTC [3991006] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:56.804 UTC [3991006] STATEMENT:  SELECT public.coordinator_plan($Q$
	EXPLAIN (COSTS FALSE)
	SELECT l_orderkey, l_linenumber, l_shipdate FROM lineitem WHERE l_orderkey = 9030 or l_orderkey = 1;
	$Q$);
2023-11-25 13:01:56.806 UTC [3991006] LOG:  00000: join order: [ "lineitem" ][ local partition join "orders" ]
2023-11-25 13:01:56.806 UTC [3991006] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:56.806 UTC [3991006] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_orderkey = o_orderkey;
2023-11-25 13:01:56.809 UTC [3991006] LOG:  00000: join order: [ "lineitem" ]
2023-11-25 13:01:56.809 UTC [3991006] CONTEXT:  PL/pgSQL function public.coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:56.809 UTC [3991006] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:56.809 UTC [3991006] STATEMENT:  SELECT public.coordinator_plan($Q$
	EXPLAIN (COSTS FALSE)
	SELECT l_orderkey, l_linenumber, l_shipdate FROM lineitem WHERE l_orderkey = 9030;
	$Q$);
2023-11-25 13:01:56.810 UTC [3991006] LOG:  00000: join order: [ "lineitem" ][ dual partition join "orders" ]
2023-11-25 13:01:56.810 UTC [3991006] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:56.810 UTC [3991006] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_partkey = o_custkey;
2023-11-25 13:01:56.811 UTC [3991006] LOG:  00000: join order: [ "lineitem" ]
2023-11-25 13:01:56.811 UTC [3991006] CONTEXT:  PL/pgSQL function public.coordinator_plan(text) line 3 at FOR over EXECUTE statement
2023-11-25 13:01:56.811 UTC [3991006] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:56.811 UTC [3991006] STATEMENT:  SELECT public.coordinator_plan($Q$
	EXPLAIN (COSTS FALSE)
	SELECT l_orderkey, l_linenumber, l_shipdate FROM lineitem WHERE l_orderkey = 9030;
	$Q$);
2023-11-25 13:01:56.813 UTC [3991006] LOG:  00000: join order: [ "lineitem" ][ dual partition join "orders" ]
2023-11-25 13:01:56.813 UTC [3991006] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:56.813 UTC [3991006] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_partkey = o_custkey;
2023-11-25 13:01:56.814 UTC [3991006] LOG:  00000: join order: [ "lineitem" ][ dual partition join "orders" ]
2023-11-25 13:01:56.814 UTC [3991006] LOCATION:  PrintJoinOrderList, multi_join_order.c:629
2023-11-25 13:01:56.814 UTC [3991006] STATEMENT:  EXPLAIN (COSTS FALSE)
	SELECT sum(l_linenumber), avg(l_linenumber) FROM lineitem, orders
		WHERE l_partkey = o_custkey;
2023-11-25 13:01:57.024 UTC [3991056] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:57.024 UTC [3991056] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 13:01:57.024 UTC [3991056] STATEMENT:  UPDATE test SET a = 5, c = 5;
2023-11-25 13:01:57.024 UTC [3991056] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:57.024 UTC [3991056] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 13:01:57.024 UTC [3991056] STATEMENT:  UPDATE test SET a = 5, c = d, d =3;
2023-11-25 13:01:57.024 UTC [3991056] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:57.024 UTC [3991056] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 13:01:57.024 UTC [3991056] STATEMENT:  UPDATE test SET c = d, d =3;
2023-11-25 13:01:57.025 UTC [3991056] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:57.025 UTC [3991056] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 13:01:57.025 UTC [3991056] STATEMENT:  UPDATE test SET d=c, c = d;
2023-11-25 13:01:57.039 UTC [3991056] ERROR:  42601: multiple assignments to same column "c"
2023-11-25 13:01:57.039 UTC [3991056] LOCATION:  process_matched_tle, rewriteHandler.c:1105
2023-11-25 13:01:57.039 UTC [3991056] STATEMENT:  UPDATE test SET c = c, c = 3;
2023-11-25 13:01:57.052 UTC [3991056] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:57.052 UTC [3991056] LOCATION:  ErrorIfOnConflictNotSupported, multi_router_planner.c:1255
2023-11-25 13:01:57.052 UTC [3991056] STATEMENT:  INSERT INTO test (c,d) VALUES(3,4) ON CONFLICT(c) DO UPDATE SET c=7;
2023-11-25 13:01:57.055 UTC [3991056] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:57.055 UTC [3991056] LOCATION:  ErrorIfOnConflictNotSupported, multi_router_planner.c:1255
2023-11-25 13:01:57.055 UTC [3991056] STATEMENT:  INSERT INTO test (d,c) VALUES(3,4) ON CONFLICT(c) DO UPDATE SET c=7;
2023-11-25 13:01:57.056 UTC [3991055] ERROR:  42501: permission denied for table reference_table_1
2023-11-25 13:01:57.056 UTC [3991055] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:57.056 UTC [3991055] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:57.056 UTC [3991055] STATEMENT:  INSERT INTO reference_table_2 SELECT * FROM reference_table_1;
2023-11-25 13:01:57.075 UTC [3991056] ERROR:  42601: multiple assignments to same column "c"
2023-11-25 13:01:57.075 UTC [3991056] LOCATION:  process_matched_tle, rewriteHandler.c:1105
2023-11-25 13:01:57.075 UTC [3991056] STATEMENT:  UPDATE test SET c = c, c = 3;
2023-11-25 13:01:57.143 UTC [3991056] ERROR:  0A000: modifying the partition value of rows is not allowed
2023-11-25 13:01:57.143 UTC [3991056] LOCATION:  TargetlistAndFunctionsSupported, multi_router_planner.c:585
2023-11-25 13:01:57.143 UTC [3991056] STATEMENT:  UPDATE test SET a = 5,d  = 2, c = 5 FROM (SELECT * FROM test LIMIT 10) t2 WHERE t2.d = test.c  and test.c = 6;
2023-11-25 13:01:57.380 UTC [3991224] ERROR:  XX000: multi-task query about to be executed
2023-11-25 13:01:57.380 UTC [3991224] HINT:  Queries are split to multiple tasks if they have to be split into several queries on the workers.
2023-11-25 13:01:57.380 UTC [3991224] LOCATION:  FinalizePlan, distributed_planner.c:1392
2023-11-25 13:01:57.380 UTC [3991224] STATEMENT:  SELECT * FROM multi_task_table;
2023-11-25 13:01:57.405 UTC [3991224] ERROR:  XX000: multi-task query about to be executed
2023-11-25 13:01:57.405 UTC [3991224] HINT:  Queries are split to multiple tasks if they have to be split into several queries on the workers.
2023-11-25 13:01:57.405 UTC [3991224] LOCATION:  FinalizePlan, distributed_planner.c:1392
2023-11-25 13:01:57.405 UTC [3991224] STATEMENT:  INSERT INTO summary_table SELECT id, SUM(order_count) FROM raw_table GROUP BY id;
2023-11-25 13:01:57.417 UTC [3991224] ERROR:  XX000: multi-task query about to be executed
2023-11-25 13:01:57.417 UTC [3991224] HINT:  Queries are split to multiple tasks if they have to be split into several queries on the workers.
2023-11-25 13:01:57.417 UTC [3991224] LOCATION:  FinalizePlan, distributed_planner.c:1392
2023-11-25 13:01:57.417 UTC [3991224] STATEMENT:  INSERT INTO summary_table SELECT id, SUM(order_count) FROM raw_table GROUP BY id;
2023-11-25 13:01:57.674 UTC [3991344] ERROR:  42P01: relation "customer_few" does not exist at character 52
2023-11-25 13:01:57.674 UTC [3991344] LOCATION:  parserOpenTable, parse_relation.c:1392
2023-11-25 13:01:57.674 UTC [3991344] STATEMENT:  SELECT customer_key, c_name, c_address
	       FROM customer_few ORDER BY customer_key LIMIT 5;
2023-11-25 13:01:57.756 UTC [3991344] ERROR:  34000: cursor "noholdcursor" does not exist
2023-11-25 13:01:57.756 UTC [3991344] LOCATION:  PerformPortalFetch, portalcmds.c:187
2023-11-25 13:01:57.756 UTC [3991344] STATEMENT:  FETCH ABSOLUTE 5 FROM noHoldCursor;
2023-11-25 13:01:57.948 UTC [3991376] ERROR:  XX000: cannot modify table "on_update_fkey_table" because there was a parallel operation on a distributed table in the transaction
2023-11-25 13:01:57.948 UTC [3991376] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:57.948 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:57.948 UTC [3991376] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 13:01:57.948 UTC [3991376] STATEMENT:  ALTER TABLE on_update_fkey_table DROP COLUMN value_1 CASCADE;
2023-11-25 13:01:57.952 UTC [3991376] ERROR:  XX000: cannot modify table "on_update_fkey_table" because there was a parallel operation on a distributed table in the transaction
2023-11-25 13:01:57.952 UTC [3991376] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:57.952 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:57.952 UTC [3991376] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 13:01:57.952 UTC [3991376] STATEMENT:  ALTER TABLE on_update_fkey_table DROP COLUMN value_1 CASCADE;
2023-11-25 13:01:57.956 UTC [3991376] ERROR:  XX000: cannot execute parallel DDL on table "on_update_fkey_table" after SELECT command on reference table "reference_table" because there is a foreign key between them and "reference_table" has been accessed in this transaction
2023-11-25 13:01:57.956 UTC [3991376] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:57.956 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:57.956 UTC [3991376] LOCATION:  CheckConflictingParallelRelationAccesses, relation_access_tracking.c:880
2023-11-25 13:01:57.956 UTC [3991376] STATEMENT:  ALTER TABLE on_update_fkey_table ADD COLUMN X INT;
2023-11-25 13:01:57.960 UTC [3991376] ERROR:  XX000: cannot execute parallel DDL on table "on_update_fkey_table" after SELECT command on reference table "transitive_reference_table" because there is a foreign key between them and "transitive_reference_table" has been accessed in this transaction
2023-11-25 13:01:57.960 UTC [3991376] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:57.960 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:57.960 UTC [3991376] LOCATION:  CheckConflictingParallelRelationAccesses, relation_access_tracking.c:880
2023-11-25 13:01:57.960 UTC [3991376] STATEMENT:  ALTER TABLE on_update_fkey_table ADD COLUMN X INT;
2023-11-25 13:01:57.996 UTC [3991376] ERROR:  23503: insert or update on table "on_update_fkey_table_2380002" violates foreign key constraint "fkey_2380002"
2023-11-25 13:01:57.996 UTC [3991376] DETAIL:  Key (value_1)=(101) is not present in table "reference_table_2380001".
2023-11-25 13:01:57.996 UTC [3991376] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:01:57.996 UTC [3991376] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:01:57.996 UTC [3991376] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 1;
2023-11-25 13:01:57.996 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:57.996 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:57.996 UTC [3991376] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 2;
2023-11-25 13:01:57.996 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:57.996 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:57.996 UTC [3991376] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 3;
2023-11-25 13:01:57.996 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:57.996 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:57.996 UTC [3991376] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 101 WHERE id = 4;
2023-11-25 13:01:58.020 UTC [3991376] ERROR:  XX000: insert or update on table "on_update_fkey_table_2380005" violates foreign key constraint "fkey_2380005"
2023-11-25 13:01:58.020 UTC [3991376] DETAIL:  Key (value_1)=(101) is not present in table "reference_table_2380001".
2023-11-25 13:01:58.020 UTC [3991376] LOCATION:  ReportCopyError, multi_copy.c:1193
2023-11-25 13:01:58.020 UTC [3991376] STATEMENT:  COPY on_update_fkey_table FROM STDIN WITH CSV;
2023-11-25 13:01:58.151 UTC [3991376] ERROR:  XX000: cannot modify table "reference_table" because there was a parallel operation on a distributed table
2023-11-25 13:01:58.151 UTC [3991376] DETAIL:  When there is a foreign key to a reference table or to a local table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:58.151 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.151 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:795
2023-11-25 13:01:58.151 UTC [3991376] STATEMENT:  UPDATE reference_table SET id = 101 WHERE id = 99;
2023-11-25 13:01:58.154 UTC [3991376] ERROR:  XX000: cannot modify table "transitive_reference_table" because there was a parallel operation on a distributed table
2023-11-25 13:01:58.154 UTC [3991376] DETAIL:  When there is a foreign key to a reference table or to a local table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:58.154 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.154 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:795
2023-11-25 13:01:58.154 UTC [3991376] STATEMENT:  UPDATE transitive_reference_table SET id = 101 WHERE id = 99;
2023-11-25 13:01:58.159 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.159 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.159 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.159 UTC [3991376] STATEMENT:  ALTER TABLE reference_table ADD COLUMN X INT;
2023-11-25 13:01:58.163 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.163 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.163 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.163 UTC [3991376] STATEMENT:  ALTER TABLE transitive_reference_table ADD COLUMN X INT;
2023-11-25 13:01:58.171 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.171 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.171 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.171 UTC [3991376] STATEMENT:  ALTER TABLE reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 13:01:58.179 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.179 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.179 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.179 UTC [3991376] STATEMENT:  ALTER TABLE transitive_reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 13:01:58.183 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.183 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.183 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.183 UTC [3991376] STATEMENT:  TRUNCATE reference_table CASCADE;
2023-11-25 13:01:58.188 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.188 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.188 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.188 UTC [3991376] STATEMENT:  TRUNCATE transitive_reference_table CASCADE;
2023-11-25 13:01:58.211 UTC [3991376] ERROR:  XX000: cannot execute DDL on table because there was a parallel SELECT access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.211 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.211 UTC [3991376] CONTEXT:  SQL statement "SELECT citus_drop_all_shards(v_obj.objid, v_obj.schema_name, v_obj.object_name, drop_shards_metadata_only := false)"
	PL/pgSQL function citus_drop_trigger() line 25 at PERFORM
2023-11-25 13:01:58.211 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:761
2023-11-25 13:01:58.211 UTC [3991376] STATEMENT:  DROP TABLE reference_table CASCADE;
2023-11-25 13:01:58.228 UTC [3991376] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.228 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.228 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.228 UTC [3991376] STATEMENT:  UPDATE reference_table SET id = 160 WHERE id = 15;
2023-11-25 13:01:58.232 UTC [3991376] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.232 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.232 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.232 UTC [3991376] STATEMENT:  UPDATE transitive_reference_table SET id = 160 WHERE id = 15;
2023-11-25 13:01:58.236 UTC [3991376] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.236 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.236 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.236 UTC [3991376] STATEMENT:  UPDATE reference_table SET id = 160 WHERE id = 15;
2023-11-25 13:01:58.240 UTC [3991376] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.240 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.240 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.240 UTC [3991376] STATEMENT:  UPDATE transitive_reference_table SET id = 160 WHERE id = 15;
2023-11-25 13:01:58.245 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.245 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.245 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.245 UTC [3991376] STATEMENT:  ALTER TABLE reference_table ADD COLUMN X INT;
2023-11-25 13:01:58.249 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.249 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.249 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.249 UTC [3991376] STATEMENT:  ALTER TABLE transitive_reference_table ADD COLUMN X INT;
2023-11-25 13:01:58.256 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.256 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.256 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.256 UTC [3991376] STATEMENT:  ALTER TABLE reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 13:01:58.262 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.262 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.262 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.262 UTC [3991376] STATEMENT:  ALTER TABLE transitive_reference_table ALTER COLUMN id SET DATA TYPE smallint;
2023-11-25 13:01:58.267 UTC [3991376] ERROR:  XX000: cannot execute SELECT on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.267 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.267 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.267 UTC [3991376] STATEMENT:  SELECT count(*) FROM reference_table;
2023-11-25 13:01:58.271 UTC [3991376] ERROR:  XX000: cannot execute SELECT on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.271 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.271 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.271 UTC [3991376] STATEMENT:  SELECT count(*) FROM transitive_reference_table;
2023-11-25 13:01:58.295 UTC [3991376] ERROR:  XX000: cannot execute SELECT on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.295 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.295 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.295 UTC [3991376] STATEMENT:  SELECT count(*) FROM reference_table;
2023-11-25 13:01:58.300 UTC [3991376] ERROR:  XX000: cannot execute SELECT on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.300 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.300 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.300 UTC [3991376] STATEMENT:  SELECT count(*) FROM transitive_reference_table;
2023-11-25 13:01:58.304 UTC [3991376] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.304 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.304 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.304 UTC [3991376] STATEMENT:  UPDATE reference_table SET id = 160 WHERE id = 15;
2023-11-25 13:01:58.308 UTC [3991376] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.308 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.308 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.308 UTC [3991376] STATEMENT:  UPDATE transitive_reference_table SET id = 160 WHERE id = 15;
2023-11-25 13:01:58.312 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.312 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.312 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.312 UTC [3991376] STATEMENT:  ALTER TABLE reference_table ADD COLUMN X int;
2023-11-25 13:01:58.317 UTC [3991376] ERROR:  XX000: cannot execute DDL on table "transitive_reference_table" because there was a parallel DDL access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.317 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.317 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.317 UTC [3991376] STATEMENT:  ALTER TABLE transitive_reference_table ADD COLUMN X int;
2023-11-25 13:01:58.321 UTC [3991376] ERROR:  XX000: cannot modify table "on_update_fkey_table" because there was a parallel operation on a distributed table in the transaction
2023-11-25 13:01:58.321 UTC [3991376] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:58.321 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.321 UTC [3991376] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 13:01:58.321 UTC [3991376] STATEMENT:  ALTER TABLE on_update_fkey_table ALTER COLUMN value_1 SET DATA TYPE smallint;
2023-11-25 13:01:58.329 UTC [3991376] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.329 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.329 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.329 UTC [3991376] STATEMENT:  DELETE FROM reference_table  WHERE id = 99;
2023-11-25 13:01:58.339 UTC [3991376] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.339 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.339 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.339 UTC [3991376] STATEMENT:  DELETE FROM transitive_reference_table  WHERE id = 99;
2023-11-25 13:01:58.349 UTC [3991376] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.349 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.349 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.349 UTC [3991376] STATEMENT:  UPDATE reference_table SET id = 101 WHERE id = 99;
2023-11-25 13:01:58.358 UTC [3991376] ERROR:  XX000: cannot execute DML on table "transitive_reference_table" because there was a parallel DML access to distributed table "on_update_fkey_table" in the same transaction
2023-11-25 13:01:58.358 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.358 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.358 UTC [3991376] STATEMENT:  UPDATE transitive_reference_table SET id = 101 WHERE id = 99;
2023-11-25 13:01:58.363 UTC [3991376] ERROR:  XX000: cannot modify table "reference_table" because there was a parallel operation on a distributed table
2023-11-25 13:01:58.363 UTC [3991376] DETAIL:  When there is a foreign key to a reference table or to a local table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:58.363 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.363 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:795
2023-11-25 13:01:58.363 UTC [3991376] STATEMENT:  UPDATE reference_table SET id = 101 WHERE id = 99;
2023-11-25 13:01:58.364 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.364 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.364 UTC [3991376] STATEMENT:  UPDATE on_update_fkey_table SET value_1 = 5 WHERE id != 11;
2023-11-25 13:01:58.394 UTC [3991376] ERROR:  XX000: cannot distribute relation "test_table_2" in this transaction because it has a foreign key to a reference table
2023-11-25 13:01:58.394 UTC [3991376] DETAIL:  If a hash distributed table has a foreign key to a reference table, it has to be created in sequential mode before any parallel commands have been executed in the same transaction
2023-11-25 13:01:58.394 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.394 UTC [3991376] LOCATION:  CanUseExclusiveConnections, create_distributed_table.c:2256
2023-11-25 13:01:58.394 UTC [3991376] STATEMENT:  SELECT create_distributed_table('test_table_2', 'id');
2023-11-25 13:01:58.395 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.395 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.395 UTC [3991376] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 13:01:58.396 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.396 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.396 UTC [3991376] STATEMENT:  DROP TABLE test_table_1 CASCADE;
2023-11-25 13:01:58.437 UTC [3991376] ERROR:  XX000: cannot modify table "test_table_2" because there was a parallel operation on a distributed table in the transaction
2023-11-25 13:01:58.437 UTC [3991376] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:58.437 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.437 UTC [3991376] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 13:01:58.437 UTC [3991376] STATEMENT:  ALTER TABLE test_table_2 ADD CONSTRAINT c_check FOREIGN KEY (value_1) REFERENCES test_table_1(id);
2023-11-25 13:01:58.438 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.438 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.438 UTC [3991376] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 13:01:58.438 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.438 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.438 UTC [3991376] STATEMENT:  DROP TABLE test_table_1, test_table_2;
2023-11-25 13:01:58.474 UTC [3991376] ERROR:  XX000: cannot modify table "test_table_2" because there was a parallel operation on a distributed table in the transaction
2023-11-25 13:01:58.474 UTC [3991376] DETAIL:  When there is a foreign key to a reference table, Citus needs to perform all operations over a single connection per node to ensure consistency.
2023-11-25 13:01:58.474 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.474 UTC [3991376] LOCATION:  SetupExecutionModeForAlterTable, table.c:3638
2023-11-25 13:01:58.474 UTC [3991376] STATEMENT:  ALTER TABLE test_table_2 ADD CONSTRAINT c_check FOREIGN KEY (value_1) REFERENCES test_table_1(id);
2023-11-25 13:01:58.475 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.475 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.475 UTC [3991376] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 13:01:58.475 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.475 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.475 UTC [3991376] STATEMENT:  DROP TABLE test_table_1 CASCADE;
2023-11-25 13:01:58.497 UTC [3991376] ERROR:  XX000: cannot distribute "test_table_2" in sequential mode because a parallel query was executed in this transaction
2023-11-25 13:01:58.497 UTC [3991376] HINT:  If you have manually set citus.multi_shard_modify_mode to 'sequential', try with 'parallel' option. 
2023-11-25 13:01:58.497 UTC [3991376] LOCATION:  CanUseExclusiveConnections, create_distributed_table.c:2269
2023-11-25 13:01:58.497 UTC [3991376] STATEMENT:  SELECT create_distributed_table('test_table_2', 'id');
2023-11-25 13:01:58.497 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.497 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.497 UTC [3991376] STATEMENT:  CREATE TABLE test_table_1(id int PRIMARY KEY);
2023-11-25 13:01:58.497 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.497 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.497 UTC [3991376] STATEMENT:  SELECT create_reference_table('test_table_1');
2023-11-25 13:01:58.497 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.497 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.497 UTC [3991376] STATEMENT:  ALTER TABLE test_table_2 ADD CONSTRAINT c_check FOREIGN KEY (value_1) REFERENCES test_table_1(id);
2023-11-25 13:01:58.497 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.497 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.497 UTC [3991376] STATEMENT:  SET LOCAL client_min_messages TO ERROR;
2023-11-25 13:01:58.497 UTC [3991376] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:01:58.497 UTC [3991376] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:01:58.497 UTC [3991376] STATEMENT:  DROP TABLE test_table_1 CASCADE;
2023-11-25 13:01:58.621 UTC [3991376] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "distributed_table" in the same transaction
2023-11-25 13:01:58.621 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.621 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.621 UTC [3991376] STATEMENT:  WITH t1 AS (DELETE FROM distributed_table RETURNING id),
		t2 AS (DELETE FROM reference_table RETURNING id)
		SELECT count(*) FROM distributed_table, t1, t2 WHERE  value_1 = t1.id AND value_1 = t2.id;
2023-11-25 13:01:58.624 UTC [3991376] ERROR:  XX000: cannot execute DML on table "reference_table" because there was a parallel DML access to distributed table "distributed_table" in the same transaction
2023-11-25 13:01:58.624 UTC [3991376] HINT:  Try re-running the transaction with "SET LOCAL citus.multi_shard_modify_mode TO 'sequential';"
2023-11-25 13:01:58.624 UTC [3991376] LOCATION:  CheckConflictingRelationAccesses, relation_access_tracking.c:772
2023-11-25 13:01:58.624 UTC [3991376] STATEMENT:  WITH t1 AS (DELETE FROM distributed_table RETURNING id)
		DELETE FROM reference_table RETURNING id;
2023-11-25 13:01:59.023 UTC [3991546] ERROR:  XX000: you cannot alter access method of a partitioned table
2023-11-25 13:01:59.023 UTC [3991546] LOCATION:  AlterTableSetAccessMethod, alter_table.c:487
2023-11-25 13:01:59.023 UTC [3991546] STATEMENT:  SELECT alter_table_set_access_method('partitioned_table', 'columnar');
2023-11-25 13:01:59.066 UTC [3991546] ERROR:  P0001: partition column of partitioned_table cannot be cast to a timestamptz
2023-11-25 13:01:59.066 UTC [3991546] CONTEXT:  PL/pgSQL function alter_old_partitions_set_access_method(regclass,timestamp with time zone,name) line 14 at RAISE
2023-11-25 13:01:59.066 UTC [3991546] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:01:59.066 UTC [3991546] STATEMENT:  CALL alter_old_partitions_set_access_method('partitioned_table', '2021-01-01', 'columnar');
2023-11-25 13:01:59.425 UTC [3991546] ERROR:  0A000: Foreign keys and AFTER ROW triggers are not supported for columnar tables
2023-11-25 13:01:59.425 UTC [3991546] HINT:  Consider an AFTER STATEMENT trigger instead.
2023-11-25 13:01:59.425 UTC [3991546] CONTEXT:  SQL statement "ALTER TABLE alter_table_set_access_method.test_fk_p ATTACH PARTITION alter_table_set_access_method.test_fk_p1 FOR VALUES FROM (10) TO (20);"
2023-11-25 13:01:59.425 UTC [3991546] LOCATION:  ColumnarTriggerCreateHook, columnar_tableam.c:2140
2023-11-25 13:01:59.425 UTC [3991546] STATEMENT:  select alter_table_set_access_method('test_fk_p1', 'columnar');
2023-11-25 13:01:59.426 UTC [3991546] ERROR:  XX000: the access method of alter_table_set_access_method.same_access_method is already heap
2023-11-25 13:01:59.426 UTC [3991546] LOCATION:  AlterTableSetAccessMethod, alter_table.c:514
2023-11-25 13:01:59.426 UTC [3991546] STATEMENT:  SELECT alter_table_set_access_method('same_access_method', 'heap');
2023-11-25 13:01:59.431 UTC [3991546] WARNING:  0A000: "view v_local" has dependency to "table local" that is not in Citus' metadata
2023-11-25 13:01:59.431 UTC [3991546] DETAIL:  "view v_local" will be created only locally
2023-11-25 13:01:59.431 UTC [3991546] HINT:  Distribute "table local" first to distribute "view v_local"
2023-11-25 13:01:59.431 UTC [3991546] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:01:59.585 UTC [3991546] ERROR:  XX000: you cannot alter access method of a view
2023-11-25 13:01:59.585 UTC [3991546] LOCATION:  AlterTableSetAccessMethod, alter_table.c:492
2023-11-25 13:01:59.585 UTC [3991546] STATEMENT:  select alter_table_set_access_method('view_test_view','columnar');
2023-11-25 13:02:00.059 UTC [3991637] ERROR:  XX000: cannot complete operation because table is a partition
2023-11-25 13:02:00.059 UTC [3991637] HINT:  the parent table is "partitioned_table"
2023-11-25 13:02:00.059 UTC [3991637] LOCATION:  EnsureTableNotPartition, alter_table.c:1172
2023-11-25 13:02:00.059 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('partitioned_table_1_5', shard_count := 10, distribution_column := 'a');
2023-11-25 13:02:00.262 UTC [3991637] WARNING:  01000: foreign key table_with_references_a1_fkey will be dropped
2023-11-25 13:02:00.262 UTC [3991637] LOCATION:  WarningsForDroppingForeignKeysWithDistributedTables, alter_table.c:2096
2023-11-25 13:02:00.262 UTC [3991637] WARNING:  01000: foreign key referencing_dist_table_a_fkey will be dropped
2023-11-25 13:02:00.262 UTC [3991637] LOCATION:  WarningsForDroppingForeignKeysWithDistributedTables, alter_table.c:2096
2023-11-25 13:02:00.758 UTC [3991637] LOG:  00000: performing blocking isolate_tenant_to_new_shard 
2023-11-25 13:02:00.758 UTC [3991637] LOCATION:  SplitShard, shard_split.c:507
2023-11-25 13:02:00.758 UTC [3991637] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:02:00.759 UTC [3991637] LOG:  00000: creating child shards for isolate_tenant_to_new_shard
2023-11-25 13:02:00.759 UTC [3991637] LOCATION:  BlockingShardSplit, shard_split.c:571
2023-11-25 13:02:00.759 UTC [3991637] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:02:00.768 UTC [3991637] LOG:  00000: performing copy for isolate_tenant_to_new_shard
2023-11-25 13:02:00.768 UTC [3991637] LOCATION:  BlockingShardSplit, shard_split.c:577
2023-11-25 13:02:00.768 UTC [3991637] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:02:00.769 UTC [3991637] LOG:  00000: creating auxillary structures (indexes, stats, replicaindentities, triggers) for isolate_tenant_to_new_shard
2023-11-25 13:02:00.769 UTC [3991637] LOCATION:  BlockingShardSplit, shard_split.c:587
2023-11-25 13:02:00.769 UTC [3991637] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:02:00.769 UTC [3991637] LOG:  00000: marking deferred cleanup of source shard(s) for isolate_tenant_to_new_shard
2023-11-25 13:02:00.769 UTC [3991637] LOCATION:  BlockingShardSplit, shard_split.c:609
2023-11-25 13:02:00.769 UTC [3991637] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:02:00.770 UTC [3991637] LOG:  00000: creating foreign key constraints (if any) for isolate_tenant_to_new_shard
2023-11-25 13:02:00.770 UTC [3991637] LOCATION:  BlockingShardSplit, shard_split.c:625
2023-11-25 13:02:00.770 UTC [3991637] STATEMENT:  SELECT 1 FROM isolate_tenant_to_new_shard('shard_split_table', 5, shard_transfer_mode => 'block_writes');
2023-11-25 13:02:00.805 UTC [3991637] ERROR:  XX000: you have to specify at least one of the distribution_column, shard_count or colocate_with parameters
2023-11-25 13:02:00.805 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1813
2023-11-25 13:02:00.805 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table');
2023-11-25 13:02:00.805 UTC [3991637] ERROR:  XX000: you have to specify at least one of the distribution_column, shard_count or colocate_with parameters
2023-11-25 13:02:00.805 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1813
2023-11-25 13:02:00.805 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', cascade_to_colocated := false);
2023-11-25 13:02:00.806 UTC [3991637] ERROR:  XX000: this call doesn't change any properties of the table
2023-11-25 13:02:00.806 UTC [3991637] HINT:  check citus_tables view to see current properties of the table
2023-11-25 13:02:00.806 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1891
2023-11-25 13:02:00.806 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'b');
2023-11-25 13:02:00.806 UTC [3991637] ERROR:  XX000: this call doesn't change any properties of the table
2023-11-25 13:02:00.806 UTC [3991637] HINT:  check citus_tables view to see current properties of the table
2023-11-25 13:02:00.806 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1891
2023-11-25 13:02:00.806 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', shard_count := 10);
2023-11-25 13:02:00.826 UTC [3991637] ERROR:  XX000: this call doesn't change any properties of the table
2023-11-25 13:02:00.826 UTC [3991637] HINT:  check citus_tables view to see current properties of the table
2023-11-25 13:02:00.826 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1891
2023-11-25 13:02:00.826 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'colocation_table');
2023-11-25 13:02:00.876 UTC [3991637] ERROR:  XX000: distribution_column cannot be cascaded to colocated tables
2023-11-25 13:02:00.876 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1873
2023-11-25 13:02:00.876 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'b', cascade_to_colocated := true);
2023-11-25 13:02:00.876 UTC [3991637] ERROR:  XX000: distribution_column cannot be cascaded to colocated tables
2023-11-25 13:02:00.876 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1873
2023-11-25 13:02:00.876 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'b', shard_count:=12, colocate_with:='colocation_table_2', cascade_to_colocated := true);
2023-11-25 13:02:00.876 UTC [3991637] ERROR:  XX000: shard_count or colocate_with is necessary for cascading to colocated tables
2023-11-25 13:02:00.876 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1879
2023-11-25 13:02:00.876 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', cascade_to_colocated := true);
2023-11-25 13:02:00.876 UTC [3991637] ERROR:  XX000: colocate_with := 'none' cannot be cascaded to colocated tables
2023-11-25 13:02:00.876 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1899
2023-11-25 13:02:00.876 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'none', cascade_to_colocated := true);
2023-11-25 13:02:00.876 UTC [3991637] ERROR:  XX000: cascade_to_colocated parameter is necessary
2023-11-25 13:02:00.876 UTC [3991637] DETAIL:  this table is colocated with some other tables
2023-11-25 13:02:00.876 UTC [3991637] HINT:  cascade_to_colocated := false will break the current colocation, cascade_to_colocated := true will change the shard count of colocated tables too.
2023-11-25 13:02:00.876 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1907
2023-11-25 13:02:00.876 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', shard_count := 14);
2023-11-25 13:02:00.906 UTC [3991637] ERROR:  XX000: shard_count cannot be different than the shard count of the table in colocate_with
2023-11-25 13:02:00.906 UTC [3991637] HINT:  if no shard_count is specified shard count will be same with colocate_with table's
2023-11-25 13:02:00.906 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1927
2023-11-25 13:02:00.906 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'colocation_table', shard_count := 16);
2023-11-25 13:02:00.913 UTC [3991637] ERROR:  XX000: cannot colocate with different_type_table because data type of its distribution column is different than dist_table
2023-11-25 13:02:00.913 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1968
2023-11-25 13:02:00.913 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with := 'different_type_table');
2023-11-25 13:02:00.913 UTC [3991637] ERROR:  XX000: cannot colocate with different_type_table and change distribution column to a because data type of column a is different then the distribution column of the different_type_table
2023-11-25 13:02:00.913 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1959
2023-11-25 13:02:00.913 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', distribution_column := 'a', colocate_with := 'different_type_table');
2023-11-25 13:02:00.913 UTC [3991637] ERROR:  XX000: shard_count cannot be 0
2023-11-25 13:02:00.913 UTC [3991637] HINT:  if you no longer want this to be a distributed table you can try undistribute_table() function
2023-11-25 13:02:00.913 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1864
2023-11-25 13:02:00.913 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', shard_count := 0);
2023-11-25 13:02:00.917 UTC [3991637] ERROR:  XX000: cannot colocate with reference_table because it is not a distributed table
2023-11-25 13:02:00.917 UTC [3991637] LOCATION:  CheckAlterDistributedTableConversionParameters, alter_table.c:1855
2023-11-25 13:02:00.917 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('dist_table', colocate_with:='reference_table');
2023-11-25 13:02:00.918 UTC [3991637] ERROR:  0A000: relation append_table should be a hash distributed table
2023-11-25 13:02:00.918 UTC [3991637] LOCATION:  EnsureHashDistributedTable, metadata_utility.c:2284
2023-11-25 13:02:00.918 UTC [3991637] STATEMENT:  SELECT alter_distributed_table('append_table', shard_count:=6);
2023-11-25 13:02:02.875 UTC [3991834] ERROR:  0A000: cannot push down subquery on the target list
2023-11-25 13:02:02.875 UTC [3991834] DETAIL:  Subqueries in the SELECT part of the query can only be pushed down if they happen before aggregates and window functions
2023-11-25 13:02:02.875 UTC [3991834] LOCATION:  MultiLogicalPlanOptimize, multi_logical_optimizer.c:479
2023-11-25 13:02:02.875 UTC [3991834] STATEMENT:  /*
	 * Test that we don't get a crash. See #5248.
	 */
	SELECT   subq_3.c15 AS c0,
	         subq_3.c0  AS c1,
	         subq_3.c15 AS c2,
	         subq_0.c1  AS c3,
	         pg_catalog.String_agg( Cast(
	                                      (
	                                      SELECT tgargs
	                                      FROM   pg_catalog.pg_trigger limit 1 offset 1) AS BYTEA), Cast(
	                                                                                                      (
	                                                                                                      SELECT minimum_value
	                                                                                                      FROM   columnar.chunk limit 1 offset 5) AS BYTEA)) OVER (partition BY subq_3.c10 ORDER BY subq_3.c12,subq_0.c2) AS c4,
	         subq_0.c1                                                                                                                                                                                                    AS c5
	FROM     (
	                    SELECT     ref_1.address                      AS c0,
	                               ref_1.error                        AS c1,
	                               sample_0.NAME                      AS c2,
	                               sample_2.trftosql                  AS c3
	                    FROM       pg_catalog.pg_statio_all_sequences AS ref_0
	                    INNER JOIN pg_catalog.pg_hba_file_rules       AS ref_1
	                    ON         ((
	                                                 SELECT pg_catalog.Max(aggnumdirectargs)
	                                                 FROM   pg_catalog.pg_aggregate) <= ref_0.blks_hit)
	                    INNER JOIN countries  AS sample_0 TABLESAMPLE system (6.4)
	                    INNER JOIN local_data AS sample_1 TABLESAMPLE bernoulli (8)
	                    ON         ((
	                                                     true)
	                               OR         (
	                                                     sample_0.NAME IS NOT NULL))
	                    INNER JOIN pg_catalog.pg_transform AS sample_2 TABLESAMPLE bernoulli (1.2)
	                    INNER JOIN pg_catalog.pg_language  AS ref_2
	                    ON         ((
	                                                 SELECT shard_cost_function
	                                                 FROM   pg_catalog.pg_dist_rebalance_strategy limit 1 offset 1) IS NULL)
	                    RIGHT JOIN pg_catalog.pg_index AS sample_3 TABLESAMPLE system (0.3)
	                    ON         ((
	                                                     cast(NULL AS bpchar) ~<=~ cast(NULL AS bpchar))
	                               OR         ((
	                                                                EXISTS
	                                                                (
	                                                                       SELECT sample_3.indnkeyatts        AS c0,
	                                                                              sample_2.trflang            AS c1,
	                                                                              sample_2.trftype            AS c2
	                                                                       FROM   pg_catalog.pg_statistic_ext AS sample_4 TABLESAMPLE bernoulli (8.6)
	                                                                       WHERE  sample_2.trftype IS NOT NULL))
	                                          AND        (
	                                                                false)))
	                    ON         (
	                                          EXISTS
	                                          (
	                                                 SELECT sample_0.id           AS c0,
	                                                        sample_3.indisprimary AS c1
	                                                 FROM   orgs           AS sample_5 TABLESAMPLE system (5.3)
	                                                 WHERE  false))
	                    ON         (
	                                          cast(NULL AS float8) >
	                                          (
	                                                 SELECT pg_catalog.avg(enumsortorder)
	                                                 FROM   pg_catalog.pg_enum) )
	                    WHERE      cast(COALESCE(
	                               CASE
	                                          WHEN ref_1.auth_method ~>=~ ref_1.auth_method THEN cast(NULL AS path)
	                                          ELSE cast(NULL AS path)
	                               END , cast(NULL AS path)) AS path) = cast(NULL AS path)) AS subq_0,
	         lateral
	         (
	                SELECT
	                       (
	                              SELECT pg_catalog.stddev(total_time)
	                              FROM   pg_catalog.pg_stat_user_functions) AS c0,
	                       subq_0.c1                                        AS c1,
	                       subq_2.c0                                        AS c2,
	                       subq_0.c2                                        AS c3,
	                       subq_0.c0                                        AS c4,
	                       cast(COALESCE(subq_2.c0, subq_2.c0) AS text)     AS c5,
	                       subq_2.c0                                        AS c6,
	                       subq_2.c1                                        AS c7,
	                       subq_2.c1                                        AS c8,
	                       subq_2.c1                                        AS c9,
	                       subq_0.c3                                        AS c10,
	                       pg_catalog.pg_stat_get_db_temp_files( cast(
	                                                                   (
	                                                                   SELECT objoid
	                                                                   FROM   pg_catalog.pg_description limit 1 offset 1) AS oid)) AS c11,
	                       subq_0.c3                                                                                               AS c12,
	                       subq_2.c1                                                                                               AS c13,
	                       subq_0.c0                                                                                               AS c14,
	                       subq_0.c3                                                                                               AS c15,
	                       subq_0.c3                                                                                               AS c16,
	                       subq_0.c1                                                                                               AS c17,
	                       subq_0.c2                                                                                               AS c18
	                FROM   (
	                              SELECT subq_1.c2                        AS c0,
	                                     subq_0.c3                        AS c1
	                              FROM   information_schema.element_types AS ref_3,
	                                     lateral
	                                     (
	                                            SELECT subq_0.c1            AS c0,
	                                                   sample_6.info        AS c1,
	                                                   subq_0.c2            AS c2,
	                                                   subq_0.c3            AS c3,
	                                                   ref_3.domain_default AS c4,
	                                                   sample_6.user_id     AS c5,
	                                                   ref_3.collation_name AS c6
	                                            FROM   orders        AS sample_6 TABLESAMPLE system (3.8)
	                                            WHERE  sample_6.price = sample_6.org_id limit 58) AS subq_1
	                              WHERE  (
	                                            subq_1.c2 <= subq_0.c2)
	                              AND    (
	                                            cast(NULL AS line) ?-| cast(NULL AS line)) limit 59) AS subq_2
	                WHERE  cast(COALESCE(pg_catalog.age( cast(
	                                                           (
	                                                           SELECT pg_catalog.max(event_time)
	                                                           FROM   events) AS "timestamp")),
	                       (
	                              SELECT write_lag
	                              FROM   pg_catalog.pg_stat_replication limit 1 offset 3) ) AS "interval") >
	                       (
	                              SELECT utc_offset
	                              FROM   pg_catalog.pg_timezone_names limit 1 offset 4) limit 91) AS subq_3
	WHERE    pg_catalog.pg_backup_stop() > cast(NULL AS record) limit 100;
2023-11-25 13:02:03.214 UTC [3991948] ERROR:  22023: relation with OID 31838 does not exist
2023-11-25 13:02:03.214 UTC [3991948] LOCATION:  EnsureRelationExists, create_distributed_table.c:969
2023-11-25 13:02:03.214 UTC [3991948] STATEMENT:  SELECT undistribute_table('dist_table'), create_distributed_table('dist_table', 'a');
2023-11-25 13:02:03.279 UTC [3991948] ERROR:  XX000: cannot complete operation because table referenced_table is referenced by a foreign key
2023-11-25 13:02:03.279 UTC [3991948] HINT:  Use cascade option to undistribute all the relations involved in a foreign key relationship with undistribute_table.referenced_table by executing SELECT undistribute_table($$undistribute_table.referenced_table$$, cascade_via_foreign_keys=>true)
2023-11-25 13:02:03.279 UTC [3991948] LOCATION:  EnsureTableNotReferenced, alter_table.c:1129
2023-11-25 13:02:03.279 UTC [3991948] STATEMENT:  SELECT undistribute_table('referenced_table');
2023-11-25 13:02:03.279 UTC [3991948] ERROR:  XX000: cannot complete operation because table referencing_table has a foreign key
2023-11-25 13:02:03.279 UTC [3991948] HINT:  Use cascade option to undistribute all the relations involved in a foreign key relationship with undistribute_table.referencing_table by executing SELECT undistribute_table($$undistribute_table.referencing_table$$, cascade_via_foreign_keys=>true)
2023-11-25 13:02:03.279 UTC [3991948] LOCATION:  EnsureTableNotReferencing, alter_table.c:1100
2023-11-25 13:02:03.279 UTC [3991948] STATEMENT:  SELECT undistribute_table('referencing_table');
2023-11-25 13:02:03.328 UTC [3991948] ERROR:  XX000: cannot complete operation because table is a partition
2023-11-25 13:02:03.328 UTC [3991948] HINT:  the parent table is "partitioned_table"
2023-11-25 13:02:03.328 UTC [3991948] LOCATION:  EnsureTableNotPartition, alter_table.c:1172
2023-11-25 13:02:03.328 UTC [3991948] STATEMENT:  SELECT undistribute_table('partitioned_table_1_5');
2023-11-25 13:02:03.424 UTC [3991948] ERROR:  XX000: cannot alter table because an extension depends on it
2023-11-25 13:02:03.424 UTC [3991948] LOCATION:  ErrorIfUnsupportedCascadeObjects, alter_table.c:1405
2023-11-25 13:02:03.424 UTC [3991948] STATEMENT:  SELECT undistribute_table ('extension_table');
2023-11-25 13:02:03.439 UTC [3991948] ERROR:  XX000: cannot alter table because an extension depends on it
2023-11-25 13:02:03.439 UTC [3991948] LOCATION:  ErrorIfUnsupportedCascadeObjects, alter_table.c:1405
2023-11-25 13:02:03.439 UTC [3991948] STATEMENT:  SELECT undistribute_table('rule_table_2');
2023-11-25 13:02:03.660 UTC [3992019] WARNING:  01000: Error on node with node id 16: failed to connect to localhost:0
2023-11-25 13:02:03.660 UTC [3992019] CONTEXT:  PL/pgSQL function run_command_on_all_nodes(text,boolean,boolean) line 46 at RAISE
2023-11-25 13:02:03.660 UTC [3992019] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:02:03.764 UTC [3992069] ERROR:  P0001: the coordinator is not added to the metadata
2023-11-25 13:02:03.764 UTC [3992069] HINT:  Add the node as a coordinator by using: SELECT citus_set_coordinator_host('<hostname>')
2023-11-25 13:02:03.764 UTC [3992069] CONTEXT:  PL/pgSQL function run_command_on_coordinator(text,boolean) line 36 at RAISE
2023-11-25 13:02:03.764 UTC [3992069] LOCATION:  exec_stmt_raise, pl_exec.c:3903
2023-11-25 13:02:03.764 UTC [3992069] STATEMENT:  SELECT success, result FROM run_command_on_coordinator('select inet_server_port()');
2023-11-25 13:02:03.952 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:03.952 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:03.952 UTC [3976581] LOG:  00000: parameter "citus.background_task_queue_interval" changed to "1s"
2023-11-25 13:02:03.952 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:04.955 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:04.955 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:04.955 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:04.958 UTC [3992129] LOG:  00000: task jobid/taskid started: 1450000/1450000
2023-11-25 13:02:04.958 UTC [3992129] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:04.958 UTC [3992129] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:04.960 UTC [3992129] LOG:  00000: task jobid/taskid succeeded: 1450000/1450000
2023-11-25 13:02:04.960 UTC [3992129] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:04.960 UTC [3992129] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:05.965 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:05.965 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:05.965 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:05.967 UTC [3992131] LOG:  00000: task jobid/taskid started: 1450001/1450001
2023-11-25 13:02:05.967 UTC [3992131] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:05.967 UTC [3992131] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:06.960 UTC [3992132] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:06.960 UTC [3992132] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450001/1450001)
2023-11-25 13:02:06.960 UTC [3992132] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:06.960 UTC [3992131] LOG:  00000: task jobid/taskid is cancelled: 1450001/1450001
2023-11-25 13:02:06.960 UTC [3992131] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:06.960 UTC [3992131] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:06.962 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450001/1450001)" (PID 3992132) exited with exit code 1
2023-11-25 13:02:06.962 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:07.965 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:07.965 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:07.965 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:07.967 UTC [3992133] LOG:  00000: task jobid/taskid started: 1450002/1450002
2023-11-25 13:02:07.967 UTC [3992133] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:07.967 UTC [3992133] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:07.969 UTC [3992134] ERROR:  22012: division by zero
2023-11-25 13:02:07.969 UTC [3992134] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450002/1450002)
2023-11-25 13:02:07.969 UTC [3992134] LOCATION:  int4div, int.c:840
2023-11-25 13:02:07.970 UTC [3992133] LOG:  00000: task jobid/taskid failed: 1450002/1450002
2023-11-25 13:02:07.970 UTC [3992133] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:07.970 UTC [3992133] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 13:02:07.971 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450002/1450002)" (PID 3992134) exited with exit code 1
2023-11-25 13:02:07.971 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:09.975 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:09.975 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:09.975 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:09.978 UTC [3992135] LOG:  00000: task jobid/taskid started: 1450003/1450003
2023-11-25 13:02:09.978 UTC [3992135] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:09.978 UTC [3992135] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:09.980 UTC [3992135] LOG:  00000: task jobid/taskid succeeded: 1450003/1450003
2023-11-25 13:02:09.980 UTC [3992135] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:09.980 UTC [3992135] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:09.982 UTC [3992135] LOG:  00000: task jobid/taskid started: 1450003/1450004
2023-11-25 13:02:09.982 UTC [3992135] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:09.982 UTC [3992135] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:09.984 UTC [3992135] LOG:  00000: task jobid/taskid succeeded: 1450003/1450004
2023-11-25 13:02:09.984 UTC [3992135] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:09.984 UTC [3992135] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:09.986 UTC [3992135] LOG:  00000: task jobid/taskid started: 1450003/1450005
2023-11-25 13:02:09.986 UTC [3992135] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:09.986 UTC [3992135] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:09.988 UTC [3992135] LOG:  00000: task jobid/taskid succeeded: 1450003/1450005
2023-11-25 13:02:09.988 UTC [3992135] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:09.988 UTC [3992135] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:10.993 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:10.993 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:10.993 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:10.995 UTC [3992139] LOG:  00000: task jobid/taskid started: 1450004/1450006
2023-11-25 13:02:10.995 UTC [3992139] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:10.995 UTC [3992139] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:10.998 UTC [3992139] LOG:  00000: task jobid/taskid succeeded: 1450004/1450006
2023-11-25 13:02:10.998 UTC [3992139] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:10.998 UTC [3992139] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:10.999 UTC [3992139] LOG:  00000: task jobid/taskid started: 1450004/1450007
2023-11-25 13:02:10.999 UTC [3992139] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:10.999 UTC [3992139] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:11.002 UTC [3992141] ERROR:  22012: division by zero
2023-11-25 13:02:11.002 UTC [3992141] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450004/1450007)
2023-11-25 13:02:11.002 UTC [3992141] LOCATION:  int4div, int.c:840
2023-11-25 13:02:11.002 UTC [3992139] LOG:  00000: task jobid/taskid failed: 1450004/1450007
2023-11-25 13:02:11.002 UTC [3992139] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:11.002 UTC [3992139] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 13:02:11.003 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450004/1450007)" (PID 3992141) exited with exit code 1
2023-11-25 13:02:11.003 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:13.008 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:13.008 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:13.008 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:13.011 UTC [3992142] LOG:  00000: task jobid/taskid started: 1450005/1450009
2023-11-25 13:02:13.011 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.011 UTC [3992142] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:13.011 UTC [3992142] LOG:  00000: task jobid/taskid started: 1450005/1450010
2023-11-25 13:02:13.011 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.011 UTC [3992142] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:13.012 UTC [3992142] LOG:  00000: task jobid/taskid started: 1450005/1450011
2023-11-25 13:02:13.012 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.012 UTC [3992142] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:13.012 UTC [3992142] LOG:  00000: task jobid/taskid started: 1450006/1450012
2023-11-25 13:02:13.012 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.012 UTC [3992142] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:13.012 UTC [3992142] WARNING:  01000: unable to start background worker for background task execution
2023-11-25 13:02:13.012 UTC [3992142] DETAIL:  Already reached the maximum number of task executors: 4/4
2023-11-25 13:02:13.012 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.012 UTC [3992142] LOCATION:  NewExecutorExceedsCitusLimit, background_jobs.c:491
2023-11-25 13:02:13.947 UTC [3992146] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:13.947 UTC [3992146] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450006/1450012)
2023-11-25 13:02:13.947 UTC [3992146] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:13.947 UTC [3992142] LOG:  00000: task jobid/taskid is cancelled: 1450006/1450012
2023-11-25 13:02:13.947 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.947 UTC [3992142] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:13.948 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450006/1450012)" (PID 3992146) exited with exit code 1
2023-11-25 13:02:13.948 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:13.949 UTC [3992142] LOG:  00000: able to start a background worker with 0 seconds delay
2023-11-25 13:02:13.949 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.949 UTC [3992142] LOCATION:  CheckAndResetLastWorkerAllocationFailure, background_jobs.c:679
2023-11-25 13:02:13.949 UTC [3992142] LOG:  00000: task jobid/taskid started: 1450007/1450013
2023-11-25 13:02:13.949 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:13.949 UTC [3992142] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:14.949 UTC [3992143] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:14.949 UTC [3992143] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450005/1450009)
2023-11-25 13:02:14.949 UTC [3992143] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:14.949 UTC [3992145] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:14.949 UTC [3992145] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450005/1450011)
2023-11-25 13:02:14.949 UTC [3992145] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:14.949 UTC [3992144] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:14.949 UTC [3992144] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450005/1450010)
2023-11-25 13:02:14.949 UTC [3992144] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:14.950 UTC [3992142] LOG:  00000: task jobid/taskid is cancelled: 1450005/1450011
2023-11-25 13:02:14.950 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:14.950 UTC [3992142] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:14.951 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450005/1450009)" (PID 3992143) exited with exit code 1
2023-11-25 13:02:14.951 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:14.951 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450005/1450010)" (PID 3992144) exited with exit code 1
2023-11-25 13:02:14.951 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:14.951 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450005/1450011)" (PID 3992145) exited with exit code 1
2023-11-25 13:02:14.951 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:14.951 UTC [3992142] LOG:  00000: task jobid/taskid is cancelled: 1450005/1450009
2023-11-25 13:02:14.951 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:14.951 UTC [3992142] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:14.951 UTC [3992142] LOG:  00000: task jobid/taskid is cancelled: 1450005/1450010
2023-11-25 13:02:14.951 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:14.951 UTC [3992142] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:14.952 UTC [3992147] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:14.952 UTC [3992147] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450007/1450013)
2023-11-25 13:02:14.952 UTC [3992147] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:14.952 UTC [3992142] LOG:  00000: task jobid/taskid is cancelled: 1450007/1450013
2023-11-25 13:02:14.952 UTC [3992142] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:14.952 UTC [3992142] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:14.953 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450007/1450013)" (PID 3992147) exited with exit code 1
2023-11-25 13:02:14.953 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:15.953 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:15.953 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:15.953 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:15.956 UTC [3992149] LOG:  00000: task jobid/taskid started: 1450008/1450014
2023-11-25 13:02:15.956 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:15.956 UTC [3992149] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:15.956 UTC [3992149] LOG:  00000: task jobid/taskid started: 1450008/1450015
2023-11-25 13:02:15.956 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:15.956 UTC [3992149] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:15.957 UTC [3992149] LOG:  00000: task jobid/taskid started: 1450008/1450016
2023-11-25 13:02:15.957 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:15.957 UTC [3992149] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:15.957 UTC [3992149] LOG:  00000: task jobid/taskid started: 1450009/1450017
2023-11-25 13:02:15.957 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:15.957 UTC [3992149] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:15.957 UTC [3992149] WARNING:  01000: unable to start background worker for background task execution
2023-11-25 13:02:15.957 UTC [3992149] DETAIL:  Already reached the maximum number of task executors: 4/4
2023-11-25 13:02:15.957 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:15.957 UTC [3992149] LOCATION:  NewExecutorExceedsCitusLimit, background_jobs.c:491
2023-11-25 13:02:16.956 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:16.956 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:16.956 UTC [3976581] LOG:  00000: parameter "citus.max_background_task_executors" changed to "5"
2023-11-25 13:02:16.956 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:16.957 UTC [3992149] LOG:  00000: able to start a background worker with 1 seconds delay
2023-11-25 13:02:16.957 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:16.957 UTC [3992149] LOCATION:  CheckAndResetLastWorkerAllocationFailure, background_jobs.c:679
2023-11-25 13:02:16.957 UTC [3992149] LOG:  00000: task jobid/taskid started: 1450010/1450018
2023-11-25 13:02:16.957 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:16.957 UTC [3992149] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:17.959 UTC [3992151] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:17.959 UTC [3992151] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450008/1450015)
2023-11-25 13:02:17.959 UTC [3992151] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:17.959 UTC [3992152] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:17.959 UTC [3992152] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450008/1450016)
2023-11-25 13:02:17.959 UTC [3992152] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:17.959 UTC [3992150] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:17.959 UTC [3992150] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450008/1450014)
2023-11-25 13:02:17.959 UTC [3992150] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:17.959 UTC [3992149] LOG:  00000: task jobid/taskid is cancelled: 1450008/1450015
2023-11-25 13:02:17.959 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:17.959 UTC [3992149] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:17.961 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450008/1450014)" (PID 3992150) exited with exit code 1
2023-11-25 13:02:17.961 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:17.961 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450008/1450015)" (PID 3992151) exited with exit code 1
2023-11-25 13:02:17.961 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:17.961 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450008/1450016)" (PID 3992152) exited with exit code 1
2023-11-25 13:02:17.961 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:17.961 UTC [3992149] LOG:  00000: task jobid/taskid is cancelled: 1450008/1450014
2023-11-25 13:02:17.961 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:17.961 UTC [3992149] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:17.961 UTC [3992149] LOG:  00000: task jobid/taskid is cancelled: 1450008/1450016
2023-11-25 13:02:17.961 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:17.961 UTC [3992149] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:17.961 UTC [3992153] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:17.961 UTC [3992153] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450009/1450017)
2023-11-25 13:02:17.961 UTC [3992153] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:17.961 UTC [3992149] LOG:  00000: task jobid/taskid is cancelled: 1450009/1450017
2023-11-25 13:02:17.961 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:17.961 UTC [3992149] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:17.962 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450009/1450017)" (PID 3992153) exited with exit code 1
2023-11-25 13:02:17.962 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:17.962 UTC [3992154] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:17.962 UTC [3992154] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450010/1450018)
2023-11-25 13:02:17.962 UTC [3992154] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:17.962 UTC [3992149] LOG:  00000: task jobid/taskid is cancelled: 1450010/1450018
2023-11-25 13:02:17.962 UTC [3992149] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:17.962 UTC [3992149] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:17.963 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450010/1450018)" (PID 3992154) exited with exit code 1
2023-11-25 13:02:17.963 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:18.963 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:18.963 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:18.963 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:18.966 UTC [3992157] LOG:  00000: task jobid/taskid started: 1450011/1450019
2023-11-25 13:02:18.966 UTC [3992157] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:18.966 UTC [3992157] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:18.966 UTC [3992157] LOG:  00000: task jobid/taskid started: 1450012/1450020
2023-11-25 13:02:18.966 UTC [3992157] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:18.966 UTC [3992157] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:19.964 UTC [3992157] LOG:  00000: handling termination signal
2023-11-25 13:02:19.964 UTC [3992157] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:19.964 UTC [3992157] LOCATION:  CitusBackgroundTaskQueueMonitorMain, background_jobs.c:1232
2023-11-25 13:02:19.964 UTC [3992158] FATAL:  57P01: terminating background worker "Citus Background Task Queue Executor: regression/postgres for (1450011/1450019)" due to administrator command
2023-11-25 13:02:19.964 UTC [3992158] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450011/1450019)
2023-11-25 13:02:19.964 UTC [3992158] LOCATION:  ProcessInterrupts, postgres.c:3213
2023-11-25 13:02:19.964 UTC [3992159] FATAL:  57P01: terminating background worker "Citus Background Task Queue Executor: regression/postgres for (1450012/1450020)" due to administrator command
2023-11-25 13:02:19.964 UTC [3992159] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450012/1450020)
2023-11-25 13:02:19.964 UTC [3992159] LOCATION:  ProcessInterrupts, postgres.c:3213
2023-11-25 13:02:19.964 UTC [3992157] LOG:  00000: task jobid/taskid failed: 1450012/1450020
2023-11-25 13:02:19.964 UTC [3992157] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:19.964 UTC [3992157] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 13:02:19.966 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450011/1450019)" (PID 3992158) exited with exit code 1
2023-11-25 13:02:19.966 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:19.966 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450012/1450020)" (PID 3992159) exited with exit code 1
2023-11-25 13:02:19.966 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:19.966 UTC [3992157] LOG:  00000: task jobid/taskid failed: 1450011/1450019
2023-11-25 13:02:19.966 UTC [3992157] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:19.966 UTC [3992157] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 13:02:22.973 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:22.973 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:22.973 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:22.976 UTC [3992160] LOG:  00000: task jobid/taskid started: 1450013/1450021
2023-11-25 13:02:22.976 UTC [3992160] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:22.976 UTC [3992160] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:22.977 UTC [3992160] LOG:  00000: task jobid/taskid started: 1450014/1450022
2023-11-25 13:02:22.977 UTC [3992160] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:22.977 UTC [3992160] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:23.975 UTC [3992160] LOG:  00000: handling cancellation signal
2023-11-25 13:02:23.975 UTC [3992160] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:23.975 UTC [3992160] LOCATION:  CitusBackgroundTaskQueueMonitorMain, background_jobs.c:1239
2023-11-25 13:02:23.976 UTC [3992161] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:23.976 UTC [3992161] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450013/1450021)
2023-11-25 13:02:23.976 UTC [3992161] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:23.976 UTC [3992160] LOG:  00000: task jobid/taskid is cancelled: 1450014/1450022
2023-11-25 13:02:23.976 UTC [3992160] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:23.976 UTC [3992160] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:23.976 UTC [3992162] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:23.976 UTC [3992162] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450014/1450022)
2023-11-25 13:02:23.976 UTC [3992162] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:23.977 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450013/1450021)" (PID 3992161) exited with exit code 1
2023-11-25 13:02:23.977 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:23.977 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450014/1450022)" (PID 3992162) exited with exit code 1
2023-11-25 13:02:23.977 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:23.977 UTC [3992160] LOG:  00000: task jobid/taskid is cancelled: 1450013/1450021
2023-11-25 13:02:23.977 UTC [3992160] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:23.977 UTC [3992160] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:24.980 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:24.980 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:24.980 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:24.983 UTC [3992163] LOG:  00000: task jobid/taskid started: 1450015/1450023
2023-11-25 13:02:24.983 UTC [3992163] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:24.983 UTC [3992163] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:24.983 UTC [3992163] LOG:  00000: task jobid/taskid started: 1450016/1450024
2023-11-25 13:02:24.983 UTC [3992163] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:24.983 UTC [3992163] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:24.986 UTC [3992163] LOG:  00000: task jobid/taskid succeeded: 1450016/1450024
2023-11-25 13:02:24.986 UTC [3992163] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:24.986 UTC [3992163] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:25.980 UTC [3992164] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:25.980 UTC [3992164] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450015/1450023)
2023-11-25 13:02:25.980 UTC [3992164] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:25.980 UTC [3992163] LOG:  00000: task jobid/taskid is cancelled: 1450015/1450023
2023-11-25 13:02:25.980 UTC [3992163] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:25.980 UTC [3992163] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:25.981 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450015/1450023)" (PID 3992164) exited with exit code 1
2023-11-25 13:02:25.981 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:26.985 UTC [3976651] LOG:  00000: found scheduled background tasks, starting new background task queue monitor
2023-11-25 13:02:26.985 UTC [3976651] CONTEXT:  Citus maintenance daemon for database 16384 user 10
2023-11-25 13:02:26.985 UTC [3976651] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:772
2023-11-25 13:02:26.987 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450025
2023-11-25 13:02:26.987 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:26.987 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:26.988 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450026
2023-11-25 13:02:26.988 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:26.988 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:28.992 UTC [3992166] LOG:  00000: task jobid/taskid succeeded: 1450017/1450026
2023-11-25 13:02:28.992 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:28.992 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:28.994 UTC [3992166] LOG:  00000: task jobid/taskid succeeded: 1450017/1450025
2023-11-25 13:02:28.994 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:28.994 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:28.995 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450027
2023-11-25 13:02:28.995 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:28.995 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:29.970 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:29.970 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:29.971 UTC [3976581] LOG:  00000: parameter "citus.max_background_task_executors_per_node" changed to "2"
2023-11-25 13:02:29.971 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:29.972 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450028
2023-11-25 13:02:29.972 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:29.972 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:29.972 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450029
2023-11-25 13:02:29.972 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:29.972 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:33.002 UTC [3992166] LOG:  00000: task jobid/taskid succeeded: 1450017/1450027
2023-11-25 13:02:33.002 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:33.002 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:33.004 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450030
2023-11-25 13:02:33.004 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:33.004 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:33.977 UTC [3992166] LOG:  00000: task jobid/taskid succeeded: 1450017/1450029
2023-11-25 13:02:33.977 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:33.977 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:33.979 UTC [3992166] LOG:  00000: task jobid/taskid succeeded: 1450017/1450028
2023-11-25 13:02:33.979 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:33.979 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:33.980 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450031
2023-11-25 13:02:33.980 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:33.980 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:34.987 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:34.987 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:34.987 UTC [3976581] LOG:  00000: parameter "citus.max_background_task_executors_per_node" changed to "3"
2023-11-25 13:02:34.987 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:34.988 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450032
2023-11-25 13:02:34.988 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:34.988 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:35.990 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:35.990 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:35.991 UTC [3992172] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:35.991 UTC [3992172] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)
2023-11-25 13:02:35.991 UTC [3992172] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:35.991 UTC [3976581] LOG:  00000: parameter "citus.max_background_task_executors_per_node" removed from configuration file, reset to default
2023-11-25 13:02:35.991 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 13:02:35.991 UTC [3992166] LOG:  00000: task jobid/taskid failed: 1450017/1450030
2023-11-25 13:02:35.991 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:35.991 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:770
2023-11-25 13:02:35.992 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)" (PID 3992172) exited with exit code 1
2023-11-25 13:02:35.992 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:39.989 UTC [3992166] LOG:  00000: task jobid/taskid succeeded: 1450017/1450031
2023-11-25 13:02:39.989 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:39.989 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:40.997 UTC [3992166] LOG:  00000: task jobid/taskid succeeded: 1450017/1450032
2023-11-25 13:02:40.997 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:40.997 UTC [3992166] LOCATION:  ConsumeExecutorQueue, background_jobs.c:777
2023-11-25 13:02:40.999 UTC [3992166] LOG:  00000: task jobid/taskid started: 1450017/1450030
2023-11-25 13:02:40.999 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:40.999 UTC [3992166] LOCATION:  AssignRunnableTaskToNewExecutor, background_jobs.c:603
2023-11-25 13:02:41.992 UTC [3992178] ERROR:  57014: canceling statement due to user request
2023-11-25 13:02:41.992 UTC [3992178] CONTEXT:  Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)
2023-11-25 13:02:41.992 UTC [3992178] LOCATION:  ProcessInterrupts, postgres.c:3356
2023-11-25 13:02:41.992 UTC [3992166] LOG:  00000: task jobid/taskid is cancelled: 1450017/1450030
2023-11-25 13:02:41.992 UTC [3992166] CONTEXT:  Citus Background Task Queue Monitor: regression
2023-11-25 13:02:41.992 UTC [3992166] LOCATION:  TaskConcurrentCancelCheck, background_jobs.c:720
2023-11-25 13:02:41.994 UTC [3976581] LOG:  00000: background worker "Citus Background Task Queue Executor: regression/postgres for (1450017/1450030)" (PID 3992178) exited with exit code 1
2023-11-25 13:02:41.994 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:42.995 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:42.995 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:43.004 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:43.004 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:43.004 UTC [3976581] LOG:  00000: parameter "citus.background_task_queue_interval" removed from configuration file, reset to default
2023-11-25 13:02:43.004 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 13:02:43.004 UTC [3976581] LOG:  00000: parameter "citus.max_background_task_executors" removed from configuration file, reset to default
2023-11-25 13:02:43.004 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 13:02:43.117 UTC [3992193] ERROR:  22P02: invalid input syntax for type cluster_clock: "(-1, 100)" at character 39
2023-11-25 13:02:43.117 UTC [3992193] LOCATION:  cluster_clock_in_internal, type_utils.c:71
2023-11-25 13:02:43.117 UTC [3992193] STATEMENT:  INSERT INTO cluster_clock_type values('(-1, 100)');
2023-11-25 13:02:43.118 UTC [3992193] ERROR:  22P02: invalid input syntax for type cluster_clock: "(100, -1)" at character 39
2023-11-25 13:02:43.118 UTC [3992193] LOCATION:  cluster_clock_in_internal, type_utils.c:82
2023-11-25 13:02:43.118 UTC [3992193] STATEMENT:  INSERT INTO cluster_clock_type values('(100, -1)');
2023-11-25 13:02:43.118 UTC [3992193] ERROR:  22P02: invalid input syntax for type cluster_clock: "(4398046511104, 100)" at character 39
2023-11-25 13:02:43.118 UTC [3992193] LOCATION:  cluster_clock_in_internal, type_utils.c:71
2023-11-25 13:02:43.118 UTC [3992193] STATEMENT:  INSERT INTO cluster_clock_type values('(4398046511104, 100)');
2023-11-25 13:02:43.118 UTC [3992193] ERROR:  22P02: invalid input syntax for type cluster_clock: "(0, 4194304)" at character 39
2023-11-25 13:02:43.118 UTC [3992193] LOCATION:  cluster_clock_in_internal, type_utils.c:82
2023-11-25 13:02:43.118 UTC [3992193] STATEMENT:  INSERT INTO cluster_clock_type values('(0, 4194304)');
2023-11-25 13:02:43.121 UTC [3992193] ERROR:  23505: duplicate key value violates unique constraint "cluster_clock_type_cc_key"
2023-11-25 13:02:43.121 UTC [3992193] DETAIL:  Key (cc)=((100,1)) already exists.
2023-11-25 13:02:43.121 UTC [3992193] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 13:02:43.121 UTC [3992193] STATEMENT:  INSERT INTO cluster_clock_type values('(100, 1)');
2023-11-25 13:02:43.121 UTC [3992193] ERROR:  23505: duplicate key value violates unique constraint "cluster_clock_type_cc_key"
2023-11-25 13:02:43.121 UTC [3992193] DETAIL:  Key (cc)=((100,200)) already exists.
2023-11-25 13:02:43.121 UTC [3992193] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 13:02:43.121 UTC [3992193] STATEMENT:  INSERT INTO cluster_clock_type values('(100, 200)');
2023-11-25 13:02:43.121 UTC [3992193] ERROR:  23505: duplicate key value violates unique constraint "cluster_clock_type_cc_key"
2023-11-25 13:02:43.121 UTC [3992193] DETAIL:  Key (cc)=((100,100)) already exists.
2023-11-25 13:02:43.121 UTC [3992193] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 13:02:43.121 UTC [3992193] STATEMENT:  INSERT INTO cluster_clock_type values('(100, 100)');
2023-11-25 13:02:43.235 UTC [3992193] WARNING:  01000: GUC enable_cluster_clock is off
2023-11-25 13:02:43.235 UTC [3992193] LOCATION:  PrepareAndSetTransactionClock, causal_clock.c:419
2023-11-25 13:02:43.238 UTC [3992193] ERROR:  42501: permission denied for sequence pg_dist_clock_logical_seq
2023-11-25 13:02:43.238 UTC [3992193] LOCATION:  do_setval, sequence.c:967
2023-11-25 13:02:43.238 UTC [3992193] STATEMENT:  SELECT setval('pg_dist_clock_logical_seq', 100, true);
2023-11-25 13:02:43.349 UTC [3992237] LOG:  00000: deferred drop of orphaned resource alter_distributed_table.shard_split_table_362791 on localhost:57637 completed
2023-11-25 13:02:43.349 UTC [3992237] LOCATION:  DropOrphanedResourcesForCleanup, shard_cleaner.c:298
2023-11-25 13:02:43.349 UTC [3992237] STATEMENT:  CALL citus_cleanup_orphaned_resources()
2023-11-25 13:02:43.813 UTC [3992231] WARNING:  0A000: "view pg_source_view" has dependency to "table pg_source" that is not in Citus' metadata
2023-11-25 13:02:43.813 UTC [3992231] DETAIL:  "view pg_source_view" will be created only locally
2023-11-25 13:02:43.813 UTC [3992231] HINT:  Distribute "table pg_source" first to distribute "view pg_source_view"
2023-11-25 13:02:43.813 UTC [3992231] LOCATION:  DeferErrorIfHasUnsupportedDependency, dependency.c:950
2023-11-25 13:02:43.974 UTC [3992231] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 13:02:43.974 UTC [3992231] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 13:02:43.974 UTC [3992231] STATEMENT:  MERGE INTO target_serial sda
	USING source_serial sdn
	ON sda.id = sdn.id
	WHEN NOT matched THEN
	       INSERT (id, z) VALUES (id, z);
2023-11-25 13:02:43.987 UTC [3992231] ERROR:  0A000: cannot assign to system column "ctid" at character 110
2023-11-25 13:02:43.987 UTC [3992231] LOCATION:  transformAssignedExpr, parse_target.c:480
2023-11-25 13:02:43.987 UTC [3992231] STATEMENT:  MERGE INTO target_set
	USING source_set AS foo ON target_set.t1 = foo.s1
	WHEN MATCHED THEN
	        UPDATE SET ctid = '(0,100)';
2023-11-25 13:02:43.987 UTC [3992231] ERROR:  0A000: cannot pushdown the subquery since not all subqueries in the UNION have the partition column in the same position
2023-11-25 13:02:43.987 UTC [3992231] DETAIL:  Each leaf query of the UNION should return the partition column in the same position and all joins must be on the partition column
2023-11-25 13:02:43.987 UTC [3992231] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:582
2023-11-25 13:02:43.987 UTC [3992231] STATEMENT:  MERGE INTO target_set
	USING (SELECT s1,s2 FROM source_set UNION SELECT s2,s1 FROM source_set) AS foo ON target_set.t1 = foo.s1
	WHEN MATCHED THEN
	        UPDATE SET t2 = t2 + 1;
2023-11-25 13:02:43.987 UTC [3992231] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:02:43.987 UTC [3992231] DETAIL:  Limit clause is currently unsupported when a subquery references a column from another query
2023-11-25 13:02:43.987 UTC [3992231] LOCATION:  DeferErrorIfSubqueryRequiresMerge, query_pushdown_planning.c:1156
2023-11-25 13:02:43.987 UTC [3992231] STATEMENT:  MERGE INTO target_set
	USING (SELECT 2 as s3, source_set.* FROM (SELECT * FROM source_set LIMIT 1) as foo LEFT JOIN source_set USING( s1)) AS foo
	ON target_set.t1 = foo.s1
	WHEN MATCHED THEN UPDATE SET t2 = t2 + 1
	WHEN NOT MATCHED THEN INSERT VALUES(s1, s3);
2023-11-25 13:02:43.988 UTC [3992231] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:02:43.988 UTC [3992231] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:02:43.988 UTC [3992231] STATEMENT:  EXPLAIN
	WITH cte_1 AS (DELETE FROM target_json)
	MERGE INTO target_json sda
	USING source_json sdn
	ON sda.id = sdn.id
	WHEN NOT matched THEN
		INSERT (id, z) VALUES (sdn.id, 5);
2023-11-25 13:02:43.988 UTC [3992231] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:02:43.988 UTC [3992231] DETAIL:  could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 13:02:43.988 UTC [3992231] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 13:02:43.988 UTC [3992231] STATEMENT:  MERGE INTO citus_target t
	USING (SELECT count(*), id FROM citus_source GROUP BY GROUPING SETS (id, val)) subq
	ON subq.id = t.id
	WHEN MATCHED AND t.id > 350 THEN
	    UPDATE SET val = t.val || 'Updated'
	WHEN NOT MATCHED THEN
	        INSERT VALUES (subq.id, 99)
	WHEN MATCHED AND t.id < 350 THEN
	        DELETE;
2023-11-25 13:02:43.988 UTC [3992231] ERROR:  0A000: cannot push down this subquery
2023-11-25 13:02:43.988 UTC [3992231] DETAIL:  could not run distributed query with GROUPING SETS, CUBE, or ROLLUP
2023-11-25 13:02:43.988 UTC [3992231] LOCATION:  DeferErrorIfCannotPushdownSubquery, query_pushdown_planning.c:1048
2023-11-25 13:02:43.988 UTC [3992231] STATEMENT:  WITH subq AS
	(
	SELECT count(*), id FROM citus_source GROUP BY GROUPING SETS (id, val)
	)
	MERGE INTO citus_target t
	USING subq
	ON subq.id = t.id
	WHEN MATCHED AND t.id > 350 THEN
	    UPDATE SET val = t.val || 'Updated'
	WHEN NOT MATCHED THEN
	        INSERT VALUES (subq.id, 99)
	WHEN MATCHED AND t.id < 350 THEN
	        DELETE;
2023-11-25 13:02:43.988 UTC [3992231] ERROR:  0A000: cannot perform MERGE INSERT with DEFAULTS
2023-11-25 13:02:43.988 UTC [3992231] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:546
2023-11-25 13:02:43.988 UTC [3992231] STATEMENT:  MERGE INTO citus_target t
	USING citus_source s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT DEFAULT VALUES;
2023-11-25 13:02:43.988 UTC [3992231] ERROR:  0A000: MERGE INSERT must refer a source column for distribution column 
2023-11-25 13:02:43.988 UTC [3992231] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:583
2023-11-25 13:02:43.988 UTC [3992231] STATEMENT:  MERGE INTO citus_target t
	USING citus_source s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT VALUES(10000);
2023-11-25 13:02:43.989 UTC [3992231] ERROR:  0A000: MERGE INSERT must refer a source column for distribution column 
2023-11-25 13:02:43.989 UTC [3992231] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:583
2023-11-25 13:02:43.989 UTC [3992231] STATEMENT:  MERGE INTO citus_target t
	USING citus_source s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT (id) VALUES(1000);
2023-11-25 13:02:43.989 UTC [3992231] ERROR:  0A000: MERGE INSERT must use the source table distribution column value
2023-11-25 13:02:43.989 UTC [3992231] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:575
2023-11-25 13:02:43.989 UTC [3992231] STATEMENT:  MERGE INTO t1 t
	USING s1 s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT (id) VALUES(s.val);
2023-11-25 13:02:43.989 UTC [3992231] ERROR:  0A000: MERGE INSERT must have distribution column as value
2023-11-25 13:02:43.989 UTC [3992231] LOCATION:  InsertDistributionColumnMatchesSource, merge_planner.c:592
2023-11-25 13:02:43.989 UTC [3992231] STATEMENT:  MERGE INTO t1 t
	USING s1 s
	ON t.id = s.id
	WHEN NOT MATCHED THEN
	  INSERT (val) VALUES(s.val);
2023-11-25 13:02:43.989 UTC [3992231] ERROR:  0A000: updating the distribution column is not allowed in MERGE actions
2023-11-25 13:02:43.989 UTC [3992231] LOCATION:  MergeQualAndTargetListFunctionsSupported, merge_planner.c:651
2023-11-25 13:02:43.989 UTC [3992231] STATEMENT:  MERGE INTO target_cj t
	  USING source_cj1 s
	  ON t.tid = s.sid1 AND t.tid = 2
	  WHEN MATCHED THEN
	    UPDATE SET tid = tid + 9, src = src || ' updated by merge'
	  WHEN NOT MATCHED THEN
	    INSERT VALUES (sid1, 'inserted by merge', val1);
2023-11-25 13:02:43.989 UTC [3992231] ERROR:  0A000: cannot execute MERGE on relation "foreign_table"
2023-11-25 13:02:43.989 UTC [3992231] DETAIL:  This operation is not supported for foreign tables.
2023-11-25 13:02:43.989 UTC [3992231] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 13:02:43.989 UTC [3992231] STATEMENT:  MERGE INTO foreign_table
		USING ft_target ON (foreign_table.id = ft_target.id)
		WHEN MATCHED THEN
			DELETE
		WHEN NOT MATCHED THEN
			INSERT (id, user_val) VALUES (ft_target.id, ft_target.user_val);
2023-11-25 13:02:44.008 UTC [3992231] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 13:02:44.008 UTC [3992231] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 13:02:44.008 UTC [3992231] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.val) -- val is not a distribution column
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 13:02:44.024 UTC [3992231] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 13:02:44.024 UTC [3992231] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 13:02:44.024 UTC [3992231] STATEMENT:  MERGE INTO t1 USING (SELECT * FROM s1 WHERE true) s1 ON
	  t1.id = s1.id AND s1.id = 2
	   WHEN matched THEN
	 UPDATE SET id = s1.id, val = random();
2023-11-25 13:02:44.025 UTC [3992231] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 13:02:44.025 UTC [3992231] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 13:02:44.025 UTC [3992231] STATEMENT:  MERGE INTO t1
	USING s1 ON t1.id = s1.id
	WHEN NOT MATCHED THEN
		INSERT VALUES(s1.id, add_s(s1.val, 2));
2023-11-25 13:02:44.025 UTC [3992231] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 13:02:44.025 UTC [3992231] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 13:02:44.025 UTC [3992231] STATEMENT:  MERGE INTO t1
	USING s1 ON t1.id = s1.id AND t1.id = 2 AND (merge_when_and_write())
	WHEN MATCHED THEN
	        UPDATE SET val = t1.val + s1.val;
2023-11-25 13:02:44.025 UTC [3992231] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 13:02:44.025 UTC [3992231] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 13:02:44.025 UTC [3992231] STATEMENT:  MERGE INTO t1
	USING s1 ON t1.id = s1.id AND t1.id = 2
	WHEN MATCHED AND (merge_when_and_write()) THEN
	        UPDATE SET val = t1.val + s1.val;
2023-11-25 13:02:44.026 UTC [3992231] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:02:44.026 UTC [3992231] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:02:44.026 UTC [3992231] STATEMENT:  MERGE INTO t1
		USING (SELECT * FROM s1) sub ON (sub.val = t1.id) -- sub.val is not a distribution column
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 13:02:44.026 UTC [3992231] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:02:44.026 UTC [3992231] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:02:44.026 UTC [3992231] STATEMENT:  WITH s1_res AS (
		SELECT * FROM s1
	)
	MERGE INTO t1
		USING s1_res ON (s1_res.val = t1.id)
		WHEN MATCHED AND s1_res.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1_res.id, s1_res.val);
2023-11-25 13:02:44.026 UTC [3992231] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:02:44.026 UTC [3992231] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:02:44.026 UTC [3992231] STATEMENT:  WITH s1_res AS (
		SELECT * FROM s1
	)
	MERGE INTO t1
		USING s1_res ON (TRUE)
		WHEN MATCHED AND s1_res.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1_res.id, s1_res.val);
2023-11-25 13:02:44.026 UTC [3992231] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:02:44.026 UTC [3992231] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:02:44.026 UTC [3992231] STATEMENT:  WITH s1_res AS (
	     SELECT * FROM s1
	 )
	 MERGE INTO t1 USING s1_res ON (s1_res.id = t1.val)
	 WHEN MATCHED THEN DELETE
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1_res.id, s1_res.val);
2023-11-25 13:02:44.048 UTC [3992231] ERROR:  0A000: MERGE command is not supported on reference tables yet
2023-11-25 13:02:44.048 UTC [3992231] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:330
2023-11-25 13:02:44.048 UTC [3992231] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.id)
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 13:02:44.064 UTC [3992231] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 13:02:44.064 UTC [3992231] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 13:02:44.064 UTC [3992231] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.id)
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 13:02:44.065 UTC [3992231] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 13:02:44.065 UTC [3992231] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 13:02:44.065 UTC [3992231] STATEMENT:  MERGE INTO t1
		USING (SELECT * FROM s1) sub ON (sub.id = t1.id)
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 13:02:44.075 UTC [3992231] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 13:02:44.075 UTC [3992231] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 13:02:44.075 UTC [3992231] STATEMENT:  MERGE INTO t1
		USING (SELECT s1.id, pg.val FROM s1, pg) sub ON (sub.id = t1.id)
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 13:02:44.076 UTC [3992231] ERROR:  0A000: MERGE command is not supported with combination of distributed/local tables yet
2023-11-25 13:02:44.076 UTC [3992231] LOCATION:  ErrorIfMergeHasUnsupportedTables, merge_planner.c:456
2023-11-25 13:02:44.076 UTC [3992231] STATEMENT:  WITH pg_res AS (
		SELECT * FROM pg
	)
	MERGE INTO t1
		USING (SELECT s1.id, pg_res.val FROM s1, pg_res) sub ON (sub.id = t1.id)
		WHEN MATCHED AND sub.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (sub.id, sub.val);
2023-11-25 13:02:44.092 UTC [3992231] ERROR:  21000: MERGE command cannot affect row a second time
2023-11-25 13:02:44.092 UTC [3992231] HINT:  Ensure that not more than one source row matches any one target row.
2023-11-25 13:02:44.092 UTC [3992231] LOCATION:  ExecMergeMatched, nodeModifyTable.c:2932
2023-11-25 13:02:44.092 UTC [3992231] STATEMENT:  MERGE INTO t1
		USING s1 ON (s1.id = t1.id)
		WHEN MATCHED AND s1.val = 0 THEN
			DELETE
		WHEN MATCHED THEN
			UPDATE SET val = t1.val + 1
		WHEN NOT MATCHED THEN
			INSERT (id, val) VALUES (s1.id, s1.val);
2023-11-25 13:02:44.092 UTC [3992231] ERROR:  0A000: cannot execute MERGE on relation "mv_source"
2023-11-25 13:02:44.092 UTC [3992231] DETAIL:  This operation is not supported for materialized views.
2023-11-25 13:02:44.092 UTC [3992231] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 13:02:44.092 UTC [3992231] STATEMENT:  MERGE INTO mv_source
	USING mv_target
	ON mv_source.id = mv_target.id
	WHEN MATCHED THEN
	    DO NOTHING
	WHEN NOT MATCHED THEN
	    INSERT VALUES(mv_source.id, mv_source.val);
2023-11-25 13:02:44.104 UTC [3992231] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated
2023-11-25 13:02:44.104 UTC [3992231] LOCATION:  ErrorIfDistTablesNotColocated, merge_planner.c:277
2023-11-25 13:02:44.104 UTC [3992231] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 13:02:44.108 UTC [3992231] ERROR:  0A000: MERGE command is only supported when all distributed tables are co-located and joined on their distribution columns
2023-11-25 13:02:44.108 UTC [3992231] LOCATION:  DeferErrorIfUnsupportedSubqueryPushdown, query_pushdown_planning.c:602
2023-11-25 13:02:44.108 UTC [3992231] STATEMENT:  MERGE INTO dist_target
	USING dist_colocated
	ON dist_target.id = dist_colocated.val -- val is not the distribution column
	WHEN MATCHED THEN
	UPDATE SET val = dist_colocated.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_colocated.id, dist_colocated.val);
2023-11-25 13:02:44.108 UTC [3992231] ERROR:  0A000: For MERGE command, both the source and target must be distributed
2023-11-25 13:02:44.108 UTC [3992231] LOCATION:  ErrorIfDistTablesNotColocated, merge_planner.c:269
2023-11-25 13:02:44.108 UTC [3992231] STATEMENT:  MERGE INTO dist_target
	USING (SELECT 100 id) AS source
	ON dist_target.id = source.id AND dist_target.val = 'const'
	WHEN MATCHED THEN
	UPDATE SET val = 'source'
	WHEN NOT MATCHED THEN
	INSERT VALUES(source.id, 'source');
2023-11-25 13:02:44.119 UTC [3992231] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 13:02:44.119 UTC [3992231] HINT:  Consider using hash distribution instead
2023-11-25 13:02:44.119 UTC [3992231] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 13:02:44.119 UTC [3992231] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 13:02:44.123 UTC [3992231] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 13:02:44.123 UTC [3992231] HINT:  Consider using hash distribution instead
2023-11-25 13:02:44.123 UTC [3992231] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 13:02:44.123 UTC [3992231] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 13:02:44.133 UTC [3992231] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 13:02:44.133 UTC [3992231] HINT:  Consider using hash distribution instead
2023-11-25 13:02:44.133 UTC [3992231] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 13:02:44.133 UTC [3992231] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 13:02:44.139 UTC [3992231] ERROR:  0A000: For MERGE command, all the distributed tables must be colocated, for append/range distribution, colocation is not supported
2023-11-25 13:02:44.139 UTC [3992231] HINT:  Consider using hash distribution instead
2023-11-25 13:02:44.139 UTC [3992231] LOCATION:  CheckIfRTETypeIsUnsupported, merge_planner.c:339
2023-11-25 13:02:44.139 UTC [3992231] STATEMENT:  MERGE INTO dist_target
	USING dist_source
	ON dist_target.id = dist_source.id
	WHEN MATCHED THEN
	UPDATE SET val = dist_source.val
	WHEN NOT MATCHED THEN
	INSERT VALUES(dist_source.id, dist_source.val);
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42601: syntax error at or near "RANDOMWORD" at character 21
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target t RANDOMWORD
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42601: syntax error at or near "INSERT" at character 75
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42601: syntax error at or near "INTO" at character 86
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT INTO target DEFAULT VALUES;
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42601: syntax error at or near "," at character 98
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT VALUES (1,1), (2,2);
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42601: syntax error at or near "SELECT" at character 86
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT SELECT (1, 1);
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42601: syntax error at or near "UPDATE" at character 79
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42601: syntax error at or near "target" at character 82
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		UPDATE target SET balance = 0;
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  42712: name "target" specified more than once
2023-11-25 13:02:44.545 UTC [3992321] DETAIL:  The name is used both as MERGE target table and data source.
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  transformMergeStmt, parse_merge.c:206
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  MERGE INTO target
	USING target
	ON tid = tid
	WHEN MATCHED THEN DO NOTHING;
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  0A000: MERGE not supported in WITH query at character 6
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  transformWithClause, parse_cte.c:131
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  WITH foo AS (
	  MERGE INTO target USING source ON (true)
	  WHEN MATCHED THEN DELETE
	) SELECT * FROM foo;
2023-11-25 13:02:44.545 UTC [3992321] ERROR:  0A000: MERGE not supported in COPY
2023-11-25 13:02:44.545 UTC [3992321] LOCATION:  DoCopy, copy.c:281
2023-11-25 13:02:44.545 UTC [3992321] STATEMENT:  COPY (
	  MERGE INTO target USING source ON (true)
	  WHEN MATCHED THEN DELETE
	) TO stdout;
2023-11-25 13:02:44.552 UTC [3992321] ERROR:  0A000: cannot execute MERGE on relation "tv"
2023-11-25 13:02:44.552 UTC [3992321] DETAIL:  This operation is not supported for views.
2023-11-25 13:02:44.552 UTC [3992321] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 13:02:44.552 UTC [3992321] STATEMENT:  MERGE INTO tv t
	USING source s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 13:02:44.558 UTC [3992321] ERROR:  0A000: cannot execute MERGE on relation "mv"
2023-11-25 13:02:44.558 UTC [3992321] DETAIL:  This operation is not supported for materialized views.
2023-11-25 13:02:44.558 UTC [3992321] LOCATION:  transformMergeStmt, parse_merge.c:180
2023-11-25 13:02:44.558 UTC [3992321] STATEMENT:  MERGE INTO mv t
	USING source s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 13:02:44.558 UTC [3992321] ERROR:  42501: permission denied for table source2
2023-11-25 13:02:44.558 UTC [3992321] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:02:44.558 UTC [3992321] STATEMENT:  MERGE INTO target
	USING source2
	ON target.tid = source2.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 13:02:44.560 UTC [3992321] ERROR:  42501: permission denied for table target
2023-11-25 13:02:44.560 UTC [3992321] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:02:44.560 UTC [3992321] STATEMENT:  MERGE INTO target
	USING source2
	ON target.tid = source2.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 13:02:44.565 UTC [3992321] ERROR:  42501: permission denied for table target2
2023-11-25 13:02:44.565 UTC [3992321] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:02:44.565 UTC [3992321] STATEMENT:  MERGE INTO target2
	USING source
	ON target2.tid = source.sid
	WHEN MATCHED THEN
		DELETE;
2023-11-25 13:02:44.565 UTC [3992321] ERROR:  42501: permission denied for table target2
2023-11-25 13:02:44.565 UTC [3992321] LOCATION:  aclcheck_error, aclchk.c:3650
2023-11-25 13:02:44.565 UTC [3992321] STATEMENT:  MERGE INTO target2
	USING source
	ON target2.tid = source.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 13:02:44.565 UTC [3992321] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 55
2023-11-25 13:02:44.565 UTC [3992321] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 13:02:44.565 UTC [3992321] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 13:02:44.565 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING (SELECT * FROM source WHERE t.tid > sid) s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT DEFAULT VALUES;
2023-11-25 13:02:44.581 UTC [3992321] ERROR:  21000: MERGE command cannot affect row a second time
2023-11-25 13:02:44.581 UTC [3992321] HINT:  Ensure that not more than one source row matches any one target row.
2023-11-25 13:02:44.581 UTC [3992321] LOCATION:  ExecMergeMatched, nodeModifyTable.c:2932
2023-11-25 13:02:44.581 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		UPDATE SET balance = 0;
2023-11-25 13:02:44.581 UTC [3992321] ERROR:  21000: MERGE command cannot affect row a second time
2023-11-25 13:02:44.581 UTC [3992321] HINT:  Ensure that not more than one source row matches any one target row.
2023-11-25 13:02:44.581 UTC [3992321] LOCATION:  ExecMergeMatched, nodeModifyTable.c:2932
2023-11-25 13:02:44.581 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN
		DELETE;
2023-11-25 13:02:44.582 UTC [3992321] ERROR:  23505: duplicate key value violates unique constraint "targetidx_4001000"
2023-11-25 13:02:44.582 UTC [3992321] DETAIL:  Key (tid)=(4) already exists.
2023-11-25 13:02:44.582 UTC [3992321] LOCATION:  _bt_check_unique, nbtinsert.c:664
2023-11-25 13:02:44.582 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
	  INSERT VALUES (4, NULL);
2023-11-25 13:02:44.582 UTC [3992321] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:02:44.582 UTC [3992321] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:02:44.582 UTC [3992321] STATEMENT:  SELECT * FROM target ORDER BY tid;
2023-11-25 13:02:44.590 UTC [3992321] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 109
2023-11-25 13:02:44.590 UTC [3992321] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 13:02:44.590 UTC [3992321] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 13:02:44.590 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN NOT MATCHED THEN
		INSERT (tid, balance) VALUES (t.tid, s.delta);
2023-11-25 13:02:44.590 UTC [3992321] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 109
2023-11-25 13:02:44.590 UTC [3992321] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 13:02:44.590 UTC [3992321] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 13:02:44.590 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON (SELECT true)
	WHEN NOT MATCHED THEN
		INSERT (tid, balance) VALUES (t.tid, s.delta);
2023-11-25 13:02:44.590 UTC [3992321] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:02:44.590 UTC [3992321] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:02:44.590 UTC [3992321] STATEMENT:  SELECT * FROM target ORDER BY tid;
2023-11-25 13:02:44.591 UTC [3992321] ERROR:  42601: unreachable WHEN clause specified after unconditional WHEN clause
2023-11-25 13:02:44.591 UTC [3992321] LOCATION:  transformMergeStmt, parse_merge.c:159
2023-11-25 13:02:44.591 UTC [3992321] STATEMENT:  MERGE INTO target t
	USING source AS s
	ON t.tid = s.sid
	WHEN MATCHED THEN /* Terminal WHEN clause for MATCHED */
		DELETE
	WHEN MATCHED AND s.delta > 0 THEN
		UPDATE SET balance = t.balance - s.delta;
2023-11-25 13:02:44.600 UTC [3992321] ERROR:  42P01: invalid reference to FROM-clause entry for table "t" at character 80
2023-11-25 13:02:44.600 UTC [3992321] HINT:  There is an entry for table "t", but it cannot be referenced from this part of the query.
2023-11-25 13:02:44.600 UTC [3992321] LOCATION:  errorMissingRTE, parse_relation.c:3597
2023-11-25 13:02:44.600 UTC [3992321] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid
	WHEN NOT MATCHED AND t.balance = 100 THEN
		INSERT (tid) VALUES (s.sid);
2023-11-25 13:02:44.600 UTC [3992321] ERROR:  25P02: current transaction is aborted, commands ignored until end of transaction block
2023-11-25 13:02:44.600 UTC [3992321] LOCATION:  exec_simple_query, postgres.c:1112
2023-11-25 13:02:44.600 UTC [3992321] STATEMENT:  SELECT * FROM wq_target;
2023-11-25 13:02:44.604 UTC [3992321] ERROR:  42P10: cannot use system column "xmin" in MERGE WHEN condition at character 76
2023-11-25 13:02:44.604 UTC [3992321] LOCATION:  scanNSItemForColumn, parse_relation.c:709
2023-11-25 13:02:44.604 UTC [3992321] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid
	WHEN MATCHED AND t.xmin = t.xmax THEN
		UPDATE SET balance = t.balance + s.balance;
2023-11-25 13:02:44.608 UTC [3992321] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 13:02:44.608 UTC [3992321] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 13:02:44.608 UTC [3992321] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid
	WHEN MATCHED AND (merge_when_and_write()) THEN
		UPDATE SET balance = t.balance + s.balance;
2023-11-25 13:02:44.609 UTC [3992321] ERROR:  0A000: non-IMMUTABLE functions are not yet supported in MERGE sql with distributed tables 
2023-11-25 13:02:44.609 UTC [3992321] LOCATION:  MergeQuerySupported, merge_planner.c:134
2023-11-25 13:02:44.609 UTC [3992321] STATEMENT:  MERGE INTO wq_target t
	USING wq_source s ON t.tid = s.sid AND (merge_when_and_write())
	WHEN MATCHED THEN
		UPDATE SET balance = t.balance + s.balance;
2023-11-25 13:02:44.660 UTC [3992321] ERROR:  42702: column reference "balance" is ambiguous at character 98
2023-11-25 13:02:44.660 UTC [3992321] LOCATION:  colNameToVar, parse_relation.c:898
2023-11-25 13:02:44.660 UTC [3992321] STATEMENT:  MERGE INTO sq_target
	USING v
	ON tid = sid
	WHEN MATCHED AND tid > 2 THEN
	    UPDATE SET balance = balance + delta
	WHEN NOT MATCHED THEN
		INSERT (balance, tid) VALUES (balance + delta, sid)
	WHEN MATCHED AND tid < 2 THEN
		DELETE;
2023-11-25 13:02:44.662 UTC [3992321] ERROR:  42601: syntax error at or near "RETURNING" at character 231
2023-11-25 13:02:44.662 UTC [3992321] LOCATION:  scanner_yyerror, scan.l:1188
2023-11-25 13:02:44.662 UTC [3992321] STATEMENT:  MERGE INTO sq_target t
	USING v
	ON tid = sid
	WHEN MATCHED AND tid > 2 THEN
	    UPDATE SET balance = t.balance + delta
	WHEN NOT MATCHED THEN
		INSERT (balance, tid) VALUES (balance + delta, sid)
	WHEN MATCHED AND tid < 2 THEN
		DELETE
	RETURNING *;
2023-11-25 13:02:45.022 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:45.022 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:45.022 UTC [3976581] LOG:  00000: parameter "citus.max_cached_conns_per_worker" changed to "0"
2023-11-25 13:02:45.022 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:45.023 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:45.023 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:45.023 UTC [3976581] LOG:  00000: parameter "citus.distributed_deadlock_detection_factor" changed to "-1"
2023-11-25 13:02:45.023 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:45.023 UTC [3976581] LOG:  00000: parameter "citus.recover_2pc_interval" changed to "1ms"
2023-11-25 13:02:45.023 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:45.124 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:45.124 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:45.125 UTC [3976581] LOG:  00000: parameter "citus.recover_2pc_interval" changed to "-1"
2023-11-25 13:02:45.125 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:453
2023-11-25 13:02:45.361 UTC [3976581] LOG:  00000: received SIGHUP, reloading configuration files
2023-11-25 13:02:45.361 UTC [3976581] LOCATION:  SIGHUP_handler, postmaster.c:2769
2023-11-25 13:02:45.361 UTC [3976581] LOG:  00000: parameter "citus.distributed_deadlock_detection_factor" removed from configuration file, reset to default
2023-11-25 13:02:45.361 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 13:02:45.361 UTC [3976581] LOG:  00000: parameter "citus.max_cached_conns_per_worker" removed from configuration file, reset to default
2023-11-25 13:02:45.361 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 13:02:45.361 UTC [3976581] LOG:  00000: parameter "citus.recover_2pc_interval" removed from configuration file, reset to default
2023-11-25 13:02:45.361 UTC [3976581] LOCATION:  ProcessConfigFileInternal, guc-file.l:388
2023-11-25 13:02:45.501 UTC [3992507] ERROR:  0A000: cannot complete operation on generated_identities.smallint_identity_column with smallint/int identity column
2023-11-25 13:02:45.501 UTC [3992507] HINT:  Use bigint identity column instead.
2023-11-25 13:02:45.501 UTC [3992507] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 13:02:45.501 UTC [3992507] STATEMENT:  SELECT create_distributed_table('smallint_identity_column', 'a');
2023-11-25 13:02:45.645 UTC [3992507] ERROR:  0A000: cannot complete operation on generated_identities.smallint_identity_column with smallint/int identity column
2023-11-25 13:02:45.645 UTC [3992507] HINT:  Use bigint identity column instead.
2023-11-25 13:02:45.645 UTC [3992507] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 13:02:45.645 UTC [3992507] STATEMENT:  SELECT create_distributed_table_concurrently('smallint_identity_column', 'a');
2023-11-25 13:02:45.645 UTC [3992507] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 13:02:45.645 UTC [3992507] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 13:02:45.645 UTC [3992507] STATEMENT:  SELECT create_reference_table('smallint_identity_column');
2023-11-25 13:02:45.653 UTC [3992507] ERROR:  0A000: cannot complete operation on generated_identities.int_identity_column with smallint/int identity column
2023-11-25 13:02:45.653 UTC [3992507] HINT:  Use bigint identity column instead.
2023-11-25 13:02:45.653 UTC [3992507] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 13:02:45.653 UTC [3992507] STATEMENT:  SELECT create_distributed_table('int_identity_column', 'a');
2023-11-25 13:02:45.671 UTC [3992507] ERROR:  0A000: cannot complete operation on generated_identities.int_identity_column with smallint/int identity column
2023-11-25 13:02:45.671 UTC [3992507] HINT:  Use bigint identity column instead.
2023-11-25 13:02:45.671 UTC [3992507] LOCATION:  ErrorIfTableHasUnsupportedIdentityColumn, table.c:3997
2023-11-25 13:02:45.671 UTC [3992507] STATEMENT:  SELECT create_distributed_table_concurrently('int_identity_column', 'a');
2023-11-25 13:02:45.671 UTC [3992507] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 13:02:45.671 UTC [3992507] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 13:02:45.671 UTC [3992507] STATEMENT:  SELECT create_reference_table('int_identity_column');
2023-11-25 13:02:45.755 UTC [3992554] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 13:02:45.755 UTC [3992554] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 13:02:45.755 UTC [3992554] STATEMENT:  SELECT alter_distributed_table('bigint_identity_column', 'b');
2023-11-25 13:02:45.755 UTC [3992554] ERROR:  0A000: cannot complete operation on a table with identity column
2023-11-25 13:02:45.755 UTC [3992554] LOCATION:  ErrorIfTableHasIdentityColumn, table.c:4026
2023-11-25 13:02:45.755 UTC [3992554] STATEMENT:  SELECT undistribute_table('bigint_identity_column');
2023-11-25 13:02:45.863 UTC [3992571] ERROR:  0A000: alter table command is currently unsupported
2023-11-25 13:02:45.863 UTC [3992571] DETAIL:  Only ADD|DROP COLUMN, SET|DROP NOT NULL, SET|DROP DEFAULT, ADD|DROP|VALIDATE CONSTRAINT, SET (), RESET (), ENABLE|DISABLE|NO FORCE|FORCE ROW LEVEL SECURITY, ATTACH|DETACH PARTITION and TYPE subcommands are supported.
2023-11-25 13:02:45.863 UTC [3992571] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3506
2023-11-25 13:02:45.863 UTC [3992571] STATEMENT:  ALTER TABLE partitioned_table ALTER COLUMN g ADD GENERATED ALWAYS AS IDENTITY;
2023-11-25 13:02:45.863 UTC [3992571] ERROR:  XX000: cannot execute ALTER COLUMN command involving identity column
2023-11-25 13:02:45.863 UTC [3992571] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3306
2023-11-25 13:02:45.863 UTC [3992571] STATEMENT:  ALTER TABLE partitioned_table ALTER COLUMN b TYPE int;
2023-11-25 13:02:45.942 UTC [3992586] ERROR:  42501: must be owner of table color
2023-11-25 13:02:45.942 UTC [3992586] LOCATION:  aclcheck_error, aclchk.c:3788
2023-11-25 13:02:45.942 UTC [3992586] STATEMENT:  SELECT create_distributed_table('color', 'color_id');
2023-11-25 13:02:45.970 UTC [3992586] LOG:  00000: performing non-blocking create_distributed_table_concurrently 
2023-11-25 13:02:45.970 UTC [3992586] LOCATION:  SplitShard, shard_split.c:519
2023-11-25 13:02:45.970 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:45.975 UTC [3992586] LOG:  00000: creating child shards for create_distributed_table_concurrently
2023-11-25 13:02:45.975 UTC [3992586] LOCATION:  NonBlockingShardSplit, shard_split.c:1430
2023-11-25 13:02:45.975 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:46.001 UTC [3992586] LOG:  00000: creating replication artifacts (publications, replication slots, subscriptions for create_distributed_table_concurrently
2023-11-25 13:02:46.001 UTC [3992586] LOCATION:  NonBlockingShardSplit, shard_split.c:1462
2023-11-25 13:02:46.001 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:46.012 UTC [3992596] LOG:  00000: Initializing CDC decoder
2023-11-25 13:02:46.012 UTC [3992596] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 13:02:46.012 UTC [3992596] STATEMENT:  CREATE_REPLICATION_SLOT citus_shard_split_slot_16_10_24 LOGICAL citus EXPORT_SNAPSHOT;
2023-11-25 13:02:46.012 UTC [3992596] LOG:  00000: logical decoding found consistent point at 0/7C6AC40
2023-11-25 13:02:46.012 UTC [3992596] DETAIL:  There are no running transactions.
2023-11-25 13:02:46.012 UTC [3992596] LOCATION:  SnapBuildFindSnapshot, snapbuild.c:1366
2023-11-25 13:02:46.012 UTC [3992596] STATEMENT:  CREATE_REPLICATION_SLOT citus_shard_split_slot_16_10_24 LOGICAL citus EXPORT_SNAPSHOT;
2023-11-25 13:02:46.012 UTC [3992596] LOG:  00000: exported logical decoding snapshot: "00000007-00000A5B-1" with 0 transaction IDs
2023-11-25 13:02:46.012 UTC [3992596] LOCATION:  SnapBuildExportSnapshot, snapbuild.c:687
2023-11-25 13:02:46.012 UTC [3992596] STATEMENT:  CREATE_REPLICATION_SLOT citus_shard_split_slot_16_10_24 LOGICAL citus EXPORT_SNAPSHOT;
2023-11-25 13:02:46.019 UTC [3992595] LOG:  00000: Initializing CDC decoder
2023-11-25 13:02:46.019 UTC [3992595] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 13:02:46.019 UTC [3992595] STATEMENT:  SELECT pg_catalog.pg_copy_logical_replication_slot('citus_shard_split_slot_16_10_24', 'citus_shard_split_slot_34_10_24')
2023-11-25 13:02:46.041 UTC [3992586] LOG:  00000: performing copy for create_distributed_table_concurrently
2023-11-25 13:02:46.041 UTC [3992586] LOCATION:  NonBlockingShardSplit, shard_split.c:1534
2023-11-25 13:02:46.041 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:46.042 UTC [3992599] LOG:  00000: performing copy from shard generated_identities.color_363176 to [generated_identities.color_363177 (nodeId: 16), generated_identities.color_363178 (nodeId: 34), generated_identities.color_363179 (nodeId: 16), generated_identities.color_363180 (nodeId: 34)]
2023-11-25 13:02:46.042 UTC [3992599] LOCATION:  worker_split_copy, worker_split_copy_udf.c:107
2023-11-25 13:02:46.042 UTC [3992599] STATEMENT:  SELECT pg_catalog.worker_split_copy(363176, 'color_id', ARRAY[ROW(363177, -2147483648, -1073741825, 16)::pg_catalog.split_copy_info,ROW(363178, -1073741824, -1, 34)::pg_catalog.split_copy_info,ROW(363179, 0, 1073741823, 16)::pg_catalog.split_copy_info,ROW(363180, 1073741824, 2147483647, 34)::pg_catalog.split_copy_info]);
2023-11-25 13:02:46.042 UTC [3992586] LOG:  00000: replicating changes for create_distributed_table_concurrently
2023-11-25 13:02:46.042 UTC [3992586] LOCATION:  NonBlockingShardSplit, shard_split.c:1541
2023-11-25 13:02:46.042 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:46.049 UTC [3992604] LOG:  00000: Initializing CDC decoder
2023-11-25 13:02:46.049 UTC [3992604] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 13:02:46.049 UTC [3992604] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_16_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_16_10_24"', binary 'true')
2023-11-25 13:02:46.049 UTC [3992605] LOG:  00000: Initializing CDC decoder
2023-11-25 13:02:46.049 UTC [3992605] LOCATION:  _PG_output_plugin_init, cdc_decoder.c:82
2023-11-25 13:02:46.049 UTC [3992605] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_34_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_34_10_24"', binary 'true')
2023-11-25 13:02:46.049 UTC [3992605] LOG:  00000: starting logical decoding for slot "citus_shard_split_slot_34_10_24"
2023-11-25 13:02:46.049 UTC [3992605] DETAIL:  Streaming transactions committing after 0/7C6AC78, reading WAL from 0/7C6AC40.
2023-11-25 13:02:46.049 UTC [3992605] LOCATION:  CreateDecodingContext, logical.c:569
2023-11-25 13:02:46.049 UTC [3992605] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_34_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_34_10_24"', binary 'true')
2023-11-25 13:02:46.049 UTC [3992604] LOG:  00000: starting logical decoding for slot "citus_shard_split_slot_16_10_24"
2023-11-25 13:02:46.049 UTC [3992604] DETAIL:  Streaming transactions committing after 0/7C6AC78, reading WAL from 0/7C6AC40.
2023-11-25 13:02:46.049 UTC [3992604] LOCATION:  CreateDecodingContext, logical.c:569
2023-11-25 13:02:46.049 UTC [3992604] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_16_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_16_10_24"', binary 'true')
2023-11-25 13:02:46.049 UTC [3992605] LOG:  00000: logical decoding found consistent point at 0/7C6AC40
2023-11-25 13:02:46.049 UTC [3992605] DETAIL:  There are no running transactions.
2023-11-25 13:02:46.049 UTC [3992605] LOCATION:  SnapBuildFindSnapshot, snapbuild.c:1366
2023-11-25 13:02:46.049 UTC [3992605] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_34_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_34_10_24"', binary 'true')
2023-11-25 13:02:46.049 UTC [3992604] LOG:  00000: logical decoding found consistent point at 0/7C6AC40
2023-11-25 13:02:46.049 UTC [3992604] DETAIL:  There are no running transactions.
2023-11-25 13:02:46.049 UTC [3992604] LOCATION:  SnapBuildFindSnapshot, snapbuild.c:1366
2023-11-25 13:02:46.049 UTC [3992604] STATEMENT:  START_REPLICATION SLOT "citus_shard_split_slot_16_10_24" LOGICAL 0/0 (proto_version '3', publication_names '"citus_shard_split_publication_16_10_24"', binary 'true')
2023-11-25 13:02:47.046 UTC [3992586] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:02:47.046 UTC [3992586] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:02:47.046 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.047 UTC [3992586] LOG:  00000: The LSN of the target subscriptions on node localhost:57637 have caught up with the source LSN 
2023-11-25 13:02:47.047 UTC [3992586] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:02:47.047 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.066 UTC [3992586] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:02:47.066 UTC [3992586] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:02:47.066 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.066 UTC [3992586] LOG:  00000: The LSN of the target subscriptions on node localhost:57637 have caught up with the source LSN 
2023-11-25 13:02:47.066 UTC [3992586] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:02:47.066 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.067 UTC [3992586] LOG:  00000: The LSN of the target subscriptions on node localhost:57638 have caught up with the source LSN 
2023-11-25 13:02:47.067 UTC [3992586] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:02:47.067 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.067 UTC [3992586] LOG:  00000: The LSN of the target subscriptions on node localhost:57637 have caught up with the source LSN 
2023-11-25 13:02:47.067 UTC [3992586] LOCATION:  WaitForGroupedLogicalRepTargetsToCatchUp, multi_logical_replication.c:1842
2023-11-25 13:02:47.067 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.067 UTC [3992586] LOG:  00000: marking deferred cleanup of source shard(s) for create_distributed_table_concurrently
2023-11-25 13:02:47.067 UTC [3992586] LOCATION:  NonBlockingShardSplit, shard_split.c:1560
2023-11-25 13:02:47.067 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.069 UTC [3992586] LOG:  00000: creating foreign key constraints (if any) for create_distributed_table_concurrently
2023-11-25 13:02:47.069 UTC [3992586] LOCATION:  NonBlockingShardSplit, shard_split.c:1610
2023-11-25 13:02:47.069 UTC [3992586] STATEMENT:  SELECT create_distributed_table_concurrently('color', 'color_id');
2023-11-25 13:02:47.195 UTC [3992619] ERROR:  0A000: cannot execute ADD COLUMN commands involving identity columns when metadata is synchronized to workers
2023-11-25 13:02:47.195 UTC [3992619] LOCATION:  ErrorIfUnsupportedAlterTableStmt, table.c:3182
2023-11-25 13:02:47.195 UTC [3992619] STATEMENT:  ALTER TABLE color ADD COLUMN color_id BIGINT GENERATED ALWAYS AS IDENTITY;
2023-11-25 13:02:47.196 UTC [3992619] ERROR:  XX000: Altering a distributed sequence is currently not supported.
2023-11-25 13:02:47.196 UTC [3992619] LOCATION:  PreprocessAlterSequenceStmt, sequence.c:464
2023-11-25 13:02:47.196 UTC [3992619] STATEMENT:  ALTER SEQUENCE color_color_id_seq RESTART WITH 1000;
2023-11-25 13:02:47.196 UTC [3992619] ERROR:  428C9: cannot insert a non-DEFAULT value into column "color_id"
2023-11-25 13:02:47.196 UTC [3992619] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 13:02:47.196 UTC [3992619] HINT:  Use OVERRIDING SYSTEM VALUE to override.
2023-11-25 13:02:47.196 UTC [3992619] LOCATION:  rewriteTargetListIU, rewriteHandler.c:884
2023-11-25 13:02:47.196 UTC [3992619] STATEMENT:  INSERT INTO color(color_id, color_name) VALUES (1, 'Red');
2023-11-25 13:02:47.196 UTC [3992619] ERROR:  428C9: cannot insert a non-DEFAULT value into column "color_id"
2023-11-25 13:02:47.196 UTC [3992619] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 13:02:47.196 UTC [3992619] HINT:  Use OVERRIDING SYSTEM VALUE to override.
2023-11-25 13:02:47.196 UTC [3992619] LOCATION:  rewriteTargetListIU, rewriteHandler.c:884
2023-11-25 13:02:47.196 UTC [3992619] STATEMENT:  INSERT INTO color(color_id, color_name) VALUES (NULL, 'Red');
2023-11-25 13:02:47.201 UTC [3992619] ERROR:  23505: duplicate key value violates unique constraint "color_color_id_key_12400000"
2023-11-25 13:02:47.201 UTC [3992619] DETAIL:  Key (color_id)=(1) already exists.
2023-11-25 13:02:47.201 UTC [3992619] CONTEXT:  while executing command on localhost:57637
2023-11-25 13:02:47.201 UTC [3992619] LOCATION:  ReportResultError, remote_commands.c:317
2023-11-25 13:02:47.201 UTC [3992619] STATEMENT:  INSERT INTO color(color_id, color_name) OVERRIDING SYSTEM VALUE VALUES (1, 'Red');
2023-11-25 13:02:47.202 UTC [3992619] ERROR:  428C9: column "color_id" can only be updated to DEFAULT
2023-11-25 13:02:47.202 UTC [3992619] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 13:02:47.202 UTC [3992619] LOCATION:  rewriteTargetListIU, rewriteHandler.c:950
2023-11-25 13:02:47.202 UTC [3992619] STATEMENT:  UPDATE color SET color_id = NULL;
2023-11-25 13:02:47.202 UTC [3992619] ERROR:  428C9: column "color_id" can only be updated to DEFAULT
2023-11-25 13:02:47.202 UTC [3992619] DETAIL:  Column "color_id" is an identity column defined as GENERATED ALWAYS.
2023-11-25 13:02:47.202 UTC [3992619] LOCATION:  rewriteTargetListIU, rewriteHandler.c:950
2023-11-25 13:02:47.202 UTC [3992619] STATEMENT:  UPDATE color SET color_id = 1;
2023-11-25 13:02:47.445 UTC [3992642] LOG:  00000: starting maintenance daemon on database 33274 user 10
2023-11-25 13:02:47.445 UTC [3992642] CONTEXT:  Citus maintenance daemon for database 33274 user 10
2023-11-25 13:02:47.445 UTC [3992642] LOCATION:  CitusMaintenanceDaemonMain, maintenanced.c:373
2023-11-25 13:02:47.567 UTC [3976582] LOG:  00000: checkpoint starting: immediate force wait
2023-11-25 13:02:47.567 UTC [3976582] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 13:02:47.589 UTC [3976582] LOG:  00000: checkpoint complete: wrote 2627 buffers (16.0%); 0 WAL file(s) added, 0 removed, 4 recycled; write=0.011 s, sync=0.001 s, total=0.023 s; sync files=0, longest=0.000 s, average=0.000 s; distance=61748 kB, estimate=61748 kB
2023-11-25 13:02:47.589 UTC [3976582] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 13:02:47.598 UTC [3976582] LOG:  00000: checkpoint starting: immediate force wait
2023-11-25 13:02:47.598 UTC [3976582] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 13:02:47.598 UTC [3976582] LOG:  00000: checkpoint complete: wrote 2 buffers (0.0%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.001 s; sync files=0, longest=0.000 s, average=0.000 s; distance=1 kB, estimate=55573 kB
2023-11-25 13:02:47.598 UTC [3976582] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 13:02:48.605 UTC [3976581] LOG:  00000: received fast shutdown request
2023-11-25 13:02:48.605 UTC [3976581] LOCATION:  pmdie, postmaster.c:2904
2023-11-25 13:02:48.605 UTC [3976581] LOG:  00000: aborting any active transactions
2023-11-25 13:02:48.605 UTC [3976581] LOCATION:  pmdie, postmaster.c:2922
2023-11-25 13:02:48.606 UTC [3976581] LOG:  00000: background worker "logical replication launcher" (PID 3976587) exited with exit code 1
2023-11-25 13:02:48.606 UTC [3976581] LOCATION:  LogChildExit, postmaster.c:3737
2023-11-25 13:02:48.607 UTC [3976582] LOG:  00000: shutting down
2023-11-25 13:02:48.607 UTC [3976582] LOCATION:  ShutdownXLOG, xlog.c:6039
2023-11-25 13:02:48.607 UTC [3976582] LOG:  00000: checkpoint starting: shutdown immediate
2023-11-25 13:02:48.607 UTC [3976582] LOCATION:  LogCheckpointStart, xlog.c:6089
2023-11-25 13:02:48.607 UTC [3976582] LOG:  00000: checkpoint complete: wrote 11 buffers (0.1%); 0 WAL file(s) added, 0 removed, 0 recycled; write=0.001 s, sync=0.001 s, total=0.001 s; sync files=0, longest=0.000 s, average=0.000 s; distance=32 kB, estimate=50019 kB
2023-11-25 13:02:48.607 UTC [3976582] LOCATION:  LogCheckpointEnd, xlog.c:6170
2023-11-25 13:02:48.619 UTC [3976581] LOG:  00000: database system is shut down
2023-11-25 13:02:48.619 UTC [3976581] LOCATION:  UnlinkLockFiles, miscinit.c:977
